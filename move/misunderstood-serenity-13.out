INFO:root:Using device cuda
wandb: Currently logged in as: mathildepapillon (use `wandb login --relogin` to force relogin)
TORCH
1.11.0
wandb: wandb version 0.12.15 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.14
wandb: Run data is saved locally in /home/papillon/move/move/wandb/run-20220421_233233-1w23tczv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-serenity-13
wandb: â­ï¸ View project at https://wandb.ai/bioshape-lab/move
wandb: ðŸš€ View run at https://wandb.ai/bioshape-lab/move/runs/1w23tczv
INFO:root:Config: {config}
INFO:root:Run server specific commands
INFO:root:Initialize model
INFO:root:Loading raw datasets:
INFO:root:- data/mariel_betternot_and_retrograde.npy of shape (9925, 53, 3)
INFO:root:- data/mariel_beyond.npy of shape (5803, 53, 3)
INFO:root:- data/mariel_chunli.npy of shape (3866, 53, 3)
INFO:root:- data/mariel_honey.npy of shape (5309, 53, 3)
INFO:root:- data/mariel_knownbetter.npy of shape (6649, 53, 3)
INFO:root:- data/mariel_penelope.npy of shape (6757, 53, 3)
INFO:root:Preprocessing: Load seq_data of shape (38181, 128, 159)
INFO:root:>> Train ds has shape (34363, 128, 159)
INFO:root:>> Valid ds has shape (1909, 128, 159)
INFO:root:>> Test ds has shape (1909, 128, 159)
INFO:root:Preprocessing: Convert into torch dataloader
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 0): Loss/seq after 00000 batchs: 4009.07568359375
INFO:root:Train (Epoch 0): Loss/seq after 00050 batchs: 6911.50439453125
INFO:root:Train (Epoch 0): Loss/seq after 00100 batchs: 5018.1630859375
INFO:root:Train (Epoch 0): Loss/seq after 00150 batchs: 3878.8916015625
INFO:root:Train (Epoch 0): Loss/seq after 00200 batchs: 3582.132568359375
INFO:root:Train (Epoch 0): Loss/seq after 00250 batchs: 3409.31591796875
INFO:root:Train (Epoch 0): Loss/seq after 00300 batchs: 3097.554443359375
INFO:root:Train (Epoch 0): Loss/seq after 00350 batchs: 2809.05615234375
INFO:root:Train (Epoch 0): Loss/seq after 00400 batchs: 2939.458740234375
INFO:root:Train (Epoch 0): Loss/seq after 00450 batchs: 2776.76123046875
INFO:root:Train (Epoch 0): Loss/seq after 00500 batchs: 2770.2705078125
INFO:root:Train (Epoch 0): Loss/seq after 00550 batchs: 2645.54345703125
INFO:root:Train (Epoch 0): Loss/seq after 00600 batchs: 2553.647705078125
INFO:root:Train (Epoch 0): Loss/seq after 00650 batchs: 2646.837158203125
INFO:root:Train (Epoch 0): Loss/seq after 00700 batchs: 2679.72216796875
INFO:root:Train (Epoch 0): Loss/seq after 00750 batchs: 2657.21044921875
INFO:root:Train (Epoch 0): Loss/seq after 00800 batchs: 2681.91845703125
INFO:root:Train (Epoch 0): Loss/seq after 00850 batchs: 2596.156005859375
INFO:root:Train (Epoch 0): Loss/seq after 00900 batchs: 2560.17041015625
INFO:root:Train (Epoch 0): Loss/seq after 00950 batchs: 2700.289794921875
INFO:root:Train (Epoch 0): Loss/seq after 01000 batchs: 2710.349365234375
INFO:root:Train (Epoch 0): Loss/seq after 01050 batchs: 2685.930908203125
INFO:root:Train (Epoch 0): Loss/seq after 01100 batchs: 2637.58251953125
INFO:root:Train (Epoch 0): Loss/seq after 01150 batchs: 2572.31689453125
INFO:root:Train (Epoch 0): Loss/seq after 01200 batchs: 2518.2412109375
INFO:root:Train (Epoch 0): Loss/seq after 01250 batchs: 2484.988525390625
INFO:root:Train (Epoch 0): Loss/seq after 01300 batchs: 2465.260986328125
INFO:root:Train (Epoch 0): Loss/seq after 01350 batchs: 2433.423583984375
INFO:root:Train (Epoch 0): Loss/seq after 01400 batchs: 2458.5654296875
INFO:root:Train (Epoch 0): Loss/seq after 01450 batchs: 2420.28125
INFO:root:Train (Epoch 0): Loss/seq after 01500 batchs: 2378.198974609375
INFO:root:Train (Epoch 0): Loss/seq after 01550 batchs: 2360.505126953125
INFO:root:Train (Epoch 0): Loss/seq after 01600 batchs: 2316.619873046875
INFO:root:Train (Epoch 0): Loss/seq after 01650 batchs: 2289.36328125
INFO:root:Train (Epoch 0): Loss/seq after 01700 batchs: 2255.527099609375
INFO:root:Train (Epoch 0): Loss/seq after 01750 batchs: 2219.903564453125
INFO:root:Train (Epoch 0): Loss/seq after 01800 batchs: 2183.30126953125
INFO:root:Train (Epoch 0): Loss/seq after 01850 batchs: 2147.623291015625
INFO:root:Train (Epoch 0): Loss/seq after 01900 batchs: 2126.105712890625
INFO:root:Train (Epoch 0): Loss/seq after 01950 batchs: 2101.340576171875
INFO:root:Train (Epoch 0): Loss/seq after 02000 batchs: 2073.102294921875
INFO:root:Train (Epoch 0): Loss/seq after 02050 batchs: 2047.1204833984375
INFO:root:Train (Epoch 0): Loss/seq after 02100 batchs: 2018.720703125
INFO:root:Train (Epoch 0): Loss/seq after 02150 batchs: 1992.3095703125
INFO:root:Train (Epoch 0): Loss/seq after 02200 batchs: 1965.21533203125
INFO:root:Train (Epoch 0): Loss/seq after 02250 batchs: 1961.692626953125
INFO:root:Train (Epoch 0): Loss/seq after 02300 batchs: 1960.3580322265625
INFO:root:Train (Epoch 0): Loss/seq after 02350 batchs: 1939.43701171875
INFO:root:Train (Epoch 0): Loss/seq after 02400 batchs: 1923.0262451171875
INFO:root:Train (Epoch 0): Loss/seq after 02450 batchs: 1898.759033203125
INFO:root:Train (Epoch 0): Loss/seq after 02500 batchs: 1868.8814697265625
INFO:root:Train (Epoch 0): Loss/seq after 02550 batchs: 1850.953857421875
INFO:root:Train (Epoch 0): Loss/seq after 02600 batchs: 1841.3143310546875
INFO:root:Train (Epoch 0): Loss/seq after 02650 batchs: 1827.8671875
INFO:root:Train (Epoch 0): Loss/seq after 02700 batchs: 1819.494873046875
INFO:root:Train (Epoch 0): Loss/seq after 02750 batchs: 1842.5462646484375
INFO:root:Train (Epoch 0): Loss/seq after 02800 batchs: 1855.307861328125
INFO:root:Train (Epoch 0): Loss/seq after 02850 batchs: 1852.887451171875
INFO:root:Train (Epoch 0): Loss/seq after 02900 batchs: 1847.2257080078125
INFO:root:Train (Epoch 0): Loss/seq after 02950 batchs: 1832.4664306640625
INFO:root:Train (Epoch 0): Loss/seq after 03000 batchs: 1820.7523193359375
INFO:root:Train (Epoch 0): Loss/seq after 03050 batchs: 1814.2398681640625
INFO:root:Train (Epoch 0): Loss/seq after 03100 batchs: 1828.316650390625
INFO:root:Train (Epoch 0): Loss/seq after 03150 batchs: 1847.6466064453125
INFO:root:Train (Epoch 0): Loss/seq after 03200 batchs: 1854.630615234375
INFO:root:Train (Epoch 0): Loss/seq after 03250 batchs: 1861.042724609375
INFO:root:Train (Epoch 0): Loss/seq after 03300 batchs: 1857.44580078125
INFO:root:Train (Epoch 0): Loss/seq after 03350 batchs: 1851.3316650390625
INFO:root:Train (Epoch 0): Loss/seq after 03400 batchs: 1834.4393310546875
INFO:root:Train (Epoch 0): Loss/seq after 03450 batchs: 1822.4599609375
INFO:root:Train (Epoch 0): Loss/seq after 03500 batchs: 1818.8582763671875
INFO:root:Train (Epoch 0): Loss/seq after 03550 batchs: 1808.6724853515625
INFO:root:Train (Epoch 0): Loss/seq after 03600 batchs: 1808.5992431640625
INFO:root:Train (Epoch 0): Loss/seq after 03650 batchs: 1798.7301025390625
INFO:root:Train (Epoch 0): Loss/seq after 03700 batchs: 1791.9365234375
INFO:root:Train (Epoch 0): Loss/seq after 03750 batchs: 1784.913330078125
INFO:root:Train (Epoch 0): Loss/seq after 03800 batchs: 1771.30712890625
INFO:root:Train (Epoch 0): Loss/seq after 03850 batchs: 1760.702880859375
INFO:root:Train (Epoch 0): Loss/seq after 03900 batchs: 1767.7974853515625
INFO:root:Train (Epoch 0): Loss/seq after 03950 batchs: 1773.170654296875
INFO:root:Train (Epoch 0): Loss/seq after 04000 batchs: 1758.951416015625
INFO:root:Train (Epoch 0): Loss/seq after 04050 batchs: 1744.6409912109375
INFO:root:Train (Epoch 0): Loss/seq after 04100 batchs: 1735.8896484375
INFO:root:Train (Epoch 0): Loss/seq after 04150 batchs: 1725.1549072265625
INFO:root:Train (Epoch 0): Loss/seq after 04200 batchs: 1716.3468017578125
INFO:root:Train (Epoch 0): Loss/seq after 04250 batchs: 1706.9075927734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 0): Loss/seq after 00000 batches: 1034.7528076171875
INFO:root:# Valid (Epoch 0): Loss/seq after 00050 batches: 1177.4775390625
INFO:root:# Valid (Epoch 0): Loss/seq after 00100 batches: 1575.6766357421875
INFO:root:# Valid (Epoch 0): Loss/seq after 00150 batches: 1307.15185546875
INFO:root:# Valid (Epoch 0): Loss/seq after 00200 batches: 1179.7369384765625
INFO:root:Artifacts: Make stick videos for epoch 0
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_0_on_20220421_233719.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_0_index_1076_on_20220421_233719.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 1): Loss/seq after 00000 batchs: 2424.092529296875
INFO:root:Train (Epoch 1): Loss/seq after 00050 batchs: 2049.755859375
INFO:root:Train (Epoch 1): Loss/seq after 00100 batchs: 1960.450439453125
INFO:root:Train (Epoch 1): Loss/seq after 00150 batchs: 1723.0574951171875
INFO:root:Train (Epoch 1): Loss/seq after 00200 batchs: 1875.7625732421875
INFO:root:Train (Epoch 1): Loss/seq after 00250 batchs: 2012.251220703125
INFO:root:Train (Epoch 1): Loss/seq after 00300 batchs: 1902.897216796875
INFO:root:Train (Epoch 1): Loss/seq after 00350 batchs: 1769.298583984375
INFO:root:Train (Epoch 1): Loss/seq after 00400 batchs: 1856.0782470703125
INFO:root:Train (Epoch 1): Loss/seq after 00450 batchs: 1754.602294921875
INFO:root:Train (Epoch 1): Loss/seq after 00500 batchs: 1812.2991943359375
INFO:root:Train (Epoch 1): Loss/seq after 00550 batchs: 1737.443115234375
INFO:root:Train (Epoch 1): Loss/seq after 00600 batchs: 1690.430419921875
INFO:root:Train (Epoch 1): Loss/seq after 00650 batchs: 1740.52685546875
INFO:root:Train (Epoch 1): Loss/seq after 00700 batchs: 1810.1968994140625
INFO:root:Train (Epoch 1): Loss/seq after 00750 batchs: 1845.53271484375
INFO:root:Train (Epoch 1): Loss/seq after 00800 batchs: 1820.2000732421875
INFO:root:Train (Epoch 1): Loss/seq after 00850 batchs: 1772.2713623046875
INFO:root:Train (Epoch 1): Loss/seq after 00900 batchs: 1773.7705078125
INFO:root:Train (Epoch 1): Loss/seq after 00950 batchs: 1877.7562255859375
INFO:root:Train (Epoch 1): Loss/seq after 01000 batchs: 1880.230712890625
INFO:root:Train (Epoch 1): Loss/seq after 01050 batchs: 1862.201416015625
INFO:root:Train (Epoch 1): Loss/seq after 01100 batchs: 1859.16796875
INFO:root:Train (Epoch 1): Loss/seq after 01150 batchs: 1826.120849609375
INFO:root:Train (Epoch 1): Loss/seq after 01200 batchs: 1800.378173828125
INFO:root:Train (Epoch 1): Loss/seq after 01250 batchs: 1785.599365234375
INFO:root:Train (Epoch 1): Loss/seq after 01300 batchs: 1788.5452880859375
INFO:root:Train (Epoch 1): Loss/seq after 01350 batchs: 1780.650146484375
INFO:root:Train (Epoch 1): Loss/seq after 01400 batchs: 1828.732177734375
INFO:root:Train (Epoch 1): Loss/seq after 01450 batchs: 1806.9066162109375
INFO:root:Train (Epoch 1): Loss/seq after 01500 batchs: 1783.197021484375
INFO:root:Train (Epoch 1): Loss/seq after 01550 batchs: 1779.853271484375
INFO:root:Train (Epoch 1): Loss/seq after 01600 batchs: 1751.548828125
INFO:root:Train (Epoch 1): Loss/seq after 01650 batchs: 1741.4241943359375
INFO:root:Train (Epoch 1): Loss/seq after 01700 batchs: 1722.04150390625
INFO:root:Train (Epoch 1): Loss/seq after 01750 batchs: 1700.1011962890625
INFO:root:Train (Epoch 1): Loss/seq after 01800 batchs: 1676.61328125
INFO:root:Train (Epoch 1): Loss/seq after 01850 batchs: 1653.3726806640625
INFO:root:Train (Epoch 1): Loss/seq after 01900 batchs: 1643.641357421875
INFO:root:Train (Epoch 1): Loss/seq after 01950 batchs: 1630.35791015625
INFO:root:Train (Epoch 1): Loss/seq after 02000 batchs: 1612.8665771484375
INFO:root:Train (Epoch 1): Loss/seq after 02050 batchs: 1597.264404296875
INFO:root:Train (Epoch 1): Loss/seq after 02100 batchs: 1578.6561279296875
INFO:root:Train (Epoch 1): Loss/seq after 02150 batchs: 1561.6951904296875
INFO:root:Train (Epoch 1): Loss/seq after 02200 batchs: 1543.652099609375
INFO:root:Train (Epoch 1): Loss/seq after 02250 batchs: 1547.8223876953125
INFO:root:Train (Epoch 1): Loss/seq after 02300 batchs: 1548.3975830078125
INFO:root:Train (Epoch 1): Loss/seq after 02350 batchs: 1534.5699462890625
INFO:root:Train (Epoch 1): Loss/seq after 02400 batchs: 1525.786376953125
INFO:root:Train (Epoch 1): Loss/seq after 02450 batchs: 1509.000244140625
INFO:root:Train (Epoch 1): Loss/seq after 02500 batchs: 1486.314453125
INFO:root:Train (Epoch 1): Loss/seq after 02550 batchs: 1472.338623046875
INFO:root:Train (Epoch 1): Loss/seq after 02600 batchs: 1467.071533203125
INFO:root:Train (Epoch 1): Loss/seq after 02650 batchs: 1458.4124755859375
INFO:root:Train (Epoch 1): Loss/seq after 02700 batchs: 1452.4757080078125
INFO:root:Train (Epoch 1): Loss/seq after 02750 batchs: 1481.394775390625
INFO:root:Train (Epoch 1): Loss/seq after 02800 batchs: 1493.1431884765625
INFO:root:Train (Epoch 1): Loss/seq after 02850 batchs: 1491.57177734375
INFO:root:Train (Epoch 1): Loss/seq after 02900 batchs: 1489.0068359375
INFO:root:Train (Epoch 1): Loss/seq after 02950 batchs: 1478.72998046875
INFO:root:Train (Epoch 1): Loss/seq after 03000 batchs: 1472.444091796875
INFO:root:Train (Epoch 1): Loss/seq after 03050 batchs: 1471.1640625
INFO:root:Train (Epoch 1): Loss/seq after 03100 batchs: 1491.30126953125
INFO:root:Train (Epoch 1): Loss/seq after 03150 batchs: 1511.2783203125
INFO:root:Train (Epoch 1): Loss/seq after 03200 batchs: 1523.0714111328125
INFO:root:Train (Epoch 1): Loss/seq after 03250 batchs: 1534.1700439453125
INFO:root:Train (Epoch 1): Loss/seq after 03300 batchs: 1534.945068359375
INFO:root:Train (Epoch 1): Loss/seq after 03350 batchs: 1533.8621826171875
INFO:root:Train (Epoch 1): Loss/seq after 03400 batchs: 1521.1412353515625
INFO:root:Train (Epoch 1): Loss/seq after 03450 batchs: 1513.406494140625
INFO:root:Train (Epoch 1): Loss/seq after 03500 batchs: 1514.291748046875
INFO:root:Train (Epoch 1): Loss/seq after 03550 batchs: 1507.8023681640625
INFO:root:Train (Epoch 1): Loss/seq after 03600 batchs: 1511.1915283203125
INFO:root:Train (Epoch 1): Loss/seq after 03650 batchs: 1504.5919189453125
INFO:root:Train (Epoch 1): Loss/seq after 03700 batchs: 1501.67822265625
INFO:root:Train (Epoch 1): Loss/seq after 03750 batchs: 1498.2403564453125
INFO:root:Train (Epoch 1): Loss/seq after 03800 batchs: 1488.1641845703125
INFO:root:Train (Epoch 1): Loss/seq after 03850 batchs: 1480.94384765625
INFO:root:Train (Epoch 1): Loss/seq after 03900 batchs: 1489.26806640625
INFO:root:Train (Epoch 1): Loss/seq after 03950 batchs: 1496.65283203125
INFO:root:Train (Epoch 1): Loss/seq after 04000 batchs: 1484.6265869140625
INFO:root:Train (Epoch 1): Loss/seq after 04050 batchs: 1473.4578857421875
INFO:root:Train (Epoch 1): Loss/seq after 04100 batchs: 1467.697998046875
INFO:root:Train (Epoch 1): Loss/seq after 04150 batchs: 1459.90185546875
INFO:root:Train (Epoch 1): Loss/seq after 04200 batchs: 1453.8409423828125
INFO:root:Train (Epoch 1): Loss/seq after 04250 batchs: 1447.2308349609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 1): Loss/seq after 00000 batches: 1010.371826171875
INFO:root:# Valid (Epoch 1): Loss/seq after 00050 batches: 1160.763671875
INFO:root:# Valid (Epoch 1): Loss/seq after 00100 batches: 1549.9168701171875
INFO:root:# Valid (Epoch 1): Loss/seq after 00150 batches: 1280.2469482421875
INFO:root:# Valid (Epoch 1): Loss/seq after 00200 batches: 1152.720947265625
INFO:root:Artifacts: Make stick videos for epoch 1
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_1_on_20220421_234210.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_1_index_1200_on_20220421_234210.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 2): Loss/seq after 00000 batchs: 2419.2470703125
INFO:root:Train (Epoch 2): Loss/seq after 00050 batchs: 2010.228515625
INFO:root:Train (Epoch 2): Loss/seq after 00100 batchs: 1887.858154296875
INFO:root:Train (Epoch 2): Loss/seq after 00150 batchs: 1673.097412109375
INFO:root:Train (Epoch 2): Loss/seq after 00200 batchs: 1780.199951171875
INFO:root:Train (Epoch 2): Loss/seq after 00250 batchs: 1932.617919921875
INFO:root:Train (Epoch 2): Loss/seq after 00300 batchs: 1833.1153564453125
INFO:root:Train (Epoch 2): Loss/seq after 00350 batchs: 1699.87744140625
INFO:root:Train (Epoch 2): Loss/seq after 00400 batchs: 1774.0189208984375
INFO:root:Train (Epoch 2): Loss/seq after 00450 batchs: 1678.476318359375
INFO:root:Train (Epoch 2): Loss/seq after 00500 batchs: 1733.4014892578125
INFO:root:Train (Epoch 2): Loss/seq after 00550 batchs: 1661.8546142578125
INFO:root:Train (Epoch 2): Loss/seq after 00600 batchs: 1622.1851806640625
INFO:root:Train (Epoch 2): Loss/seq after 00650 batchs: 1680.7532958984375
INFO:root:Train (Epoch 2): Loss/seq after 00700 batchs: 1753.9044189453125
INFO:root:Train (Epoch 2): Loss/seq after 00750 batchs: 1787.739501953125
INFO:root:Train (Epoch 2): Loss/seq after 00800 batchs: 1764.3072509765625
INFO:root:Train (Epoch 2): Loss/seq after 00850 batchs: 1718.707275390625
INFO:root:Train (Epoch 2): Loss/seq after 00900 batchs: 1714.427490234375
INFO:root:Train (Epoch 2): Loss/seq after 00950 batchs: 1811.1533203125
INFO:root:Train (Epoch 2): Loss/seq after 01000 batchs: 1810.0247802734375
INFO:root:Train (Epoch 2): Loss/seq after 01050 batchs: 1780.3240966796875
INFO:root:Train (Epoch 2): Loss/seq after 01100 batchs: 1763.6102294921875
INFO:root:Train (Epoch 2): Loss/seq after 01150 batchs: 1733.7171630859375
INFO:root:Train (Epoch 2): Loss/seq after 01200 batchs: 1708.246337890625
INFO:root:Train (Epoch 2): Loss/seq after 01250 batchs: 1697.1966552734375
INFO:root:Train (Epoch 2): Loss/seq after 01300 batchs: 1702.833984375
INFO:root:Train (Epoch 2): Loss/seq after 01350 batchs: 1696.84228515625
INFO:root:Train (Epoch 2): Loss/seq after 01400 batchs: 1745.63037109375
INFO:root:Train (Epoch 2): Loss/seq after 01450 batchs: 1724.3944091796875
INFO:root:Train (Epoch 2): Loss/seq after 01500 batchs: 1703.06884765625
INFO:root:Train (Epoch 2): Loss/seq after 01550 batchs: 1699.7828369140625
INFO:root:Train (Epoch 2): Loss/seq after 01600 batchs: 1673.1552734375
INFO:root:Train (Epoch 2): Loss/seq after 01650 batchs: 1661.6971435546875
INFO:root:Train (Epoch 2): Loss/seq after 01700 batchs: 1644.4322509765625
INFO:root:Train (Epoch 2): Loss/seq after 01750 batchs: 1624.3123779296875
INFO:root:Train (Epoch 2): Loss/seq after 01800 batchs: 1602.5802001953125
INFO:root:Train (Epoch 2): Loss/seq after 01850 batchs: 1581.00244140625
INFO:root:Train (Epoch 2): Loss/seq after 01900 batchs: 1572.822509765625
INFO:root:Train (Epoch 2): Loss/seq after 01950 batchs: 1561.042724609375
INFO:root:Train (Epoch 2): Loss/seq after 02000 batchs: 1544.967529296875
INFO:root:Train (Epoch 2): Loss/seq after 02050 batchs: 1530.771728515625
INFO:root:Train (Epoch 2): Loss/seq after 02100 batchs: 1513.5025634765625
INFO:root:Train (Epoch 2): Loss/seq after 02150 batchs: 1497.8466796875
INFO:root:Train (Epoch 2): Loss/seq after 02200 batchs: 1481.032470703125
INFO:root:Train (Epoch 2): Loss/seq after 02250 batchs: 1483.31982421875
INFO:root:Train (Epoch 2): Loss/seq after 02300 batchs: 1486.3909912109375
INFO:root:Train (Epoch 2): Loss/seq after 02350 batchs: 1473.942138671875
INFO:root:Train (Epoch 2): Loss/seq after 02400 batchs: 1466.1937255859375
INFO:root:Train (Epoch 2): Loss/seq after 02450 batchs: 1450.4744873046875
INFO:root:Train (Epoch 2): Loss/seq after 02500 batchs: 1428.796875
INFO:root:Train (Epoch 2): Loss/seq after 02550 batchs: 1417.078125
INFO:root:Train (Epoch 2): Loss/seq after 02600 batchs: 1414.3287353515625
INFO:root:Train (Epoch 2): Loss/seq after 02650 batchs: 1408.314697265625
INFO:root:Train (Epoch 2): Loss/seq after 02700 batchs: 1406.0709228515625
INFO:root:Train (Epoch 2): Loss/seq after 02750 batchs: 1434.9371337890625
INFO:root:Train (Epoch 2): Loss/seq after 02800 batchs: 1443.2144775390625
INFO:root:Train (Epoch 2): Loss/seq after 02850 batchs: 1439.6580810546875
INFO:root:Train (Epoch 2): Loss/seq after 02900 batchs: 1436.2493896484375
INFO:root:Train (Epoch 2): Loss/seq after 02950 batchs: 1426.002685546875
INFO:root:Train (Epoch 2): Loss/seq after 03000 batchs: 1420.4290771484375
INFO:root:Train (Epoch 2): Loss/seq after 03050 batchs: 1419.889892578125
INFO:root:Train (Epoch 2): Loss/seq after 03100 batchs: 1437.3583984375
INFO:root:Train (Epoch 2): Loss/seq after 03150 batchs: 1457.2139892578125
INFO:root:Train (Epoch 2): Loss/seq after 03200 batchs: 1469.4583740234375
INFO:root:Train (Epoch 2): Loss/seq after 03250 batchs: 1481.3526611328125
INFO:root:Train (Epoch 2): Loss/seq after 03300 batchs: 1479.5205078125
INFO:root:Train (Epoch 2): Loss/seq after 03350 batchs: 1477.5146484375
INFO:root:Train (Epoch 2): Loss/seq after 03400 batchs: 1465.486328125
INFO:root:Train (Epoch 2): Loss/seq after 03450 batchs: 1458.7967529296875
INFO:root:Train (Epoch 2): Loss/seq after 03500 batchs: 1459.2918701171875
INFO:root:Train (Epoch 2): Loss/seq after 03550 batchs: 1453.3675537109375
INFO:root:Train (Epoch 2): Loss/seq after 03600 batchs: 1457.6865234375
INFO:root:Train (Epoch 2): Loss/seq after 03650 batchs: 1451.86572265625
INFO:root:Train (Epoch 2): Loss/seq after 03700 batchs: 1449.399169921875
INFO:root:Train (Epoch 2): Loss/seq after 03750 batchs: 1446.57470703125
INFO:root:Train (Epoch 2): Loss/seq after 03800 batchs: 1437.10107421875
INFO:root:Train (Epoch 2): Loss/seq after 03850 batchs: 1430.4613037109375
INFO:root:Train (Epoch 2): Loss/seq after 03900 batchs: 1437.871826171875
INFO:root:Train (Epoch 2): Loss/seq after 03950 batchs: 1445.965576171875
INFO:root:Train (Epoch 2): Loss/seq after 04000 batchs: 1434.41943359375
INFO:root:Train (Epoch 2): Loss/seq after 04050 batchs: 1423.7901611328125
INFO:root:Train (Epoch 2): Loss/seq after 04100 batchs: 1418.5078125
INFO:root:Train (Epoch 2): Loss/seq after 04150 batchs: 1411.216064453125
INFO:root:Train (Epoch 2): Loss/seq after 04200 batchs: 1405.0704345703125
INFO:root:Train (Epoch 2): Loss/seq after 04250 batchs: 1398.905029296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 2): Loss/seq after 00000 batches: 989.9805908203125
INFO:root:# Valid (Epoch 2): Loss/seq after 00050 batches: 1144.09375
INFO:root:# Valid (Epoch 2): Loss/seq after 00100 batches: 1504.908447265625
INFO:root:# Valid (Epoch 2): Loss/seq after 00150 batches: 1250.29345703125
INFO:root:# Valid (Epoch 2): Loss/seq after 00200 batches: 1130.7415771484375
INFO:root:Artifacts: Make stick videos for epoch 2
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_2_on_20220421_234700.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_2_index_171_on_20220421_234700.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 3): Loss/seq after 00000 batchs: 3340.219970703125
INFO:root:Train (Epoch 3): Loss/seq after 00050 batchs: 1943.6239013671875
INFO:root:Train (Epoch 3): Loss/seq after 00100 batchs: 1923.7794189453125
INFO:root:Train (Epoch 3): Loss/seq after 00150 batchs: 1689.5430908203125
INFO:root:Train (Epoch 3): Loss/seq after 00200 batchs: 1787.8297119140625
INFO:root:Train (Epoch 3): Loss/seq after 00250 batchs: 1888.6243896484375
INFO:root:Train (Epoch 3): Loss/seq after 00300 batchs: 1767.9189453125
INFO:root:Train (Epoch 3): Loss/seq after 00350 batchs: 1643.175537109375
INFO:root:Train (Epoch 3): Loss/seq after 00400 batchs: 1701.998291015625
INFO:root:Train (Epoch 3): Loss/seq after 00450 batchs: 1611.5101318359375
INFO:root:Train (Epoch 3): Loss/seq after 00500 batchs: 1663.0213623046875
INFO:root:Train (Epoch 3): Loss/seq after 00550 batchs: 1594.4996337890625
INFO:root:Train (Epoch 3): Loss/seq after 00600 batchs: 1554.574462890625
INFO:root:Train (Epoch 3): Loss/seq after 00650 batchs: 1613.8525390625
INFO:root:Train (Epoch 3): Loss/seq after 00700 batchs: 1691.309814453125
INFO:root:Train (Epoch 3): Loss/seq after 00750 batchs: 1729.3922119140625
INFO:root:Train (Epoch 3): Loss/seq after 00800 batchs: 1709.150146484375
INFO:root:Train (Epoch 3): Loss/seq after 00850 batchs: 1666.479248046875
INFO:root:Train (Epoch 3): Loss/seq after 00900 batchs: 1671.01904296875
INFO:root:Train (Epoch 3): Loss/seq after 00950 batchs: 1763.468017578125
INFO:root:Train (Epoch 3): Loss/seq after 01000 batchs: 1761.060791015625
INFO:root:Train (Epoch 3): Loss/seq after 01050 batchs: 1733.4986572265625
INFO:root:Train (Epoch 3): Loss/seq after 01100 batchs: 1714.6092529296875
INFO:root:Train (Epoch 3): Loss/seq after 01150 batchs: 1684.6331787109375
INFO:root:Train (Epoch 3): Loss/seq after 01200 batchs: 1664.309814453125
INFO:root:Train (Epoch 3): Loss/seq after 01250 batchs: 1653.5257568359375
INFO:root:Train (Epoch 3): Loss/seq after 01300 batchs: 1661.2000732421875
INFO:root:Train (Epoch 3): Loss/seq after 01350 batchs: 1657.3436279296875
INFO:root:Train (Epoch 3): Loss/seq after 01400 batchs: 1706.6197509765625
INFO:root:Train (Epoch 3): Loss/seq after 01450 batchs: 1687.2977294921875
INFO:root:Train (Epoch 3): Loss/seq after 01500 batchs: 1667.4180908203125
INFO:root:Train (Epoch 3): Loss/seq after 01550 batchs: 1664.8974609375
INFO:root:Train (Epoch 3): Loss/seq after 01600 batchs: 1639.2655029296875
INFO:root:Train (Epoch 3): Loss/seq after 01650 batchs: 1627.7457275390625
INFO:root:Train (Epoch 3): Loss/seq after 01700 batchs: 1611.3013916015625
INFO:root:Train (Epoch 3): Loss/seq after 01750 batchs: 1591.941650390625
INFO:root:Train (Epoch 3): Loss/seq after 01800 batchs: 1570.9608154296875
INFO:root:Train (Epoch 3): Loss/seq after 01850 batchs: 1550.084228515625
INFO:root:Train (Epoch 3): Loss/seq after 01900 batchs: 1542.6705322265625
INFO:root:Train (Epoch 3): Loss/seq after 01950 batchs: 1531.66748046875
INFO:root:Train (Epoch 3): Loss/seq after 02000 batchs: 1516.2005615234375
INFO:root:Train (Epoch 3): Loss/seq after 02050 batchs: 1502.6279296875
INFO:root:Train (Epoch 3): Loss/seq after 02100 batchs: 1485.8829345703125
INFO:root:Train (Epoch 3): Loss/seq after 02150 batchs: 1470.775146484375
INFO:root:Train (Epoch 3): Loss/seq after 02200 batchs: 1454.4986572265625
INFO:root:Train (Epoch 3): Loss/seq after 02250 batchs: 1457.0880126953125
INFO:root:Train (Epoch 3): Loss/seq after 02300 batchs: 1459.6939697265625
INFO:root:Train (Epoch 3): Loss/seq after 02350 batchs: 1447.589111328125
INFO:root:Train (Epoch 3): Loss/seq after 02400 batchs: 1440.293212890625
INFO:root:Train (Epoch 3): Loss/seq after 02450 batchs: 1424.765380859375
INFO:root:Train (Epoch 3): Loss/seq after 02500 batchs: 1403.5634765625
INFO:root:Train (Epoch 3): Loss/seq after 02550 batchs: 1392.520263671875
INFO:root:Train (Epoch 3): Loss/seq after 02600 batchs: 1389.513671875
INFO:root:Train (Epoch 3): Loss/seq after 02650 batchs: 1382.8621826171875
INFO:root:Train (Epoch 3): Loss/seq after 02700 batchs: 1379.890380859375
INFO:root:Train (Epoch 3): Loss/seq after 02750 batchs: 1408.4561767578125
INFO:root:Train (Epoch 3): Loss/seq after 02800 batchs: 1418.93505859375
INFO:root:Train (Epoch 3): Loss/seq after 02850 batchs: 1415.275146484375
INFO:root:Train (Epoch 3): Loss/seq after 02900 batchs: 1412.24462890625
INFO:root:Train (Epoch 3): Loss/seq after 02950 batchs: 1402.4674072265625
INFO:root:Train (Epoch 3): Loss/seq after 03000 batchs: 1397.25341796875
INFO:root:Train (Epoch 3): Loss/seq after 03050 batchs: 1397.050537109375
INFO:root:Train (Epoch 3): Loss/seq after 03100 batchs: 1416.0811767578125
INFO:root:Train (Epoch 3): Loss/seq after 03150 batchs: 1435.73486328125
INFO:root:Train (Epoch 3): Loss/seq after 03200 batchs: 1447.6478271484375
INFO:root:Train (Epoch 3): Loss/seq after 03250 batchs: 1456.78515625
INFO:root:Train (Epoch 3): Loss/seq after 03300 batchs: 1455.951416015625
INFO:root:Train (Epoch 3): Loss/seq after 03350 batchs: 1453.7764892578125
INFO:root:Train (Epoch 3): Loss/seq after 03400 batchs: 1442.0716552734375
INFO:root:Train (Epoch 3): Loss/seq after 03450 batchs: 1433.6590576171875
INFO:root:Train (Epoch 3): Loss/seq after 03500 batchs: 1432.1513671875
INFO:root:Train (Epoch 3): Loss/seq after 03550 batchs: 1426.3182373046875
INFO:root:Train (Epoch 3): Loss/seq after 03600 batchs: 1430.7666015625
INFO:root:Train (Epoch 3): Loss/seq after 03650 batchs: 1425.774658203125
INFO:root:Train (Epoch 3): Loss/seq after 03700 batchs: 1423.57373046875
INFO:root:Train (Epoch 3): Loss/seq after 03750 batchs: 1421.056884765625
INFO:root:Train (Epoch 3): Loss/seq after 03800 batchs: 1411.86279296875
INFO:root:Train (Epoch 3): Loss/seq after 03850 batchs: 1405.4984130859375
INFO:root:Train (Epoch 3): Loss/seq after 03900 batchs: 1415.6944580078125
INFO:root:Train (Epoch 3): Loss/seq after 03950 batchs: 1423.5648193359375
INFO:root:Train (Epoch 3): Loss/seq after 04000 batchs: 1413.100341796875
INFO:root:Train (Epoch 3): Loss/seq after 04050 batchs: 1402.7550048828125
INFO:root:Train (Epoch 3): Loss/seq after 04100 batchs: 1397.894287109375
INFO:root:Train (Epoch 3): Loss/seq after 04150 batchs: 1390.793701171875
INFO:root:Train (Epoch 3): Loss/seq after 04200 batchs: 1385.0704345703125
INFO:root:Train (Epoch 3): Loss/seq after 04250 batchs: 1379.1512451171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 3): Loss/seq after 00000 batches: 1012.0648803710938
INFO:root:# Valid (Epoch 3): Loss/seq after 00050 batches: 1154.95458984375
INFO:root:# Valid (Epoch 3): Loss/seq after 00100 batches: 1508.361572265625
INFO:root:# Valid (Epoch 3): Loss/seq after 00150 batches: 1236.4234619140625
INFO:root:# Valid (Epoch 3): Loss/seq after 00200 batches: 1114.378662109375
INFO:root:Artifacts: Make stick videos for epoch 3
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_3_on_20220421_235202.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_3_index_121_on_20220421_235202.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 4): Loss/seq after 00000 batchs: 2567.35009765625
INFO:root:Train (Epoch 4): Loss/seq after 00050 batchs: 1833.960693359375
INFO:root:Train (Epoch 4): Loss/seq after 00100 batchs: 1923.711181640625
INFO:root:Train (Epoch 4): Loss/seq after 00150 batchs: 1698.126220703125
INFO:root:Train (Epoch 4): Loss/seq after 00200 batchs: 1862.3441162109375
INFO:root:Train (Epoch 4): Loss/seq after 00250 batchs: 1966.499267578125
INFO:root:Train (Epoch 4): Loss/seq after 00300 batchs: 1841.0465087890625
INFO:root:Train (Epoch 4): Loss/seq after 00350 batchs: 1705.315185546875
INFO:root:Train (Epoch 4): Loss/seq after 00400 batchs: 1797.724853515625
INFO:root:Train (Epoch 4): Loss/seq after 00450 batchs: 1697.851806640625
INFO:root:Train (Epoch 4): Loss/seq after 00500 batchs: 1769.1402587890625
INFO:root:Train (Epoch 4): Loss/seq after 00550 batchs: 1694.910888671875
INFO:root:Train (Epoch 4): Loss/seq after 00600 batchs: 1662.9244384765625
INFO:root:Train (Epoch 4): Loss/seq after 00650 batchs: 1709.8280029296875
INFO:root:Train (Epoch 4): Loss/seq after 00700 batchs: 1760.34326171875
INFO:root:Train (Epoch 4): Loss/seq after 00750 batchs: 1786.800537109375
INFO:root:Train (Epoch 4): Loss/seq after 00800 batchs: 1768.031005859375
INFO:root:Train (Epoch 4): Loss/seq after 00850 batchs: 1721.037841796875
INFO:root:Train (Epoch 4): Loss/seq after 00900 batchs: 1732.6597900390625
INFO:root:Train (Epoch 4): Loss/seq after 00950 batchs: 1831.072509765625
INFO:root:Train (Epoch 4): Loss/seq after 01000 batchs: 1825.2879638671875
INFO:root:Train (Epoch 4): Loss/seq after 01050 batchs: 1803.466796875
INFO:root:Train (Epoch 4): Loss/seq after 01100 batchs: 1794.3673095703125
INFO:root:Train (Epoch 4): Loss/seq after 01150 batchs: 1762.3668212890625
INFO:root:Train (Epoch 4): Loss/seq after 01200 batchs: 1737.7373046875
INFO:root:Train (Epoch 4): Loss/seq after 01250 batchs: 1724.355712890625
INFO:root:Train (Epoch 4): Loss/seq after 01300 batchs: 1724.8209228515625
INFO:root:Train (Epoch 4): Loss/seq after 01350 batchs: 1713.5313720703125
INFO:root:Train (Epoch 4): Loss/seq after 01400 batchs: 1757.046875
INFO:root:Train (Epoch 4): Loss/seq after 01450 batchs: 1738.5548095703125
INFO:root:Train (Epoch 4): Loss/seq after 01500 batchs: 1716.3463134765625
INFO:root:Train (Epoch 4): Loss/seq after 01550 batchs: 1716.2369384765625
INFO:root:Train (Epoch 4): Loss/seq after 01600 batchs: 1688.5321044921875
INFO:root:Train (Epoch 4): Loss/seq after 01650 batchs: 1677.0606689453125
INFO:root:Train (Epoch 4): Loss/seq after 01700 batchs: 1659.3231201171875
INFO:root:Train (Epoch 4): Loss/seq after 01750 batchs: 1638.5499267578125
INFO:root:Train (Epoch 4): Loss/seq after 01800 batchs: 1616.28662109375
INFO:root:Train (Epoch 4): Loss/seq after 01850 batchs: 1594.1243896484375
INFO:root:Train (Epoch 4): Loss/seq after 01900 batchs: 1585.3448486328125
INFO:root:Train (Epoch 4): Loss/seq after 01950 batchs: 1573.105712890625
INFO:root:Train (Epoch 4): Loss/seq after 02000 batchs: 1556.514892578125
INFO:root:Train (Epoch 4): Loss/seq after 02050 batchs: 1541.846923828125
INFO:root:Train (Epoch 4): Loss/seq after 02100 batchs: 1524.1219482421875
INFO:root:Train (Epoch 4): Loss/seq after 02150 batchs: 1507.997802734375
INFO:root:Train (Epoch 4): Loss/seq after 02200 batchs: 1490.83349609375
INFO:root:Train (Epoch 4): Loss/seq after 02250 batchs: 1497.361083984375
INFO:root:Train (Epoch 4): Loss/seq after 02300 batchs: 1500.6265869140625
INFO:root:Train (Epoch 4): Loss/seq after 02350 batchs: 1487.4261474609375
INFO:root:Train (Epoch 4): Loss/seq after 02400 batchs: 1479.048583984375
INFO:root:Train (Epoch 4): Loss/seq after 02450 batchs: 1462.7913818359375
INFO:root:Train (Epoch 4): Loss/seq after 02500 batchs: 1441.0184326171875
INFO:root:Train (Epoch 4): Loss/seq after 02550 batchs: 1431.2935791015625
INFO:root:Train (Epoch 4): Loss/seq after 02600 batchs: 1428.53564453125
INFO:root:Train (Epoch 4): Loss/seq after 02650 batchs: 1422.06201171875
INFO:root:Train (Epoch 4): Loss/seq after 02700 batchs: 1422.5604248046875
INFO:root:Train (Epoch 4): Loss/seq after 02750 batchs: 1451.7095947265625
INFO:root:Train (Epoch 4): Loss/seq after 02800 batchs: 1460.891845703125
INFO:root:Train (Epoch 4): Loss/seq after 02850 batchs: 1457.257568359375
INFO:root:Train (Epoch 4): Loss/seq after 02900 batchs: 1454.9473876953125
INFO:root:Train (Epoch 4): Loss/seq after 02950 batchs: 1444.81494140625
INFO:root:Train (Epoch 4): Loss/seq after 03000 batchs: 1438.9552001953125
INFO:root:Train (Epoch 4): Loss/seq after 03050 batchs: 1438.070556640625
INFO:root:Train (Epoch 4): Loss/seq after 03100 batchs: 1458.94921875
INFO:root:Train (Epoch 4): Loss/seq after 03150 batchs: 1477.8931884765625
INFO:root:Train (Epoch 4): Loss/seq after 03200 batchs: 1487.037353515625
INFO:root:Train (Epoch 4): Loss/seq after 03250 batchs: 1493.4261474609375
INFO:root:Train (Epoch 4): Loss/seq after 03300 batchs: 1494.09521484375
INFO:root:Train (Epoch 4): Loss/seq after 03350 batchs: 1493.313720703125
INFO:root:Train (Epoch 4): Loss/seq after 03400 batchs: 1481.023193359375
INFO:root:Train (Epoch 4): Loss/seq after 03450 batchs: 1472.0255126953125
INFO:root:Train (Epoch 4): Loss/seq after 03500 batchs: 1470.4051513671875
INFO:root:Train (Epoch 4): Loss/seq after 03550 batchs: 1464.034423828125
INFO:root:Train (Epoch 4): Loss/seq after 03600 batchs: 1468.00439453125
INFO:root:Train (Epoch 4): Loss/seq after 03650 batchs: 1462.487548828125
INFO:root:Train (Epoch 4): Loss/seq after 03700 batchs: 1459.7198486328125
INFO:root:Train (Epoch 4): Loss/seq after 03750 batchs: 1456.71533203125
INFO:root:Train (Epoch 4): Loss/seq after 03800 batchs: 1447.054443359375
INFO:root:Train (Epoch 4): Loss/seq after 03850 batchs: 1440.21533203125
INFO:root:Train (Epoch 4): Loss/seq after 03900 batchs: 1448.9520263671875
INFO:root:Train (Epoch 4): Loss/seq after 03950 batchs: 1454.267822265625
INFO:root:Train (Epoch 4): Loss/seq after 04000 batchs: 1443.1121826171875
INFO:root:Train (Epoch 4): Loss/seq after 04050 batchs: 1432.38330078125
INFO:root:Train (Epoch 4): Loss/seq after 04100 batchs: 1427.143798828125
INFO:root:Train (Epoch 4): Loss/seq after 04150 batchs: 1419.6837158203125
INFO:root:Train (Epoch 4): Loss/seq after 04200 batchs: 1413.35888671875
INFO:root:Train (Epoch 4): Loss/seq after 04250 batchs: 1406.8638916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 4): Loss/seq after 00000 batches: 989.2630004882812
INFO:root:# Valid (Epoch 4): Loss/seq after 00050 batches: 1140.9248046875
INFO:root:# Valid (Epoch 4): Loss/seq after 00100 batches: 1479.1407470703125
INFO:root:# Valid (Epoch 4): Loss/seq after 00150 batches: 1221.32177734375
INFO:root:# Valid (Epoch 4): Loss/seq after 00200 batches: 1102.4520263671875
INFO:root:Artifacts: Make stick videos for epoch 4
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_4_on_20220421_235648.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_4_index_596_on_20220421_235648.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 5): Loss/seq after 00000 batchs: 2041.9901123046875
INFO:root:Train (Epoch 5): Loss/seq after 00050 batchs: 1865.3043212890625
INFO:root:Train (Epoch 5): Loss/seq after 00100 batchs: 1878.0477294921875
INFO:root:Train (Epoch 5): Loss/seq after 00150 batchs: 1662.0113525390625
INFO:root:Train (Epoch 5): Loss/seq after 00200 batchs: 1763.826416015625
INFO:root:Train (Epoch 5): Loss/seq after 00250 batchs: 1895.4619140625
INFO:root:Train (Epoch 5): Loss/seq after 00300 batchs: 1781.03271484375
INFO:root:Train (Epoch 5): Loss/seq after 00350 batchs: 1655.4324951171875
INFO:root:Train (Epoch 5): Loss/seq after 00400 batchs: 1726.948486328125
INFO:root:Train (Epoch 5): Loss/seq after 00450 batchs: 1636.6553955078125
INFO:root:Train (Epoch 5): Loss/seq after 00500 batchs: 1662.453125
INFO:root:Train (Epoch 5): Loss/seq after 00550 batchs: 1591.7244873046875
INFO:root:Train (Epoch 5): Loss/seq after 00600 batchs: 1551.4869384765625
INFO:root:Train (Epoch 5): Loss/seq after 00650 batchs: 1592.1038818359375
INFO:root:Train (Epoch 5): Loss/seq after 00700 batchs: 1643.9127197265625
INFO:root:Train (Epoch 5): Loss/seq after 00750 batchs: 1680.2791748046875
INFO:root:Train (Epoch 5): Loss/seq after 00800 batchs: 1662.5439453125
INFO:root:Train (Epoch 5): Loss/seq after 00850 batchs: 1621.9208984375
INFO:root:Train (Epoch 5): Loss/seq after 00900 batchs: 1631.801513671875
INFO:root:Train (Epoch 5): Loss/seq after 00950 batchs: 1708.3270263671875
INFO:root:Train (Epoch 5): Loss/seq after 01000 batchs: 1705.5791015625
INFO:root:Train (Epoch 5): Loss/seq after 01050 batchs: 1684.729248046875
INFO:root:Train (Epoch 5): Loss/seq after 01100 batchs: 1685.12158203125
INFO:root:Train (Epoch 5): Loss/seq after 01150 batchs: 1656.5206298828125
INFO:root:Train (Epoch 5): Loss/seq after 01200 batchs: 1636.9666748046875
INFO:root:Train (Epoch 5): Loss/seq after 01250 batchs: 1629.3284912109375
INFO:root:Train (Epoch 5): Loss/seq after 01300 batchs: 1633.7349853515625
INFO:root:Train (Epoch 5): Loss/seq after 01350 batchs: 1629.1951904296875
INFO:root:Train (Epoch 5): Loss/seq after 01400 batchs: 1672.296142578125
INFO:root:Train (Epoch 5): Loss/seq after 01450 batchs: 1656.927490234375
INFO:root:Train (Epoch 5): Loss/seq after 01500 batchs: 1637.729248046875
INFO:root:Train (Epoch 5): Loss/seq after 01550 batchs: 1638.6414794921875
INFO:root:Train (Epoch 5): Loss/seq after 01600 batchs: 1613.745849609375
INFO:root:Train (Epoch 5): Loss/seq after 01650 batchs: 1603.880126953125
INFO:root:Train (Epoch 5): Loss/seq after 01700 batchs: 1588.1514892578125
INFO:root:Train (Epoch 5): Loss/seq after 01750 batchs: 1569.356689453125
INFO:root:Train (Epoch 5): Loss/seq after 01800 batchs: 1549.0421142578125
INFO:root:Train (Epoch 5): Loss/seq after 01850 batchs: 1528.685546875
INFO:root:Train (Epoch 5): Loss/seq after 01900 batchs: 1521.6246337890625
INFO:root:Train (Epoch 5): Loss/seq after 01950 batchs: 1511.0439453125
INFO:root:Train (Epoch 5): Loss/seq after 02000 batchs: 1496.0130615234375
INFO:root:Train (Epoch 5): Loss/seq after 02050 batchs: 1482.8675537109375
INFO:root:Train (Epoch 5): Loss/seq after 02100 batchs: 1466.5345458984375
INFO:root:Train (Epoch 5): Loss/seq after 02150 batchs: 1451.7969970703125
INFO:root:Train (Epoch 5): Loss/seq after 02200 batchs: 1435.9669189453125
INFO:root:Train (Epoch 5): Loss/seq after 02250 batchs: 1440.33984375
INFO:root:Train (Epoch 5): Loss/seq after 02300 batchs: 1444.68603515625
INFO:root:Train (Epoch 5): Loss/seq after 02350 batchs: 1432.907958984375
INFO:root:Train (Epoch 5): Loss/seq after 02400 batchs: 1425.8624267578125
INFO:root:Train (Epoch 5): Loss/seq after 02450 batchs: 1410.8363037109375
INFO:root:Train (Epoch 5): Loss/seq after 02500 batchs: 1389.96484375
INFO:root:Train (Epoch 5): Loss/seq after 02550 batchs: 1380.07421875
INFO:root:Train (Epoch 5): Loss/seq after 02600 batchs: 1377.636962890625
INFO:root:Train (Epoch 5): Loss/seq after 02650 batchs: 1371.197509765625
INFO:root:Train (Epoch 5): Loss/seq after 02700 batchs: 1366.6298828125
INFO:root:Train (Epoch 5): Loss/seq after 02750 batchs: 1396.36376953125
INFO:root:Train (Epoch 5): Loss/seq after 02800 batchs: 1404.83642578125
INFO:root:Train (Epoch 5): Loss/seq after 02850 batchs: 1401.10009765625
INFO:root:Train (Epoch 5): Loss/seq after 02900 batchs: 1398.968017578125
INFO:root:Train (Epoch 5): Loss/seq after 02950 batchs: 1389.405517578125
INFO:root:Train (Epoch 5): Loss/seq after 03000 batchs: 1384.4517822265625
INFO:root:Train (Epoch 5): Loss/seq after 03050 batchs: 1384.4248046875
INFO:root:Train (Epoch 5): Loss/seq after 03100 batchs: 1401.677978515625
INFO:root:Train (Epoch 5): Loss/seq after 03150 batchs: 1419.2330322265625
INFO:root:Train (Epoch 5): Loss/seq after 03200 batchs: 1427.8056640625
INFO:root:Train (Epoch 5): Loss/seq after 03250 batchs: 1435.5633544921875
INFO:root:Train (Epoch 5): Loss/seq after 03300 batchs: 1437.0028076171875
INFO:root:Train (Epoch 5): Loss/seq after 03350 batchs: 1435.9283447265625
INFO:root:Train (Epoch 5): Loss/seq after 03400 batchs: 1424.4510498046875
INFO:root:Train (Epoch 5): Loss/seq after 03450 batchs: 1416.7418212890625
INFO:root:Train (Epoch 5): Loss/seq after 03500 batchs: 1415.5196533203125
INFO:root:Train (Epoch 5): Loss/seq after 03550 batchs: 1409.09814453125
INFO:root:Train (Epoch 5): Loss/seq after 03600 batchs: 1413.1954345703125
INFO:root:Train (Epoch 5): Loss/seq after 03650 batchs: 1407.7440185546875
INFO:root:Train (Epoch 5): Loss/seq after 03700 batchs: 1405.70654296875
INFO:root:Train (Epoch 5): Loss/seq after 03750 batchs: 1403.3868408203125
INFO:root:Train (Epoch 5): Loss/seq after 03800 batchs: 1394.446044921875
INFO:root:Train (Epoch 5): Loss/seq after 03850 batchs: 1388.2774658203125
INFO:root:Train (Epoch 5): Loss/seq after 03900 batchs: 1394.9283447265625
INFO:root:Train (Epoch 5): Loss/seq after 03950 batchs: 1401.8385009765625
INFO:root:Train (Epoch 5): Loss/seq after 04000 batchs: 1391.0179443359375
INFO:root:Train (Epoch 5): Loss/seq after 04050 batchs: 1380.904296875
INFO:root:Train (Epoch 5): Loss/seq after 04100 batchs: 1376.1759033203125
INFO:root:Train (Epoch 5): Loss/seq after 04150 batchs: 1369.3343505859375
INFO:root:Train (Epoch 5): Loss/seq after 04200 batchs: 1364.2625732421875
INFO:root:Train (Epoch 5): Loss/seq after 04250 batchs: 1358.6436767578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 5): Loss/seq after 00000 batches: 1027.2803955078125
INFO:root:# Valid (Epoch 5): Loss/seq after 00050 batches: 1160.28515625
INFO:root:# Valid (Epoch 5): Loss/seq after 00100 batches: 1534.20849609375
INFO:root:# Valid (Epoch 5): Loss/seq after 00150 batches: 1253.5369873046875
INFO:root:# Valid (Epoch 5): Loss/seq after 00200 batches: 1124.5093994140625
INFO:root:Artifacts: Make stick videos for epoch 5
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_5_on_20220422_000138.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_5_index_1689_on_20220422_000138.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 6): Loss/seq after 00000 batchs: 1767.9534912109375
INFO:root:Train (Epoch 6): Loss/seq after 00050 batchs: 1849.3084716796875
INFO:root:Train (Epoch 6): Loss/seq after 00100 batchs: 1809.18798828125
INFO:root:Train (Epoch 6): Loss/seq after 00150 batchs: 1618.2711181640625
INFO:root:Train (Epoch 6): Loss/seq after 00200 batchs: 1712.497802734375
INFO:root:Train (Epoch 6): Loss/seq after 00250 batchs: 1860.3365478515625
INFO:root:Train (Epoch 6): Loss/seq after 00300 batchs: 1751.9993896484375
INFO:root:Train (Epoch 6): Loss/seq after 00350 batchs: 1632.1241455078125
INFO:root:Train (Epoch 6): Loss/seq after 00400 batchs: 1706.7215576171875
INFO:root:Train (Epoch 6): Loss/seq after 00450 batchs: 1616.788818359375
INFO:root:Train (Epoch 6): Loss/seq after 00500 batchs: 1657.34619140625
INFO:root:Train (Epoch 6): Loss/seq after 00550 batchs: 1588.98095703125
INFO:root:Train (Epoch 6): Loss/seq after 00600 batchs: 1551.018798828125
INFO:root:Train (Epoch 6): Loss/seq after 00650 batchs: 1597.4384765625
INFO:root:Train (Epoch 6): Loss/seq after 00700 batchs: 1634.3074951171875
INFO:root:Train (Epoch 6): Loss/seq after 00750 batchs: 1665.63671875
INFO:root:Train (Epoch 6): Loss/seq after 00800 batchs: 1648.9244384765625
INFO:root:Train (Epoch 6): Loss/seq after 00850 batchs: 1609.1116943359375
INFO:root:Train (Epoch 6): Loss/seq after 00900 batchs: 1608.9697265625
INFO:root:Train (Epoch 6): Loss/seq after 00950 batchs: 1689.92333984375
INFO:root:Train (Epoch 6): Loss/seq after 01000 batchs: 1689.4312744140625
INFO:root:Train (Epoch 6): Loss/seq after 01050 batchs: 1667.4451904296875
INFO:root:Train (Epoch 6): Loss/seq after 01100 batchs: 1654.2552490234375
INFO:root:Train (Epoch 6): Loss/seq after 01150 batchs: 1627.351318359375
INFO:root:Train (Epoch 6): Loss/seq after 01200 batchs: 1607.2698974609375
INFO:root:Train (Epoch 6): Loss/seq after 01250 batchs: 1597.4010009765625
INFO:root:Train (Epoch 6): Loss/seq after 01300 batchs: 1602.35986328125
INFO:root:Train (Epoch 6): Loss/seq after 01350 batchs: 1596.1693115234375
INFO:root:Train (Epoch 6): Loss/seq after 01400 batchs: 1631.997314453125
INFO:root:Train (Epoch 6): Loss/seq after 01450 batchs: 1614.4443359375
INFO:root:Train (Epoch 6): Loss/seq after 01500 batchs: 1596.4505615234375
INFO:root:Train (Epoch 6): Loss/seq after 01550 batchs: 1595.99609375
INFO:root:Train (Epoch 6): Loss/seq after 01600 batchs: 1571.7513427734375
INFO:root:Train (Epoch 6): Loss/seq after 01650 batchs: 1561.73583984375
INFO:root:Train (Epoch 6): Loss/seq after 01700 batchs: 1547.397705078125
INFO:root:Train (Epoch 6): Loss/seq after 01750 batchs: 1529.609375
INFO:root:Train (Epoch 6): Loss/seq after 01800 batchs: 1510.3077392578125
INFO:root:Train (Epoch 6): Loss/seq after 01850 batchs: 1490.97705078125
INFO:root:Train (Epoch 6): Loss/seq after 01900 batchs: 1484.914794921875
INFO:root:Train (Epoch 6): Loss/seq after 01950 batchs: 1475.249267578125
INFO:root:Train (Epoch 6): Loss/seq after 02000 batchs: 1461.146484375
INFO:root:Train (Epoch 6): Loss/seq after 02050 batchs: 1448.83056640625
INFO:root:Train (Epoch 6): Loss/seq after 02100 batchs: 1433.3079833984375
INFO:root:Train (Epoch 6): Loss/seq after 02150 batchs: 1419.3582763671875
INFO:root:Train (Epoch 6): Loss/seq after 02200 batchs: 1404.2430419921875
INFO:root:Train (Epoch 6): Loss/seq after 02250 batchs: 1409.343017578125
INFO:root:Train (Epoch 6): Loss/seq after 02300 batchs: 1413.734375
INFO:root:Train (Epoch 6): Loss/seq after 02350 batchs: 1402.8668212890625
INFO:root:Train (Epoch 6): Loss/seq after 02400 batchs: 1396.130126953125
INFO:root:Train (Epoch 6): Loss/seq after 02450 batchs: 1381.1556396484375
INFO:root:Train (Epoch 6): Loss/seq after 02500 batchs: 1360.944580078125
INFO:root:Train (Epoch 6): Loss/seq after 02550 batchs: 1349.660400390625
INFO:root:Train (Epoch 6): Loss/seq after 02600 batchs: 1346.463134765625
INFO:root:Train (Epoch 6): Loss/seq after 02650 batchs: 1339.7093505859375
INFO:root:Train (Epoch 6): Loss/seq after 02700 batchs: 1336.1414794921875
INFO:root:Train (Epoch 6): Loss/seq after 02750 batchs: 1366.5909423828125
INFO:root:Train (Epoch 6): Loss/seq after 02800 batchs: 1373.10546875
INFO:root:Train (Epoch 6): Loss/seq after 02850 batchs: 1369.5845947265625
INFO:root:Train (Epoch 6): Loss/seq after 02900 batchs: 1366.455078125
INFO:root:Train (Epoch 6): Loss/seq after 02950 batchs: 1357.0699462890625
INFO:root:Train (Epoch 6): Loss/seq after 03000 batchs: 1352.6043701171875
INFO:root:Train (Epoch 6): Loss/seq after 03050 batchs: 1353.1151123046875
INFO:root:Train (Epoch 6): Loss/seq after 03100 batchs: 1369.4835205078125
INFO:root:Train (Epoch 6): Loss/seq after 03150 batchs: 1385.5047607421875
INFO:root:Train (Epoch 6): Loss/seq after 03200 batchs: 1395.45263671875
INFO:root:Train (Epoch 6): Loss/seq after 03250 batchs: 1403.032470703125
INFO:root:Train (Epoch 6): Loss/seq after 03300 batchs: 1403.4786376953125
INFO:root:Train (Epoch 6): Loss/seq after 03350 batchs: 1403.03955078125
INFO:root:Train (Epoch 6): Loss/seq after 03400 batchs: 1392.149658203125
INFO:root:Train (Epoch 6): Loss/seq after 03450 batchs: 1384.012939453125
INFO:root:Train (Epoch 6): Loss/seq after 03500 batchs: 1384.5440673828125
INFO:root:Train (Epoch 6): Loss/seq after 03550 batchs: 1378.603271484375
INFO:root:Train (Epoch 6): Loss/seq after 03600 batchs: 1382.93994140625
INFO:root:Train (Epoch 6): Loss/seq after 03650 batchs: 1377.7208251953125
INFO:root:Train (Epoch 6): Loss/seq after 03700 batchs: 1375.974853515625
INFO:root:Train (Epoch 6): Loss/seq after 03750 batchs: 1374.0400390625
INFO:root:Train (Epoch 6): Loss/seq after 03800 batchs: 1365.2991943359375
INFO:root:Train (Epoch 6): Loss/seq after 03850 batchs: 1359.3253173828125
INFO:root:Train (Epoch 6): Loss/seq after 03900 batchs: 1365.8756103515625
INFO:root:Train (Epoch 6): Loss/seq after 03950 batchs: 1373.548583984375
INFO:root:Train (Epoch 6): Loss/seq after 04000 batchs: 1362.7576904296875
INFO:root:Train (Epoch 6): Loss/seq after 04050 batchs: 1352.9935302734375
INFO:root:Train (Epoch 6): Loss/seq after 04100 batchs: 1348.4437255859375
INFO:root:Train (Epoch 6): Loss/seq after 04150 batchs: 1341.9449462890625
INFO:root:Train (Epoch 6): Loss/seq after 04200 batchs: 1336.2796630859375
INFO:root:Train (Epoch 6): Loss/seq after 04250 batchs: 1330.771240234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 6): Loss/seq after 00000 batches: 955.0875854492188
INFO:root:# Valid (Epoch 6): Loss/seq after 00050 batches: 1125.3087158203125
INFO:root:# Valid (Epoch 6): Loss/seq after 00100 batches: 1468.5838623046875
INFO:root:# Valid (Epoch 6): Loss/seq after 00150 batches: 1227.5494384765625
INFO:root:# Valid (Epoch 6): Loss/seq after 00200 batches: 1113.99560546875
INFO:root:Artifacts: Make stick videos for epoch 6
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_6_on_20220422_000643.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_6_index_1845_on_20220422_000643.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 7): Loss/seq after 00000 batchs: 2636.1328125
INFO:root:Train (Epoch 7): Loss/seq after 00050 batchs: 1818.8629150390625
INFO:root:Train (Epoch 7): Loss/seq after 00100 batchs: 1858.450439453125
INFO:root:Train (Epoch 7): Loss/seq after 00150 batchs: 1646.4307861328125
INFO:root:Train (Epoch 7): Loss/seq after 00200 batchs: 1745.5802001953125
INFO:root:Train (Epoch 7): Loss/seq after 00250 batchs: 1854.786376953125
INFO:root:Train (Epoch 7): Loss/seq after 00300 batchs: 1736.533447265625
INFO:root:Train (Epoch 7): Loss/seq after 00350 batchs: 1615.0294189453125
INFO:root:Train (Epoch 7): Loss/seq after 00400 batchs: 1677.580322265625
INFO:root:Train (Epoch 7): Loss/seq after 00450 batchs: 1589.4228515625
INFO:root:Train (Epoch 7): Loss/seq after 00500 batchs: 1630.5177001953125
INFO:root:Train (Epoch 7): Loss/seq after 00550 batchs: 1559.64404296875
INFO:root:Train (Epoch 7): Loss/seq after 00600 batchs: 1519.149169921875
INFO:root:Train (Epoch 7): Loss/seq after 00650 batchs: 1556.72607421875
INFO:root:Train (Epoch 7): Loss/seq after 00700 batchs: 1597.2313232421875
INFO:root:Train (Epoch 7): Loss/seq after 00750 batchs: 1633.351806640625
INFO:root:Train (Epoch 7): Loss/seq after 00800 batchs: 1618.5185546875
INFO:root:Train (Epoch 7): Loss/seq after 00850 batchs: 1580.7203369140625
INFO:root:Train (Epoch 7): Loss/seq after 00900 batchs: 1581.1549072265625
INFO:root:Train (Epoch 7): Loss/seq after 00950 batchs: 1647.3153076171875
INFO:root:Train (Epoch 7): Loss/seq after 01000 batchs: 1644.96142578125
INFO:root:Train (Epoch 7): Loss/seq after 01050 batchs: 1623.4439697265625
INFO:root:Train (Epoch 7): Loss/seq after 01100 batchs: 1614.279052734375
INFO:root:Train (Epoch 7): Loss/seq after 01150 batchs: 1589.4967041015625
INFO:root:Train (Epoch 7): Loss/seq after 01200 batchs: 1572.0511474609375
INFO:root:Train (Epoch 7): Loss/seq after 01250 batchs: 1569.1817626953125
INFO:root:Train (Epoch 7): Loss/seq after 01300 batchs: 1570.9525146484375
INFO:root:Train (Epoch 7): Loss/seq after 01350 batchs: 1565.743408203125
INFO:root:Train (Epoch 7): Loss/seq after 01400 batchs: 1608.7060546875
INFO:root:Train (Epoch 7): Loss/seq after 01450 batchs: 1594.689453125
INFO:root:Train (Epoch 7): Loss/seq after 01500 batchs: 1577.6005859375
INFO:root:Train (Epoch 7): Loss/seq after 01550 batchs: 1577.3326416015625
INFO:root:Train (Epoch 7): Loss/seq after 01600 batchs: 1553.9461669921875
INFO:root:Train (Epoch 7): Loss/seq after 01650 batchs: 1545.1678466796875
INFO:root:Train (Epoch 7): Loss/seq after 01700 batchs: 1531.1192626953125
INFO:root:Train (Epoch 7): Loss/seq after 01750 batchs: 1513.8048095703125
INFO:root:Train (Epoch 7): Loss/seq after 01800 batchs: 1494.9356689453125
INFO:root:Train (Epoch 7): Loss/seq after 01850 batchs: 1476.0262451171875
INFO:root:Train (Epoch 7): Loss/seq after 01900 batchs: 1470.2950439453125
INFO:root:Train (Epoch 7): Loss/seq after 01950 batchs: 1461.0369873046875
INFO:root:Train (Epoch 7): Loss/seq after 02000 batchs: 1447.27587890625
INFO:root:Train (Epoch 7): Loss/seq after 02050 batchs: 1435.3048095703125
INFO:root:Train (Epoch 7): Loss/seq after 02100 batchs: 1420.0982666015625
INFO:root:Train (Epoch 7): Loss/seq after 02150 batchs: 1406.4464111328125
INFO:root:Train (Epoch 7): Loss/seq after 02200 batchs: 1391.6234130859375
INFO:root:Train (Epoch 7): Loss/seq after 02250 batchs: 1395.8656005859375
INFO:root:Train (Epoch 7): Loss/seq after 02300 batchs: 1399.65771484375
INFO:root:Train (Epoch 7): Loss/seq after 02350 batchs: 1388.5673828125
INFO:root:Train (Epoch 7): Loss/seq after 02400 batchs: 1382.158203125
INFO:root:Train (Epoch 7): Loss/seq after 02450 batchs: 1367.284423828125
INFO:root:Train (Epoch 7): Loss/seq after 02500 batchs: 1347.3275146484375
INFO:root:Train (Epoch 7): Loss/seq after 02550 batchs: 1334.6123046875
INFO:root:Train (Epoch 7): Loss/seq after 02600 batchs: 1331.75244140625
INFO:root:Train (Epoch 7): Loss/seq after 02650 batchs: 1325.060546875
INFO:root:Train (Epoch 7): Loss/seq after 02700 batchs: 1320.6820068359375
INFO:root:Train (Epoch 7): Loss/seq after 02750 batchs: 1349.711669921875
INFO:root:Train (Epoch 7): Loss/seq after 02800 batchs: 1356.6905517578125
INFO:root:Train (Epoch 7): Loss/seq after 02850 batchs: 1353.145263671875
INFO:root:Train (Epoch 7): Loss/seq after 02900 batchs: 1350.5067138671875
INFO:root:Train (Epoch 7): Loss/seq after 02950 batchs: 1341.1915283203125
INFO:root:Train (Epoch 7): Loss/seq after 03000 batchs: 1336.982666015625
INFO:root:Train (Epoch 7): Loss/seq after 03050 batchs: 1337.739501953125
INFO:root:Train (Epoch 7): Loss/seq after 03100 batchs: 1354.9302978515625
INFO:root:Train (Epoch 7): Loss/seq after 03150 batchs: 1372.9598388671875
INFO:root:Train (Epoch 7): Loss/seq after 03200 batchs: 1383.0184326171875
INFO:root:Train (Epoch 7): Loss/seq after 03250 batchs: 1389.8909912109375
INFO:root:Train (Epoch 7): Loss/seq after 03300 batchs: 1392.4337158203125
INFO:root:Train (Epoch 7): Loss/seq after 03350 batchs: 1393.12548828125
INFO:root:Train (Epoch 7): Loss/seq after 03400 batchs: 1382.223876953125
INFO:root:Train (Epoch 7): Loss/seq after 03450 batchs: 1374.1597900390625
INFO:root:Train (Epoch 7): Loss/seq after 03500 batchs: 1373.2142333984375
INFO:root:Train (Epoch 7): Loss/seq after 03550 batchs: 1367.415771484375
INFO:root:Train (Epoch 7): Loss/seq after 03600 batchs: 1372.0242919921875
INFO:root:Train (Epoch 7): Loss/seq after 03650 batchs: 1367.6082763671875
INFO:root:Train (Epoch 7): Loss/seq after 03700 batchs: 1366.0970458984375
INFO:root:Train (Epoch 7): Loss/seq after 03750 batchs: 1364.3695068359375
INFO:root:Train (Epoch 7): Loss/seq after 03800 batchs: 1355.995361328125
INFO:root:Train (Epoch 7): Loss/seq after 03850 batchs: 1350.2301025390625
INFO:root:Train (Epoch 7): Loss/seq after 03900 batchs: 1356.1842041015625
INFO:root:Train (Epoch 7): Loss/seq after 03950 batchs: 1361.5814208984375
INFO:root:Train (Epoch 7): Loss/seq after 04000 batchs: 1350.916748046875
INFO:root:Train (Epoch 7): Loss/seq after 04050 batchs: 1341.3001708984375
INFO:root:Train (Epoch 7): Loss/seq after 04100 batchs: 1336.7957763671875
INFO:root:Train (Epoch 7): Loss/seq after 04150 batchs: 1330.447265625
INFO:root:Train (Epoch 7): Loss/seq after 04200 batchs: 1324.820068359375
INFO:root:Train (Epoch 7): Loss/seq after 04250 batchs: 1319.6043701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 7): Loss/seq after 00000 batches: 1000.6668090820312
INFO:root:# Valid (Epoch 7): Loss/seq after 00050 batches: 1145.1644287109375
INFO:root:# Valid (Epoch 7): Loss/seq after 00100 batches: 1494.58447265625
INFO:root:# Valid (Epoch 7): Loss/seq after 00150 batches: 1231.856201171875
INFO:root:# Valid (Epoch 7): Loss/seq after 00200 batches: 1112.003173828125
INFO:root:Artifacts: Make stick videos for epoch 7
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_7_on_20220422_001136.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_7_index_573_on_20220422_001136.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 8): Loss/seq after 00000 batchs: 1970.202392578125
INFO:root:Train (Epoch 8): Loss/seq after 00050 batchs: 1863.3355712890625
INFO:root:Train (Epoch 8): Loss/seq after 00100 batchs: 1764.4932861328125
INFO:root:Train (Epoch 8): Loss/seq after 00150 batchs: 1605.3311767578125
INFO:root:Train (Epoch 8): Loss/seq after 00200 batchs: 1697.8031005859375
INFO:root:Train (Epoch 8): Loss/seq after 00250 batchs: 1803.10986328125
INFO:root:Train (Epoch 8): Loss/seq after 00300 batchs: 1694.0633544921875
INFO:root:Train (Epoch 8): Loss/seq after 00350 batchs: 1578.21728515625
INFO:root:Train (Epoch 8): Loss/seq after 00400 batchs: 1630.961669921875
INFO:root:Train (Epoch 8): Loss/seq after 00450 batchs: 1547.8021240234375
INFO:root:Train (Epoch 8): Loss/seq after 00500 batchs: 1585.8310546875
INFO:root:Train (Epoch 8): Loss/seq after 00550 batchs: 1516.981689453125
INFO:root:Train (Epoch 8): Loss/seq after 00600 batchs: 1479.2821044921875
INFO:root:Train (Epoch 8): Loss/seq after 00650 batchs: 1523.58251953125
INFO:root:Train (Epoch 8): Loss/seq after 00700 batchs: 1558.9267578125
INFO:root:Train (Epoch 8): Loss/seq after 00750 batchs: 1600.2593994140625
INFO:root:Train (Epoch 8): Loss/seq after 00800 batchs: 1586.38525390625
INFO:root:Train (Epoch 8): Loss/seq after 00850 batchs: 1550.802978515625
INFO:root:Train (Epoch 8): Loss/seq after 00900 batchs: 1552.451171875
INFO:root:Train (Epoch 8): Loss/seq after 00950 batchs: 1617.2357177734375
INFO:root:Train (Epoch 8): Loss/seq after 01000 batchs: 1620.029541015625
INFO:root:Train (Epoch 8): Loss/seq after 01050 batchs: 1599.5267333984375
INFO:root:Train (Epoch 8): Loss/seq after 01100 batchs: 1586.5164794921875
INFO:root:Train (Epoch 8): Loss/seq after 01150 batchs: 1562.82373046875
INFO:root:Train (Epoch 8): Loss/seq after 01200 batchs: 1545.96044921875
INFO:root:Train (Epoch 8): Loss/seq after 01250 batchs: 1535.5960693359375
INFO:root:Train (Epoch 8): Loss/seq after 01300 batchs: 1536.321044921875
INFO:root:Train (Epoch 8): Loss/seq after 01350 batchs: 1531.5821533203125
INFO:root:Train (Epoch 8): Loss/seq after 01400 batchs: 1565.1688232421875
INFO:root:Train (Epoch 8): Loss/seq after 01450 batchs: 1549.8902587890625
INFO:root:Train (Epoch 8): Loss/seq after 01500 batchs: 1534.05810546875
INFO:root:Train (Epoch 8): Loss/seq after 01550 batchs: 1538.2137451171875
INFO:root:Train (Epoch 8): Loss/seq after 01600 batchs: 1516.095947265625
INFO:root:Train (Epoch 8): Loss/seq after 01650 batchs: 1509.349609375
INFO:root:Train (Epoch 8): Loss/seq after 01700 batchs: 1496.55126953125
INFO:root:Train (Epoch 8): Loss/seq after 01750 batchs: 1480.021728515625
INFO:root:Train (Epoch 8): Loss/seq after 01800 batchs: 1462.061767578125
INFO:root:Train (Epoch 8): Loss/seq after 01850 batchs: 1444.072509765625
INFO:root:Train (Epoch 8): Loss/seq after 01900 batchs: 1439.1143798828125
INFO:root:Train (Epoch 8): Loss/seq after 01950 batchs: 1430.6478271484375
INFO:root:Train (Epoch 8): Loss/seq after 02000 batchs: 1417.4801025390625
INFO:root:Train (Epoch 8): Loss/seq after 02050 batchs: 1406.100830078125
INFO:root:Train (Epoch 8): Loss/seq after 02100 batchs: 1391.5693359375
INFO:root:Train (Epoch 8): Loss/seq after 02150 batchs: 1378.533935546875
INFO:root:Train (Epoch 8): Loss/seq after 02200 batchs: 1364.333984375
INFO:root:Train (Epoch 8): Loss/seq after 02250 batchs: 1369.3485107421875
INFO:root:Train (Epoch 8): Loss/seq after 02300 batchs: 1374.836181640625
INFO:root:Train (Epoch 8): Loss/seq after 02350 batchs: 1364.146728515625
INFO:root:Train (Epoch 8): Loss/seq after 02400 batchs: 1358.09521484375
INFO:root:Train (Epoch 8): Loss/seq after 02450 batchs: 1343.870361328125
INFO:root:Train (Epoch 8): Loss/seq after 02500 batchs: 1324.390869140625
INFO:root:Train (Epoch 8): Loss/seq after 02550 batchs: 1313.273681640625
INFO:root:Train (Epoch 8): Loss/seq after 02600 batchs: 1310.1376953125
INFO:root:Train (Epoch 8): Loss/seq after 02650 batchs: 1304.408935546875
INFO:root:Train (Epoch 8): Loss/seq after 02700 batchs: 1300.8173828125
INFO:root:Train (Epoch 8): Loss/seq after 02750 batchs: 1333.96875
INFO:root:Train (Epoch 8): Loss/seq after 02800 batchs: 1353.2125244140625
INFO:root:Train (Epoch 8): Loss/seq after 02850 batchs: 1358.1334228515625
INFO:root:Train (Epoch 8): Loss/seq after 02900 batchs: 1358.8160400390625
INFO:root:Train (Epoch 8): Loss/seq after 02950 batchs: 1349.8427734375
INFO:root:Train (Epoch 8): Loss/seq after 03000 batchs: 1345.613037109375
INFO:root:Train (Epoch 8): Loss/seq after 03050 batchs: 1346.32080078125
INFO:root:Train (Epoch 8): Loss/seq after 03100 batchs: 1374.2874755859375
INFO:root:Train (Epoch 8): Loss/seq after 03150 batchs: 1402.486083984375
INFO:root:Train (Epoch 8): Loss/seq after 03200 batchs: 1414.5355224609375
INFO:root:Train (Epoch 8): Loss/seq after 03250 batchs: 1421.9913330078125
INFO:root:Train (Epoch 8): Loss/seq after 03300 batchs: 1427.5047607421875
INFO:root:Train (Epoch 8): Loss/seq after 03350 batchs: 1428.9129638671875
INFO:root:Train (Epoch 8): Loss/seq after 03400 batchs: 1417.5972900390625
INFO:root:Train (Epoch 8): Loss/seq after 03450 batchs: 1411.5601806640625
INFO:root:Train (Epoch 8): Loss/seq after 03500 batchs: 1414.00439453125
INFO:root:Train (Epoch 8): Loss/seq after 03550 batchs: 1408.06884765625
INFO:root:Train (Epoch 8): Loss/seq after 03600 batchs: 1412.9366455078125
INFO:root:Train (Epoch 8): Loss/seq after 03650 batchs: 1407.4251708984375
INFO:root:Train (Epoch 8): Loss/seq after 03700 batchs: 1405.148681640625
INFO:root:Train (Epoch 8): Loss/seq after 03750 batchs: 1402.7139892578125
INFO:root:Train (Epoch 8): Loss/seq after 03800 batchs: 1393.6739501953125
INFO:root:Train (Epoch 8): Loss/seq after 03850 batchs: 1387.3909912109375
INFO:root:Train (Epoch 8): Loss/seq after 03900 batchs: 1402.3812255859375
INFO:root:Train (Epoch 8): Loss/seq after 03950 batchs: 1410.53857421875
INFO:root:Train (Epoch 8): Loss/seq after 04000 batchs: 1399.4205322265625
INFO:root:Train (Epoch 8): Loss/seq after 04050 batchs: 1389.2298583984375
INFO:root:Train (Epoch 8): Loss/seq after 04100 batchs: 1384.554931640625
INFO:root:Train (Epoch 8): Loss/seq after 04150 batchs: 1378.5255126953125
INFO:root:Train (Epoch 8): Loss/seq after 04200 batchs: 1372.6868896484375
INFO:root:Train (Epoch 8): Loss/seq after 04250 batchs: 1367.2642822265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 8): Loss/seq after 00000 batches: 951.3411254882812
INFO:root:# Valid (Epoch 8): Loss/seq after 00050 batches: 1122.40771484375
INFO:root:# Valid (Epoch 8): Loss/seq after 00100 batches: 1458.3555908203125
INFO:root:# Valid (Epoch 8): Loss/seq after 00150 batches: 1206.977294921875
INFO:root:# Valid (Epoch 8): Loss/seq after 00200 batches: 1091.15869140625
INFO:root:Artifacts: Make stick videos for epoch 8
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_8_on_20220422_001630.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_8_index_1848_on_20220422_001630.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 9): Loss/seq after 00000 batchs: 2340.910888671875
INFO:root:Train (Epoch 9): Loss/seq after 00050 batchs: 1885.869873046875
INFO:root:Train (Epoch 9): Loss/seq after 00100 batchs: 1795.692626953125
INFO:root:Train (Epoch 9): Loss/seq after 00150 batchs: 1581.87744140625
INFO:root:Train (Epoch 9): Loss/seq after 00200 batchs: 1704.0789794921875
INFO:root:Train (Epoch 9): Loss/seq after 00250 batchs: 1823.163818359375
INFO:root:Train (Epoch 9): Loss/seq after 00300 batchs: 1707.091552734375
INFO:root:Train (Epoch 9): Loss/seq after 00350 batchs: 1589.6160888671875
INFO:root:Train (Epoch 9): Loss/seq after 00400 batchs: 1651.5303955078125
INFO:root:Train (Epoch 9): Loss/seq after 00450 batchs: 1565.8609619140625
INFO:root:Train (Epoch 9): Loss/seq after 00500 batchs: 1600.513916015625
INFO:root:Train (Epoch 9): Loss/seq after 00550 batchs: 1529.9276123046875
INFO:root:Train (Epoch 9): Loss/seq after 00600 batchs: 1494.92236328125
INFO:root:Train (Epoch 9): Loss/seq after 00650 batchs: 1538.6756591796875
INFO:root:Train (Epoch 9): Loss/seq after 00700 batchs: 1570.801025390625
INFO:root:Train (Epoch 9): Loss/seq after 00750 batchs: 1599.1353759765625
INFO:root:Train (Epoch 9): Loss/seq after 00800 batchs: 1587.283935546875
INFO:root:Train (Epoch 9): Loss/seq after 00850 batchs: 1551.49560546875
INFO:root:Train (Epoch 9): Loss/seq after 00900 batchs: 1569.1246337890625
INFO:root:Train (Epoch 9): Loss/seq after 00950 batchs: 1645.7216796875
INFO:root:Train (Epoch 9): Loss/seq after 01000 batchs: 1643.8673095703125
INFO:root:Train (Epoch 9): Loss/seq after 01050 batchs: 1622.43896484375
INFO:root:Train (Epoch 9): Loss/seq after 01100 batchs: 1609.324462890625
INFO:root:Train (Epoch 9): Loss/seq after 01150 batchs: 1584.7972412109375
INFO:root:Train (Epoch 9): Loss/seq after 01200 batchs: 1565.6104736328125
INFO:root:Train (Epoch 9): Loss/seq after 01250 batchs: 1555.083740234375
INFO:root:Train (Epoch 9): Loss/seq after 01300 batchs: 1555.7176513671875
INFO:root:Train (Epoch 9): Loss/seq after 01350 batchs: 1549.7227783203125
INFO:root:Train (Epoch 9): Loss/seq after 01400 batchs: 1588.44873046875
INFO:root:Train (Epoch 9): Loss/seq after 01450 batchs: 1571.72412109375
INFO:root:Train (Epoch 9): Loss/seq after 01500 batchs: 1555.2904052734375
INFO:root:Train (Epoch 9): Loss/seq after 01550 batchs: 1555.751708984375
INFO:root:Train (Epoch 9): Loss/seq after 01600 batchs: 1532.6458740234375
INFO:root:Train (Epoch 9): Loss/seq after 01650 batchs: 1522.4022216796875
INFO:root:Train (Epoch 9): Loss/seq after 01700 batchs: 1508.6829833984375
INFO:root:Train (Epoch 9): Loss/seq after 01750 batchs: 1491.8660888671875
INFO:root:Train (Epoch 9): Loss/seq after 01800 batchs: 1473.423583984375
INFO:root:Train (Epoch 9): Loss/seq after 01850 batchs: 1455.2001953125
INFO:root:Train (Epoch 9): Loss/seq after 01900 batchs: 1450.0174560546875
INFO:root:Train (Epoch 9): Loss/seq after 01950 batchs: 1441.341064453125
INFO:root:Train (Epoch 9): Loss/seq after 02000 batchs: 1427.8175048828125
INFO:root:Train (Epoch 9): Loss/seq after 02050 batchs: 1416.117431640625
INFO:root:Train (Epoch 9): Loss/seq after 02100 batchs: 1401.2979736328125
INFO:root:Train (Epoch 9): Loss/seq after 02150 batchs: 1388.1488037109375
INFO:root:Train (Epoch 9): Loss/seq after 02200 batchs: 1373.746826171875
INFO:root:Train (Epoch 9): Loss/seq after 02250 batchs: 1376.515380859375
INFO:root:Train (Epoch 9): Loss/seq after 02300 batchs: 1380.6802978515625
INFO:root:Train (Epoch 9): Loss/seq after 02350 batchs: 1368.9930419921875
INFO:root:Train (Epoch 9): Loss/seq after 02400 batchs: 1362.69189453125
INFO:root:Train (Epoch 9): Loss/seq after 02450 batchs: 1347.695068359375
INFO:root:Train (Epoch 9): Loss/seq after 02500 batchs: 1328.0850830078125
INFO:root:Train (Epoch 9): Loss/seq after 02550 batchs: 1316.299072265625
INFO:root:Train (Epoch 9): Loss/seq after 02600 batchs: 1312.7032470703125
INFO:root:Train (Epoch 9): Loss/seq after 02650 batchs: 1306.3167724609375
INFO:root:Train (Epoch 9): Loss/seq after 02700 batchs: 1302.893798828125
INFO:root:Train (Epoch 9): Loss/seq after 02750 batchs: 1336.0205078125
INFO:root:Train (Epoch 9): Loss/seq after 02800 batchs: 1341.5054931640625
INFO:root:Train (Epoch 9): Loss/seq after 02850 batchs: 1337.749755859375
INFO:root:Train (Epoch 9): Loss/seq after 02900 batchs: 1334.7872314453125
INFO:root:Train (Epoch 9): Loss/seq after 02950 batchs: 1325.651611328125
INFO:root:Train (Epoch 9): Loss/seq after 03000 batchs: 1321.693603515625
INFO:root:Train (Epoch 9): Loss/seq after 03050 batchs: 1322.62548828125
INFO:root:Train (Epoch 9): Loss/seq after 03100 batchs: 1337.6185302734375
INFO:root:Train (Epoch 9): Loss/seq after 03150 batchs: 1354.9100341796875
INFO:root:Train (Epoch 9): Loss/seq after 03200 batchs: 1366.386474609375
INFO:root:Train (Epoch 9): Loss/seq after 03250 batchs: 1373.12841796875
INFO:root:Train (Epoch 9): Loss/seq after 03300 batchs: 1373.41064453125
INFO:root:Train (Epoch 9): Loss/seq after 03350 batchs: 1372.9991455078125
INFO:root:Train (Epoch 9): Loss/seq after 03400 batchs: 1362.4495849609375
INFO:root:Train (Epoch 9): Loss/seq after 03450 batchs: 1353.909912109375
INFO:root:Train (Epoch 9): Loss/seq after 03500 batchs: 1353.3367919921875
INFO:root:Train (Epoch 9): Loss/seq after 03550 batchs: 1347.314697265625
INFO:root:Train (Epoch 9): Loss/seq after 03600 batchs: 1351.627685546875
INFO:root:Train (Epoch 9): Loss/seq after 03650 batchs: 1346.12548828125
INFO:root:Train (Epoch 9): Loss/seq after 03700 batchs: 1344.5926513671875
INFO:root:Train (Epoch 9): Loss/seq after 03750 batchs: 1342.9417724609375
INFO:root:Train (Epoch 9): Loss/seq after 03800 batchs: 1334.6251220703125
INFO:root:Train (Epoch 9): Loss/seq after 03850 batchs: 1328.900634765625
INFO:root:Train (Epoch 9): Loss/seq after 03900 batchs: 1335.637939453125
INFO:root:Train (Epoch 9): Loss/seq after 03950 batchs: 1341.5692138671875
INFO:root:Train (Epoch 9): Loss/seq after 04000 batchs: 1331.1484375
INFO:root:Train (Epoch 9): Loss/seq after 04050 batchs: 1321.7630615234375
INFO:root:Train (Epoch 9): Loss/seq after 04100 batchs: 1316.83935546875
INFO:root:Train (Epoch 9): Loss/seq after 04150 batchs: 1310.3095703125
INFO:root:Train (Epoch 9): Loss/seq after 04200 batchs: 1304.30517578125
INFO:root:Train (Epoch 9): Loss/seq after 04250 batchs: 1299.142578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 9): Loss/seq after 00000 batches: 915.1484985351562
INFO:root:# Valid (Epoch 9): Loss/seq after 00050 batches: 1112.3695068359375
INFO:root:# Valid (Epoch 9): Loss/seq after 00100 batches: 1448.4888916015625
INFO:root:# Valid (Epoch 9): Loss/seq after 00150 batches: 1220.1246337890625
INFO:root:# Valid (Epoch 9): Loss/seq after 00200 batches: 1110.8575439453125
INFO:root:Artifacts: Make stick videos for epoch 9
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_9_on_20220422_002118.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_9_index_1296_on_20220422_002118.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 10): Loss/seq after 00000 batchs: 2125.94140625
INFO:root:Train (Epoch 10): Loss/seq after 00050 batchs: 1748.7445068359375
INFO:root:Train (Epoch 10): Loss/seq after 00100 batchs: 1752.017578125
INFO:root:Train (Epoch 10): Loss/seq after 00150 batchs: 1541.2978515625
INFO:root:Train (Epoch 10): Loss/seq after 00200 batchs: 1650.4183349609375
INFO:root:Train (Epoch 10): Loss/seq after 00250 batchs: 1758.620361328125
INFO:root:Train (Epoch 10): Loss/seq after 00300 batchs: 1651.099365234375
INFO:root:Train (Epoch 10): Loss/seq after 00350 batchs: 1541.4063720703125
INFO:root:Train (Epoch 10): Loss/seq after 00400 batchs: 1593.037353515625
INFO:root:Train (Epoch 10): Loss/seq after 00450 batchs: 1513.78564453125
INFO:root:Train (Epoch 10): Loss/seq after 00500 batchs: 1547.4757080078125
INFO:root:Train (Epoch 10): Loss/seq after 00550 batchs: 1483.6805419921875
INFO:root:Train (Epoch 10): Loss/seq after 00600 batchs: 1448.2637939453125
INFO:root:Train (Epoch 10): Loss/seq after 00650 batchs: 1478.1068115234375
INFO:root:Train (Epoch 10): Loss/seq after 00700 batchs: 1515.08740234375
INFO:root:Train (Epoch 10): Loss/seq after 00750 batchs: 1551.434326171875
INFO:root:Train (Epoch 10): Loss/seq after 00800 batchs: 1540.492431640625
INFO:root:Train (Epoch 10): Loss/seq after 00850 batchs: 1508.117431640625
INFO:root:Train (Epoch 10): Loss/seq after 00900 batchs: 1511.4588623046875
INFO:root:Train (Epoch 10): Loss/seq after 00950 batchs: 1563.8663330078125
INFO:root:Train (Epoch 10): Loss/seq after 01000 batchs: 1564.8153076171875
INFO:root:Train (Epoch 10): Loss/seq after 01050 batchs: 1545.5281982421875
INFO:root:Train (Epoch 10): Loss/seq after 01100 batchs: 1535.766357421875
INFO:root:Train (Epoch 10): Loss/seq after 01150 batchs: 1514.5230712890625
INFO:root:Train (Epoch 10): Loss/seq after 01200 batchs: 1499.7425537109375
INFO:root:Train (Epoch 10): Loss/seq after 01250 batchs: 1492.73974609375
INFO:root:Train (Epoch 10): Loss/seq after 01300 batchs: 1493.361328125
INFO:root:Train (Epoch 10): Loss/seq after 01350 batchs: 1489.684814453125
INFO:root:Train (Epoch 10): Loss/seq after 01400 batchs: 1527.3197021484375
INFO:root:Train (Epoch 10): Loss/seq after 01450 batchs: 1512.034423828125
INFO:root:Train (Epoch 10): Loss/seq after 01500 batchs: 1497.818115234375
INFO:root:Train (Epoch 10): Loss/seq after 01550 batchs: 1499.265380859375
INFO:root:Train (Epoch 10): Loss/seq after 01600 batchs: 1477.8670654296875
INFO:root:Train (Epoch 10): Loss/seq after 01650 batchs: 1469.1241455078125
INFO:root:Train (Epoch 10): Loss/seq after 01700 batchs: 1456.72021484375
INFO:root:Train (Epoch 10): Loss/seq after 01750 batchs: 1441.3397216796875
INFO:root:Train (Epoch 10): Loss/seq after 01800 batchs: 1424.38818359375
INFO:root:Train (Epoch 10): Loss/seq after 01850 batchs: 1407.4134521484375
INFO:root:Train (Epoch 10): Loss/seq after 01900 batchs: 1404.1680908203125
INFO:root:Train (Epoch 10): Loss/seq after 01950 batchs: 1396.779296875
INFO:root:Train (Epoch 10): Loss/seq after 02000 batchs: 1384.631103515625
INFO:root:Train (Epoch 10): Loss/seq after 02050 batchs: 1374.1883544921875
INFO:root:Train (Epoch 10): Loss/seq after 02100 batchs: 1360.4307861328125
INFO:root:Train (Epoch 10): Loss/seq after 02150 batchs: 1348.172119140625
INFO:root:Train (Epoch 10): Loss/seq after 02200 batchs: 1334.6656494140625
INFO:root:Train (Epoch 10): Loss/seq after 02250 batchs: 1338.5477294921875
INFO:root:Train (Epoch 10): Loss/seq after 02300 batchs: 1343.052734375
INFO:root:Train (Epoch 10): Loss/seq after 02350 batchs: 1332.3236083984375
INFO:root:Train (Epoch 10): Loss/seq after 02400 batchs: 1326.92138671875
INFO:root:Train (Epoch 10): Loss/seq after 02450 batchs: 1313.0869140625
INFO:root:Train (Epoch 10): Loss/seq after 02500 batchs: 1294.1630859375
INFO:root:Train (Epoch 10): Loss/seq after 02550 batchs: 1282.019775390625
INFO:root:Train (Epoch 10): Loss/seq after 02600 batchs: 1279.424560546875
INFO:root:Train (Epoch 10): Loss/seq after 02650 batchs: 1274.1124267578125
INFO:root:Train (Epoch 10): Loss/seq after 02700 batchs: 1270.849609375
INFO:root:Train (Epoch 10): Loss/seq after 02750 batchs: 1303.7308349609375
INFO:root:Train (Epoch 10): Loss/seq after 02800 batchs: 1311.941650390625
INFO:root:Train (Epoch 10): Loss/seq after 02850 batchs: 1308.9847412109375
INFO:root:Train (Epoch 10): Loss/seq after 02900 batchs: 1306.7861328125
INFO:root:Train (Epoch 10): Loss/seq after 02950 batchs: 1298.3516845703125
INFO:root:Train (Epoch 10): Loss/seq after 03000 batchs: 1294.84521484375
INFO:root:Train (Epoch 10): Loss/seq after 03050 batchs: 1296.265380859375
INFO:root:Train (Epoch 10): Loss/seq after 03100 batchs: 1311.2471923828125
INFO:root:Train (Epoch 10): Loss/seq after 03150 batchs: 1325.24853515625
INFO:root:Train (Epoch 10): Loss/seq after 03200 batchs: 1335.055419921875
INFO:root:Train (Epoch 10): Loss/seq after 03250 batchs: 1341.45947265625
INFO:root:Train (Epoch 10): Loss/seq after 03300 batchs: 1342.390380859375
INFO:root:Train (Epoch 10): Loss/seq after 03350 batchs: 1342.379638671875
INFO:root:Train (Epoch 10): Loss/seq after 03400 batchs: 1332.2811279296875
INFO:root:Train (Epoch 10): Loss/seq after 03450 batchs: 1324.959228515625
INFO:root:Train (Epoch 10): Loss/seq after 03500 batchs: 1324.7318115234375
INFO:root:Train (Epoch 10): Loss/seq after 03550 batchs: 1319.5667724609375
INFO:root:Train (Epoch 10): Loss/seq after 03600 batchs: 1324.3953857421875
INFO:root:Train (Epoch 10): Loss/seq after 03650 batchs: 1319.522216796875
INFO:root:Train (Epoch 10): Loss/seq after 03700 batchs: 1318.1885986328125
INFO:root:Train (Epoch 10): Loss/seq after 03750 batchs: 1316.914794921875
INFO:root:Train (Epoch 10): Loss/seq after 03800 batchs: 1308.914794921875
INFO:root:Train (Epoch 10): Loss/seq after 03850 batchs: 1303.4794921875
INFO:root:Train (Epoch 10): Loss/seq after 03900 batchs: 1311.4285888671875
INFO:root:Train (Epoch 10): Loss/seq after 03950 batchs: 1316.6846923828125
INFO:root:Train (Epoch 10): Loss/seq after 04000 batchs: 1306.5953369140625
INFO:root:Train (Epoch 10): Loss/seq after 04050 batchs: 1297.5126953125
INFO:root:Train (Epoch 10): Loss/seq after 04100 batchs: 1292.856689453125
INFO:root:Train (Epoch 10): Loss/seq after 04150 batchs: 1286.496337890625
INFO:root:Train (Epoch 10): Loss/seq after 04200 batchs: 1281.001953125
INFO:root:Train (Epoch 10): Loss/seq after 04250 batchs: 1275.9224853515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 10): Loss/seq after 00000 batches: 913.0289306640625
INFO:root:# Valid (Epoch 10): Loss/seq after 00050 batches: 1110.626708984375
INFO:root:# Valid (Epoch 10): Loss/seq after 00100 batches: 1433.0399169921875
INFO:root:# Valid (Epoch 10): Loss/seq after 00150 batches: 1193.125
INFO:root:# Valid (Epoch 10): Loss/seq after 00200 batches: 1081.4390869140625
INFO:root:Artifacts: Make stick videos for epoch 10
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_10_on_20220422_002609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_10_index_1710_on_20220422_002609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 11): Loss/seq after 00000 batchs: 2366.4384765625
INFO:root:Train (Epoch 11): Loss/seq after 00050 batchs: 1768.9725341796875
INFO:root:Train (Epoch 11): Loss/seq after 00100 batchs: 1749.59521484375
INFO:root:Train (Epoch 11): Loss/seq after 00150 batchs: 1543.7000732421875
INFO:root:Train (Epoch 11): Loss/seq after 00200 batchs: 1648.68994140625
INFO:root:Train (Epoch 11): Loss/seq after 00250 batchs: 1756.9835205078125
INFO:root:Train (Epoch 11): Loss/seq after 00300 batchs: 1649.8243408203125
INFO:root:Train (Epoch 11): Loss/seq after 00350 batchs: 1540.9251708984375
INFO:root:Train (Epoch 11): Loss/seq after 00400 batchs: 1589.7193603515625
INFO:root:Train (Epoch 11): Loss/seq after 00450 batchs: 1510.763671875
INFO:root:Train (Epoch 11): Loss/seq after 00500 batchs: 1540.5445556640625
INFO:root:Train (Epoch 11): Loss/seq after 00550 batchs: 1480.5545654296875
INFO:root:Train (Epoch 11): Loss/seq after 00600 batchs: 1447.131103515625
INFO:root:Train (Epoch 11): Loss/seq after 00650 batchs: 1471.5819091796875
INFO:root:Train (Epoch 11): Loss/seq after 00700 batchs: 1509.578857421875
INFO:root:Train (Epoch 11): Loss/seq after 00750 batchs: 1544.876953125
INFO:root:Train (Epoch 11): Loss/seq after 00800 batchs: 1535.1558837890625
INFO:root:Train (Epoch 11): Loss/seq after 00850 batchs: 1503.455810546875
INFO:root:Train (Epoch 11): Loss/seq after 00900 batchs: 1509.9666748046875
INFO:root:Train (Epoch 11): Loss/seq after 00950 batchs: 1572.9384765625
INFO:root:Train (Epoch 11): Loss/seq after 01000 batchs: 1568.8963623046875
INFO:root:Train (Epoch 11): Loss/seq after 01050 batchs: 1551.6728515625
INFO:root:Train (Epoch 11): Loss/seq after 01100 batchs: 1550.962890625
INFO:root:Train (Epoch 11): Loss/seq after 01150 batchs: 1526.895263671875
INFO:root:Train (Epoch 11): Loss/seq after 01200 batchs: 1510.9212646484375
INFO:root:Train (Epoch 11): Loss/seq after 01250 batchs: 1501.203369140625
INFO:root:Train (Epoch 11): Loss/seq after 01300 batchs: 1504.8028564453125
INFO:root:Train (Epoch 11): Loss/seq after 01350 batchs: 1501.7672119140625
INFO:root:Train (Epoch 11): Loss/seq after 01400 batchs: 1532.814697265625
INFO:root:Train (Epoch 11): Loss/seq after 01450 batchs: 1518.1051025390625
INFO:root:Train (Epoch 11): Loss/seq after 01500 batchs: 1503.4112548828125
INFO:root:Train (Epoch 11): Loss/seq after 01550 batchs: 1504.4703369140625
INFO:root:Train (Epoch 11): Loss/seq after 01600 batchs: 1483.10595703125
INFO:root:Train (Epoch 11): Loss/seq after 01650 batchs: 1475.557373046875
INFO:root:Train (Epoch 11): Loss/seq after 01700 batchs: 1463.1644287109375
INFO:root:Train (Epoch 11): Loss/seq after 01750 batchs: 1447.842041015625
INFO:root:Train (Epoch 11): Loss/seq after 01800 batchs: 1430.877197265625
INFO:root:Train (Epoch 11): Loss/seq after 01850 batchs: 1413.70068359375
INFO:root:Train (Epoch 11): Loss/seq after 01900 batchs: 1409.8404541015625
INFO:root:Train (Epoch 11): Loss/seq after 01950 batchs: 1402.22802734375
INFO:root:Train (Epoch 11): Loss/seq after 02000 batchs: 1389.973876953125
INFO:root:Train (Epoch 11): Loss/seq after 02050 batchs: 1379.3775634765625
INFO:root:Train (Epoch 11): Loss/seq after 02100 batchs: 1365.51904296875
INFO:root:Train (Epoch 11): Loss/seq after 02150 batchs: 1353.135498046875
INFO:root:Train (Epoch 11): Loss/seq after 02200 batchs: 1339.52197265625
INFO:root:Train (Epoch 11): Loss/seq after 02250 batchs: 1343.029296875
INFO:root:Train (Epoch 11): Loss/seq after 02300 batchs: 1348.774658203125
INFO:root:Train (Epoch 11): Loss/seq after 02350 batchs: 1338.2490234375
INFO:root:Train (Epoch 11): Loss/seq after 02400 batchs: 1332.7388916015625
INFO:root:Train (Epoch 11): Loss/seq after 02450 batchs: 1318.9041748046875
INFO:root:Train (Epoch 11): Loss/seq after 02500 batchs: 1299.9290771484375
INFO:root:Train (Epoch 11): Loss/seq after 02550 batchs: 1289.448974609375
INFO:root:Train (Epoch 11): Loss/seq after 02600 batchs: 1289.14697265625
INFO:root:Train (Epoch 11): Loss/seq after 02650 batchs: 1285.1087646484375
INFO:root:Train (Epoch 11): Loss/seq after 02700 batchs: 1282.4306640625
INFO:root:Train (Epoch 11): Loss/seq after 02750 batchs: 1313.9129638671875
INFO:root:Train (Epoch 11): Loss/seq after 02800 batchs: 1322.6866455078125
INFO:root:Train (Epoch 11): Loss/seq after 02850 batchs: 1320.0516357421875
INFO:root:Train (Epoch 11): Loss/seq after 02900 batchs: 1318.291015625
INFO:root:Train (Epoch 11): Loss/seq after 02950 batchs: 1309.980712890625
INFO:root:Train (Epoch 11): Loss/seq after 03000 batchs: 1306.3095703125
INFO:root:Train (Epoch 11): Loss/seq after 03050 batchs: 1307.53564453125
INFO:root:Train (Epoch 11): Loss/seq after 03100 batchs: 1321.8345947265625
INFO:root:Train (Epoch 11): Loss/seq after 03150 batchs: 1337.974853515625
INFO:root:Train (Epoch 11): Loss/seq after 03200 batchs: 1345.52099609375
INFO:root:Train (Epoch 11): Loss/seq after 03250 batchs: 1353.264404296875
INFO:root:Train (Epoch 11): Loss/seq after 03300 batchs: 1352.880126953125
INFO:root:Train (Epoch 11): Loss/seq after 03350 batchs: 1352.415283203125
INFO:root:Train (Epoch 11): Loss/seq after 03400 batchs: 1342.2652587890625
INFO:root:Train (Epoch 11): Loss/seq after 03450 batchs: 1335.7607421875
INFO:root:Train (Epoch 11): Loss/seq after 03500 batchs: 1335.1661376953125
INFO:root:Train (Epoch 11): Loss/seq after 03550 batchs: 1329.144287109375
INFO:root:Train (Epoch 11): Loss/seq after 03600 batchs: 1333.8514404296875
INFO:root:Train (Epoch 11): Loss/seq after 03650 batchs: 1328.751220703125
INFO:root:Train (Epoch 11): Loss/seq after 03700 batchs: 1327.594970703125
INFO:root:Train (Epoch 11): Loss/seq after 03750 batchs: 1326.257080078125
INFO:root:Train (Epoch 11): Loss/seq after 03800 batchs: 1318.1312255859375
INFO:root:Train (Epoch 11): Loss/seq after 03850 batchs: 1312.621826171875
INFO:root:Train (Epoch 11): Loss/seq after 03900 batchs: 1319.312255859375
INFO:root:Train (Epoch 11): Loss/seq after 03950 batchs: 1324.6495361328125
INFO:root:Train (Epoch 11): Loss/seq after 04000 batchs: 1314.501708984375
INFO:root:Train (Epoch 11): Loss/seq after 04050 batchs: 1305.330322265625
INFO:root:Train (Epoch 11): Loss/seq after 04100 batchs: 1300.797607421875
INFO:root:Train (Epoch 11): Loss/seq after 04150 batchs: 1294.9171142578125
INFO:root:Train (Epoch 11): Loss/seq after 04200 batchs: 1289.314453125
INFO:root:Train (Epoch 11): Loss/seq after 04250 batchs: 1284.4649658203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 11): Loss/seq after 00000 batches: 946.0309448242188
INFO:root:# Valid (Epoch 11): Loss/seq after 00050 batches: 1120.06884765625
INFO:root:# Valid (Epoch 11): Loss/seq after 00100 batches: 1453.0401611328125
INFO:root:# Valid (Epoch 11): Loss/seq after 00150 batches: 1225.661376953125
INFO:root:# Valid (Epoch 11): Loss/seq after 00200 batches: 1117.0289306640625
INFO:root:Artifacts: Make stick videos for epoch 11
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_11_on_20220422_003109.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_11_index_1306_on_20220422_003109.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 12): Loss/seq after 00000 batchs: 1825.746337890625
INFO:root:Train (Epoch 12): Loss/seq after 00050 batchs: 1793.551025390625
INFO:root:Train (Epoch 12): Loss/seq after 00100 batchs: 1727.78125
INFO:root:Train (Epoch 12): Loss/seq after 00150 batchs: 1539.6737060546875
INFO:root:Train (Epoch 12): Loss/seq after 00200 batchs: 1646.9114990234375
INFO:root:Train (Epoch 12): Loss/seq after 00250 batchs: 1753.7227783203125
INFO:root:Train (Epoch 12): Loss/seq after 00300 batchs: 1649.460693359375
INFO:root:Train (Epoch 12): Loss/seq after 00350 batchs: 1540.2491455078125
INFO:root:Train (Epoch 12): Loss/seq after 00400 batchs: 1590.257080078125
INFO:root:Train (Epoch 12): Loss/seq after 00450 batchs: 1511.357421875
INFO:root:Train (Epoch 12): Loss/seq after 00500 batchs: 1544.290283203125
INFO:root:Train (Epoch 12): Loss/seq after 00550 batchs: 1483.611328125
INFO:root:Train (Epoch 12): Loss/seq after 00600 batchs: 1451.2359619140625
INFO:root:Train (Epoch 12): Loss/seq after 00650 batchs: 1481.1390380859375
INFO:root:Train (Epoch 12): Loss/seq after 00700 batchs: 1503.2608642578125
INFO:root:Train (Epoch 12): Loss/seq after 00750 batchs: 1539.087158203125
INFO:root:Train (Epoch 12): Loss/seq after 00800 batchs: 1530.9486083984375
INFO:root:Train (Epoch 12): Loss/seq after 00850 batchs: 1498.85546875
INFO:root:Train (Epoch 12): Loss/seq after 00900 batchs: 1507.975830078125
INFO:root:Train (Epoch 12): Loss/seq after 00950 batchs: 1574.783935546875
INFO:root:Train (Epoch 12): Loss/seq after 01000 batchs: 1569.987060546875
INFO:root:Train (Epoch 12): Loss/seq after 01050 batchs: 1552.1300048828125
INFO:root:Train (Epoch 12): Loss/seq after 01100 batchs: 1543.1298828125
INFO:root:Train (Epoch 12): Loss/seq after 01150 batchs: 1520.593994140625
INFO:root:Train (Epoch 12): Loss/seq after 01200 batchs: 1505.786865234375
INFO:root:Train (Epoch 12): Loss/seq after 01250 batchs: 1501.833984375
INFO:root:Train (Epoch 12): Loss/seq after 01300 batchs: 1503.4080810546875
INFO:root:Train (Epoch 12): Loss/seq after 01350 batchs: 1498.732421875
INFO:root:Train (Epoch 12): Loss/seq after 01400 batchs: 1531.4818115234375
INFO:root:Train (Epoch 12): Loss/seq after 01450 batchs: 1519.069580078125
INFO:root:Train (Epoch 12): Loss/seq after 01500 batchs: 1504.46923828125
INFO:root:Train (Epoch 12): Loss/seq after 01550 batchs: 1506.2276611328125
INFO:root:Train (Epoch 12): Loss/seq after 01600 batchs: 1485.1588134765625
INFO:root:Train (Epoch 12): Loss/seq after 01650 batchs: 1477.4381103515625
INFO:root:Train (Epoch 12): Loss/seq after 01700 batchs: 1465.0101318359375
INFO:root:Train (Epoch 12): Loss/seq after 01750 batchs: 1449.5478515625
INFO:root:Train (Epoch 12): Loss/seq after 01800 batchs: 1432.4610595703125
INFO:root:Train (Epoch 12): Loss/seq after 01850 batchs: 1415.21630859375
INFO:root:Train (Epoch 12): Loss/seq after 01900 batchs: 1411.08837890625
INFO:root:Train (Epoch 12): Loss/seq after 01950 batchs: 1403.449462890625
INFO:root:Train (Epoch 12): Loss/seq after 02000 batchs: 1391.0841064453125
INFO:root:Train (Epoch 12): Loss/seq after 02050 batchs: 1380.4951171875
INFO:root:Train (Epoch 12): Loss/seq after 02100 batchs: 1366.5736083984375
INFO:root:Train (Epoch 12): Loss/seq after 02150 batchs: 1354.151123046875
INFO:root:Train (Epoch 12): Loss/seq after 02200 batchs: 1340.526611328125
INFO:root:Train (Epoch 12): Loss/seq after 02250 batchs: 1343.79638671875
INFO:root:Train (Epoch 12): Loss/seq after 02300 batchs: 1347.1258544921875
INFO:root:Train (Epoch 12): Loss/seq after 02350 batchs: 1336.38232421875
INFO:root:Train (Epoch 12): Loss/seq after 02400 batchs: 1331.0308837890625
INFO:root:Train (Epoch 12): Loss/seq after 02450 batchs: 1317.22119140625
INFO:root:Train (Epoch 12): Loss/seq after 02500 batchs: 1298.316650390625
INFO:root:Train (Epoch 12): Loss/seq after 02550 batchs: 1286.36181640625
INFO:root:Train (Epoch 12): Loss/seq after 02600 batchs: 1284.412109375
INFO:root:Train (Epoch 12): Loss/seq after 02650 batchs: 1278.4139404296875
INFO:root:Train (Epoch 12): Loss/seq after 02700 batchs: 1275.3280029296875
INFO:root:Train (Epoch 12): Loss/seq after 02750 batchs: 1306.587890625
INFO:root:Train (Epoch 12): Loss/seq after 02800 batchs: 1313.2255859375
INFO:root:Train (Epoch 12): Loss/seq after 02850 batchs: 1310.171875
INFO:root:Train (Epoch 12): Loss/seq after 02900 batchs: 1308.3223876953125
INFO:root:Train (Epoch 12): Loss/seq after 02950 batchs: 1299.836669921875
INFO:root:Train (Epoch 12): Loss/seq after 03000 batchs: 1296.3121337890625
INFO:root:Train (Epoch 12): Loss/seq after 03050 batchs: 1297.71484375
INFO:root:Train (Epoch 12): Loss/seq after 03100 batchs: 1312.74609375
INFO:root:Train (Epoch 12): Loss/seq after 03150 batchs: 1328.522705078125
INFO:root:Train (Epoch 12): Loss/seq after 03200 batchs: 1336.2911376953125
INFO:root:Train (Epoch 12): Loss/seq after 03250 batchs: 1343.974609375
INFO:root:Train (Epoch 12): Loss/seq after 03300 batchs: 1343.54638671875
INFO:root:Train (Epoch 12): Loss/seq after 03350 batchs: 1343.0740966796875
INFO:root:Train (Epoch 12): Loss/seq after 03400 batchs: 1332.9488525390625
INFO:root:Train (Epoch 12): Loss/seq after 03450 batchs: 1325.6204833984375
INFO:root:Train (Epoch 12): Loss/seq after 03500 batchs: 1324.80419921875
INFO:root:Train (Epoch 12): Loss/seq after 03550 batchs: 1319.43603515625
INFO:root:Train (Epoch 12): Loss/seq after 03600 batchs: 1324.29345703125
INFO:root:Train (Epoch 12): Loss/seq after 03650 batchs: 1319.198486328125
INFO:root:Train (Epoch 12): Loss/seq after 03700 batchs: 1318.3123779296875
INFO:root:Train (Epoch 12): Loss/seq after 03750 batchs: 1317.2520751953125
INFO:root:Train (Epoch 12): Loss/seq after 03800 batchs: 1309.568115234375
INFO:root:Train (Epoch 12): Loss/seq after 03850 batchs: 1304.42333984375
INFO:root:Train (Epoch 12): Loss/seq after 03900 batchs: 1310.22509765625
INFO:root:Train (Epoch 12): Loss/seq after 03950 batchs: 1316.5509033203125
INFO:root:Train (Epoch 12): Loss/seq after 04000 batchs: 1306.488525390625
INFO:root:Train (Epoch 12): Loss/seq after 04050 batchs: 1297.4107666015625
INFO:root:Train (Epoch 12): Loss/seq after 04100 batchs: 1293.189453125
INFO:root:Train (Epoch 12): Loss/seq after 04150 batchs: 1287.3507080078125
INFO:root:Train (Epoch 12): Loss/seq after 04200 batchs: 1282.1485595703125
INFO:root:Train (Epoch 12): Loss/seq after 04250 batchs: 1277.427001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 12): Loss/seq after 00000 batches: 989.4187622070312
INFO:root:# Valid (Epoch 12): Loss/seq after 00050 batches: 1140.41650390625
INFO:root:# Valid (Epoch 12): Loss/seq after 00100 batches: 1480.92431640625
INFO:root:# Valid (Epoch 12): Loss/seq after 00150 batches: 1226.42529296875
INFO:root:# Valid (Epoch 12): Loss/seq after 00200 batches: 1108.471923828125
INFO:root:Artifacts: Make stick videos for epoch 12
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_12_on_20220422_003553.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_12_index_391_on_20220422_003553.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 13): Loss/seq after 00000 batchs: 2046.471435546875
INFO:root:Train (Epoch 13): Loss/seq after 00050 batchs: 1777.2706298828125
INFO:root:Train (Epoch 13): Loss/seq after 00100 batchs: 1716.3079833984375
INFO:root:Train (Epoch 13): Loss/seq after 00150 batchs: 1555.2491455078125
INFO:root:Train (Epoch 13): Loss/seq after 00200 batchs: 1662.0611572265625
INFO:root:Train (Epoch 13): Loss/seq after 00250 batchs: 1768.1011962890625
INFO:root:Train (Epoch 13): Loss/seq after 00300 batchs: 1661.2271728515625
INFO:root:Train (Epoch 13): Loss/seq after 00350 batchs: 1550.245849609375
INFO:root:Train (Epoch 13): Loss/seq after 00400 batchs: 1599.3631591796875
INFO:root:Train (Epoch 13): Loss/seq after 00450 batchs: 1519.420166015625
INFO:root:Train (Epoch 13): Loss/seq after 00500 batchs: 1554.139892578125
INFO:root:Train (Epoch 13): Loss/seq after 00550 batchs: 1488.09228515625
INFO:root:Train (Epoch 13): Loss/seq after 00600 batchs: 1453.0986328125
INFO:root:Train (Epoch 13): Loss/seq after 00650 batchs: 1482.0396728515625
INFO:root:Train (Epoch 13): Loss/seq after 00700 batchs: 1507.5032958984375
INFO:root:Train (Epoch 13): Loss/seq after 00750 batchs: 1539.7374267578125
INFO:root:Train (Epoch 13): Loss/seq after 00800 batchs: 1529.041748046875
INFO:root:Train (Epoch 13): Loss/seq after 00850 batchs: 1497.5634765625
INFO:root:Train (Epoch 13): Loss/seq after 00900 batchs: 1504.05615234375
INFO:root:Train (Epoch 13): Loss/seq after 00950 batchs: 1571.0562744140625
INFO:root:Train (Epoch 13): Loss/seq after 01000 batchs: 1569.38720703125
INFO:root:Train (Epoch 13): Loss/seq after 01050 batchs: 1551.5933837890625
INFO:root:Train (Epoch 13): Loss/seq after 01100 batchs: 1542.318359375
INFO:root:Train (Epoch 13): Loss/seq after 01150 batchs: 1520.258544921875
INFO:root:Train (Epoch 13): Loss/seq after 01200 batchs: 1506.1295166015625
INFO:root:Train (Epoch 13): Loss/seq after 01250 batchs: 1500.533447265625
INFO:root:Train (Epoch 13): Loss/seq after 01300 batchs: 1500.89892578125
INFO:root:Train (Epoch 13): Loss/seq after 01350 batchs: 1496.6754150390625
INFO:root:Train (Epoch 13): Loss/seq after 01400 batchs: 1538.9970703125
INFO:root:Train (Epoch 13): Loss/seq after 01450 batchs: 1525.9649658203125
INFO:root:Train (Epoch 13): Loss/seq after 01500 batchs: 1511.1876220703125
INFO:root:Train (Epoch 13): Loss/seq after 01550 batchs: 1512.5032958984375
INFO:root:Train (Epoch 13): Loss/seq after 01600 batchs: 1491.310791015625
INFO:root:Train (Epoch 13): Loss/seq after 01650 batchs: 1483.5445556640625
INFO:root:Train (Epoch 13): Loss/seq after 01700 batchs: 1470.98388671875
INFO:root:Train (Epoch 13): Loss/seq after 01750 batchs: 1455.4788818359375
INFO:root:Train (Epoch 13): Loss/seq after 01800 batchs: 1438.27197265625
INFO:root:Train (Epoch 13): Loss/seq after 01850 batchs: 1420.882568359375
INFO:root:Train (Epoch 13): Loss/seq after 01900 batchs: 1416.476806640625
INFO:root:Train (Epoch 13): Loss/seq after 01950 batchs: 1408.5682373046875
INFO:root:Train (Epoch 13): Loss/seq after 02000 batchs: 1396.072998046875
INFO:root:Train (Epoch 13): Loss/seq after 02050 batchs: 1385.2271728515625
INFO:root:Train (Epoch 13): Loss/seq after 02100 batchs: 1371.206298828125
INFO:root:Train (Epoch 13): Loss/seq after 02150 batchs: 1358.728271484375
INFO:root:Train (Epoch 13): Loss/seq after 02200 batchs: 1344.99609375
INFO:root:Train (Epoch 13): Loss/seq after 02250 batchs: 1349.475341796875
INFO:root:Train (Epoch 13): Loss/seq after 02300 batchs: 1354.0869140625
INFO:root:Train (Epoch 13): Loss/seq after 02350 batchs: 1343.107666015625
INFO:root:Train (Epoch 13): Loss/seq after 02400 batchs: 1337.4459228515625
INFO:root:Train (Epoch 13): Loss/seq after 02450 batchs: 1323.3929443359375
INFO:root:Train (Epoch 13): Loss/seq after 02500 batchs: 1304.3485107421875
INFO:root:Train (Epoch 13): Loss/seq after 02550 batchs: 1292.2318115234375
INFO:root:Train (Epoch 13): Loss/seq after 02600 batchs: 1290.2528076171875
INFO:root:Train (Epoch 13): Loss/seq after 02650 batchs: 1284.53662109375
INFO:root:Train (Epoch 13): Loss/seq after 02700 batchs: 1280.737548828125
INFO:root:Train (Epoch 13): Loss/seq after 02750 batchs: 1312.4017333984375
INFO:root:Train (Epoch 13): Loss/seq after 02800 batchs: 1317.6591796875
INFO:root:Train (Epoch 13): Loss/seq after 02850 batchs: 1314.7994384765625
INFO:root:Train (Epoch 13): Loss/seq after 02900 batchs: 1312.51611328125
INFO:root:Train (Epoch 13): Loss/seq after 02950 batchs: 1303.9949951171875
INFO:root:Train (Epoch 13): Loss/seq after 03000 batchs: 1300.4073486328125
INFO:root:Train (Epoch 13): Loss/seq after 03050 batchs: 1301.7325439453125
INFO:root:Train (Epoch 13): Loss/seq after 03100 batchs: 1317.54345703125
INFO:root:Train (Epoch 13): Loss/seq after 03150 batchs: 1331.163818359375
INFO:root:Train (Epoch 13): Loss/seq after 03200 batchs: 1339.18603515625
INFO:root:Train (Epoch 13): Loss/seq after 03250 batchs: 1345.6573486328125
INFO:root:Train (Epoch 13): Loss/seq after 03300 batchs: 1345.5740966796875
INFO:root:Train (Epoch 13): Loss/seq after 03350 batchs: 1345.346923828125
INFO:root:Train (Epoch 13): Loss/seq after 03400 batchs: 1335.4237060546875
INFO:root:Train (Epoch 13): Loss/seq after 03450 batchs: 1330.5831298828125
INFO:root:Train (Epoch 13): Loss/seq after 03500 batchs: 1330.929443359375
INFO:root:Train (Epoch 13): Loss/seq after 03550 batchs: 1325.9248046875
INFO:root:Train (Epoch 13): Loss/seq after 03600 batchs: 1331.0465087890625
INFO:root:Train (Epoch 13): Loss/seq after 03650 batchs: 1325.9298095703125
INFO:root:Train (Epoch 13): Loss/seq after 03700 batchs: 1324.7440185546875
INFO:root:Train (Epoch 13): Loss/seq after 03750 batchs: 1323.42626953125
INFO:root:Train (Epoch 13): Loss/seq after 03800 batchs: 1315.5240478515625
INFO:root:Train (Epoch 13): Loss/seq after 03850 batchs: 1310.1097412109375
INFO:root:Train (Epoch 13): Loss/seq after 03900 batchs: 1317.586669921875
INFO:root:Train (Epoch 13): Loss/seq after 03950 batchs: 1323.255859375
INFO:root:Train (Epoch 13): Loss/seq after 04000 batchs: 1313.1356201171875
INFO:root:Train (Epoch 13): Loss/seq after 04050 batchs: 1303.9912109375
INFO:root:Train (Epoch 13): Loss/seq after 04100 batchs: 1299.3687744140625
INFO:root:Train (Epoch 13): Loss/seq after 04150 batchs: 1293.036376953125
INFO:root:Train (Epoch 13): Loss/seq after 04200 batchs: 1287.5396728515625
INFO:root:Train (Epoch 13): Loss/seq after 04250 batchs: 1282.2269287109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 13): Loss/seq after 00000 batches: 933.4893798828125
INFO:root:# Valid (Epoch 13): Loss/seq after 00050 batches: 1116.22119140625
INFO:root:# Valid (Epoch 13): Loss/seq after 00100 batches: 1483.51123046875
INFO:root:# Valid (Epoch 13): Loss/seq after 00150 batches: 1243.1395263671875
INFO:root:# Valid (Epoch 13): Loss/seq after 00200 batches: 1134.71240234375
INFO:root:Artifacts: Make stick videos for epoch 13
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_13_on_20220422_004102.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_13_index_1491_on_20220422_004102.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 14): Loss/seq after 00000 batchs: 1920.66357421875
INFO:root:Train (Epoch 14): Loss/seq after 00050 batchs: 1735.912109375
INFO:root:Train (Epoch 14): Loss/seq after 00100 batchs: 1676.5457763671875
INFO:root:Train (Epoch 14): Loss/seq after 00150 batchs: 1532.3121337890625
INFO:root:Train (Epoch 14): Loss/seq after 00200 batchs: 1636.1031494140625
INFO:root:Train (Epoch 14): Loss/seq after 00250 batchs: 1749.23291015625
INFO:root:Train (Epoch 14): Loss/seq after 00300 batchs: 1646.4761962890625
INFO:root:Train (Epoch 14): Loss/seq after 00350 batchs: 1538.2081298828125
INFO:root:Train (Epoch 14): Loss/seq after 00400 batchs: 1598.609130859375
INFO:root:Train (Epoch 14): Loss/seq after 00450 batchs: 1518.7440185546875
INFO:root:Train (Epoch 14): Loss/seq after 00500 batchs: 1549.166748046875
INFO:root:Train (Epoch 14): Loss/seq after 00550 batchs: 1485.81787109375
INFO:root:Train (Epoch 14): Loss/seq after 00600 batchs: 1448.8048095703125
INFO:root:Train (Epoch 14): Loss/seq after 00650 batchs: 1476.1649169921875
INFO:root:Train (Epoch 14): Loss/seq after 00700 batchs: 1504.7379150390625
INFO:root:Train (Epoch 14): Loss/seq after 00750 batchs: 1537.791259765625
INFO:root:Train (Epoch 14): Loss/seq after 00800 batchs: 1527.3790283203125
INFO:root:Train (Epoch 14): Loss/seq after 00850 batchs: 1496.3585205078125
INFO:root:Train (Epoch 14): Loss/seq after 00900 batchs: 1501.145263671875
INFO:root:Train (Epoch 14): Loss/seq after 00950 batchs: 1562.391845703125
INFO:root:Train (Epoch 14): Loss/seq after 01000 batchs: 1564.3919677734375
INFO:root:Train (Epoch 14): Loss/seq after 01050 batchs: 1545.9637451171875
INFO:root:Train (Epoch 14): Loss/seq after 01100 batchs: 1535.3409423828125
INFO:root:Train (Epoch 14): Loss/seq after 01150 batchs: 1515.18701171875
INFO:root:Train (Epoch 14): Loss/seq after 01200 batchs: 1500.9425048828125
INFO:root:Train (Epoch 14): Loss/seq after 01250 batchs: 1496.9605712890625
INFO:root:Train (Epoch 14): Loss/seq after 01300 batchs: 1497.022705078125
INFO:root:Train (Epoch 14): Loss/seq after 01350 batchs: 1491.7760009765625
INFO:root:Train (Epoch 14): Loss/seq after 01400 batchs: 1526.6993408203125
INFO:root:Train (Epoch 14): Loss/seq after 01450 batchs: 1513.591796875
INFO:root:Train (Epoch 14): Loss/seq after 01500 batchs: 1499.15625
INFO:root:Train (Epoch 14): Loss/seq after 01550 batchs: 1499.7794189453125
INFO:root:Train (Epoch 14): Loss/seq after 01600 batchs: 1479.16259765625
INFO:root:Train (Epoch 14): Loss/seq after 01650 batchs: 1470.9599609375
INFO:root:Train (Epoch 14): Loss/seq after 01700 batchs: 1458.4031982421875
INFO:root:Train (Epoch 14): Loss/seq after 01750 batchs: 1443.0447998046875
INFO:root:Train (Epoch 14): Loss/seq after 01800 batchs: 1426.0035400390625
INFO:root:Train (Epoch 14): Loss/seq after 01850 batchs: 1409.0556640625
INFO:root:Train (Epoch 14): Loss/seq after 01900 batchs: 1404.9564208984375
INFO:root:Train (Epoch 14): Loss/seq after 01950 batchs: 1397.3013916015625
INFO:root:Train (Epoch 14): Loss/seq after 02000 batchs: 1384.9154052734375
INFO:root:Train (Epoch 14): Loss/seq after 02050 batchs: 1374.3636474609375
INFO:root:Train (Epoch 14): Loss/seq after 02100 batchs: 1360.6005859375
INFO:root:Train (Epoch 14): Loss/seq after 02150 batchs: 1348.2342529296875
INFO:root:Train (Epoch 14): Loss/seq after 02200 batchs: 1334.72802734375
INFO:root:Train (Epoch 14): Loss/seq after 02250 batchs: 1339.5333251953125
INFO:root:Train (Epoch 14): Loss/seq after 02300 batchs: 1343.3878173828125
INFO:root:Train (Epoch 14): Loss/seq after 02350 batchs: 1332.826171875
INFO:root:Train (Epoch 14): Loss/seq after 02400 batchs: 1327.2747802734375
INFO:root:Train (Epoch 14): Loss/seq after 02450 batchs: 1313.13427734375
INFO:root:Train (Epoch 14): Loss/seq after 02500 batchs: 1294.24365234375
INFO:root:Train (Epoch 14): Loss/seq after 02550 batchs: 1282.053955078125
INFO:root:Train (Epoch 14): Loss/seq after 02600 batchs: 1279.7286376953125
INFO:root:Train (Epoch 14): Loss/seq after 02650 batchs: 1273.8485107421875
INFO:root:Train (Epoch 14): Loss/seq after 02700 batchs: 1271.3345947265625
INFO:root:Train (Epoch 14): Loss/seq after 02750 batchs: 1301.3499755859375
INFO:root:Train (Epoch 14): Loss/seq after 02800 batchs: 1307.0308837890625
INFO:root:Train (Epoch 14): Loss/seq after 02850 batchs: 1303.811279296875
INFO:root:Train (Epoch 14): Loss/seq after 02900 batchs: 1301.25732421875
INFO:root:Train (Epoch 14): Loss/seq after 02950 batchs: 1292.7564697265625
INFO:root:Train (Epoch 14): Loss/seq after 03000 batchs: 1289.3458251953125
INFO:root:Train (Epoch 14): Loss/seq after 03050 batchs: 1290.86669921875
INFO:root:Train (Epoch 14): Loss/seq after 03100 batchs: 1306.1484375
INFO:root:Train (Epoch 14): Loss/seq after 03150 batchs: 1320.730224609375
INFO:root:Train (Epoch 14): Loss/seq after 03200 batchs: 1327.49658203125
INFO:root:Train (Epoch 14): Loss/seq after 03250 batchs: 1334.3736572265625
INFO:root:Train (Epoch 14): Loss/seq after 03300 batchs: 1333.8148193359375
INFO:root:Train (Epoch 14): Loss/seq after 03350 batchs: 1334.18212890625
INFO:root:Train (Epoch 14): Loss/seq after 03400 batchs: 1324.25830078125
INFO:root:Train (Epoch 14): Loss/seq after 03450 batchs: 1317.2210693359375
INFO:root:Train (Epoch 14): Loss/seq after 03500 batchs: 1316.7835693359375
INFO:root:Train (Epoch 14): Loss/seq after 03550 batchs: 1311.36669921875
INFO:root:Train (Epoch 14): Loss/seq after 03600 batchs: 1316.4970703125
INFO:root:Train (Epoch 14): Loss/seq after 03650 batchs: 1312.0074462890625
INFO:root:Train (Epoch 14): Loss/seq after 03700 batchs: 1311.171875
INFO:root:Train (Epoch 14): Loss/seq after 03750 batchs: 1310.0777587890625
INFO:root:Train (Epoch 14): Loss/seq after 03800 batchs: 1302.51318359375
INFO:root:Train (Epoch 14): Loss/seq after 03850 batchs: 1297.4044189453125
INFO:root:Train (Epoch 14): Loss/seq after 03900 batchs: 1304.8350830078125
INFO:root:Train (Epoch 14): Loss/seq after 03950 batchs: 1311.7301025390625
INFO:root:Train (Epoch 14): Loss/seq after 04000 batchs: 1301.7535400390625
INFO:root:Train (Epoch 14): Loss/seq after 04050 batchs: 1292.7401123046875
INFO:root:Train (Epoch 14): Loss/seq after 04100 batchs: 1288.8336181640625
INFO:root:Train (Epoch 14): Loss/seq after 04150 batchs: 1283.018798828125
INFO:root:Train (Epoch 14): Loss/seq after 04200 batchs: 1278.3966064453125
INFO:root:Train (Epoch 14): Loss/seq after 04250 batchs: 1273.598388671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 14): Loss/seq after 00000 batches: 975.0340576171875
INFO:root:# Valid (Epoch 14): Loss/seq after 00050 batches: 1132.5306396484375
INFO:root:# Valid (Epoch 14): Loss/seq after 00100 batches: 1489.7008056640625
INFO:root:# Valid (Epoch 14): Loss/seq after 00150 batches: 1234.142333984375
INFO:root:# Valid (Epoch 14): Loss/seq after 00200 batches: 1116.9940185546875
INFO:root:Artifacts: Make stick videos for epoch 14
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_14_on_20220422_004557.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_14_index_282_on_20220422_004557.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 15): Loss/seq after 00000 batchs: 2129.58837890625
INFO:root:Train (Epoch 15): Loss/seq after 00050 batchs: 1780.4234619140625
INFO:root:Train (Epoch 15): Loss/seq after 00100 batchs: 1735.795166015625
INFO:root:Train (Epoch 15): Loss/seq after 00150 batchs: 1563.8572998046875
INFO:root:Train (Epoch 15): Loss/seq after 00200 batchs: 1666.10791015625
INFO:root:Train (Epoch 15): Loss/seq after 00250 batchs: 1776.9736328125
INFO:root:Train (Epoch 15): Loss/seq after 00300 batchs: 1670.4276123046875
INFO:root:Train (Epoch 15): Loss/seq after 00350 batchs: 1558.0579833984375
INFO:root:Train (Epoch 15): Loss/seq after 00400 batchs: 1607.761474609375
INFO:root:Train (Epoch 15): Loss/seq after 00450 batchs: 1527.001220703125
INFO:root:Train (Epoch 15): Loss/seq after 00500 batchs: 1557.9632568359375
INFO:root:Train (Epoch 15): Loss/seq after 00550 batchs: 1492.33984375
INFO:root:Train (Epoch 15): Loss/seq after 00600 batchs: 1456.579833984375
INFO:root:Train (Epoch 15): Loss/seq after 00650 batchs: 1486.5477294921875
INFO:root:Train (Epoch 15): Loss/seq after 00700 batchs: 1505.8621826171875
INFO:root:Train (Epoch 15): Loss/seq after 00750 batchs: 1536.1285400390625
INFO:root:Train (Epoch 15): Loss/seq after 00800 batchs: 1525.9097900390625
INFO:root:Train (Epoch 15): Loss/seq after 00850 batchs: 1492.4779052734375
INFO:root:Train (Epoch 15): Loss/seq after 00900 batchs: 1500.5567626953125
INFO:root:Train (Epoch 15): Loss/seq after 00950 batchs: 1563.38671875
INFO:root:Train (Epoch 15): Loss/seq after 01000 batchs: 1559.17724609375
INFO:root:Train (Epoch 15): Loss/seq after 01050 batchs: 1541.2093505859375
INFO:root:Train (Epoch 15): Loss/seq after 01100 batchs: 1531.5177001953125
INFO:root:Train (Epoch 15): Loss/seq after 01150 batchs: 1508.53857421875
INFO:root:Train (Epoch 15): Loss/seq after 01200 batchs: 1493.2408447265625
INFO:root:Train (Epoch 15): Loss/seq after 01250 batchs: 1484.5115966796875
INFO:root:Train (Epoch 15): Loss/seq after 01300 batchs: 1487.1571044921875
INFO:root:Train (Epoch 15): Loss/seq after 01350 batchs: 1483.36669921875
INFO:root:Train (Epoch 15): Loss/seq after 01400 batchs: 1514.7542724609375
INFO:root:Train (Epoch 15): Loss/seq after 01450 batchs: 1501.1356201171875
INFO:root:Train (Epoch 15): Loss/seq after 01500 batchs: 1487.1585693359375
INFO:root:Train (Epoch 15): Loss/seq after 01550 batchs: 1487.8775634765625
INFO:root:Train (Epoch 15): Loss/seq after 01600 batchs: 1467.2686767578125
INFO:root:Train (Epoch 15): Loss/seq after 01650 batchs: 1459.2034912109375
INFO:root:Train (Epoch 15): Loss/seq after 01700 batchs: 1447.6700439453125
INFO:root:Train (Epoch 15): Loss/seq after 01750 batchs: 1432.6539306640625
INFO:root:Train (Epoch 15): Loss/seq after 01800 batchs: 1416.1190185546875
INFO:root:Train (Epoch 15): Loss/seq after 01850 batchs: 1399.3299560546875
INFO:root:Train (Epoch 15): Loss/seq after 01900 batchs: 1395.566650390625
INFO:root:Train (Epoch 15): Loss/seq after 01950 batchs: 1388.1153564453125
INFO:root:Train (Epoch 15): Loss/seq after 02000 batchs: 1376.2236328125
INFO:root:Train (Epoch 15): Loss/seq after 02050 batchs: 1365.90673828125
INFO:root:Train (Epoch 15): Loss/seq after 02100 batchs: 1352.3543701171875
INFO:root:Train (Epoch 15): Loss/seq after 02150 batchs: 1340.247802734375
INFO:root:Train (Epoch 15): Loss/seq after 02200 batchs: 1326.8896484375
INFO:root:Train (Epoch 15): Loss/seq after 02250 batchs: 1330.2679443359375
INFO:root:Train (Epoch 15): Loss/seq after 02300 batchs: 1334.580322265625
INFO:root:Train (Epoch 15): Loss/seq after 02350 batchs: 1324.086181640625
INFO:root:Train (Epoch 15): Loss/seq after 02400 batchs: 1318.9114990234375
INFO:root:Train (Epoch 15): Loss/seq after 02450 batchs: 1305.1590576171875
INFO:root:Train (Epoch 15): Loss/seq after 02500 batchs: 1286.4722900390625
INFO:root:Train (Epoch 15): Loss/seq after 02550 batchs: 1274.7899169921875
INFO:root:Train (Epoch 15): Loss/seq after 02600 batchs: 1272.0767822265625
INFO:root:Train (Epoch 15): Loss/seq after 02650 batchs: 1266.9974365234375
INFO:root:Train (Epoch 15): Loss/seq after 02700 batchs: 1262.955810546875
INFO:root:Train (Epoch 15): Loss/seq after 02750 batchs: 1293.05615234375
INFO:root:Train (Epoch 15): Loss/seq after 02800 batchs: 1300.19140625
INFO:root:Train (Epoch 15): Loss/seq after 02850 batchs: 1297.4332275390625
INFO:root:Train (Epoch 15): Loss/seq after 02900 batchs: 1295.3204345703125
INFO:root:Train (Epoch 15): Loss/seq after 02950 batchs: 1287.0059814453125
INFO:root:Train (Epoch 15): Loss/seq after 03000 batchs: 1283.689208984375
INFO:root:Train (Epoch 15): Loss/seq after 03050 batchs: 1285.295166015625
INFO:root:Train (Epoch 15): Loss/seq after 03100 batchs: 1300.2177734375
INFO:root:Train (Epoch 15): Loss/seq after 03150 batchs: 1315.4058837890625
INFO:root:Train (Epoch 15): Loss/seq after 03200 batchs: 1325.262451171875
INFO:root:Train (Epoch 15): Loss/seq after 03250 batchs: 1331.1551513671875
INFO:root:Train (Epoch 15): Loss/seq after 03300 batchs: 1330.4664306640625
INFO:root:Train (Epoch 15): Loss/seq after 03350 batchs: 1329.8790283203125
INFO:root:Train (Epoch 15): Loss/seq after 03400 batchs: 1320.1300048828125
INFO:root:Train (Epoch 15): Loss/seq after 03450 batchs: 1315.88525390625
INFO:root:Train (Epoch 15): Loss/seq after 03500 batchs: 1317.4681396484375
INFO:root:Train (Epoch 15): Loss/seq after 03550 batchs: 1312.5423583984375
INFO:root:Train (Epoch 15): Loss/seq after 03600 batchs: 1317.8453369140625
INFO:root:Train (Epoch 15): Loss/seq after 03650 batchs: 1312.89794921875
INFO:root:Train (Epoch 15): Loss/seq after 03700 batchs: 1311.93359375
INFO:root:Train (Epoch 15): Loss/seq after 03750 batchs: 1310.83056640625
INFO:root:Train (Epoch 15): Loss/seq after 03800 batchs: 1303.0677490234375
INFO:root:Train (Epoch 15): Loss/seq after 03850 batchs: 1297.800537109375
INFO:root:Train (Epoch 15): Loss/seq after 03900 batchs: 1302.3695068359375
INFO:root:Train (Epoch 15): Loss/seq after 03950 batchs: 1309.509033203125
INFO:root:Train (Epoch 15): Loss/seq after 04000 batchs: 1299.6041259765625
INFO:root:Train (Epoch 15): Loss/seq after 04050 batchs: 1290.625732421875
INFO:root:Train (Epoch 15): Loss/seq after 04100 batchs: 1285.86572265625
INFO:root:Train (Epoch 15): Loss/seq after 04150 batchs: 1279.5213623046875
INFO:root:Train (Epoch 15): Loss/seq after 04200 batchs: 1274.310546875
INFO:root:Train (Epoch 15): Loss/seq after 04250 batchs: 1269.52734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 15): Loss/seq after 00000 batches: 934.81201171875
INFO:root:# Valid (Epoch 15): Loss/seq after 00050 batches: 1114.82177734375
INFO:root:# Valid (Epoch 15): Loss/seq after 00100 batches: 1444.69677734375
INFO:root:# Valid (Epoch 15): Loss/seq after 00150 batches: 1225.5679931640625
INFO:root:# Valid (Epoch 15): Loss/seq after 00200 batches: 1119.5830078125
INFO:root:Artifacts: Make stick videos for epoch 15
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_15_on_20220422_005042.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_15_index_1135_on_20220422_005042.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 16): Loss/seq after 00000 batchs: 2445.183349609375
INFO:root:Train (Epoch 16): Loss/seq after 00050 batchs: 1740.3568115234375
INFO:root:Train (Epoch 16): Loss/seq after 00100 batchs: 1693.2459716796875
INFO:root:Train (Epoch 16): Loss/seq after 00150 batchs: 1545.7430419921875
INFO:root:Train (Epoch 16): Loss/seq after 00200 batchs: 1654.4736328125
INFO:root:Train (Epoch 16): Loss/seq after 00250 batchs: 1763.5367431640625
INFO:root:Train (Epoch 16): Loss/seq after 00300 batchs: 1658.908935546875
INFO:root:Train (Epoch 16): Loss/seq after 00350 batchs: 1548.885986328125
INFO:root:Train (Epoch 16): Loss/seq after 00400 batchs: 1602.2330322265625
INFO:root:Train (Epoch 16): Loss/seq after 00450 batchs: 1522.0767822265625
INFO:root:Train (Epoch 16): Loss/seq after 00500 batchs: 1555.4345703125
INFO:root:Train (Epoch 16): Loss/seq after 00550 batchs: 1488.5533447265625
INFO:root:Train (Epoch 16): Loss/seq after 00600 batchs: 1450.982666015625
INFO:root:Train (Epoch 16): Loss/seq after 00650 batchs: 1484.080810546875
INFO:root:Train (Epoch 16): Loss/seq after 00700 batchs: 1505.2130126953125
INFO:root:Train (Epoch 16): Loss/seq after 00750 batchs: 1536.08447265625
INFO:root:Train (Epoch 16): Loss/seq after 00800 batchs: 1525.4261474609375
INFO:root:Train (Epoch 16): Loss/seq after 00850 batchs: 1495.1934814453125
INFO:root:Train (Epoch 16): Loss/seq after 00900 batchs: 1502.209716796875
INFO:root:Train (Epoch 16): Loss/seq after 00950 batchs: 1561.234375
INFO:root:Train (Epoch 16): Loss/seq after 01000 batchs: 1553.6964111328125
INFO:root:Train (Epoch 16): Loss/seq after 01050 batchs: 1534.7510986328125
INFO:root:Train (Epoch 16): Loss/seq after 01100 batchs: 1522.73046875
INFO:root:Train (Epoch 16): Loss/seq after 01150 batchs: 1499.8123779296875
INFO:root:Train (Epoch 16): Loss/seq after 01200 batchs: 1483.7081298828125
INFO:root:Train (Epoch 16): Loss/seq after 01250 batchs: 1474.759765625
INFO:root:Train (Epoch 16): Loss/seq after 01300 batchs: 1479.072509765625
INFO:root:Train (Epoch 16): Loss/seq after 01350 batchs: 1474.185546875
INFO:root:Train (Epoch 16): Loss/seq after 01400 batchs: 1503.828125
INFO:root:Train (Epoch 16): Loss/seq after 01450 batchs: 1489.1251220703125
INFO:root:Train (Epoch 16): Loss/seq after 01500 batchs: 1475.950927734375
INFO:root:Train (Epoch 16): Loss/seq after 01550 batchs: 1476.6944580078125
INFO:root:Train (Epoch 16): Loss/seq after 01600 batchs: 1456.014404296875
INFO:root:Train (Epoch 16): Loss/seq after 01650 batchs: 1447.5303955078125
INFO:root:Train (Epoch 16): Loss/seq after 01700 batchs: 1435.3128662109375
INFO:root:Train (Epoch 16): Loss/seq after 01750 batchs: 1420.22802734375
INFO:root:Train (Epoch 16): Loss/seq after 01800 batchs: 1403.3311767578125
INFO:root:Train (Epoch 16): Loss/seq after 01850 batchs: 1386.8746337890625
INFO:root:Train (Epoch 16): Loss/seq after 01900 batchs: 1383.234619140625
INFO:root:Train (Epoch 16): Loss/seq after 01950 batchs: 1376.314208984375
INFO:root:Train (Epoch 16): Loss/seq after 02000 batchs: 1364.5123291015625
INFO:root:Train (Epoch 16): Loss/seq after 02050 batchs: 1354.521484375
INFO:root:Train (Epoch 16): Loss/seq after 02100 batchs: 1341.23828125
INFO:root:Train (Epoch 16): Loss/seq after 02150 batchs: 1329.2744140625
INFO:root:Train (Epoch 16): Loss/seq after 02200 batchs: 1316.1671142578125
INFO:root:Train (Epoch 16): Loss/seq after 02250 batchs: 1319.7310791015625
INFO:root:Train (Epoch 16): Loss/seq after 02300 batchs: 1323.9005126953125
INFO:root:Train (Epoch 16): Loss/seq after 02350 batchs: 1313.988037109375
INFO:root:Train (Epoch 16): Loss/seq after 02400 batchs: 1309.5457763671875
INFO:root:Train (Epoch 16): Loss/seq after 02450 batchs: 1296.84912109375
INFO:root:Train (Epoch 16): Loss/seq after 02500 batchs: 1278.34619140625
INFO:root:Train (Epoch 16): Loss/seq after 02550 batchs: 1268.647705078125
INFO:root:Train (Epoch 16): Loss/seq after 02600 batchs: 1267.71728515625
INFO:root:Train (Epoch 16): Loss/seq after 02650 batchs: 1262.377685546875
INFO:root:Train (Epoch 16): Loss/seq after 02700 batchs: 1258.7032470703125
INFO:root:Train (Epoch 16): Loss/seq after 02750 batchs: 1289.0672607421875
INFO:root:Train (Epoch 16): Loss/seq after 02800 batchs: 1297.827392578125
INFO:root:Train (Epoch 16): Loss/seq after 02850 batchs: 1295.141357421875
INFO:root:Train (Epoch 16): Loss/seq after 02900 batchs: 1292.914306640625
INFO:root:Train (Epoch 16): Loss/seq after 02950 batchs: 1284.7239990234375
INFO:root:Train (Epoch 16): Loss/seq after 03000 batchs: 1281.4493408203125
INFO:root:Train (Epoch 16): Loss/seq after 03050 batchs: 1283.0509033203125
INFO:root:Train (Epoch 16): Loss/seq after 03100 batchs: 1297.8338623046875
INFO:root:Train (Epoch 16): Loss/seq after 03150 batchs: 1315.2489013671875
INFO:root:Train (Epoch 16): Loss/seq after 03200 batchs: 1324.085205078125
INFO:root:Train (Epoch 16): Loss/seq after 03250 batchs: 1330.533203125
INFO:root:Train (Epoch 16): Loss/seq after 03300 batchs: 1330.8814697265625
INFO:root:Train (Epoch 16): Loss/seq after 03350 batchs: 1330.0247802734375
INFO:root:Train (Epoch 16): Loss/seq after 03400 batchs: 1320.2711181640625
INFO:root:Train (Epoch 16): Loss/seq after 03450 batchs: 1315.931396484375
INFO:root:Train (Epoch 16): Loss/seq after 03500 batchs: 1318.4925537109375
INFO:root:Train (Epoch 16): Loss/seq after 03550 batchs: 1313.8741455078125
INFO:root:Train (Epoch 16): Loss/seq after 03600 batchs: 1319.7484130859375
INFO:root:Train (Epoch 16): Loss/seq after 03650 batchs: 1315.14794921875
INFO:root:Train (Epoch 16): Loss/seq after 03700 batchs: 1314.2476806640625
INFO:root:Train (Epoch 16): Loss/seq after 03750 batchs: 1313.0819091796875
INFO:root:Train (Epoch 16): Loss/seq after 03800 batchs: 1305.2008056640625
INFO:root:Train (Epoch 16): Loss/seq after 03850 batchs: 1299.8779296875
INFO:root:Train (Epoch 16): Loss/seq after 03900 batchs: 1305.1746826171875
INFO:root:Train (Epoch 16): Loss/seq after 03950 batchs: 1311.0087890625
INFO:root:Train (Epoch 16): Loss/seq after 04000 batchs: 1301.0751953125
INFO:root:Train (Epoch 16): Loss/seq after 04050 batchs: 1292.0946044921875
INFO:root:Train (Epoch 16): Loss/seq after 04100 batchs: 1288.0777587890625
INFO:root:Train (Epoch 16): Loss/seq after 04150 batchs: 1282.318359375
INFO:root:Train (Epoch 16): Loss/seq after 04200 batchs: 1276.89111328125
INFO:root:Train (Epoch 16): Loss/seq after 04250 batchs: 1271.8958740234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 16): Loss/seq after 00000 batches: 947.9689331054688
INFO:root:# Valid (Epoch 16): Loss/seq after 00050 batches: 1121.7144775390625
INFO:root:# Valid (Epoch 16): Loss/seq after 00100 batches: 1458.5264892578125
INFO:root:# Valid (Epoch 16): Loss/seq after 00150 batches: 1219.137939453125
INFO:root:# Valid (Epoch 16): Loss/seq after 00200 batches: 1112.0758056640625
INFO:root:Artifacts: Make stick videos for epoch 16
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_16_on_20220422_005530.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_16_index_1245_on_20220422_005530.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 17): Loss/seq after 00000 batchs: 2527.370361328125
INFO:root:Train (Epoch 17): Loss/seq after 00050 batchs: 1696.5875244140625
INFO:root:Train (Epoch 17): Loss/seq after 00100 batchs: 1659.0494384765625
INFO:root:Train (Epoch 17): Loss/seq after 00150 batchs: 1503.04248046875
INFO:root:Train (Epoch 17): Loss/seq after 00200 batchs: 1613.814697265625
INFO:root:Train (Epoch 17): Loss/seq after 00250 batchs: 1719.1624755859375
INFO:root:Train (Epoch 17): Loss/seq after 00300 batchs: 1619.4056396484375
INFO:root:Train (Epoch 17): Loss/seq after 00350 batchs: 1514.6820068359375
INFO:root:Train (Epoch 17): Loss/seq after 00400 batchs: 1564.8726806640625
INFO:root:Train (Epoch 17): Loss/seq after 00450 batchs: 1488.762451171875
INFO:root:Train (Epoch 17): Loss/seq after 00500 batchs: 1515.800048828125
INFO:root:Train (Epoch 17): Loss/seq after 00550 batchs: 1453.4202880859375
INFO:root:Train (Epoch 17): Loss/seq after 00600 batchs: 1418.8319091796875
INFO:root:Train (Epoch 17): Loss/seq after 00650 batchs: 1441.9322509765625
INFO:root:Train (Epoch 17): Loss/seq after 00700 batchs: 1471.80029296875
INFO:root:Train (Epoch 17): Loss/seq after 00750 batchs: 1509.1494140625
INFO:root:Train (Epoch 17): Loss/seq after 00800 batchs: 1500.3494873046875
INFO:root:Train (Epoch 17): Loss/seq after 00850 batchs: 1470.97314453125
INFO:root:Train (Epoch 17): Loss/seq after 00900 batchs: 1478.5546875
INFO:root:Train (Epoch 17): Loss/seq after 00950 batchs: 1529.8297119140625
INFO:root:Train (Epoch 17): Loss/seq after 01000 batchs: 1527.3006591796875
INFO:root:Train (Epoch 17): Loss/seq after 01050 batchs: 1510.8514404296875
INFO:root:Train (Epoch 17): Loss/seq after 01100 batchs: 1500.743408203125
INFO:root:Train (Epoch 17): Loss/seq after 01150 batchs: 1479.0108642578125
INFO:root:Train (Epoch 17): Loss/seq after 01200 batchs: 1464.0396728515625
INFO:root:Train (Epoch 17): Loss/seq after 01250 batchs: 1455.3154296875
INFO:root:Train (Epoch 17): Loss/seq after 01300 batchs: 1457.125732421875
INFO:root:Train (Epoch 17): Loss/seq after 01350 batchs: 1451.10400390625
INFO:root:Train (Epoch 17): Loss/seq after 01400 batchs: 1483.09326171875
INFO:root:Train (Epoch 17): Loss/seq after 01450 batchs: 1470.6708984375
INFO:root:Train (Epoch 17): Loss/seq after 01500 batchs: 1457.9752197265625
INFO:root:Train (Epoch 17): Loss/seq after 01550 batchs: 1459.335693359375
INFO:root:Train (Epoch 17): Loss/seq after 01600 batchs: 1439.390625
INFO:root:Train (Epoch 17): Loss/seq after 01650 batchs: 1431.8798828125
INFO:root:Train (Epoch 17): Loss/seq after 01700 batchs: 1420.5003662109375
INFO:root:Train (Epoch 17): Loss/seq after 01750 batchs: 1406.33740234375
INFO:root:Train (Epoch 17): Loss/seq after 01800 batchs: 1390.4322509765625
INFO:root:Train (Epoch 17): Loss/seq after 01850 batchs: 1374.3411865234375
INFO:root:Train (Epoch 17): Loss/seq after 01900 batchs: 1371.144287109375
INFO:root:Train (Epoch 17): Loss/seq after 01950 batchs: 1364.1929931640625
INFO:root:Train (Epoch 17): Loss/seq after 02000 batchs: 1352.8214111328125
INFO:root:Train (Epoch 17): Loss/seq after 02050 batchs: 1343.2198486328125
INFO:root:Train (Epoch 17): Loss/seq after 02100 batchs: 1330.173583984375
INFO:root:Train (Epoch 17): Loss/seq after 02150 batchs: 1318.627197265625
INFO:root:Train (Epoch 17): Loss/seq after 02200 batchs: 1305.796875
INFO:root:Train (Epoch 17): Loss/seq after 02250 batchs: 1310.278564453125
INFO:root:Train (Epoch 17): Loss/seq after 02300 batchs: 1315.5494384765625
INFO:root:Train (Epoch 17): Loss/seq after 02350 batchs: 1305.5771484375
INFO:root:Train (Epoch 17): Loss/seq after 02400 batchs: 1300.7137451171875
INFO:root:Train (Epoch 17): Loss/seq after 02450 batchs: 1287.222900390625
INFO:root:Train (Epoch 17): Loss/seq after 02500 batchs: 1268.923583984375
INFO:root:Train (Epoch 17): Loss/seq after 02550 batchs: 1258.287109375
INFO:root:Train (Epoch 17): Loss/seq after 02600 batchs: 1256.944580078125
INFO:root:Train (Epoch 17): Loss/seq after 02650 batchs: 1251.7105712890625
INFO:root:Train (Epoch 17): Loss/seq after 02700 batchs: 1248.2108154296875
INFO:root:Train (Epoch 17): Loss/seq after 02750 batchs: 1278.6634521484375
INFO:root:Train (Epoch 17): Loss/seq after 02800 batchs: 1285.29541015625
INFO:root:Train (Epoch 17): Loss/seq after 02850 batchs: 1282.6905517578125
INFO:root:Train (Epoch 17): Loss/seq after 02900 batchs: 1280.2513427734375
INFO:root:Train (Epoch 17): Loss/seq after 02950 batchs: 1272.203369140625
INFO:root:Train (Epoch 17): Loss/seq after 03000 batchs: 1269.147705078125
INFO:root:Train (Epoch 17): Loss/seq after 03050 batchs: 1270.995361328125
INFO:root:Train (Epoch 17): Loss/seq after 03100 batchs: 1285.793212890625
INFO:root:Train (Epoch 17): Loss/seq after 03150 batchs: 1298.8876953125
INFO:root:Train (Epoch 17): Loss/seq after 03200 batchs: 1305.70361328125
INFO:root:Train (Epoch 17): Loss/seq after 03250 batchs: 1311.6279296875
INFO:root:Train (Epoch 17): Loss/seq after 03300 batchs: 1311.1033935546875
INFO:root:Train (Epoch 17): Loss/seq after 03350 batchs: 1311.119140625
INFO:root:Train (Epoch 17): Loss/seq after 03400 batchs: 1301.652587890625
INFO:root:Train (Epoch 17): Loss/seq after 03450 batchs: 1297.8314208984375
INFO:root:Train (Epoch 17): Loss/seq after 03500 batchs: 1298.2083740234375
INFO:root:Train (Epoch 17): Loss/seq after 03550 batchs: 1293.780517578125
INFO:root:Train (Epoch 17): Loss/seq after 03600 batchs: 1299.5760498046875
INFO:root:Train (Epoch 17): Loss/seq after 03650 batchs: 1294.838134765625
INFO:root:Train (Epoch 17): Loss/seq after 03700 batchs: 1293.9541015625
INFO:root:Train (Epoch 17): Loss/seq after 03750 batchs: 1293.128173828125
INFO:root:Train (Epoch 17): Loss/seq after 03800 batchs: 1285.658203125
INFO:root:Train (Epoch 17): Loss/seq after 03850 batchs: 1280.6727294921875
INFO:root:Train (Epoch 17): Loss/seq after 03900 batchs: 1287.31494140625
INFO:root:Train (Epoch 17): Loss/seq after 03950 batchs: 1292.91845703125
INFO:root:Train (Epoch 17): Loss/seq after 04000 batchs: 1283.159423828125
INFO:root:Train (Epoch 17): Loss/seq after 04050 batchs: 1274.3936767578125
INFO:root:Train (Epoch 17): Loss/seq after 04100 batchs: 1270.1807861328125
INFO:root:Train (Epoch 17): Loss/seq after 04150 batchs: 1264.3311767578125
INFO:root:Train (Epoch 17): Loss/seq after 04200 batchs: 1258.8870849609375
INFO:root:Train (Epoch 17): Loss/seq after 04250 batchs: 1254.0872802734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 17): Loss/seq after 00000 batches: 920.6367797851562
INFO:root:# Valid (Epoch 17): Loss/seq after 00050 batches: 1112.4852294921875
INFO:root:# Valid (Epoch 17): Loss/seq after 00100 batches: 1436.9630126953125
INFO:root:# Valid (Epoch 17): Loss/seq after 00150 batches: 1211.1328125
INFO:root:# Valid (Epoch 17): Loss/seq after 00200 batches: 1108.36328125
INFO:root:Artifacts: Make stick videos for epoch 17
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_17_on_20220422_010020.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_17_index_98_on_20220422_010020.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 18): Loss/seq after 00000 batchs: 1773.387939453125
INFO:root:Train (Epoch 18): Loss/seq after 00050 batchs: 1716.164794921875
INFO:root:Train (Epoch 18): Loss/seq after 00100 batchs: 1666.8934326171875
INFO:root:Train (Epoch 18): Loss/seq after 00150 batchs: 1490.6719970703125
INFO:root:Train (Epoch 18): Loss/seq after 00200 batchs: 1598.0655517578125
INFO:root:Train (Epoch 18): Loss/seq after 00250 batchs: 1715.1611328125
INFO:root:Train (Epoch 18): Loss/seq after 00300 batchs: 1614.54638671875
INFO:root:Train (Epoch 18): Loss/seq after 00350 batchs: 1510.3326416015625
INFO:root:Train (Epoch 18): Loss/seq after 00400 batchs: 1567.0970458984375
INFO:root:Train (Epoch 18): Loss/seq after 00450 batchs: 1490.67529296875
INFO:root:Train (Epoch 18): Loss/seq after 00500 batchs: 1521.658935546875
INFO:root:Train (Epoch 18): Loss/seq after 00550 batchs: 1457.9351806640625
INFO:root:Train (Epoch 18): Loss/seq after 00600 batchs: 1423.72265625
INFO:root:Train (Epoch 18): Loss/seq after 00650 batchs: 1452.648193359375
INFO:root:Train (Epoch 18): Loss/seq after 00700 batchs: 1468.53466796875
INFO:root:Train (Epoch 18): Loss/seq after 00750 batchs: 1500.4158935546875
INFO:root:Train (Epoch 18): Loss/seq after 00800 batchs: 1491.8704833984375
INFO:root:Train (Epoch 18): Loss/seq after 00850 batchs: 1461.6800537109375
INFO:root:Train (Epoch 18): Loss/seq after 00900 batchs: 1472.10302734375
INFO:root:Train (Epoch 18): Loss/seq after 00950 batchs: 1533.29541015625
INFO:root:Train (Epoch 18): Loss/seq after 01000 batchs: 1535.3310546875
INFO:root:Train (Epoch 18): Loss/seq after 01050 batchs: 1517.2279052734375
INFO:root:Train (Epoch 18): Loss/seq after 01100 batchs: 1509.998779296875
INFO:root:Train (Epoch 18): Loss/seq after 01150 batchs: 1488.068359375
INFO:root:Train (Epoch 18): Loss/seq after 01200 batchs: 1473.2489013671875
INFO:root:Train (Epoch 18): Loss/seq after 01250 batchs: 1464.8472900390625
INFO:root:Train (Epoch 18): Loss/seq after 01300 batchs: 1466.564208984375
INFO:root:Train (Epoch 18): Loss/seq after 01350 batchs: 1462.57861328125
INFO:root:Train (Epoch 18): Loss/seq after 01400 batchs: 1490.7275390625
INFO:root:Train (Epoch 18): Loss/seq after 01450 batchs: 1477.342041015625
INFO:root:Train (Epoch 18): Loss/seq after 01500 batchs: 1464.3013916015625
INFO:root:Train (Epoch 18): Loss/seq after 01550 batchs: 1466.7359619140625
INFO:root:Train (Epoch 18): Loss/seq after 01600 batchs: 1446.4825439453125
INFO:root:Train (Epoch 18): Loss/seq after 01650 batchs: 1438.5775146484375
INFO:root:Train (Epoch 18): Loss/seq after 01700 batchs: 1426.6192626953125
INFO:root:Train (Epoch 18): Loss/seq after 01750 batchs: 1411.8568115234375
INFO:root:Train (Epoch 18): Loss/seq after 01800 batchs: 1395.3526611328125
INFO:root:Train (Epoch 18): Loss/seq after 01850 batchs: 1379.0673828125
INFO:root:Train (Epoch 18): Loss/seq after 01900 batchs: 1375.632080078125
INFO:root:Train (Epoch 18): Loss/seq after 01950 batchs: 1368.5906982421875
INFO:root:Train (Epoch 18): Loss/seq after 02000 batchs: 1356.84130859375
INFO:root:Train (Epoch 18): Loss/seq after 02050 batchs: 1347.013916015625
INFO:root:Train (Epoch 18): Loss/seq after 02100 batchs: 1333.81005859375
INFO:root:Train (Epoch 18): Loss/seq after 02150 batchs: 1321.8692626953125
INFO:root:Train (Epoch 18): Loss/seq after 02200 batchs: 1308.894775390625
INFO:root:Train (Epoch 18): Loss/seq after 02250 batchs: 1312.3974609375
INFO:root:Train (Epoch 18): Loss/seq after 02300 batchs: 1318.1817626953125
INFO:root:Train (Epoch 18): Loss/seq after 02350 batchs: 1307.79345703125
INFO:root:Train (Epoch 18): Loss/seq after 02400 batchs: 1302.6341552734375
INFO:root:Train (Epoch 18): Loss/seq after 02450 batchs: 1288.8148193359375
INFO:root:Train (Epoch 18): Loss/seq after 02500 batchs: 1270.3719482421875
INFO:root:Train (Epoch 18): Loss/seq after 02550 batchs: 1258.659423828125
INFO:root:Train (Epoch 18): Loss/seq after 02600 batchs: 1255.7801513671875
INFO:root:Train (Epoch 18): Loss/seq after 02650 batchs: 1250.279052734375
INFO:root:Train (Epoch 18): Loss/seq after 02700 batchs: 1246.110595703125
INFO:root:Train (Epoch 18): Loss/seq after 02750 batchs: 1274.980712890625
INFO:root:Train (Epoch 18): Loss/seq after 02800 batchs: 1280.31396484375
INFO:root:Train (Epoch 18): Loss/seq after 02850 batchs: 1277.2412109375
INFO:root:Train (Epoch 18): Loss/seq after 02900 batchs: 1274.9281005859375
INFO:root:Train (Epoch 18): Loss/seq after 02950 batchs: 1266.84814453125
INFO:root:Train (Epoch 18): Loss/seq after 03000 batchs: 1263.8590087890625
INFO:root:Train (Epoch 18): Loss/seq after 03050 batchs: 1265.7933349609375
INFO:root:Train (Epoch 18): Loss/seq after 03100 batchs: 1280.1002197265625
INFO:root:Train (Epoch 18): Loss/seq after 03150 batchs: 1291.0870361328125
INFO:root:Train (Epoch 18): Loss/seq after 03200 batchs: 1297.8291015625
INFO:root:Train (Epoch 18): Loss/seq after 03250 batchs: 1301.881591796875
INFO:root:Train (Epoch 18): Loss/seq after 03300 batchs: 1301.8623046875
INFO:root:Train (Epoch 18): Loss/seq after 03350 batchs: 1301.033447265625
INFO:root:Train (Epoch 18): Loss/seq after 03400 batchs: 1291.578857421875
INFO:root:Train (Epoch 18): Loss/seq after 03450 batchs: 1284.75830078125
INFO:root:Train (Epoch 18): Loss/seq after 03500 batchs: 1283.990234375
INFO:root:Train (Epoch 18): Loss/seq after 03550 batchs: 1279.0087890625
INFO:root:Train (Epoch 18): Loss/seq after 03600 batchs: 1284.3707275390625
INFO:root:Train (Epoch 18): Loss/seq after 03650 batchs: 1279.7188720703125
INFO:root:Train (Epoch 18): Loss/seq after 03700 batchs: 1279.044677734375
INFO:root:Train (Epoch 18): Loss/seq after 03750 batchs: 1278.45068359375
INFO:root:Train (Epoch 18): Loss/seq after 03800 batchs: 1270.9952392578125
INFO:root:Train (Epoch 18): Loss/seq after 03850 batchs: 1266.044677734375
INFO:root:Train (Epoch 18): Loss/seq after 03900 batchs: 1272.3082275390625
INFO:root:Train (Epoch 18): Loss/seq after 03950 batchs: 1277.1214599609375
INFO:root:Train (Epoch 18): Loss/seq after 04000 batchs: 1267.5487060546875
INFO:root:Train (Epoch 18): Loss/seq after 04050 batchs: 1258.963134765625
INFO:root:Train (Epoch 18): Loss/seq after 04100 batchs: 1254.4366455078125
INFO:root:Train (Epoch 18): Loss/seq after 04150 batchs: 1248.33642578125
INFO:root:Train (Epoch 18): Loss/seq after 04200 batchs: 1242.953369140625
INFO:root:Train (Epoch 18): Loss/seq after 04250 batchs: 1238.26171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 18): Loss/seq after 00000 batches: 914.2515869140625
INFO:root:# Valid (Epoch 18): Loss/seq after 00050 batches: 1109.140869140625
INFO:root:# Valid (Epoch 18): Loss/seq after 00100 batches: 1437.528076171875
INFO:root:# Valid (Epoch 18): Loss/seq after 00150 batches: 1224.400146484375
INFO:root:# Valid (Epoch 18): Loss/seq after 00200 batches: 1123.775634765625
INFO:root:Artifacts: Make stick videos for epoch 18
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_18_on_20220422_010508.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_18_index_1601_on_20220422_010508.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 19): Loss/seq after 00000 batchs: 2113.189453125
INFO:root:Train (Epoch 19): Loss/seq after 00050 batchs: 1651.389404296875
INFO:root:Train (Epoch 19): Loss/seq after 00100 batchs: 1662.2923583984375
INFO:root:Train (Epoch 19): Loss/seq after 00150 batchs: 1496.6259765625
INFO:root:Train (Epoch 19): Loss/seq after 00200 batchs: 1611.37890625
INFO:root:Train (Epoch 19): Loss/seq after 00250 batchs: 1719.8555908203125
INFO:root:Train (Epoch 19): Loss/seq after 00300 batchs: 1618.963134765625
INFO:root:Train (Epoch 19): Loss/seq after 00350 batchs: 1513.112548828125
INFO:root:Train (Epoch 19): Loss/seq after 00400 batchs: 1568.854736328125
INFO:root:Train (Epoch 19): Loss/seq after 00450 batchs: 1492.5748291015625
INFO:root:Train (Epoch 19): Loss/seq after 00500 batchs: 1520.072021484375
INFO:root:Train (Epoch 19): Loss/seq after 00550 batchs: 1456.455322265625
INFO:root:Train (Epoch 19): Loss/seq after 00600 batchs: 1421.1767578125
INFO:root:Train (Epoch 19): Loss/seq after 00650 batchs: 1436.186279296875
INFO:root:Train (Epoch 19): Loss/seq after 00700 batchs: 1436.333740234375
INFO:root:Train (Epoch 19): Loss/seq after 00750 batchs: 1466.42822265625
INFO:root:Train (Epoch 19): Loss/seq after 00800 batchs: 1459.8909912109375
INFO:root:Train (Epoch 19): Loss/seq after 00850 batchs: 1431.3203125
INFO:root:Train (Epoch 19): Loss/seq after 00900 batchs: 1440.08203125
INFO:root:Train (Epoch 19): Loss/seq after 00950 batchs: 1478.7052001953125
INFO:root:Train (Epoch 19): Loss/seq after 01000 batchs: 1473.12255859375
INFO:root:Train (Epoch 19): Loss/seq after 01050 batchs: 1457.216796875
INFO:root:Train (Epoch 19): Loss/seq after 01100 batchs: 1448.74072265625
INFO:root:Train (Epoch 19): Loss/seq after 01150 batchs: 1429.0889892578125
INFO:root:Train (Epoch 19): Loss/seq after 01200 batchs: 1415.7510986328125
INFO:root:Train (Epoch 19): Loss/seq after 01250 batchs: 1408.409912109375
INFO:root:Train (Epoch 19): Loss/seq after 01300 batchs: 1409.39453125
INFO:root:Train (Epoch 19): Loss/seq after 01350 batchs: 1406.13330078125
INFO:root:Train (Epoch 19): Loss/seq after 01400 batchs: 1430.739013671875
INFO:root:Train (Epoch 19): Loss/seq after 01450 batchs: 1418.75390625
INFO:root:Train (Epoch 19): Loss/seq after 01500 batchs: 1406.789794921875
INFO:root:Train (Epoch 19): Loss/seq after 01550 batchs: 1411.2841796875
INFO:root:Train (Epoch 19): Loss/seq after 01600 batchs: 1392.3074951171875
INFO:root:Train (Epoch 19): Loss/seq after 01650 batchs: 1386.2100830078125
INFO:root:Train (Epoch 19): Loss/seq after 01700 batchs: 1375.7176513671875
INFO:root:Train (Epoch 19): Loss/seq after 01750 batchs: 1362.318603515625
INFO:root:Train (Epoch 19): Loss/seq after 01800 batchs: 1347.1318359375
INFO:root:Train (Epoch 19): Loss/seq after 01850 batchs: 1332.309814453125
INFO:root:Train (Epoch 19): Loss/seq after 01900 batchs: 1329.9302978515625
INFO:root:Train (Epoch 19): Loss/seq after 01950 batchs: 1324.1473388671875
INFO:root:Train (Epoch 19): Loss/seq after 02000 batchs: 1313.541015625
INFO:root:Train (Epoch 19): Loss/seq after 02050 batchs: 1304.7550048828125
INFO:root:Train (Epoch 19): Loss/seq after 02100 batchs: 1292.5400390625
INFO:root:Train (Epoch 19): Loss/seq after 02150 batchs: 1281.5238037109375
INFO:root:Train (Epoch 19): Loss/seq after 02200 batchs: 1269.466552734375
INFO:root:Train (Epoch 19): Loss/seq after 02250 batchs: 1273.675048828125
INFO:root:Train (Epoch 19): Loss/seq after 02300 batchs: 1280.34521484375
INFO:root:Train (Epoch 19): Loss/seq after 02350 batchs: 1270.6929931640625
INFO:root:Train (Epoch 19): Loss/seq after 02400 batchs: 1266.5455322265625
INFO:root:Train (Epoch 19): Loss/seq after 02450 batchs: 1253.58056640625
INFO:root:Train (Epoch 19): Loss/seq after 02500 batchs: 1235.806884765625
INFO:root:Train (Epoch 19): Loss/seq after 02550 batchs: 1224.5657958984375
INFO:root:Train (Epoch 19): Loss/seq after 02600 batchs: 1222.140380859375
INFO:root:Train (Epoch 19): Loss/seq after 02650 batchs: 1217.0377197265625
INFO:root:Train (Epoch 19): Loss/seq after 02700 batchs: 1213.2677001953125
INFO:root:Train (Epoch 19): Loss/seq after 02750 batchs: 1243.7578125
INFO:root:Train (Epoch 19): Loss/seq after 02800 batchs: 1250.75537109375
INFO:root:Train (Epoch 19): Loss/seq after 02850 batchs: 1248.050048828125
INFO:root:Train (Epoch 19): Loss/seq after 02900 batchs: 1246.5228271484375
INFO:root:Train (Epoch 19): Loss/seq after 02950 batchs: 1238.517822265625
INFO:root:Train (Epoch 19): Loss/seq after 03000 batchs: 1235.986083984375
INFO:root:Train (Epoch 19): Loss/seq after 03050 batchs: 1238.22802734375
INFO:root:Train (Epoch 19): Loss/seq after 03100 batchs: 1252.8594970703125
INFO:root:Train (Epoch 19): Loss/seq after 03150 batchs: 1262.51806640625
INFO:root:Train (Epoch 19): Loss/seq after 03200 batchs: 1268.059326171875
INFO:root:Train (Epoch 19): Loss/seq after 03250 batchs: 1268.8779296875
INFO:root:Train (Epoch 19): Loss/seq after 03300 batchs: 1268.11328125
INFO:root:Train (Epoch 19): Loss/seq after 03350 batchs: 1267.258544921875
INFO:root:Train (Epoch 19): Loss/seq after 03400 batchs: 1258.1973876953125
INFO:root:Train (Epoch 19): Loss/seq after 03450 batchs: 1251.05859375
INFO:root:Train (Epoch 19): Loss/seq after 03500 batchs: 1250.7242431640625
INFO:root:Train (Epoch 19): Loss/seq after 03550 batchs: 1245.5428466796875
INFO:root:Train (Epoch 19): Loss/seq after 03600 batchs: 1251.2359619140625
INFO:root:Train (Epoch 19): Loss/seq after 03650 batchs: 1247.2587890625
INFO:root:Train (Epoch 19): Loss/seq after 03700 batchs: 1246.88671875
INFO:root:Train (Epoch 19): Loss/seq after 03750 batchs: 1246.58203125
INFO:root:Train (Epoch 19): Loss/seq after 03800 batchs: 1239.4283447265625
INFO:root:Train (Epoch 19): Loss/seq after 03850 batchs: 1234.8336181640625
INFO:root:Train (Epoch 19): Loss/seq after 03900 batchs: 1241.169189453125
INFO:root:Train (Epoch 19): Loss/seq after 03950 batchs: 1245.5218505859375
INFO:root:Train (Epoch 19): Loss/seq after 04000 batchs: 1236.282958984375
INFO:root:Train (Epoch 19): Loss/seq after 04050 batchs: 1228.0433349609375
INFO:root:Train (Epoch 19): Loss/seq after 04100 batchs: 1223.2669677734375
INFO:root:Train (Epoch 19): Loss/seq after 04150 batchs: 1217.3883056640625
INFO:root:Train (Epoch 19): Loss/seq after 04200 batchs: 1212.3975830078125
INFO:root:Train (Epoch 19): Loss/seq after 04250 batchs: 1208.0791015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 19): Loss/seq after 00000 batches: 872.4259033203125
INFO:root:# Valid (Epoch 19): Loss/seq after 00050 batches: 1117.3170166015625
INFO:root:# Valid (Epoch 19): Loss/seq after 00100 batches: 1453.1697998046875
INFO:root:# Valid (Epoch 19): Loss/seq after 00150 batches: 1261.6767578125
INFO:root:# Valid (Epoch 19): Loss/seq after 00200 batches: 1164.542236328125
INFO:root:Artifacts: Make stick videos for epoch 19
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_19_on_20220422_011000.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_19_index_1846_on_20220422_011000.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 20): Loss/seq after 00000 batchs: 1954.1236572265625
INFO:root:Train (Epoch 20): Loss/seq after 00050 batchs: 1581.8046875
INFO:root:Train (Epoch 20): Loss/seq after 00100 batchs: 1621.0145263671875
INFO:root:Train (Epoch 20): Loss/seq after 00150 batchs: 1459.93798828125
INFO:root:Train (Epoch 20): Loss/seq after 00200 batchs: 1567.1650390625
INFO:root:Train (Epoch 20): Loss/seq after 00250 batchs: 1679.142578125
INFO:root:Train (Epoch 20): Loss/seq after 00300 batchs: 1584.3043212890625
INFO:root:Train (Epoch 20): Loss/seq after 00350 batchs: 1483.822021484375
INFO:root:Train (Epoch 20): Loss/seq after 00400 batchs: 1530.8173828125
INFO:root:Train (Epoch 20): Loss/seq after 00450 batchs: 1458.42333984375
INFO:root:Train (Epoch 20): Loss/seq after 00500 batchs: 1489.6539306640625
INFO:root:Train (Epoch 20): Loss/seq after 00550 batchs: 1429.0594482421875
INFO:root:Train (Epoch 20): Loss/seq after 00600 batchs: 1394.00927734375
INFO:root:Train (Epoch 20): Loss/seq after 00650 batchs: 1395.091064453125
INFO:root:Train (Epoch 20): Loss/seq after 00700 batchs: 1376.2298583984375
INFO:root:Train (Epoch 20): Loss/seq after 00750 batchs: 1410.324462890625
INFO:root:Train (Epoch 20): Loss/seq after 00800 batchs: 1407.312255859375
INFO:root:Train (Epoch 20): Loss/seq after 00850 batchs: 1381.2666015625
INFO:root:Train (Epoch 20): Loss/seq after 00900 batchs: 1391.6585693359375
INFO:root:Train (Epoch 20): Loss/seq after 00950 batchs: 1425.3812255859375
INFO:root:Train (Epoch 20): Loss/seq after 01000 batchs: 1419.6014404296875
INFO:root:Train (Epoch 20): Loss/seq after 01050 batchs: 1404.580322265625
INFO:root:Train (Epoch 20): Loss/seq after 01100 batchs: 1399.33251953125
INFO:root:Train (Epoch 20): Loss/seq after 01150 batchs: 1381.858154296875
INFO:root:Train (Epoch 20): Loss/seq after 01200 batchs: 1371.1094970703125
INFO:root:Train (Epoch 20): Loss/seq after 01250 batchs: 1363.44189453125
INFO:root:Train (Epoch 20): Loss/seq after 01300 batchs: 1359.826416015625
INFO:root:Train (Epoch 20): Loss/seq after 01350 batchs: 1357.71337890625
INFO:root:Train (Epoch 20): Loss/seq after 01400 batchs: 1379.0577392578125
INFO:root:Train (Epoch 20): Loss/seq after 01450 batchs: 1368.3992919921875
INFO:root:Train (Epoch 20): Loss/seq after 01500 batchs: 1358.336669921875
INFO:root:Train (Epoch 20): Loss/seq after 01550 batchs: 1363.0107421875
INFO:root:Train (Epoch 20): Loss/seq after 01600 batchs: 1345.5152587890625
INFO:root:Train (Epoch 20): Loss/seq after 01650 batchs: 1340.49755859375
INFO:root:Train (Epoch 20): Loss/seq after 01700 batchs: 1331.426025390625
INFO:root:Train (Epoch 20): Loss/seq after 01750 batchs: 1319.3558349609375
INFO:root:Train (Epoch 20): Loss/seq after 01800 batchs: 1305.1217041015625
INFO:root:Train (Epoch 20): Loss/seq after 01850 batchs: 1291.346435546875
INFO:root:Train (Epoch 20): Loss/seq after 01900 batchs: 1290.089599609375
INFO:root:Train (Epoch 20): Loss/seq after 01950 batchs: 1285.308837890625
INFO:root:Train (Epoch 20): Loss/seq after 02000 batchs: 1275.630859375
INFO:root:Train (Epoch 20): Loss/seq after 02050 batchs: 1267.791748046875
INFO:root:Train (Epoch 20): Loss/seq after 02100 batchs: 1256.4139404296875
INFO:root:Train (Epoch 20): Loss/seq after 02150 batchs: 1246.1302490234375
INFO:root:Train (Epoch 20): Loss/seq after 02200 batchs: 1234.8455810546875
INFO:root:Train (Epoch 20): Loss/seq after 02250 batchs: 1240.229248046875
INFO:root:Train (Epoch 20): Loss/seq after 02300 batchs: 1248.8551025390625
INFO:root:Train (Epoch 20): Loss/seq after 02350 batchs: 1239.9869384765625
INFO:root:Train (Epoch 20): Loss/seq after 02400 batchs: 1236.345947265625
INFO:root:Train (Epoch 20): Loss/seq after 02450 batchs: 1223.988037109375
INFO:root:Train (Epoch 20): Loss/seq after 02500 batchs: 1206.7825927734375
INFO:root:Train (Epoch 20): Loss/seq after 02550 batchs: 1196.2044677734375
INFO:root:Train (Epoch 20): Loss/seq after 02600 batchs: 1193.8397216796875
INFO:root:Train (Epoch 20): Loss/seq after 02650 batchs: 1189.31884765625
INFO:root:Train (Epoch 20): Loss/seq after 02700 batchs: 1186.0084228515625
INFO:root:Train (Epoch 20): Loss/seq after 02750 batchs: 1216.905029296875
INFO:root:Train (Epoch 20): Loss/seq after 02800 batchs: 1223.0130615234375
INFO:root:Train (Epoch 20): Loss/seq after 02850 batchs: 1220.5048828125
INFO:root:Train (Epoch 20): Loss/seq after 02900 batchs: 1218.7548828125
INFO:root:Train (Epoch 20): Loss/seq after 02950 batchs: 1211.151123046875
INFO:root:Train (Epoch 20): Loss/seq after 03000 batchs: 1209.075927734375
INFO:root:Train (Epoch 20): Loss/seq after 03050 batchs: 1211.78271484375
INFO:root:Train (Epoch 20): Loss/seq after 03100 batchs: 1225.6075439453125
INFO:root:Train (Epoch 20): Loss/seq after 03150 batchs: 1233.958984375
INFO:root:Train (Epoch 20): Loss/seq after 03200 batchs: 1239.40771484375
INFO:root:Train (Epoch 20): Loss/seq after 03250 batchs: 1240.6351318359375
INFO:root:Train (Epoch 20): Loss/seq after 03300 batchs: 1239.555419921875
INFO:root:Train (Epoch 20): Loss/seq after 03350 batchs: 1240.1539306640625
INFO:root:Train (Epoch 20): Loss/seq after 03400 batchs: 1231.5255126953125
INFO:root:Train (Epoch 20): Loss/seq after 03450 batchs: 1224.880615234375
INFO:root:Train (Epoch 20): Loss/seq after 03500 batchs: 1224.710693359375
INFO:root:Train (Epoch 20): Loss/seq after 03550 batchs: 1220.1077880859375
INFO:root:Train (Epoch 20): Loss/seq after 03600 batchs: 1226.2193603515625
INFO:root:Train (Epoch 20): Loss/seq after 03650 batchs: 1222.2659912109375
INFO:root:Train (Epoch 20): Loss/seq after 03700 batchs: 1222.273681640625
INFO:root:Train (Epoch 20): Loss/seq after 03750 batchs: 1222.375244140625
INFO:root:Train (Epoch 20): Loss/seq after 03800 batchs: 1215.5723876953125
INFO:root:Train (Epoch 20): Loss/seq after 03850 batchs: 1211.324951171875
INFO:root:Train (Epoch 20): Loss/seq after 03900 batchs: 1215.942138671875
INFO:root:Train (Epoch 20): Loss/seq after 03950 batchs: 1219.6859130859375
INFO:root:Train (Epoch 20): Loss/seq after 04000 batchs: 1210.745849609375
INFO:root:Train (Epoch 20): Loss/seq after 04050 batchs: 1202.8414306640625
INFO:root:Train (Epoch 20): Loss/seq after 04100 batchs: 1197.8341064453125
INFO:root:Train (Epoch 20): Loss/seq after 04150 batchs: 1192.2196044921875
INFO:root:Train (Epoch 20): Loss/seq after 04200 batchs: 1187.5560302734375
INFO:root:Train (Epoch 20): Loss/seq after 04250 batchs: 1183.415771484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 20): Loss/seq after 00000 batches: 881.4349365234375
INFO:root:# Valid (Epoch 20): Loss/seq after 00050 batches: 1116.8582763671875
INFO:root:# Valid (Epoch 20): Loss/seq after 00100 batches: 1430.30322265625
INFO:root:# Valid (Epoch 20): Loss/seq after 00150 batches: 1169.6185302734375
INFO:root:# Valid (Epoch 20): Loss/seq after 00200 batches: 1059.460693359375
INFO:root:Artifacts: Make stick videos for epoch 20
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_20_on_20220422_011453.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_20_index_951_on_20220422_011453.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 21): Loss/seq after 00000 batchs: 1852.6904296875
INFO:root:Train (Epoch 21): Loss/seq after 00050 batchs: 1570.936767578125
INFO:root:Train (Epoch 21): Loss/seq after 00100 batchs: 1569.2049560546875
INFO:root:Train (Epoch 21): Loss/seq after 00150 batchs: 1429.373291015625
INFO:root:Train (Epoch 21): Loss/seq after 00200 batchs: 1545.0343017578125
INFO:root:Train (Epoch 21): Loss/seq after 00250 batchs: 1661.8560791015625
INFO:root:Train (Epoch 21): Loss/seq after 00300 batchs: 1569.7440185546875
INFO:root:Train (Epoch 21): Loss/seq after 00350 batchs: 1470.578125
INFO:root:Train (Epoch 21): Loss/seq after 00400 batchs: 1517.733642578125
INFO:root:Train (Epoch 21): Loss/seq after 00450 batchs: 1447.4757080078125
INFO:root:Train (Epoch 21): Loss/seq after 00500 batchs: 1481.627197265625
INFO:root:Train (Epoch 21): Loss/seq after 00550 batchs: 1422.30712890625
INFO:root:Train (Epoch 21): Loss/seq after 00600 batchs: 1390.545654296875
INFO:root:Train (Epoch 21): Loss/seq after 00650 batchs: 1392.5040283203125
INFO:root:Train (Epoch 21): Loss/seq after 00700 batchs: 1364.8609619140625
INFO:root:Train (Epoch 21): Loss/seq after 00750 batchs: 1402.2928466796875
INFO:root:Train (Epoch 21): Loss/seq after 00800 batchs: 1399.7174072265625
INFO:root:Train (Epoch 21): Loss/seq after 00850 batchs: 1373.822265625
INFO:root:Train (Epoch 21): Loss/seq after 00900 batchs: 1384.9324951171875
INFO:root:Train (Epoch 21): Loss/seq after 00950 batchs: 1419.68603515625
INFO:root:Train (Epoch 21): Loss/seq after 01000 batchs: 1413.002197265625
INFO:root:Train (Epoch 21): Loss/seq after 01050 batchs: 1397.7789306640625
INFO:root:Train (Epoch 21): Loss/seq after 01100 batchs: 1389.8389892578125
INFO:root:Train (Epoch 21): Loss/seq after 01150 batchs: 1372.5406494140625
INFO:root:Train (Epoch 21): Loss/seq after 01200 batchs: 1361.3922119140625
INFO:root:Train (Epoch 21): Loss/seq after 01250 batchs: 1354.1824951171875
INFO:root:Train (Epoch 21): Loss/seq after 01300 batchs: 1350.5499267578125
INFO:root:Train (Epoch 21): Loss/seq after 01350 batchs: 1345.25048828125
INFO:root:Train (Epoch 21): Loss/seq after 01400 batchs: 1364.3525390625
INFO:root:Train (Epoch 21): Loss/seq after 01450 batchs: 1354.378662109375
INFO:root:Train (Epoch 21): Loss/seq after 01500 batchs: 1345.030517578125
INFO:root:Train (Epoch 21): Loss/seq after 01550 batchs: 1349.45654296875
INFO:root:Train (Epoch 21): Loss/seq after 01600 batchs: 1332.3607177734375
INFO:root:Train (Epoch 21): Loss/seq after 01650 batchs: 1327.31201171875
INFO:root:Train (Epoch 21): Loss/seq after 01700 batchs: 1318.61279296875
INFO:root:Train (Epoch 21): Loss/seq after 01750 batchs: 1306.8306884765625
INFO:root:Train (Epoch 21): Loss/seq after 01800 batchs: 1292.932373046875
INFO:root:Train (Epoch 21): Loss/seq after 01850 batchs: 1279.5313720703125
INFO:root:Train (Epoch 21): Loss/seq after 01900 batchs: 1278.6199951171875
INFO:root:Train (Epoch 21): Loss/seq after 01950 batchs: 1274.142578125
INFO:root:Train (Epoch 21): Loss/seq after 02000 batchs: 1264.70263671875
INFO:root:Train (Epoch 21): Loss/seq after 02050 batchs: 1257.066162109375
INFO:root:Train (Epoch 21): Loss/seq after 02100 batchs: 1245.9637451171875
INFO:root:Train (Epoch 21): Loss/seq after 02150 batchs: 1235.81298828125
INFO:root:Train (Epoch 21): Loss/seq after 02200 batchs: 1224.7491455078125
INFO:root:Train (Epoch 21): Loss/seq after 02250 batchs: 1229.8751220703125
INFO:root:Train (Epoch 21): Loss/seq after 02300 batchs: 1238.0120849609375
INFO:root:Train (Epoch 21): Loss/seq after 02350 batchs: 1229.7342529296875
INFO:root:Train (Epoch 21): Loss/seq after 02400 batchs: 1226.394287109375
INFO:root:Train (Epoch 21): Loss/seq after 02450 batchs: 1214.4119873046875
INFO:root:Train (Epoch 21): Loss/seq after 02500 batchs: 1197.4205322265625
INFO:root:Train (Epoch 21): Loss/seq after 02550 batchs: 1186.988037109375
INFO:root:Train (Epoch 21): Loss/seq after 02600 batchs: 1185.1549072265625
INFO:root:Train (Epoch 21): Loss/seq after 02650 batchs: 1180.812744140625
INFO:root:Train (Epoch 21): Loss/seq after 02700 batchs: 1177.186767578125
INFO:root:Train (Epoch 21): Loss/seq after 02750 batchs: 1207.2171630859375
INFO:root:Train (Epoch 21): Loss/seq after 02800 batchs: 1213.0908203125
INFO:root:Train (Epoch 21): Loss/seq after 02850 batchs: 1210.6785888671875
INFO:root:Train (Epoch 21): Loss/seq after 02900 batchs: 1209.25146484375
INFO:root:Train (Epoch 21): Loss/seq after 02950 batchs: 1202.2537841796875
INFO:root:Train (Epoch 21): Loss/seq after 03000 batchs: 1200.319580078125
INFO:root:Train (Epoch 21): Loss/seq after 03050 batchs: 1203.0887451171875
INFO:root:Train (Epoch 21): Loss/seq after 03100 batchs: 1216.4254150390625
INFO:root:Train (Epoch 21): Loss/seq after 03150 batchs: 1222.98046875
INFO:root:Train (Epoch 21): Loss/seq after 03200 batchs: 1228.943359375
INFO:root:Train (Epoch 21): Loss/seq after 03250 batchs: 1230.777587890625
INFO:root:Train (Epoch 21): Loss/seq after 03300 batchs: 1229.7320556640625
INFO:root:Train (Epoch 21): Loss/seq after 03350 batchs: 1228.6004638671875
INFO:root:Train (Epoch 21): Loss/seq after 03400 batchs: 1220.0523681640625
INFO:root:Train (Epoch 21): Loss/seq after 03450 batchs: 1213.439697265625
INFO:root:Train (Epoch 21): Loss/seq after 03500 batchs: 1213.3150634765625
INFO:root:Train (Epoch 21): Loss/seq after 03550 batchs: 1208.669921875
INFO:root:Train (Epoch 21): Loss/seq after 03600 batchs: 1214.8414306640625
INFO:root:Train (Epoch 21): Loss/seq after 03650 batchs: 1210.9671630859375
INFO:root:Train (Epoch 21): Loss/seq after 03700 batchs: 1211.01953125
INFO:root:Train (Epoch 21): Loss/seq after 03750 batchs: 1211.13818359375
INFO:root:Train (Epoch 21): Loss/seq after 03800 batchs: 1204.436767578125
INFO:root:Train (Epoch 21): Loss/seq after 03850 batchs: 1200.263671875
INFO:root:Train (Epoch 21): Loss/seq after 03900 batchs: 1205.1795654296875
INFO:root:Train (Epoch 21): Loss/seq after 03950 batchs: 1209.02587890625
INFO:root:Train (Epoch 21): Loss/seq after 04000 batchs: 1200.1990966796875
INFO:root:Train (Epoch 21): Loss/seq after 04050 batchs: 1192.4195556640625
INFO:root:Train (Epoch 21): Loss/seq after 04100 batchs: 1187.626220703125
INFO:root:Train (Epoch 21): Loss/seq after 04150 batchs: 1182.08349609375
INFO:root:Train (Epoch 21): Loss/seq after 04200 batchs: 1177.3861083984375
INFO:root:Train (Epoch 21): Loss/seq after 04250 batchs: 1173.5225830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 21): Loss/seq after 00000 batches: 880.728759765625
INFO:root:# Valid (Epoch 21): Loss/seq after 00050 batches: 1117.6397705078125
INFO:root:# Valid (Epoch 21): Loss/seq after 00100 batches: 1434.000244140625
INFO:root:# Valid (Epoch 21): Loss/seq after 00150 batches: 1182.61572265625
INFO:root:# Valid (Epoch 21): Loss/seq after 00200 batches: 1072.92138671875
INFO:root:Artifacts: Make stick videos for epoch 21
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_21_on_20220422_011947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_21_index_1876_on_20220422_011947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 22): Loss/seq after 00000 batchs: 1802.1484375
INFO:root:Train (Epoch 22): Loss/seq after 00050 batchs: 1543.36474609375
INFO:root:Train (Epoch 22): Loss/seq after 00100 batchs: 1547.7821044921875
INFO:root:Train (Epoch 22): Loss/seq after 00150 batchs: 1405.3140869140625
INFO:root:Train (Epoch 22): Loss/seq after 00200 batchs: 1518.90234375
INFO:root:Train (Epoch 22): Loss/seq after 00250 batchs: 1630.820556640625
INFO:root:Train (Epoch 22): Loss/seq after 00300 batchs: 1543.604736328125
INFO:root:Train (Epoch 22): Loss/seq after 00350 batchs: 1447.3736572265625
INFO:root:Train (Epoch 22): Loss/seq after 00400 batchs: 1496.35009765625
INFO:root:Train (Epoch 22): Loss/seq after 00450 batchs: 1429.7530517578125
INFO:root:Train (Epoch 22): Loss/seq after 00500 batchs: 1460.147705078125
INFO:root:Train (Epoch 22): Loss/seq after 00550 batchs: 1402.1337890625
INFO:root:Train (Epoch 22): Loss/seq after 00600 batchs: 1369.0670166015625
INFO:root:Train (Epoch 22): Loss/seq after 00650 batchs: 1371.5897216796875
INFO:root:Train (Epoch 22): Loss/seq after 00700 batchs: 1344.9537353515625
INFO:root:Train (Epoch 22): Loss/seq after 00750 batchs: 1380.244384765625
INFO:root:Train (Epoch 22): Loss/seq after 00800 batchs: 1378.560546875
INFO:root:Train (Epoch 22): Loss/seq after 00850 batchs: 1358.008056640625
INFO:root:Train (Epoch 22): Loss/seq after 00900 batchs: 1370.716796875
INFO:root:Train (Epoch 22): Loss/seq after 00950 batchs: 1399.229248046875
INFO:root:Train (Epoch 22): Loss/seq after 01000 batchs: 1393.1292724609375
INFO:root:Train (Epoch 22): Loss/seq after 01050 batchs: 1379.9302978515625
INFO:root:Train (Epoch 22): Loss/seq after 01100 batchs: 1371.7581787109375
INFO:root:Train (Epoch 22): Loss/seq after 01150 batchs: 1354.8370361328125
INFO:root:Train (Epoch 22): Loss/seq after 01200 batchs: 1344.495849609375
INFO:root:Train (Epoch 22): Loss/seq after 01250 batchs: 1337.7138671875
INFO:root:Train (Epoch 22): Loss/seq after 01300 batchs: 1333.3958740234375
INFO:root:Train (Epoch 22): Loss/seq after 01350 batchs: 1328.59033203125
INFO:root:Train (Epoch 22): Loss/seq after 01400 batchs: 1346.0509033203125
INFO:root:Train (Epoch 22): Loss/seq after 01450 batchs: 1336.7901611328125
INFO:root:Train (Epoch 22): Loss/seq after 01500 batchs: 1327.5277099609375
INFO:root:Train (Epoch 22): Loss/seq after 01550 batchs: 1332.3436279296875
INFO:root:Train (Epoch 22): Loss/seq after 01600 batchs: 1315.7821044921875
INFO:root:Train (Epoch 22): Loss/seq after 01650 batchs: 1311.121826171875
INFO:root:Train (Epoch 22): Loss/seq after 01700 batchs: 1302.81982421875
INFO:root:Train (Epoch 22): Loss/seq after 01750 batchs: 1291.4110107421875
INFO:root:Train (Epoch 22): Loss/seq after 01800 batchs: 1277.906005859375
INFO:root:Train (Epoch 22): Loss/seq after 01850 batchs: 1265.018310546875
INFO:root:Train (Epoch 22): Loss/seq after 01900 batchs: 1264.591552734375
INFO:root:Train (Epoch 22): Loss/seq after 01950 batchs: 1260.6297607421875
INFO:root:Train (Epoch 22): Loss/seq after 02000 batchs: 1251.56396484375
INFO:root:Train (Epoch 22): Loss/seq after 02050 batchs: 1244.22509765625
INFO:root:Train (Epoch 22): Loss/seq after 02100 batchs: 1233.368896484375
INFO:root:Train (Epoch 22): Loss/seq after 02150 batchs: 1223.519287109375
INFO:root:Train (Epoch 22): Loss/seq after 02200 batchs: 1212.709228515625
INFO:root:Train (Epoch 22): Loss/seq after 02250 batchs: 1217.380859375
INFO:root:Train (Epoch 22): Loss/seq after 02300 batchs: 1225.6829833984375
INFO:root:Train (Epoch 22): Loss/seq after 02350 batchs: 1217.068603515625
INFO:root:Train (Epoch 22): Loss/seq after 02400 batchs: 1213.7596435546875
INFO:root:Train (Epoch 22): Loss/seq after 02450 batchs: 1201.7755126953125
INFO:root:Train (Epoch 22): Loss/seq after 02500 batchs: 1184.99072265625
INFO:root:Train (Epoch 22): Loss/seq after 02550 batchs: 1174.5001220703125
INFO:root:Train (Epoch 22): Loss/seq after 02600 batchs: 1172.5662841796875
INFO:root:Train (Epoch 22): Loss/seq after 02650 batchs: 1168.48193359375
INFO:root:Train (Epoch 22): Loss/seq after 02700 batchs: 1164.9620361328125
INFO:root:Train (Epoch 22): Loss/seq after 02750 batchs: 1195.310791015625
INFO:root:Train (Epoch 22): Loss/seq after 02800 batchs: 1200.969970703125
INFO:root:Train (Epoch 22): Loss/seq after 02850 batchs: 1198.7877197265625
INFO:root:Train (Epoch 22): Loss/seq after 02900 batchs: 1197.8455810546875
INFO:root:Train (Epoch 22): Loss/seq after 02950 batchs: 1190.46875
INFO:root:Train (Epoch 22): Loss/seq after 03000 batchs: 1188.7247314453125
INFO:root:Train (Epoch 22): Loss/seq after 03050 batchs: 1191.722412109375
INFO:root:Train (Epoch 22): Loss/seq after 03100 batchs: 1205.15380859375
INFO:root:Train (Epoch 22): Loss/seq after 03150 batchs: 1212.8701171875
INFO:root:Train (Epoch 22): Loss/seq after 03200 batchs: 1217.749755859375
INFO:root:Train (Epoch 22): Loss/seq after 03250 batchs: 1219.0015869140625
INFO:root:Train (Epoch 22): Loss/seq after 03300 batchs: 1217.90185546875
INFO:root:Train (Epoch 22): Loss/seq after 03350 batchs: 1217.4798583984375
INFO:root:Train (Epoch 22): Loss/seq after 03400 batchs: 1209.1622314453125
INFO:root:Train (Epoch 22): Loss/seq after 03450 batchs: 1203.0040283203125
INFO:root:Train (Epoch 22): Loss/seq after 03500 batchs: 1202.9173583984375
INFO:root:Train (Epoch 22): Loss/seq after 03550 batchs: 1198.5325927734375
INFO:root:Train (Epoch 22): Loss/seq after 03600 batchs: 1204.8160400390625
INFO:root:Train (Epoch 22): Loss/seq after 03650 batchs: 1201.0772705078125
INFO:root:Train (Epoch 22): Loss/seq after 03700 batchs: 1201.2333984375
INFO:root:Train (Epoch 22): Loss/seq after 03750 batchs: 1201.446533203125
INFO:root:Train (Epoch 22): Loss/seq after 03800 batchs: 1194.85302734375
INFO:root:Train (Epoch 22): Loss/seq after 03850 batchs: 1190.7503662109375
INFO:root:Train (Epoch 22): Loss/seq after 03900 batchs: 1195.177978515625
INFO:root:Train (Epoch 22): Loss/seq after 03950 batchs: 1199.04052734375
INFO:root:Train (Epoch 22): Loss/seq after 04000 batchs: 1190.3297119140625
INFO:root:Train (Epoch 22): Loss/seq after 04050 batchs: 1182.66650390625
INFO:root:Train (Epoch 22): Loss/seq after 04100 batchs: 1177.74169921875
INFO:root:Train (Epoch 22): Loss/seq after 04150 batchs: 1172.3055419921875
INFO:root:Train (Epoch 22): Loss/seq after 04200 batchs: 1167.788818359375
INFO:root:Train (Epoch 22): Loss/seq after 04250 batchs: 1163.9520263671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 22): Loss/seq after 00000 batches: 880.5845336914062
INFO:root:# Valid (Epoch 22): Loss/seq after 00050 batches: 1145.68505859375
INFO:root:# Valid (Epoch 22): Loss/seq after 00100 batches: 1469.329833984375
INFO:root:# Valid (Epoch 22): Loss/seq after 00150 batches: 1258.29833984375
INFO:root:# Valid (Epoch 22): Loss/seq after 00200 batches: 1160.8741455078125
INFO:root:Artifacts: Make stick videos for epoch 22
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_22_on_20220422_012448.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_22_index_1538_on_20220422_012448.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 23): Loss/seq after 00000 batchs: 1616.2171630859375
INFO:root:Train (Epoch 23): Loss/seq after 00050 batchs: 1570.4517822265625
INFO:root:Train (Epoch 23): Loss/seq after 00100 batchs: 1548.8465576171875
INFO:root:Train (Epoch 23): Loss/seq after 00150 batchs: 1405.9962158203125
INFO:root:Train (Epoch 23): Loss/seq after 00200 batchs: 1518.5052490234375
INFO:root:Train (Epoch 23): Loss/seq after 00250 batchs: 1620.813720703125
INFO:root:Train (Epoch 23): Loss/seq after 00300 batchs: 1535.1578369140625
INFO:root:Train (Epoch 23): Loss/seq after 00350 batchs: 1440.4801025390625
INFO:root:Train (Epoch 23): Loss/seq after 00400 batchs: 1486.3502197265625
INFO:root:Train (Epoch 23): Loss/seq after 00450 batchs: 1418.762451171875
INFO:root:Train (Epoch 23): Loss/seq after 00500 batchs: 1447.460205078125
INFO:root:Train (Epoch 23): Loss/seq after 00550 batchs: 1390.588623046875
INFO:root:Train (Epoch 23): Loss/seq after 00600 batchs: 1358.1494140625
INFO:root:Train (Epoch 23): Loss/seq after 00650 batchs: 1351.4984130859375
INFO:root:Train (Epoch 23): Loss/seq after 00700 batchs: 1324.2467041015625
INFO:root:Train (Epoch 23): Loss/seq after 00750 batchs: 1352.1954345703125
INFO:root:Train (Epoch 23): Loss/seq after 00800 batchs: 1351.8631591796875
INFO:root:Train (Epoch 23): Loss/seq after 00850 batchs: 1328.177734375
INFO:root:Train (Epoch 23): Loss/seq after 00900 batchs: 1339.728271484375
INFO:root:Train (Epoch 23): Loss/seq after 00950 batchs: 1364.86279296875
INFO:root:Train (Epoch 23): Loss/seq after 01000 batchs: 1358.070068359375
INFO:root:Train (Epoch 23): Loss/seq after 01050 batchs: 1344.9541015625
INFO:root:Train (Epoch 23): Loss/seq after 01100 batchs: 1338.83203125
INFO:root:Train (Epoch 23): Loss/seq after 01150 batchs: 1323.41064453125
INFO:root:Train (Epoch 23): Loss/seq after 01200 batchs: 1314.669921875
INFO:root:Train (Epoch 23): Loss/seq after 01250 batchs: 1308.611572265625
INFO:root:Train (Epoch 23): Loss/seq after 01300 batchs: 1302.5777587890625
INFO:root:Train (Epoch 23): Loss/seq after 01350 batchs: 1298.206787109375
INFO:root:Train (Epoch 23): Loss/seq after 01400 batchs: 1312.516357421875
INFO:root:Train (Epoch 23): Loss/seq after 01450 batchs: 1304.7591552734375
INFO:root:Train (Epoch 23): Loss/seq after 01500 batchs: 1296.89501953125
INFO:root:Train (Epoch 23): Loss/seq after 01550 batchs: 1303.173583984375
INFO:root:Train (Epoch 23): Loss/seq after 01600 batchs: 1287.67138671875
INFO:root:Train (Epoch 23): Loss/seq after 01650 batchs: 1283.6163330078125
INFO:root:Train (Epoch 23): Loss/seq after 01700 batchs: 1275.963623046875
INFO:root:Train (Epoch 23): Loss/seq after 01750 batchs: 1265.2314453125
INFO:root:Train (Epoch 23): Loss/seq after 01800 batchs: 1252.442626953125
INFO:root:Train (Epoch 23): Loss/seq after 01850 batchs: 1240.1585693359375
INFO:root:Train (Epoch 23): Loss/seq after 01900 batchs: 1240.3629150390625
INFO:root:Train (Epoch 23): Loss/seq after 01950 batchs: 1237.005859375
INFO:root:Train (Epoch 23): Loss/seq after 02000 batchs: 1228.5076904296875
INFO:root:Train (Epoch 23): Loss/seq after 02050 batchs: 1221.7091064453125
INFO:root:Train (Epoch 23): Loss/seq after 02100 batchs: 1211.40869140625
INFO:root:Train (Epoch 23): Loss/seq after 02150 batchs: 1202.03857421875
INFO:root:Train (Epoch 23): Loss/seq after 02200 batchs: 1191.7415771484375
INFO:root:Train (Epoch 23): Loss/seq after 02250 batchs: 1197.48095703125
INFO:root:Train (Epoch 23): Loss/seq after 02300 batchs: 1205.385009765625
INFO:root:Train (Epoch 23): Loss/seq after 02350 batchs: 1198.07470703125
INFO:root:Train (Epoch 23): Loss/seq after 02400 batchs: 1195.2672119140625
INFO:root:Train (Epoch 23): Loss/seq after 02450 batchs: 1183.9296875
INFO:root:Train (Epoch 23): Loss/seq after 02500 batchs: 1167.5726318359375
INFO:root:Train (Epoch 23): Loss/seq after 02550 batchs: 1157.5643310546875
INFO:root:Train (Epoch 23): Loss/seq after 02600 batchs: 1155.993896484375
INFO:root:Train (Epoch 23): Loss/seq after 02650 batchs: 1152.4112548828125
INFO:root:Train (Epoch 23): Loss/seq after 02700 batchs: 1148.5400390625
INFO:root:Train (Epoch 23): Loss/seq after 02750 batchs: 1177.9840087890625
INFO:root:Train (Epoch 23): Loss/seq after 02800 batchs: 1183.471923828125
INFO:root:Train (Epoch 23): Loss/seq after 02850 batchs: 1181.731201171875
INFO:root:Train (Epoch 23): Loss/seq after 02900 batchs: 1180.8170166015625
INFO:root:Train (Epoch 23): Loss/seq after 02950 batchs: 1174.1829833984375
INFO:root:Train (Epoch 23): Loss/seq after 03000 batchs: 1172.7314453125
INFO:root:Train (Epoch 23): Loss/seq after 03050 batchs: 1175.9732666015625
INFO:root:Train (Epoch 23): Loss/seq after 03100 batchs: 1190.9774169921875
INFO:root:Train (Epoch 23): Loss/seq after 03150 batchs: 1197.954345703125
INFO:root:Train (Epoch 23): Loss/seq after 03200 batchs: 1204.677490234375
INFO:root:Train (Epoch 23): Loss/seq after 03250 batchs: 1206.35888671875
INFO:root:Train (Epoch 23): Loss/seq after 03300 batchs: 1206.212646484375
INFO:root:Train (Epoch 23): Loss/seq after 03350 batchs: 1205.2442626953125
INFO:root:Train (Epoch 23): Loss/seq after 03400 batchs: 1197.0701904296875
INFO:root:Train (Epoch 23): Loss/seq after 03450 batchs: 1191.273193359375
INFO:root:Train (Epoch 23): Loss/seq after 03500 batchs: 1191.1727294921875
INFO:root:Train (Epoch 23): Loss/seq after 03550 batchs: 1187.013671875
INFO:root:Train (Epoch 23): Loss/seq after 03600 batchs: 1193.4122314453125
INFO:root:Train (Epoch 23): Loss/seq after 03650 batchs: 1189.7950439453125
INFO:root:Train (Epoch 23): Loss/seq after 03700 batchs: 1190.100830078125
INFO:root:Train (Epoch 23): Loss/seq after 03750 batchs: 1190.4786376953125
INFO:root:Train (Epoch 23): Loss/seq after 03800 batchs: 1184.051513671875
INFO:root:Train (Epoch 23): Loss/seq after 03850 batchs: 1180.0838623046875
INFO:root:Train (Epoch 23): Loss/seq after 03900 batchs: 1185.197998046875
INFO:root:Train (Epoch 23): Loss/seq after 03950 batchs: 1188.86181640625
INFO:root:Train (Epoch 23): Loss/seq after 04000 batchs: 1180.28466796875
INFO:root:Train (Epoch 23): Loss/seq after 04050 batchs: 1172.744384765625
INFO:root:Train (Epoch 23): Loss/seq after 04100 batchs: 1167.9931640625
INFO:root:Train (Epoch 23): Loss/seq after 04150 batchs: 1162.6798095703125
INFO:root:Train (Epoch 23): Loss/seq after 04200 batchs: 1158.2508544921875
INFO:root:Train (Epoch 23): Loss/seq after 04250 batchs: 1154.390380859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 23): Loss/seq after 00000 batches: 887.7617797851562
INFO:root:# Valid (Epoch 23): Loss/seq after 00050 batches: 1129.87744140625
INFO:root:# Valid (Epoch 23): Loss/seq after 00100 batches: 1441.344482421875
INFO:root:# Valid (Epoch 23): Loss/seq after 00150 batches: 1178.69287109375
INFO:root:# Valid (Epoch 23): Loss/seq after 00200 batches: 1069.585693359375
INFO:root:Artifacts: Make stick videos for epoch 23
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_23_on_20220422_012932.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_23_index_473_on_20220422_012932.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 24): Loss/seq after 00000 batchs: 1495.0341796875
INFO:root:Train (Epoch 24): Loss/seq after 00050 batchs: 1524.75
INFO:root:Train (Epoch 24): Loss/seq after 00100 batchs: 1543.1341552734375
INFO:root:Train (Epoch 24): Loss/seq after 00150 batchs: 1401.8475341796875
INFO:root:Train (Epoch 24): Loss/seq after 00200 batchs: 1499.5557861328125
INFO:root:Train (Epoch 24): Loss/seq after 00250 batchs: 1598.8140869140625
INFO:root:Train (Epoch 24): Loss/seq after 00300 batchs: 1516.892333984375
INFO:root:Train (Epoch 24): Loss/seq after 00350 batchs: 1424.3697509765625
INFO:root:Train (Epoch 24): Loss/seq after 00400 batchs: 1474.1317138671875
INFO:root:Train (Epoch 24): Loss/seq after 00450 batchs: 1407.8370361328125
INFO:root:Train (Epoch 24): Loss/seq after 00500 batchs: 1439.6876220703125
INFO:root:Train (Epoch 24): Loss/seq after 00550 batchs: 1383.0723876953125
INFO:root:Train (Epoch 24): Loss/seq after 00600 batchs: 1350.1134033203125
INFO:root:Train (Epoch 24): Loss/seq after 00650 batchs: 1340.5181884765625
INFO:root:Train (Epoch 24): Loss/seq after 00700 batchs: 1308.6051025390625
INFO:root:Train (Epoch 24): Loss/seq after 00750 batchs: 1343.2384033203125
INFO:root:Train (Epoch 24): Loss/seq after 00800 batchs: 1344.1219482421875
INFO:root:Train (Epoch 24): Loss/seq after 00850 batchs: 1320.78125
INFO:root:Train (Epoch 24): Loss/seq after 00900 batchs: 1332.5753173828125
INFO:root:Train (Epoch 24): Loss/seq after 00950 batchs: 1357.86669921875
INFO:root:Train (Epoch 24): Loss/seq after 01000 batchs: 1351.904541015625
INFO:root:Train (Epoch 24): Loss/seq after 01050 batchs: 1338.5030517578125
INFO:root:Train (Epoch 24): Loss/seq after 01100 batchs: 1330.6746826171875
INFO:root:Train (Epoch 24): Loss/seq after 01150 batchs: 1315.0999755859375
INFO:root:Train (Epoch 24): Loss/seq after 01200 batchs: 1306.5093994140625
INFO:root:Train (Epoch 24): Loss/seq after 01250 batchs: 1300.3558349609375
INFO:root:Train (Epoch 24): Loss/seq after 01300 batchs: 1294.2215576171875
INFO:root:Train (Epoch 24): Loss/seq after 01350 batchs: 1289.666259765625
INFO:root:Train (Epoch 24): Loss/seq after 01400 batchs: 1303.0029296875
INFO:root:Train (Epoch 24): Loss/seq after 01450 batchs: 1294.63525390625
INFO:root:Train (Epoch 24): Loss/seq after 01500 batchs: 1286.70263671875
INFO:root:Train (Epoch 24): Loss/seq after 01550 batchs: 1293.6368408203125
INFO:root:Train (Epoch 24): Loss/seq after 01600 batchs: 1278.50439453125
INFO:root:Train (Epoch 24): Loss/seq after 01650 batchs: 1275.469970703125
INFO:root:Train (Epoch 24): Loss/seq after 01700 batchs: 1268.1846923828125
INFO:root:Train (Epoch 24): Loss/seq after 01750 batchs: 1257.8270263671875
INFO:root:Train (Epoch 24): Loss/seq after 01800 batchs: 1245.4708251953125
INFO:root:Train (Epoch 24): Loss/seq after 01850 batchs: 1233.3460693359375
INFO:root:Train (Epoch 24): Loss/seq after 01900 batchs: 1233.5418701171875
INFO:root:Train (Epoch 24): Loss/seq after 01950 batchs: 1230.2066650390625
INFO:root:Train (Epoch 24): Loss/seq after 02000 batchs: 1221.8173828125
INFO:root:Train (Epoch 24): Loss/seq after 02050 batchs: 1215.1134033203125
INFO:root:Train (Epoch 24): Loss/seq after 02100 batchs: 1204.9334716796875
INFO:root:Train (Epoch 24): Loss/seq after 02150 batchs: 1195.6221923828125
INFO:root:Train (Epoch 24): Loss/seq after 02200 batchs: 1185.4854736328125
INFO:root:Train (Epoch 24): Loss/seq after 02250 batchs: 1190.1036376953125
INFO:root:Train (Epoch 24): Loss/seq after 02300 batchs: 1197.0909423828125
INFO:root:Train (Epoch 24): Loss/seq after 02350 batchs: 1189.0643310546875
INFO:root:Train (Epoch 24): Loss/seq after 02400 batchs: 1186.3704833984375
INFO:root:Train (Epoch 24): Loss/seq after 02450 batchs: 1175.0213623046875
INFO:root:Train (Epoch 24): Loss/seq after 02500 batchs: 1158.7421875
INFO:root:Train (Epoch 24): Loss/seq after 02550 batchs: 1148.6156005859375
INFO:root:Train (Epoch 24): Loss/seq after 02600 batchs: 1146.8482666015625
INFO:root:Train (Epoch 24): Loss/seq after 02650 batchs: 1143.035888671875
INFO:root:Train (Epoch 24): Loss/seq after 02700 batchs: 1139.11474609375
INFO:root:Train (Epoch 24): Loss/seq after 02750 batchs: 1167.510009765625
INFO:root:Train (Epoch 24): Loss/seq after 02800 batchs: 1171.0648193359375
INFO:root:Train (Epoch 24): Loss/seq after 02850 batchs: 1169.215087890625
INFO:root:Train (Epoch 24): Loss/seq after 02900 batchs: 1168.2529296875
INFO:root:Train (Epoch 24): Loss/seq after 02950 batchs: 1161.3341064453125
INFO:root:Train (Epoch 24): Loss/seq after 03000 batchs: 1160.0838623046875
INFO:root:Train (Epoch 24): Loss/seq after 03050 batchs: 1163.4716796875
INFO:root:Train (Epoch 24): Loss/seq after 03100 batchs: 1177.376953125
INFO:root:Train (Epoch 24): Loss/seq after 03150 batchs: 1183.708740234375
INFO:root:Train (Epoch 24): Loss/seq after 03200 batchs: 1188.420166015625
INFO:root:Train (Epoch 24): Loss/seq after 03250 batchs: 1188.745849609375
INFO:root:Train (Epoch 24): Loss/seq after 03300 batchs: 1187.4686279296875
INFO:root:Train (Epoch 24): Loss/seq after 03350 batchs: 1186.2607421875
INFO:root:Train (Epoch 24): Loss/seq after 03400 batchs: 1178.2818603515625
INFO:root:Train (Epoch 24): Loss/seq after 03450 batchs: 1172.31884765625
INFO:root:Train (Epoch 24): Loss/seq after 03500 batchs: 1172.3963623046875
INFO:root:Train (Epoch 24): Loss/seq after 03550 batchs: 1168.3084716796875
INFO:root:Train (Epoch 24): Loss/seq after 03600 batchs: 1174.991455078125
INFO:root:Train (Epoch 24): Loss/seq after 03650 batchs: 1171.9625244140625
INFO:root:Train (Epoch 24): Loss/seq after 03700 batchs: 1172.7960205078125
INFO:root:Train (Epoch 24): Loss/seq after 03750 batchs: 1173.3636474609375
INFO:root:Train (Epoch 24): Loss/seq after 03800 batchs: 1167.10107421875
INFO:root:Train (Epoch 24): Loss/seq after 03850 batchs: 1163.3880615234375
INFO:root:Train (Epoch 24): Loss/seq after 03900 batchs: 1168.2064208984375
INFO:root:Train (Epoch 24): Loss/seq after 03950 batchs: 1172.1510009765625
INFO:root:Train (Epoch 24): Loss/seq after 04000 batchs: 1163.7664794921875
INFO:root:Train (Epoch 24): Loss/seq after 04050 batchs: 1156.4434814453125
INFO:root:Train (Epoch 24): Loss/seq after 04100 batchs: 1152.15380859375
INFO:root:Train (Epoch 24): Loss/seq after 04150 batchs: 1147.0234375
INFO:root:Train (Epoch 24): Loss/seq after 04200 batchs: 1142.7535400390625
INFO:root:Train (Epoch 24): Loss/seq after 04250 batchs: 1139.1617431640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 24): Loss/seq after 00000 batches: 883.0458984375
INFO:root:# Valid (Epoch 24): Loss/seq after 00050 batches: 1116.9593505859375
INFO:root:# Valid (Epoch 24): Loss/seq after 00100 batches: 1425.8399658203125
INFO:root:# Valid (Epoch 24): Loss/seq after 00150 batches: 1165.37548828125
INFO:root:# Valid (Epoch 24): Loss/seq after 00200 batches: 1054.946533203125
INFO:root:Artifacts: Make stick videos for epoch 24
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_24_on_20220422_013428.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_24_index_899_on_20220422_013428.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 25): Loss/seq after 00000 batchs: 1870.579833984375
INFO:root:Train (Epoch 25): Loss/seq after 00050 batchs: 1482.184814453125
INFO:root:Train (Epoch 25): Loss/seq after 00100 batchs: 1497.2325439453125
INFO:root:Train (Epoch 25): Loss/seq after 00150 batchs: 1365.7869873046875
INFO:root:Train (Epoch 25): Loss/seq after 00200 batchs: 1476.3486328125
INFO:root:Train (Epoch 25): Loss/seq after 00250 batchs: 1573.359619140625
INFO:root:Train (Epoch 25): Loss/seq after 00300 batchs: 1495.9161376953125
INFO:root:Train (Epoch 25): Loss/seq after 00350 batchs: 1405.8153076171875
INFO:root:Train (Epoch 25): Loss/seq after 00400 batchs: 1455.9818115234375
INFO:root:Train (Epoch 25): Loss/seq after 00450 batchs: 1391.737060546875
INFO:root:Train (Epoch 25): Loss/seq after 00500 batchs: 1422.700927734375
INFO:root:Train (Epoch 25): Loss/seq after 00550 batchs: 1368.2645263671875
INFO:root:Train (Epoch 25): Loss/seq after 00600 batchs: 1337.06396484375
INFO:root:Train (Epoch 25): Loss/seq after 00650 batchs: 1331.1405029296875
INFO:root:Train (Epoch 25): Loss/seq after 00700 batchs: 1296.5823974609375
INFO:root:Train (Epoch 25): Loss/seq after 00750 batchs: 1333.0755615234375
INFO:root:Train (Epoch 25): Loss/seq after 00800 batchs: 1334.53857421875
INFO:root:Train (Epoch 25): Loss/seq after 00850 batchs: 1311.9080810546875
INFO:root:Train (Epoch 25): Loss/seq after 00900 batchs: 1323.372314453125
INFO:root:Train (Epoch 25): Loss/seq after 00950 batchs: 1360.243896484375
INFO:root:Train (Epoch 25): Loss/seq after 01000 batchs: 1353.673095703125
INFO:root:Train (Epoch 25): Loss/seq after 01050 batchs: 1339.671875
INFO:root:Train (Epoch 25): Loss/seq after 01100 batchs: 1329.9405517578125
INFO:root:Train (Epoch 25): Loss/seq after 01150 batchs: 1314.051513671875
INFO:root:Train (Epoch 25): Loss/seq after 01200 batchs: 1305.41845703125
INFO:root:Train (Epoch 25): Loss/seq after 01250 batchs: 1298.597900390625
INFO:root:Train (Epoch 25): Loss/seq after 01300 batchs: 1290.2073974609375
INFO:root:Train (Epoch 25): Loss/seq after 01350 batchs: 1283.6961669921875
INFO:root:Train (Epoch 25): Loss/seq after 01400 batchs: 1298.1785888671875
INFO:root:Train (Epoch 25): Loss/seq after 01450 batchs: 1290.1646728515625
INFO:root:Train (Epoch 25): Loss/seq after 01500 batchs: 1282.5404052734375
INFO:root:Train (Epoch 25): Loss/seq after 01550 batchs: 1288.649658203125
INFO:root:Train (Epoch 25): Loss/seq after 01600 batchs: 1273.6998291015625
INFO:root:Train (Epoch 25): Loss/seq after 01650 batchs: 1270.1190185546875
INFO:root:Train (Epoch 25): Loss/seq after 01700 batchs: 1263.00146484375
INFO:root:Train (Epoch 25): Loss/seq after 01750 batchs: 1252.66162109375
INFO:root:Train (Epoch 25): Loss/seq after 01800 batchs: 1240.3265380859375
INFO:root:Train (Epoch 25): Loss/seq after 01850 batchs: 1228.242919921875
INFO:root:Train (Epoch 25): Loss/seq after 01900 batchs: 1228.6533203125
INFO:root:Train (Epoch 25): Loss/seq after 01950 batchs: 1225.5675048828125
INFO:root:Train (Epoch 25): Loss/seq after 02000 batchs: 1217.356201171875
INFO:root:Train (Epoch 25): Loss/seq after 02050 batchs: 1210.739990234375
INFO:root:Train (Epoch 25): Loss/seq after 02100 batchs: 1200.6396484375
INFO:root:Train (Epoch 25): Loss/seq after 02150 batchs: 1191.3690185546875
INFO:root:Train (Epoch 25): Loss/seq after 02200 batchs: 1181.2513427734375
INFO:root:Train (Epoch 25): Loss/seq after 02250 batchs: 1186.4649658203125
INFO:root:Train (Epoch 25): Loss/seq after 02300 batchs: 1193.625732421875
INFO:root:Train (Epoch 25): Loss/seq after 02350 batchs: 1185.544677734375
INFO:root:Train (Epoch 25): Loss/seq after 02400 batchs: 1182.8006591796875
INFO:root:Train (Epoch 25): Loss/seq after 02450 batchs: 1171.4947509765625
INFO:root:Train (Epoch 25): Loss/seq after 02500 batchs: 1155.269775390625
INFO:root:Train (Epoch 25): Loss/seq after 02550 batchs: 1145.15673828125
INFO:root:Train (Epoch 25): Loss/seq after 02600 batchs: 1143.201171875
INFO:root:Train (Epoch 25): Loss/seq after 02650 batchs: 1139.1466064453125
INFO:root:Train (Epoch 25): Loss/seq after 02700 batchs: 1135.40673828125
INFO:root:Train (Epoch 25): Loss/seq after 02750 batchs: 1163.2232666015625
INFO:root:Train (Epoch 25): Loss/seq after 02800 batchs: 1168.8155517578125
INFO:root:Train (Epoch 25): Loss/seq after 02850 batchs: 1167.4359130859375
INFO:root:Train (Epoch 25): Loss/seq after 02900 batchs: 1166.84228515625
INFO:root:Train (Epoch 25): Loss/seq after 02950 batchs: 1160.22998046875
INFO:root:Train (Epoch 25): Loss/seq after 03000 batchs: 1159.013427734375
INFO:root:Train (Epoch 25): Loss/seq after 03050 batchs: 1162.572265625
INFO:root:Train (Epoch 25): Loss/seq after 03100 batchs: 1177.0303955078125
INFO:root:Train (Epoch 25): Loss/seq after 03150 batchs: 1182.9351806640625
INFO:root:Train (Epoch 25): Loss/seq after 03200 batchs: 1187.5140380859375
INFO:root:Train (Epoch 25): Loss/seq after 03250 batchs: 1187.87548828125
INFO:root:Train (Epoch 25): Loss/seq after 03300 batchs: 1186.4000244140625
INFO:root:Train (Epoch 25): Loss/seq after 03350 batchs: 1185.17041015625
INFO:root:Train (Epoch 25): Loss/seq after 03400 batchs: 1177.054443359375
INFO:root:Train (Epoch 25): Loss/seq after 03450 batchs: 1170.80224609375
INFO:root:Train (Epoch 25): Loss/seq after 03500 batchs: 1170.6446533203125
INFO:root:Train (Epoch 25): Loss/seq after 03550 batchs: 1166.4619140625
INFO:root:Train (Epoch 25): Loss/seq after 03600 batchs: 1173.076904296875
INFO:root:Train (Epoch 25): Loss/seq after 03650 batchs: 1169.5391845703125
INFO:root:Train (Epoch 25): Loss/seq after 03700 batchs: 1169.9378662109375
INFO:root:Train (Epoch 25): Loss/seq after 03750 batchs: 1170.596923828125
INFO:root:Train (Epoch 25): Loss/seq after 03800 batchs: 1164.2723388671875
INFO:root:Train (Epoch 25): Loss/seq after 03850 batchs: 1160.6146240234375
INFO:root:Train (Epoch 25): Loss/seq after 03900 batchs: 1164.9996337890625
INFO:root:Train (Epoch 25): Loss/seq after 03950 batchs: 1168.3916015625
INFO:root:Train (Epoch 25): Loss/seq after 04000 batchs: 1160.0775146484375
INFO:root:Train (Epoch 25): Loss/seq after 04050 batchs: 1152.7244873046875
INFO:root:Train (Epoch 25): Loss/seq after 04100 batchs: 1147.8544921875
INFO:root:Train (Epoch 25): Loss/seq after 04150 batchs: 1142.7967529296875
INFO:root:Train (Epoch 25): Loss/seq after 04200 batchs: 1138.5303955078125
INFO:root:Train (Epoch 25): Loss/seq after 04250 batchs: 1134.9552001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 25): Loss/seq after 00000 batches: 884.8405151367188
INFO:root:# Valid (Epoch 25): Loss/seq after 00050 batches: 1106.8907470703125
INFO:root:# Valid (Epoch 25): Loss/seq after 00100 batches: 1415.587646484375
INFO:root:# Valid (Epoch 25): Loss/seq after 00150 batches: 1148.3692626953125
INFO:root:# Valid (Epoch 25): Loss/seq after 00200 batches: 1040.5875244140625
INFO:root:Artifacts: Make stick videos for epoch 25
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_25_on_20220422_013913.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_25_index_1427_on_20220422_013913.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 26): Loss/seq after 00000 batchs: 1478.3211669921875
INFO:root:Train (Epoch 26): Loss/seq after 00050 batchs: 1468.312744140625
INFO:root:Train (Epoch 26): Loss/seq after 00100 batchs: 1481.321044921875
INFO:root:Train (Epoch 26): Loss/seq after 00150 batchs: 1356.7425537109375
INFO:root:Train (Epoch 26): Loss/seq after 00200 batchs: 1455.522705078125
INFO:root:Train (Epoch 26): Loss/seq after 00250 batchs: 1555.8917236328125
INFO:root:Train (Epoch 26): Loss/seq after 00300 batchs: 1480.374267578125
INFO:root:Train (Epoch 26): Loss/seq after 00350 batchs: 1391.21630859375
INFO:root:Train (Epoch 26): Loss/seq after 00400 batchs: 1447.0069580078125
INFO:root:Train (Epoch 26): Loss/seq after 00450 batchs: 1383.9266357421875
INFO:root:Train (Epoch 26): Loss/seq after 00500 batchs: 1417.2071533203125
INFO:root:Train (Epoch 26): Loss/seq after 00550 batchs: 1363.8486328125
INFO:root:Train (Epoch 26): Loss/seq after 00600 batchs: 1331.0927734375
INFO:root:Train (Epoch 26): Loss/seq after 00650 batchs: 1324.2623291015625
INFO:root:Train (Epoch 26): Loss/seq after 00700 batchs: 1286.1405029296875
INFO:root:Train (Epoch 26): Loss/seq after 00750 batchs: 1318.0982666015625
INFO:root:Train (Epoch 26): Loss/seq after 00800 batchs: 1319.13525390625
INFO:root:Train (Epoch 26): Loss/seq after 00850 batchs: 1293.4056396484375
INFO:root:Train (Epoch 26): Loss/seq after 00900 batchs: 1301.148681640625
INFO:root:Train (Epoch 26): Loss/seq after 00950 batchs: 1328.9776611328125
INFO:root:Train (Epoch 26): Loss/seq after 01000 batchs: 1320.2432861328125
INFO:root:Train (Epoch 26): Loss/seq after 01050 batchs: 1307.248779296875
INFO:root:Train (Epoch 26): Loss/seq after 01100 batchs: 1295.007080078125
INFO:root:Train (Epoch 26): Loss/seq after 01150 batchs: 1277.1602783203125
INFO:root:Train (Epoch 26): Loss/seq after 01200 batchs: 1269.24755859375
INFO:root:Train (Epoch 26): Loss/seq after 01250 batchs: 1263.9300537109375
INFO:root:Train (Epoch 26): Loss/seq after 01300 batchs: 1253.747802734375
INFO:root:Train (Epoch 26): Loss/seq after 01350 batchs: 1246.8402099609375
INFO:root:Train (Epoch 26): Loss/seq after 01400 batchs: 1263.153564453125
INFO:root:Train (Epoch 26): Loss/seq after 01450 batchs: 1256.45361328125
INFO:root:Train (Epoch 26): Loss/seq after 01500 batchs: 1249.5712890625
INFO:root:Train (Epoch 26): Loss/seq after 01550 batchs: 1255.01123046875
INFO:root:Train (Epoch 26): Loss/seq after 01600 batchs: 1240.875244140625
INFO:root:Train (Epoch 26): Loss/seq after 01650 batchs: 1236.9962158203125
INFO:root:Train (Epoch 26): Loss/seq after 01700 batchs: 1230.1563720703125
INFO:root:Train (Epoch 26): Loss/seq after 01750 batchs: 1219.86669921875
INFO:root:Train (Epoch 26): Loss/seq after 01800 batchs: 1207.8740234375
INFO:root:Train (Epoch 26): Loss/seq after 01850 batchs: 1195.7352294921875
INFO:root:Train (Epoch 26): Loss/seq after 01900 batchs: 1196.472412109375
INFO:root:Train (Epoch 26): Loss/seq after 01950 batchs: 1192.76513671875
INFO:root:Train (Epoch 26): Loss/seq after 02000 batchs: 1185.0452880859375
INFO:root:Train (Epoch 26): Loss/seq after 02050 batchs: 1178.845947265625
INFO:root:Train (Epoch 26): Loss/seq after 02100 batchs: 1168.7291259765625
INFO:root:Train (Epoch 26): Loss/seq after 02150 batchs: 1159.8599853515625
INFO:root:Train (Epoch 26): Loss/seq after 02200 batchs: 1150.012939453125
INFO:root:Train (Epoch 26): Loss/seq after 02250 batchs: 1156.3238525390625
INFO:root:Train (Epoch 26): Loss/seq after 02300 batchs: 1163.1552734375
INFO:root:Train (Epoch 26): Loss/seq after 02350 batchs: 1155.510009765625
INFO:root:Train (Epoch 26): Loss/seq after 02400 batchs: 1152.5133056640625
INFO:root:Train (Epoch 26): Loss/seq after 02450 batchs: 1141.66064453125
INFO:root:Train (Epoch 26): Loss/seq after 02500 batchs: 1125.40673828125
INFO:root:Train (Epoch 26): Loss/seq after 02550 batchs: 1115.1795654296875
INFO:root:Train (Epoch 26): Loss/seq after 02600 batchs: 1112.8399658203125
INFO:root:Train (Epoch 26): Loss/seq after 02650 batchs: 1108.529296875
INFO:root:Train (Epoch 26): Loss/seq after 02700 batchs: 1105.34375
INFO:root:Train (Epoch 26): Loss/seq after 02750 batchs: 1131.7874755859375
INFO:root:Train (Epoch 26): Loss/seq after 02800 batchs: 1136.129638671875
INFO:root:Train (Epoch 26): Loss/seq after 02850 batchs: 1135.45458984375
INFO:root:Train (Epoch 26): Loss/seq after 02900 batchs: 1135.5447998046875
INFO:root:Train (Epoch 26): Loss/seq after 02950 batchs: 1129.0103759765625
INFO:root:Train (Epoch 26): Loss/seq after 03000 batchs: 1128.0205078125
INFO:root:Train (Epoch 26): Loss/seq after 03050 batchs: 1131.5673828125
INFO:root:Train (Epoch 26): Loss/seq after 03100 batchs: 1147.55224609375
INFO:root:Train (Epoch 26): Loss/seq after 03150 batchs: 1153.88818359375
INFO:root:Train (Epoch 26): Loss/seq after 03200 batchs: 1157.022705078125
INFO:root:Train (Epoch 26): Loss/seq after 03250 batchs: 1157.8406982421875
INFO:root:Train (Epoch 26): Loss/seq after 03300 batchs: 1157.0777587890625
INFO:root:Train (Epoch 26): Loss/seq after 03350 batchs: 1156.0760498046875
INFO:root:Train (Epoch 26): Loss/seq after 03400 batchs: 1147.554931640625
INFO:root:Train (Epoch 26): Loss/seq after 03450 batchs: 1141.41357421875
INFO:root:Train (Epoch 26): Loss/seq after 03500 batchs: 1141.2921142578125
INFO:root:Train (Epoch 26): Loss/seq after 03550 batchs: 1137.3792724609375
INFO:root:Train (Epoch 26): Loss/seq after 03600 batchs: 1143.98046875
INFO:root:Train (Epoch 26): Loss/seq after 03650 batchs: 1140.3212890625
INFO:root:Train (Epoch 26): Loss/seq after 03700 batchs: 1140.2274169921875
INFO:root:Train (Epoch 26): Loss/seq after 03750 batchs: 1141.05322265625
INFO:root:Train (Epoch 26): Loss/seq after 03800 batchs: 1134.5614013671875
INFO:root:Train (Epoch 26): Loss/seq after 03850 batchs: 1130.900146484375
INFO:root:Train (Epoch 26): Loss/seq after 03900 batchs: 1135.42724609375
INFO:root:Train (Epoch 26): Loss/seq after 03950 batchs: 1139.431640625
INFO:root:Train (Epoch 26): Loss/seq after 04000 batchs: 1131.3343505859375
INFO:root:Train (Epoch 26): Loss/seq after 04050 batchs: 1123.8966064453125
INFO:root:Train (Epoch 26): Loss/seq after 04100 batchs: 1119.17919921875
INFO:root:Train (Epoch 26): Loss/seq after 04150 batchs: 1114.2867431640625
INFO:root:Train (Epoch 26): Loss/seq after 04200 batchs: 1110.1981201171875
INFO:root:Train (Epoch 26): Loss/seq after 04250 batchs: 1106.221435546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 26): Loss/seq after 00000 batches: 841.9287109375
INFO:root:# Valid (Epoch 26): Loss/seq after 00050 batches: 1046.06201171875
INFO:root:# Valid (Epoch 26): Loss/seq after 00100 batches: 1357.2947998046875
INFO:root:# Valid (Epoch 26): Loss/seq after 00150 batches: 1084.5496826171875
INFO:root:# Valid (Epoch 26): Loss/seq after 00200 batches: 983.8717041015625
INFO:root:Artifacts: Make stick videos for epoch 26
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_26_on_20220422_014410.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_26_index_401_on_20220422_014410.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 27): Loss/seq after 00000 batchs: 1577.9228515625
INFO:root:Train (Epoch 27): Loss/seq after 00050 batchs: 1451.8553466796875
INFO:root:Train (Epoch 27): Loss/seq after 00100 batchs: 1470.3499755859375
INFO:root:Train (Epoch 27): Loss/seq after 00150 batchs: 1340.1805419921875
INFO:root:Train (Epoch 27): Loss/seq after 00200 batchs: 1443.9400634765625
INFO:root:Train (Epoch 27): Loss/seq after 00250 batchs: 1539.47412109375
INFO:root:Train (Epoch 27): Loss/seq after 00300 batchs: 1463.2822265625
INFO:root:Train (Epoch 27): Loss/seq after 00350 batchs: 1370.616943359375
INFO:root:Train (Epoch 27): Loss/seq after 00400 batchs: 1424.0267333984375
INFO:root:Train (Epoch 27): Loss/seq after 00450 batchs: 1361.87109375
INFO:root:Train (Epoch 27): Loss/seq after 00500 batchs: 1389.64404296875
INFO:root:Train (Epoch 27): Loss/seq after 00550 batchs: 1335.8409423828125
INFO:root:Train (Epoch 27): Loss/seq after 00600 batchs: 1300.4923095703125
INFO:root:Train (Epoch 27): Loss/seq after 00650 batchs: 1296.00244140625
INFO:root:Train (Epoch 27): Loss/seq after 00700 batchs: 1260.1038818359375
INFO:root:Train (Epoch 27): Loss/seq after 00750 batchs: 1294.2440185546875
INFO:root:Train (Epoch 27): Loss/seq after 00800 batchs: 1294.1058349609375
INFO:root:Train (Epoch 27): Loss/seq after 00850 batchs: 1265.148681640625
INFO:root:Train (Epoch 27): Loss/seq after 00900 batchs: 1263.304931640625
INFO:root:Train (Epoch 27): Loss/seq after 00950 batchs: 1296.2967529296875
INFO:root:Train (Epoch 27): Loss/seq after 01000 batchs: 1287.720458984375
INFO:root:Train (Epoch 27): Loss/seq after 01050 batchs: 1274.294189453125
INFO:root:Train (Epoch 27): Loss/seq after 01100 batchs: 1260.7498779296875
INFO:root:Train (Epoch 27): Loss/seq after 01150 batchs: 1241.252685546875
INFO:root:Train (Epoch 27): Loss/seq after 01200 batchs: 1236.3223876953125
INFO:root:Train (Epoch 27): Loss/seq after 01250 batchs: 1231.1641845703125
INFO:root:Train (Epoch 27): Loss/seq after 01300 batchs: 1220.247314453125
INFO:root:Train (Epoch 27): Loss/seq after 01350 batchs: 1210.834228515625
INFO:root:Train (Epoch 27): Loss/seq after 01400 batchs: 1228.019287109375
INFO:root:Train (Epoch 27): Loss/seq after 01450 batchs: 1222.387451171875
INFO:root:Train (Epoch 27): Loss/seq after 01500 batchs: 1216.46337890625
INFO:root:Train (Epoch 27): Loss/seq after 01550 batchs: 1223.5211181640625
INFO:root:Train (Epoch 27): Loss/seq after 01600 batchs: 1210.664794921875
INFO:root:Train (Epoch 27): Loss/seq after 01650 batchs: 1207.431884765625
INFO:root:Train (Epoch 27): Loss/seq after 01700 batchs: 1200.8187255859375
INFO:root:Train (Epoch 27): Loss/seq after 01750 batchs: 1190.3795166015625
INFO:root:Train (Epoch 27): Loss/seq after 01800 batchs: 1178.635009765625
INFO:root:Train (Epoch 27): Loss/seq after 01850 batchs: 1166.4832763671875
INFO:root:Train (Epoch 27): Loss/seq after 01900 batchs: 1167.72265625
INFO:root:Train (Epoch 27): Loss/seq after 01950 batchs: 1164.1099853515625
INFO:root:Train (Epoch 27): Loss/seq after 02000 batchs: 1156.6473388671875
INFO:root:Train (Epoch 27): Loss/seq after 02050 batchs: 1150.771240234375
INFO:root:Train (Epoch 27): Loss/seq after 02100 batchs: 1140.767578125
INFO:root:Train (Epoch 27): Loss/seq after 02150 batchs: 1132.271484375
INFO:root:Train (Epoch 27): Loss/seq after 02200 batchs: 1122.6004638671875
INFO:root:Train (Epoch 27): Loss/seq after 02250 batchs: 1128.5869140625
INFO:root:Train (Epoch 27): Loss/seq after 02300 batchs: 1135.0902099609375
INFO:root:Train (Epoch 27): Loss/seq after 02350 batchs: 1126.87744140625
INFO:root:Train (Epoch 27): Loss/seq after 02400 batchs: 1123.8250732421875
INFO:root:Train (Epoch 27): Loss/seq after 02450 batchs: 1113.11181640625
INFO:root:Train (Epoch 27): Loss/seq after 02500 batchs: 1096.7939453125
INFO:root:Train (Epoch 27): Loss/seq after 02550 batchs: 1086.257568359375
INFO:root:Train (Epoch 27): Loss/seq after 02600 batchs: 1082.72802734375
INFO:root:Train (Epoch 27): Loss/seq after 02650 batchs: 1076.9169921875
INFO:root:Train (Epoch 27): Loss/seq after 02700 batchs: 1073.4466552734375
INFO:root:Train (Epoch 27): Loss/seq after 02750 batchs: 1098.680419921875
INFO:root:Train (Epoch 27): Loss/seq after 02800 batchs: 1102.1279296875
INFO:root:Train (Epoch 27): Loss/seq after 02850 batchs: 1100.8175048828125
INFO:root:Train (Epoch 27): Loss/seq after 02900 batchs: 1100.1802978515625
INFO:root:Train (Epoch 27): Loss/seq after 02950 batchs: 1093.9287109375
INFO:root:Train (Epoch 27): Loss/seq after 03000 batchs: 1093.225341796875
INFO:root:Train (Epoch 27): Loss/seq after 03050 batchs: 1096.54736328125
INFO:root:Train (Epoch 27): Loss/seq after 03100 batchs: 1112.115234375
INFO:root:Train (Epoch 27): Loss/seq after 03150 batchs: 1118.30078125
INFO:root:Train (Epoch 27): Loss/seq after 03200 batchs: 1122.4102783203125
INFO:root:Train (Epoch 27): Loss/seq after 03250 batchs: 1123.38818359375
INFO:root:Train (Epoch 27): Loss/seq after 03300 batchs: 1122.42724609375
INFO:root:Train (Epoch 27): Loss/seq after 03350 batchs: 1121.124267578125
INFO:root:Train (Epoch 27): Loss/seq after 03400 batchs: 1112.7896728515625
INFO:root:Train (Epoch 27): Loss/seq after 03450 batchs: 1106.6810302734375
INFO:root:Train (Epoch 27): Loss/seq after 03500 batchs: 1107.200927734375
INFO:root:Train (Epoch 27): Loss/seq after 03550 batchs: 1103.4764404296875
INFO:root:Train (Epoch 27): Loss/seq after 03600 batchs: 1110.327880859375
INFO:root:Train (Epoch 27): Loss/seq after 03650 batchs: 1106.7247314453125
INFO:root:Train (Epoch 27): Loss/seq after 03700 batchs: 1106.484619140625
INFO:root:Train (Epoch 27): Loss/seq after 03750 batchs: 1107.546875
INFO:root:Train (Epoch 27): Loss/seq after 03800 batchs: 1100.966064453125
INFO:root:Train (Epoch 27): Loss/seq after 03850 batchs: 1097.3817138671875
INFO:root:Train (Epoch 27): Loss/seq after 03900 batchs: 1102.0789794921875
INFO:root:Train (Epoch 27): Loss/seq after 03950 batchs: 1106.591796875
INFO:root:Train (Epoch 27): Loss/seq after 04000 batchs: 1098.76123046875
INFO:root:Train (Epoch 27): Loss/seq after 04050 batchs: 1091.1038818359375
INFO:root:Train (Epoch 27): Loss/seq after 04100 batchs: 1086.4134521484375
INFO:root:Train (Epoch 27): Loss/seq after 04150 batchs: 1081.7696533203125
INFO:root:Train (Epoch 27): Loss/seq after 04200 batchs: 1078.044189453125
INFO:root:Train (Epoch 27): Loss/seq after 04250 batchs: 1074.005126953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 27): Loss/seq after 00000 batches: 868.9689331054688
INFO:root:# Valid (Epoch 27): Loss/seq after 00050 batches: 986.4320068359375
INFO:root:# Valid (Epoch 27): Loss/seq after 00100 batches: 1331.6463623046875
INFO:root:# Valid (Epoch 27): Loss/seq after 00150 batches: 1073.729248046875
INFO:root:# Valid (Epoch 27): Loss/seq after 00200 batches: 992.8088989257812
INFO:root:Artifacts: Make stick videos for epoch 27
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_27_on_20220422_014855.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_27_index_126_on_20220422_014855.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 28): Loss/seq after 00000 batchs: 1398.7691650390625
INFO:root:Train (Epoch 28): Loss/seq after 00050 batchs: 1410.4605712890625
INFO:root:Train (Epoch 28): Loss/seq after 00100 batchs: 1454.96826171875
INFO:root:Train (Epoch 28): Loss/seq after 00150 batchs: 1324.3671875
INFO:root:Train (Epoch 28): Loss/seq after 00200 batchs: 1424.7972412109375
INFO:root:Train (Epoch 28): Loss/seq after 00250 batchs: 1520.8472900390625
INFO:root:Train (Epoch 28): Loss/seq after 00300 batchs: 1444.4635009765625
INFO:root:Train (Epoch 28): Loss/seq after 00350 batchs: 1349.674072265625
INFO:root:Train (Epoch 28): Loss/seq after 00400 batchs: 1402.9976806640625
INFO:root:Train (Epoch 28): Loss/seq after 00450 batchs: 1342.3466796875
INFO:root:Train (Epoch 28): Loss/seq after 00500 batchs: 1368.0128173828125
INFO:root:Train (Epoch 28): Loss/seq after 00550 batchs: 1315.3128662109375
INFO:root:Train (Epoch 28): Loss/seq after 00600 batchs: 1278.1400146484375
INFO:root:Train (Epoch 28): Loss/seq after 00650 batchs: 1275.6571044921875
INFO:root:Train (Epoch 28): Loss/seq after 00700 batchs: 1239.00927734375
INFO:root:Train (Epoch 28): Loss/seq after 00750 batchs: 1271.6427001953125
INFO:root:Train (Epoch 28): Loss/seq after 00800 batchs: 1271.5731201171875
INFO:root:Train (Epoch 28): Loss/seq after 00850 batchs: 1238.52734375
INFO:root:Train (Epoch 28): Loss/seq after 00900 batchs: 1233.1519775390625
INFO:root:Train (Epoch 28): Loss/seq after 00950 batchs: 1268.5765380859375
INFO:root:Train (Epoch 28): Loss/seq after 01000 batchs: 1262.04638671875
INFO:root:Train (Epoch 28): Loss/seq after 01050 batchs: 1247.713623046875
INFO:root:Train (Epoch 28): Loss/seq after 01100 batchs: 1230.318359375
INFO:root:Train (Epoch 28): Loss/seq after 01150 batchs: 1202.6375732421875
INFO:root:Train (Epoch 28): Loss/seq after 01200 batchs: 1196.5906982421875
INFO:root:Train (Epoch 28): Loss/seq after 01250 batchs: 1190.5992431640625
INFO:root:Train (Epoch 28): Loss/seq after 01300 batchs: 1178.4056396484375
INFO:root:Train (Epoch 28): Loss/seq after 01350 batchs: 1168.6181640625
INFO:root:Train (Epoch 28): Loss/seq after 01400 batchs: 1188.0601806640625
INFO:root:Train (Epoch 28): Loss/seq after 01450 batchs: 1182.6048583984375
INFO:root:Train (Epoch 28): Loss/seq after 01500 batchs: 1177.129638671875
INFO:root:Train (Epoch 28): Loss/seq after 01550 batchs: 1184.3035888671875
INFO:root:Train (Epoch 28): Loss/seq after 01600 batchs: 1170.8048095703125
INFO:root:Train (Epoch 28): Loss/seq after 01650 batchs: 1167.041015625
INFO:root:Train (Epoch 28): Loss/seq after 01700 batchs: 1160.301513671875
INFO:root:Train (Epoch 28): Loss/seq after 01750 batchs: 1149.610595703125
INFO:root:Train (Epoch 28): Loss/seq after 01800 batchs: 1137.806396484375
INFO:root:Train (Epoch 28): Loss/seq after 01850 batchs: 1125.8289794921875
INFO:root:Train (Epoch 28): Loss/seq after 01900 batchs: 1127.6796875
INFO:root:Train (Epoch 28): Loss/seq after 01950 batchs: 1123.6534423828125
INFO:root:Train (Epoch 28): Loss/seq after 02000 batchs: 1116.4908447265625
INFO:root:Train (Epoch 28): Loss/seq after 02050 batchs: 1110.73876953125
INFO:root:Train (Epoch 28): Loss/seq after 02100 batchs: 1100.787353515625
INFO:root:Train (Epoch 28): Loss/seq after 02150 batchs: 1092.5430908203125
INFO:root:Train (Epoch 28): Loss/seq after 02200 batchs: 1083.044677734375
INFO:root:Train (Epoch 28): Loss/seq after 02250 batchs: 1090.105712890625
INFO:root:Train (Epoch 28): Loss/seq after 02300 batchs: 1097.9239501953125
INFO:root:Train (Epoch 28): Loss/seq after 02350 batchs: 1089.4610595703125
INFO:root:Train (Epoch 28): Loss/seq after 02400 batchs: 1085.882080078125
INFO:root:Train (Epoch 28): Loss/seq after 02450 batchs: 1075.3330078125
INFO:root:Train (Epoch 28): Loss/seq after 02500 batchs: 1058.3118896484375
INFO:root:Train (Epoch 28): Loss/seq after 02550 batchs: 1046.947021484375
INFO:root:Train (Epoch 28): Loss/seq after 02600 batchs: 1043.296142578125
INFO:root:Train (Epoch 28): Loss/seq after 02650 batchs: 1036.9937744140625
INFO:root:Train (Epoch 28): Loss/seq after 02700 batchs: 1033.76025390625
INFO:root:Train (Epoch 28): Loss/seq after 02750 batchs: 1059.303466796875
INFO:root:Train (Epoch 28): Loss/seq after 02800 batchs: 1063.423828125
INFO:root:Train (Epoch 28): Loss/seq after 02850 batchs: 1061.882568359375
INFO:root:Train (Epoch 28): Loss/seq after 02900 batchs: 1061.806396484375
INFO:root:Train (Epoch 28): Loss/seq after 02950 batchs: 1055.968017578125
INFO:root:Train (Epoch 28): Loss/seq after 03000 batchs: 1055.3865966796875
INFO:root:Train (Epoch 28): Loss/seq after 03050 batchs: 1058.7724609375
INFO:root:Train (Epoch 28): Loss/seq after 03100 batchs: 1073.7618408203125
INFO:root:Train (Epoch 28): Loss/seq after 03150 batchs: 1080.94482421875
INFO:root:Train (Epoch 28): Loss/seq after 03200 batchs: 1084.7449951171875
INFO:root:Train (Epoch 28): Loss/seq after 03250 batchs: 1086.150634765625
INFO:root:Train (Epoch 28): Loss/seq after 03300 batchs: 1086.0565185546875
INFO:root:Train (Epoch 28): Loss/seq after 03350 batchs: 1084.826416015625
INFO:root:Train (Epoch 28): Loss/seq after 03400 batchs: 1075.5753173828125
INFO:root:Train (Epoch 28): Loss/seq after 03450 batchs: 1069.390380859375
INFO:root:Train (Epoch 28): Loss/seq after 03500 batchs: 1070.2828369140625
INFO:root:Train (Epoch 28): Loss/seq after 03550 batchs: 1066.7890625
INFO:root:Train (Epoch 28): Loss/seq after 03600 batchs: 1073.7767333984375
INFO:root:Train (Epoch 28): Loss/seq after 03650 batchs: 1070.156494140625
INFO:root:Train (Epoch 28): Loss/seq after 03700 batchs: 1069.71875
INFO:root:Train (Epoch 28): Loss/seq after 03750 batchs: 1071.117431640625
INFO:root:Train (Epoch 28): Loss/seq after 03800 batchs: 1064.53857421875
INFO:root:Train (Epoch 28): Loss/seq after 03850 batchs: 1061.0064697265625
INFO:root:Train (Epoch 28): Loss/seq after 03900 batchs: 1066.12841796875
INFO:root:Train (Epoch 28): Loss/seq after 03950 batchs: 1071.026123046875
INFO:root:Train (Epoch 28): Loss/seq after 04000 batchs: 1063.5010986328125
INFO:root:Train (Epoch 28): Loss/seq after 04050 batchs: 1055.926513671875
INFO:root:Train (Epoch 28): Loss/seq after 04100 batchs: 1051.3070068359375
INFO:root:Train (Epoch 28): Loss/seq after 04150 batchs: 1046.9439697265625
INFO:root:Train (Epoch 28): Loss/seq after 04200 batchs: 1043.338134765625
INFO:root:Train (Epoch 28): Loss/seq after 04250 batchs: 1039.1319580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 28): Loss/seq after 00000 batches: 761.7306518554688
INFO:root:# Valid (Epoch 28): Loss/seq after 00050 batches: 869.2546997070312
INFO:root:# Valid (Epoch 28): Loss/seq after 00100 batches: 1178.197265625
INFO:root:# Valid (Epoch 28): Loss/seq after 00150 batches: 922.5955200195312
INFO:root:# Valid (Epoch 28): Loss/seq after 00200 batches: 849.6022338867188
INFO:root:Artifacts: Make stick videos for epoch 28
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_28_on_20220422_015339.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_28_index_1710_on_20220422_015339.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 29): Loss/seq after 00000 batchs: 1466.6636962890625
INFO:root:Train (Epoch 29): Loss/seq after 00050 batchs: 1386.990966796875
INFO:root:Train (Epoch 29): Loss/seq after 00100 batchs: 1437.2738037109375
INFO:root:Train (Epoch 29): Loss/seq after 00150 batchs: 1304.039794921875
INFO:root:Train (Epoch 29): Loss/seq after 00200 batchs: 1404.59423828125
INFO:root:Train (Epoch 29): Loss/seq after 00250 batchs: 1506.3387451171875
INFO:root:Train (Epoch 29): Loss/seq after 00300 batchs: 1430.5692138671875
INFO:root:Train (Epoch 29): Loss/seq after 00350 batchs: 1332.9873046875
INFO:root:Train (Epoch 29): Loss/seq after 00400 batchs: 1383.93896484375
INFO:root:Train (Epoch 29): Loss/seq after 00450 batchs: 1324.2877197265625
INFO:root:Train (Epoch 29): Loss/seq after 00500 batchs: 1349.2530517578125
INFO:root:Train (Epoch 29): Loss/seq after 00550 batchs: 1296.7293701171875
INFO:root:Train (Epoch 29): Loss/seq after 00600 batchs: 1258.374267578125
INFO:root:Train (Epoch 29): Loss/seq after 00650 batchs: 1256.474609375
INFO:root:Train (Epoch 29): Loss/seq after 00700 batchs: 1219.403076171875
INFO:root:Train (Epoch 29): Loss/seq after 00750 batchs: 1255.2559814453125
INFO:root:Train (Epoch 29): Loss/seq after 00800 batchs: 1253.8731689453125
INFO:root:Train (Epoch 29): Loss/seq after 00850 batchs: 1219.82958984375
INFO:root:Train (Epoch 29): Loss/seq after 00900 batchs: 1206.442626953125
INFO:root:Train (Epoch 29): Loss/seq after 00950 batchs: 1237.066650390625
INFO:root:Train (Epoch 29): Loss/seq after 01000 batchs: 1231.812744140625
INFO:root:Train (Epoch 29): Loss/seq after 01050 batchs: 1216.3419189453125
INFO:root:Train (Epoch 29): Loss/seq after 01100 batchs: 1196.320068359375
INFO:root:Train (Epoch 29): Loss/seq after 01150 batchs: 1164.39453125
INFO:root:Train (Epoch 29): Loss/seq after 01200 batchs: 1158.9613037109375
INFO:root:Train (Epoch 29): Loss/seq after 01250 batchs: 1153.1046142578125
INFO:root:Train (Epoch 29): Loss/seq after 01300 batchs: 1141.69775390625
INFO:root:Train (Epoch 29): Loss/seq after 01350 batchs: 1131.1422119140625
INFO:root:Train (Epoch 29): Loss/seq after 01400 batchs: 1152.8306884765625
INFO:root:Train (Epoch 29): Loss/seq after 01450 batchs: 1147.309326171875
INFO:root:Train (Epoch 29): Loss/seq after 01500 batchs: 1142.46240234375
INFO:root:Train (Epoch 29): Loss/seq after 01550 batchs: 1149.6964111328125
INFO:root:Train (Epoch 29): Loss/seq after 01600 batchs: 1137.3504638671875
INFO:root:Train (Epoch 29): Loss/seq after 01650 batchs: 1134.5440673828125
INFO:root:Train (Epoch 29): Loss/seq after 01700 batchs: 1128.836181640625
INFO:root:Train (Epoch 29): Loss/seq after 01750 batchs: 1118.4595947265625
INFO:root:Train (Epoch 29): Loss/seq after 01800 batchs: 1107.54150390625
INFO:root:Train (Epoch 29): Loss/seq after 01850 batchs: 1095.8311767578125
INFO:root:Train (Epoch 29): Loss/seq after 01900 batchs: 1098.0914306640625
INFO:root:Train (Epoch 29): Loss/seq after 01950 batchs: 1093.952392578125
INFO:root:Train (Epoch 29): Loss/seq after 02000 batchs: 1087.343017578125
INFO:root:Train (Epoch 29): Loss/seq after 02050 batchs: 1081.9971923828125
INFO:root:Train (Epoch 29): Loss/seq after 02100 batchs: 1072.398681640625
INFO:root:Train (Epoch 29): Loss/seq after 02150 batchs: 1064.4708251953125
INFO:root:Train (Epoch 29): Loss/seq after 02200 batchs: 1055.3375244140625
INFO:root:Train (Epoch 29): Loss/seq after 02250 batchs: 1062.1337890625
INFO:root:Train (Epoch 29): Loss/seq after 02300 batchs: 1070.8560791015625
INFO:root:Train (Epoch 29): Loss/seq after 02350 batchs: 1062.5791015625
INFO:root:Train (Epoch 29): Loss/seq after 02400 batchs: 1059.2803955078125
INFO:root:Train (Epoch 29): Loss/seq after 02450 batchs: 1048.9952392578125
INFO:root:Train (Epoch 29): Loss/seq after 02500 batchs: 1032.128662109375
INFO:root:Train (Epoch 29): Loss/seq after 02550 batchs: 1020.796142578125
INFO:root:Train (Epoch 29): Loss/seq after 02600 batchs: 1016.452392578125
INFO:root:Train (Epoch 29): Loss/seq after 02650 batchs: 1010.4910278320312
INFO:root:Train (Epoch 29): Loss/seq after 02700 batchs: 1006.8058471679688
INFO:root:Train (Epoch 29): Loss/seq after 02750 batchs: 1032.337890625
INFO:root:Train (Epoch 29): Loss/seq after 02800 batchs: 1036.88330078125
INFO:root:Train (Epoch 29): Loss/seq after 02850 batchs: 1035.207763671875
INFO:root:Train (Epoch 29): Loss/seq after 02900 batchs: 1034.4786376953125
INFO:root:Train (Epoch 29): Loss/seq after 02950 batchs: 1028.87548828125
INFO:root:Train (Epoch 29): Loss/seq after 03000 batchs: 1028.5589599609375
INFO:root:Train (Epoch 29): Loss/seq after 03050 batchs: 1032.026611328125
INFO:root:Train (Epoch 29): Loss/seq after 03100 batchs: 1046.9156494140625
INFO:root:Train (Epoch 29): Loss/seq after 03150 batchs: 1054.5067138671875
INFO:root:Train (Epoch 29): Loss/seq after 03200 batchs: 1058.49365234375
INFO:root:Train (Epoch 29): Loss/seq after 03250 batchs: 1059.71142578125
INFO:root:Train (Epoch 29): Loss/seq after 03300 batchs: 1058.689453125
INFO:root:Train (Epoch 29): Loss/seq after 03350 batchs: 1057.34716796875
INFO:root:Train (Epoch 29): Loss/seq after 03400 batchs: 1047.806396484375
INFO:root:Train (Epoch 29): Loss/seq after 03450 batchs: 1042.1826171875
INFO:root:Train (Epoch 29): Loss/seq after 03500 batchs: 1042.8037109375
INFO:root:Train (Epoch 29): Loss/seq after 03550 batchs: 1039.5621337890625
INFO:root:Train (Epoch 29): Loss/seq after 03600 batchs: 1046.7637939453125
INFO:root:Train (Epoch 29): Loss/seq after 03650 batchs: 1043.3583984375
INFO:root:Train (Epoch 29): Loss/seq after 03700 batchs: 1042.9447021484375
INFO:root:Train (Epoch 29): Loss/seq after 03750 batchs: 1044.6297607421875
INFO:root:Train (Epoch 29): Loss/seq after 03800 batchs: 1038.14453125
INFO:root:Train (Epoch 29): Loss/seq after 03850 batchs: 1034.8001708984375
INFO:root:Train (Epoch 29): Loss/seq after 03900 batchs: 1039.88916015625
INFO:root:Train (Epoch 29): Loss/seq after 03950 batchs: 1045.0498046875
INFO:root:Train (Epoch 29): Loss/seq after 04000 batchs: 1037.765869140625
INFO:root:Train (Epoch 29): Loss/seq after 04050 batchs: 1030.2589111328125
INFO:root:Train (Epoch 29): Loss/seq after 04100 batchs: 1026.115234375
INFO:root:Train (Epoch 29): Loss/seq after 04150 batchs: 1022.027099609375
INFO:root:Train (Epoch 29): Loss/seq after 04200 batchs: 1018.6787109375
INFO:root:Train (Epoch 29): Loss/seq after 04250 batchs: 1014.5841064453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 29): Loss/seq after 00000 batches: 648.7326049804688
INFO:root:# Valid (Epoch 29): Loss/seq after 00050 batches: 815.814208984375
INFO:root:# Valid (Epoch 29): Loss/seq after 00100 batches: 1122.7816162109375
INFO:root:# Valid (Epoch 29): Loss/seq after 00150 batches: 878.6160888671875
INFO:root:# Valid (Epoch 29): Loss/seq after 00200 batches: 816.6046752929688
INFO:root:Artifacts: Make stick videos for epoch 29
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_29_on_20220422_015832.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_29_index_1050_on_20220422_015832.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 30): Loss/seq after 00000 batchs: 1404.1058349609375
INFO:root:Train (Epoch 30): Loss/seq after 00050 batchs: 1350.393310546875
INFO:root:Train (Epoch 30): Loss/seq after 00100 batchs: 1410.8167724609375
INFO:root:Train (Epoch 30): Loss/seq after 00150 batchs: 1282.5965576171875
INFO:root:Train (Epoch 30): Loss/seq after 00200 batchs: 1384.9849853515625
INFO:root:Train (Epoch 30): Loss/seq after 00250 batchs: 1490.6207275390625
INFO:root:Train (Epoch 30): Loss/seq after 00300 batchs: 1415.2154541015625
INFO:root:Train (Epoch 30): Loss/seq after 00350 batchs: 1318.573486328125
INFO:root:Train (Epoch 30): Loss/seq after 00400 batchs: 1372.2713623046875
INFO:root:Train (Epoch 30): Loss/seq after 00450 batchs: 1313.8306884765625
INFO:root:Train (Epoch 30): Loss/seq after 00500 batchs: 1338.9776611328125
INFO:root:Train (Epoch 30): Loss/seq after 00550 batchs: 1287.1353759765625
INFO:root:Train (Epoch 30): Loss/seq after 00600 batchs: 1247.9637451171875
INFO:root:Train (Epoch 30): Loss/seq after 00650 batchs: 1242.0474853515625
INFO:root:Train (Epoch 30): Loss/seq after 00700 batchs: 1204.19140625
INFO:root:Train (Epoch 30): Loss/seq after 00750 batchs: 1234.39013671875
INFO:root:Train (Epoch 30): Loss/seq after 00800 batchs: 1233.7186279296875
INFO:root:Train (Epoch 30): Loss/seq after 00850 batchs: 1198.9732666015625
INFO:root:Train (Epoch 30): Loss/seq after 00900 batchs: 1182.9940185546875
INFO:root:Train (Epoch 30): Loss/seq after 00950 batchs: 1212.03125
INFO:root:Train (Epoch 30): Loss/seq after 01000 batchs: 1206.636962890625
INFO:root:Train (Epoch 30): Loss/seq after 01050 batchs: 1192.4141845703125
INFO:root:Train (Epoch 30): Loss/seq after 01100 batchs: 1174.0718994140625
INFO:root:Train (Epoch 30): Loss/seq after 01150 batchs: 1142.86376953125
INFO:root:Train (Epoch 30): Loss/seq after 01200 batchs: 1137.28759765625
INFO:root:Train (Epoch 30): Loss/seq after 01250 batchs: 1133.1593017578125
INFO:root:Train (Epoch 30): Loss/seq after 01300 batchs: 1121.45947265625
INFO:root:Train (Epoch 30): Loss/seq after 01350 batchs: 1110.0167236328125
INFO:root:Train (Epoch 30): Loss/seq after 01400 batchs: 1134.9796142578125
INFO:root:Train (Epoch 30): Loss/seq after 01450 batchs: 1130.105712890625
INFO:root:Train (Epoch 30): Loss/seq after 01500 batchs: 1126.1826171875
INFO:root:Train (Epoch 30): Loss/seq after 01550 batchs: 1133.6983642578125
INFO:root:Train (Epoch 30): Loss/seq after 01600 batchs: 1121.4683837890625
INFO:root:Train (Epoch 30): Loss/seq after 01650 batchs: 1118.97607421875
INFO:root:Train (Epoch 30): Loss/seq after 01700 batchs: 1113.3902587890625
INFO:root:Train (Epoch 30): Loss/seq after 01750 batchs: 1103.4949951171875
INFO:root:Train (Epoch 30): Loss/seq after 01800 batchs: 1092.495849609375
INFO:root:Train (Epoch 30): Loss/seq after 01850 batchs: 1080.9332275390625
INFO:root:Train (Epoch 30): Loss/seq after 01900 batchs: 1083.4725341796875
INFO:root:Train (Epoch 30): Loss/seq after 01950 batchs: 1079.419921875
INFO:root:Train (Epoch 30): Loss/seq after 02000 batchs: 1073.098876953125
INFO:root:Train (Epoch 30): Loss/seq after 02050 batchs: 1067.907470703125
INFO:root:Train (Epoch 30): Loss/seq after 02100 batchs: 1058.5252685546875
INFO:root:Train (Epoch 30): Loss/seq after 02150 batchs: 1050.75390625
INFO:root:Train (Epoch 30): Loss/seq after 02200 batchs: 1041.8826904296875
INFO:root:Train (Epoch 30): Loss/seq after 02250 batchs: 1049.2247314453125
INFO:root:Train (Epoch 30): Loss/seq after 02300 batchs: 1057.32568359375
INFO:root:Train (Epoch 30): Loss/seq after 02350 batchs: 1049.1826171875
INFO:root:Train (Epoch 30): Loss/seq after 02400 batchs: 1046.2200927734375
INFO:root:Train (Epoch 30): Loss/seq after 02450 batchs: 1036.16064453125
INFO:root:Train (Epoch 30): Loss/seq after 02500 batchs: 1019.3875732421875
INFO:root:Train (Epoch 30): Loss/seq after 02550 batchs: 1008.12060546875
INFO:root:Train (Epoch 30): Loss/seq after 02600 batchs: 1003.7394409179688
INFO:root:Train (Epoch 30): Loss/seq after 02650 batchs: 997.9443359375
INFO:root:Train (Epoch 30): Loss/seq after 02700 batchs: 994.3929443359375
INFO:root:Train (Epoch 30): Loss/seq after 02750 batchs: 1019.09716796875
INFO:root:Train (Epoch 30): Loss/seq after 02800 batchs: 1023.9608764648438
INFO:root:Train (Epoch 30): Loss/seq after 02850 batchs: 1022.6309204101562
INFO:root:Train (Epoch 30): Loss/seq after 02900 batchs: 1022.1839599609375
INFO:root:Train (Epoch 30): Loss/seq after 02950 batchs: 1017.0183715820312
INFO:root:Train (Epoch 30): Loss/seq after 03000 batchs: 1016.8173217773438
INFO:root:Train (Epoch 30): Loss/seq after 03050 batchs: 1020.1503295898438
INFO:root:Train (Epoch 30): Loss/seq after 03100 batchs: 1035.306396484375
INFO:root:Train (Epoch 30): Loss/seq after 03150 batchs: 1043.4029541015625
INFO:root:Train (Epoch 30): Loss/seq after 03200 batchs: 1047.5770263671875
INFO:root:Train (Epoch 30): Loss/seq after 03250 batchs: 1048.955322265625
INFO:root:Train (Epoch 30): Loss/seq after 03300 batchs: 1048.6595458984375
INFO:root:Train (Epoch 30): Loss/seq after 03350 batchs: 1047.282958984375
INFO:root:Train (Epoch 30): Loss/seq after 03400 batchs: 1037.718505859375
INFO:root:Train (Epoch 30): Loss/seq after 03450 batchs: 1032.04833984375
INFO:root:Train (Epoch 30): Loss/seq after 03500 batchs: 1032.8974609375
INFO:root:Train (Epoch 30): Loss/seq after 03550 batchs: 1029.9268798828125
INFO:root:Train (Epoch 30): Loss/seq after 03600 batchs: 1037.233642578125
INFO:root:Train (Epoch 30): Loss/seq after 03650 batchs: 1033.895751953125
INFO:root:Train (Epoch 30): Loss/seq after 03700 batchs: 1033.6162109375
INFO:root:Train (Epoch 30): Loss/seq after 03750 batchs: 1035.4156494140625
INFO:root:Train (Epoch 30): Loss/seq after 03800 batchs: 1029.0006103515625
INFO:root:Train (Epoch 30): Loss/seq after 03850 batchs: 1025.7313232421875
INFO:root:Train (Epoch 30): Loss/seq after 03900 batchs: 1030.8193359375
INFO:root:Train (Epoch 30): Loss/seq after 03950 batchs: 1036.131591796875
INFO:root:Train (Epoch 30): Loss/seq after 04000 batchs: 1028.974609375
INFO:root:Train (Epoch 30): Loss/seq after 04050 batchs: 1021.5203247070312
INFO:root:Train (Epoch 30): Loss/seq after 04100 batchs: 1017.6555786132812
INFO:root:Train (Epoch 30): Loss/seq after 04150 batchs: 1013.7515258789062
INFO:root:Train (Epoch 30): Loss/seq after 04200 batchs: 1010.5390014648438
INFO:root:Train (Epoch 30): Loss/seq after 04250 batchs: 1006.4151000976562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 30): Loss/seq after 00000 batches: 647.8775024414062
INFO:root:# Valid (Epoch 30): Loss/seq after 00050 batches: 820.9556884765625
INFO:root:# Valid (Epoch 30): Loss/seq after 00100 batches: 1128.86767578125
INFO:root:# Valid (Epoch 30): Loss/seq after 00150 batches: 888.4841918945312
INFO:root:# Valid (Epoch 30): Loss/seq after 00200 batches: 828.86181640625
INFO:root:Artifacts: Make stick videos for epoch 30
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_30_on_20220422_020341.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_30_index_1484_on_20220422_020341.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 31): Loss/seq after 00000 batchs: 1462.262451171875
INFO:root:Train (Epoch 31): Loss/seq after 00050 batchs: 1344.275634765625
INFO:root:Train (Epoch 31): Loss/seq after 00100 batchs: 1410.6419677734375
INFO:root:Train (Epoch 31): Loss/seq after 00150 batchs: 1285.161376953125
INFO:root:Train (Epoch 31): Loss/seq after 00200 batchs: 1386.6728515625
INFO:root:Train (Epoch 31): Loss/seq after 00250 batchs: 1495.286376953125
INFO:root:Train (Epoch 31): Loss/seq after 00300 batchs: 1418.3056640625
INFO:root:Train (Epoch 31): Loss/seq after 00350 batchs: 1321.2215576171875
INFO:root:Train (Epoch 31): Loss/seq after 00400 batchs: 1374.903076171875
INFO:root:Train (Epoch 31): Loss/seq after 00450 batchs: 1315.863525390625
INFO:root:Train (Epoch 31): Loss/seq after 00500 batchs: 1341.3253173828125
INFO:root:Train (Epoch 31): Loss/seq after 00550 batchs: 1288.7149658203125
INFO:root:Train (Epoch 31): Loss/seq after 00600 batchs: 1249.582275390625
INFO:root:Train (Epoch 31): Loss/seq after 00650 batchs: 1241.842529296875
INFO:root:Train (Epoch 31): Loss/seq after 00700 batchs: 1206.02783203125
INFO:root:Train (Epoch 31): Loss/seq after 00750 batchs: 1235.3927001953125
INFO:root:Train (Epoch 31): Loss/seq after 00800 batchs: 1234.5484619140625
INFO:root:Train (Epoch 31): Loss/seq after 00850 batchs: 1199.5186767578125
INFO:root:Train (Epoch 31): Loss/seq after 00900 batchs: 1182.72900390625
INFO:root:Train (Epoch 31): Loss/seq after 00950 batchs: 1210.0902099609375
INFO:root:Train (Epoch 31): Loss/seq after 01000 batchs: 1202.870361328125
INFO:root:Train (Epoch 31): Loss/seq after 01050 batchs: 1187.0791015625
INFO:root:Train (Epoch 31): Loss/seq after 01100 batchs: 1166.860107421875
INFO:root:Train (Epoch 31): Loss/seq after 01150 batchs: 1134.64208984375
INFO:root:Train (Epoch 31): Loss/seq after 01200 batchs: 1128.822509765625
INFO:root:Train (Epoch 31): Loss/seq after 01250 batchs: 1123.810302734375
INFO:root:Train (Epoch 31): Loss/seq after 01300 batchs: 1110.3074951171875
INFO:root:Train (Epoch 31): Loss/seq after 01350 batchs: 1098.8760986328125
INFO:root:Train (Epoch 31): Loss/seq after 01400 batchs: 1120.529296875
INFO:root:Train (Epoch 31): Loss/seq after 01450 batchs: 1115.9541015625
INFO:root:Train (Epoch 31): Loss/seq after 01500 batchs: 1112.1309814453125
INFO:root:Train (Epoch 31): Loss/seq after 01550 batchs: 1119.35986328125
INFO:root:Train (Epoch 31): Loss/seq after 01600 batchs: 1107.3011474609375
INFO:root:Train (Epoch 31): Loss/seq after 01650 batchs: 1104.8128662109375
INFO:root:Train (Epoch 31): Loss/seq after 01700 batchs: 1099.200439453125
INFO:root:Train (Epoch 31): Loss/seq after 01750 batchs: 1089.3673095703125
INFO:root:Train (Epoch 31): Loss/seq after 01800 batchs: 1078.698486328125
INFO:root:Train (Epoch 31): Loss/seq after 01850 batchs: 1067.4996337890625
INFO:root:Train (Epoch 31): Loss/seq after 01900 batchs: 1070.371337890625
INFO:root:Train (Epoch 31): Loss/seq after 01950 batchs: 1066.6507568359375
INFO:root:Train (Epoch 31): Loss/seq after 02000 batchs: 1060.569580078125
INFO:root:Train (Epoch 31): Loss/seq after 02050 batchs: 1055.6622314453125
INFO:root:Train (Epoch 31): Loss/seq after 02100 batchs: 1046.4344482421875
INFO:root:Train (Epoch 31): Loss/seq after 02150 batchs: 1038.8568115234375
INFO:root:Train (Epoch 31): Loss/seq after 02200 batchs: 1030.18408203125
INFO:root:Train (Epoch 31): Loss/seq after 02250 batchs: 1037.5101318359375
INFO:root:Train (Epoch 31): Loss/seq after 02300 batchs: 1046.2484130859375
INFO:root:Train (Epoch 31): Loss/seq after 02350 batchs: 1038.1632080078125
INFO:root:Train (Epoch 31): Loss/seq after 02400 batchs: 1035.2012939453125
INFO:root:Train (Epoch 31): Loss/seq after 02450 batchs: 1025.2158203125
INFO:root:Train (Epoch 31): Loss/seq after 02500 batchs: 1008.568603515625
INFO:root:Train (Epoch 31): Loss/seq after 02550 batchs: 997.3712158203125
INFO:root:Train (Epoch 31): Loss/seq after 02600 batchs: 992.6737670898438
INFO:root:Train (Epoch 31): Loss/seq after 02650 batchs: 986.9927368164062
INFO:root:Train (Epoch 31): Loss/seq after 02700 batchs: 983.5176391601562
INFO:root:Train (Epoch 31): Loss/seq after 02750 batchs: 1007.3995361328125
INFO:root:Train (Epoch 31): Loss/seq after 02800 batchs: 1011.5264892578125
INFO:root:Train (Epoch 31): Loss/seq after 02850 batchs: 1010.26904296875
INFO:root:Train (Epoch 31): Loss/seq after 02900 batchs: 1010.4398803710938
INFO:root:Train (Epoch 31): Loss/seq after 02950 batchs: 1005.1395874023438
INFO:root:Train (Epoch 31): Loss/seq after 03000 batchs: 1005.0729370117188
INFO:root:Train (Epoch 31): Loss/seq after 03050 batchs: 1008.4472045898438
INFO:root:Train (Epoch 31): Loss/seq after 03100 batchs: 1023.7387084960938
INFO:root:Train (Epoch 31): Loss/seq after 03150 batchs: 1031.324462890625
INFO:root:Train (Epoch 31): Loss/seq after 03200 batchs: 1035.593505859375
INFO:root:Train (Epoch 31): Loss/seq after 03250 batchs: 1037.2529296875
INFO:root:Train (Epoch 31): Loss/seq after 03300 batchs: 1036.44970703125
INFO:root:Train (Epoch 31): Loss/seq after 03350 batchs: 1035.1090087890625
INFO:root:Train (Epoch 31): Loss/seq after 03400 batchs: 1025.6236572265625
INFO:root:Train (Epoch 31): Loss/seq after 03450 batchs: 1020.1113891601562
INFO:root:Train (Epoch 31): Loss/seq after 03500 batchs: 1020.939208984375
INFO:root:Train (Epoch 31): Loss/seq after 03550 batchs: 1017.7073974609375
INFO:root:Train (Epoch 31): Loss/seq after 03600 batchs: 1025.061767578125
INFO:root:Train (Epoch 31): Loss/seq after 03650 batchs: 1021.8592529296875
INFO:root:Train (Epoch 31): Loss/seq after 03700 batchs: 1021.640380859375
INFO:root:Train (Epoch 31): Loss/seq after 03750 batchs: 1023.5648803710938
INFO:root:Train (Epoch 31): Loss/seq after 03800 batchs: 1017.3015747070312
INFO:root:Train (Epoch 31): Loss/seq after 03850 batchs: 1014.1524047851562
INFO:root:Train (Epoch 31): Loss/seq after 03900 batchs: 1019.2537841796875
INFO:root:Train (Epoch 31): Loss/seq after 03950 batchs: 1024.261962890625
INFO:root:Train (Epoch 31): Loss/seq after 04000 batchs: 1017.2113037109375
INFO:root:Train (Epoch 31): Loss/seq after 04050 batchs: 1009.849609375
INFO:root:Train (Epoch 31): Loss/seq after 04100 batchs: 1005.6787719726562
INFO:root:Train (Epoch 31): Loss/seq after 04150 batchs: 1001.7893676757812
INFO:root:Train (Epoch 31): Loss/seq after 04200 batchs: 998.583984375
INFO:root:Train (Epoch 31): Loss/seq after 04250 batchs: 994.541748046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 31): Loss/seq after 00000 batches: 587.0703125
INFO:root:# Valid (Epoch 31): Loss/seq after 00050 batches: 781.0367431640625
INFO:root:# Valid (Epoch 31): Loss/seq after 00100 batches: 1077.2103271484375
INFO:root:# Valid (Epoch 31): Loss/seq after 00150 batches: 848.4638671875
INFO:root:# Valid (Epoch 31): Loss/seq after 00200 batches: 791.7330932617188
INFO:root:Artifacts: Make stick videos for epoch 31
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_31_on_20220422_020843.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_31_index_1197_on_20220422_020843.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 32): Loss/seq after 00000 batchs: 1451.2454833984375
INFO:root:Train (Epoch 32): Loss/seq after 00050 batchs: 1328.7862548828125
INFO:root:Train (Epoch 32): Loss/seq after 00100 batchs: 1389.0660400390625
INFO:root:Train (Epoch 32): Loss/seq after 00150 batchs: 1262.6029052734375
INFO:root:Train (Epoch 32): Loss/seq after 00200 batchs: 1369.13232421875
INFO:root:Train (Epoch 32): Loss/seq after 00250 batchs: 1472.986572265625
INFO:root:Train (Epoch 32): Loss/seq after 00300 batchs: 1399.6649169921875
INFO:root:Train (Epoch 32): Loss/seq after 00350 batchs: 1304.170654296875
INFO:root:Train (Epoch 32): Loss/seq after 00400 batchs: 1355.912109375
INFO:root:Train (Epoch 32): Loss/seq after 00450 batchs: 1298.8218994140625
INFO:root:Train (Epoch 32): Loss/seq after 00500 batchs: 1323.7427978515625
INFO:root:Train (Epoch 32): Loss/seq after 00550 batchs: 1272.56103515625
INFO:root:Train (Epoch 32): Loss/seq after 00600 batchs: 1233.6114501953125
INFO:root:Train (Epoch 32): Loss/seq after 00650 batchs: 1226.6640625
INFO:root:Train (Epoch 32): Loss/seq after 00700 batchs: 1192.7230224609375
INFO:root:Train (Epoch 32): Loss/seq after 00750 batchs: 1222.437744140625
INFO:root:Train (Epoch 32): Loss/seq after 00800 batchs: 1223.0780029296875
INFO:root:Train (Epoch 32): Loss/seq after 00850 batchs: 1189.3719482421875
INFO:root:Train (Epoch 32): Loss/seq after 00900 batchs: 1171.939697265625
INFO:root:Train (Epoch 32): Loss/seq after 00950 batchs: 1199.0374755859375
INFO:root:Train (Epoch 32): Loss/seq after 01000 batchs: 1191.9537353515625
INFO:root:Train (Epoch 32): Loss/seq after 01050 batchs: 1174.2119140625
INFO:root:Train (Epoch 32): Loss/seq after 01100 batchs: 1153.46435546875
INFO:root:Train (Epoch 32): Loss/seq after 01150 batchs: 1121.4464111328125
INFO:root:Train (Epoch 32): Loss/seq after 01200 batchs: 1116.102783203125
INFO:root:Train (Epoch 32): Loss/seq after 01250 batchs: 1111.1231689453125
INFO:root:Train (Epoch 32): Loss/seq after 01300 batchs: 1095.75927734375
INFO:root:Train (Epoch 32): Loss/seq after 01350 batchs: 1083.4730224609375
INFO:root:Train (Epoch 32): Loss/seq after 01400 batchs: 1103.7923583984375
INFO:root:Train (Epoch 32): Loss/seq after 01450 batchs: 1099.684814453125
INFO:root:Train (Epoch 32): Loss/seq after 01500 batchs: 1096.277099609375
INFO:root:Train (Epoch 32): Loss/seq after 01550 batchs: 1103.9444580078125
INFO:root:Train (Epoch 32): Loss/seq after 01600 batchs: 1092.138427734375
INFO:root:Train (Epoch 32): Loss/seq after 01650 batchs: 1089.909912109375
INFO:root:Train (Epoch 32): Loss/seq after 01700 batchs: 1084.5919189453125
INFO:root:Train (Epoch 32): Loss/seq after 01750 batchs: 1075.135986328125
INFO:root:Train (Epoch 32): Loss/seq after 01800 batchs: 1064.7255859375
INFO:root:Train (Epoch 32): Loss/seq after 01850 batchs: 1053.9239501953125
INFO:root:Train (Epoch 32): Loss/seq after 01900 batchs: 1057.060791015625
INFO:root:Train (Epoch 32): Loss/seq after 01950 batchs: 1053.7452392578125
INFO:root:Train (Epoch 32): Loss/seq after 02000 batchs: 1047.93408203125
INFO:root:Train (Epoch 32): Loss/seq after 02050 batchs: 1043.2708740234375
INFO:root:Train (Epoch 32): Loss/seq after 02100 batchs: 1034.292724609375
INFO:root:Train (Epoch 32): Loss/seq after 02150 batchs: 1027.035888671875
INFO:root:Train (Epoch 32): Loss/seq after 02200 batchs: 1018.7205810546875
INFO:root:Train (Epoch 32): Loss/seq after 02250 batchs: 1026.145263671875
INFO:root:Train (Epoch 32): Loss/seq after 02300 batchs: 1035.4217529296875
INFO:root:Train (Epoch 32): Loss/seq after 02350 batchs: 1027.5679931640625
INFO:root:Train (Epoch 32): Loss/seq after 02400 batchs: 1024.8568115234375
INFO:root:Train (Epoch 32): Loss/seq after 02450 batchs: 1015.0747680664062
INFO:root:Train (Epoch 32): Loss/seq after 02500 batchs: 998.5528564453125
INFO:root:Train (Epoch 32): Loss/seq after 02550 batchs: 987.5755615234375
INFO:root:Train (Epoch 32): Loss/seq after 02600 batchs: 983.2152709960938
INFO:root:Train (Epoch 32): Loss/seq after 02650 batchs: 977.6665649414062
INFO:root:Train (Epoch 32): Loss/seq after 02700 batchs: 974.4605102539062
INFO:root:Train (Epoch 32): Loss/seq after 02750 batchs: 998.35400390625
INFO:root:Train (Epoch 32): Loss/seq after 02800 batchs: 1002.233154296875
INFO:root:Train (Epoch 32): Loss/seq after 02850 batchs: 1001.1483764648438
INFO:root:Train (Epoch 32): Loss/seq after 02900 batchs: 1000.9898681640625
INFO:root:Train (Epoch 32): Loss/seq after 02950 batchs: 995.828125
INFO:root:Train (Epoch 32): Loss/seq after 03000 batchs: 995.8912353515625
INFO:root:Train (Epoch 32): Loss/seq after 03050 batchs: 999.3173828125
INFO:root:Train (Epoch 32): Loss/seq after 03100 batchs: 1013.9891967773438
INFO:root:Train (Epoch 32): Loss/seq after 03150 batchs: 1021.73779296875
INFO:root:Train (Epoch 32): Loss/seq after 03200 batchs: 1025.7991943359375
INFO:root:Train (Epoch 32): Loss/seq after 03250 batchs: 1027.35205078125
INFO:root:Train (Epoch 32): Loss/seq after 03300 batchs: 1026.6085205078125
INFO:root:Train (Epoch 32): Loss/seq after 03350 batchs: 1025.285888671875
INFO:root:Train (Epoch 32): Loss/seq after 03400 batchs: 1015.93310546875
INFO:root:Train (Epoch 32): Loss/seq after 03450 batchs: 1010.43603515625
INFO:root:Train (Epoch 32): Loss/seq after 03500 batchs: 1011.36767578125
INFO:root:Train (Epoch 32): Loss/seq after 03550 batchs: 1008.4408569335938
INFO:root:Train (Epoch 32): Loss/seq after 03600 batchs: 1015.9381103515625
INFO:root:Train (Epoch 32): Loss/seq after 03650 batchs: 1012.7569580078125
INFO:root:Train (Epoch 32): Loss/seq after 03700 batchs: 1012.6130981445312
INFO:root:Train (Epoch 32): Loss/seq after 03750 batchs: 1014.632568359375
INFO:root:Train (Epoch 32): Loss/seq after 03800 batchs: 1008.485107421875
INFO:root:Train (Epoch 32): Loss/seq after 03850 batchs: 1005.3487548828125
INFO:root:Train (Epoch 32): Loss/seq after 03900 batchs: 1010.4470825195312
INFO:root:Train (Epoch 32): Loss/seq after 03950 batchs: 1015.4085693359375
INFO:root:Train (Epoch 32): Loss/seq after 04000 batchs: 1008.4349975585938
INFO:root:Train (Epoch 32): Loss/seq after 04050 batchs: 1001.1644287109375
INFO:root:Train (Epoch 32): Loss/seq after 04100 batchs: 997.10791015625
INFO:root:Train (Epoch 32): Loss/seq after 04150 batchs: 993.3551025390625
INFO:root:Train (Epoch 32): Loss/seq after 04200 batchs: 990.326171875
INFO:root:Train (Epoch 32): Loss/seq after 04250 batchs: 986.36865234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 32): Loss/seq after 00000 batches: 601.6103515625
INFO:root:# Valid (Epoch 32): Loss/seq after 00050 batches: 786.94091796875
INFO:root:# Valid (Epoch 32): Loss/seq after 00100 batches: 1074.5821533203125
INFO:root:# Valid (Epoch 32): Loss/seq after 00150 batches: 842.3165283203125
INFO:root:# Valid (Epoch 32): Loss/seq after 00200 batches: 785.8275146484375
INFO:root:Artifacts: Make stick videos for epoch 32
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_32_on_20220422_021331.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_32_index_1223_on_20220422_021331.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 33): Loss/seq after 00000 batchs: 1502.7589111328125
INFO:root:Train (Epoch 33): Loss/seq after 00050 batchs: 1330.844970703125
INFO:root:Train (Epoch 33): Loss/seq after 00100 batchs: 1399.8902587890625
INFO:root:Train (Epoch 33): Loss/seq after 00150 batchs: 1274.705810546875
INFO:root:Train (Epoch 33): Loss/seq after 00200 batchs: 1375.1461181640625
INFO:root:Train (Epoch 33): Loss/seq after 00250 batchs: 1478.9263916015625
INFO:root:Train (Epoch 33): Loss/seq after 00300 batchs: 1404.7540283203125
INFO:root:Train (Epoch 33): Loss/seq after 00350 batchs: 1309.35693359375
INFO:root:Train (Epoch 33): Loss/seq after 00400 batchs: 1361.3634033203125
INFO:root:Train (Epoch 33): Loss/seq after 00450 batchs: 1303.55517578125
INFO:root:Train (Epoch 33): Loss/seq after 00500 batchs: 1329.655029296875
INFO:root:Train (Epoch 33): Loss/seq after 00550 batchs: 1277.9217529296875
INFO:root:Train (Epoch 33): Loss/seq after 00600 batchs: 1238.08740234375
INFO:root:Train (Epoch 33): Loss/seq after 00650 batchs: 1230.6715087890625
INFO:root:Train (Epoch 33): Loss/seq after 00700 batchs: 1192.456298828125
INFO:root:Train (Epoch 33): Loss/seq after 00750 batchs: 1225.5743408203125
INFO:root:Train (Epoch 33): Loss/seq after 00800 batchs: 1224.597900390625
INFO:root:Train (Epoch 33): Loss/seq after 00850 batchs: 1190.604248046875
INFO:root:Train (Epoch 33): Loss/seq after 00900 batchs: 1172.2640380859375
INFO:root:Train (Epoch 33): Loss/seq after 00950 batchs: 1197.46484375
INFO:root:Train (Epoch 33): Loss/seq after 01000 batchs: 1190.3974609375
INFO:root:Train (Epoch 33): Loss/seq after 01050 batchs: 1173.4656982421875
INFO:root:Train (Epoch 33): Loss/seq after 01100 batchs: 1153.200439453125
INFO:root:Train (Epoch 33): Loss/seq after 01150 batchs: 1120.814453125
INFO:root:Train (Epoch 33): Loss/seq after 01200 batchs: 1115.2864990234375
INFO:root:Train (Epoch 33): Loss/seq after 01250 batchs: 1110.107177734375
INFO:root:Train (Epoch 33): Loss/seq after 01300 batchs: 1094.81396484375
INFO:root:Train (Epoch 33): Loss/seq after 01350 batchs: 1081.0791015625
INFO:root:Train (Epoch 33): Loss/seq after 01400 batchs: 1101.25537109375
INFO:root:Train (Epoch 33): Loss/seq after 01450 batchs: 1096.495849609375
INFO:root:Train (Epoch 33): Loss/seq after 01500 batchs: 1093.18212890625
INFO:root:Train (Epoch 33): Loss/seq after 01550 batchs: 1100.67578125
INFO:root:Train (Epoch 33): Loss/seq after 01600 batchs: 1089.0743408203125
INFO:root:Train (Epoch 33): Loss/seq after 01650 batchs: 1086.8731689453125
INFO:root:Train (Epoch 33): Loss/seq after 01700 batchs: 1081.5914306640625
INFO:root:Train (Epoch 33): Loss/seq after 01750 batchs: 1072.1414794921875
INFO:root:Train (Epoch 33): Loss/seq after 01800 batchs: 1061.720458984375
INFO:root:Train (Epoch 33): Loss/seq after 01850 batchs: 1050.9649658203125
INFO:root:Train (Epoch 33): Loss/seq after 01900 batchs: 1054.1766357421875
INFO:root:Train (Epoch 33): Loss/seq after 01950 batchs: 1050.9171142578125
INFO:root:Train (Epoch 33): Loss/seq after 02000 batchs: 1045.2138671875
INFO:root:Train (Epoch 33): Loss/seq after 02050 batchs: 1040.6021728515625
INFO:root:Train (Epoch 33): Loss/seq after 02100 batchs: 1031.6798095703125
INFO:root:Train (Epoch 33): Loss/seq after 02150 batchs: 1024.4696044921875
INFO:root:Train (Epoch 33): Loss/seq after 02200 batchs: 1016.1129150390625
INFO:root:Train (Epoch 33): Loss/seq after 02250 batchs: 1023.668701171875
INFO:root:Train (Epoch 33): Loss/seq after 02300 batchs: 1032.434326171875
INFO:root:Train (Epoch 33): Loss/seq after 02350 batchs: 1024.6361083984375
INFO:root:Train (Epoch 33): Loss/seq after 02400 batchs: 1022.072998046875
INFO:root:Train (Epoch 33): Loss/seq after 02450 batchs: 1012.49560546875
INFO:root:Train (Epoch 33): Loss/seq after 02500 batchs: 996.0181884765625
INFO:root:Train (Epoch 33): Loss/seq after 02550 batchs: 985.3092041015625
INFO:root:Train (Epoch 33): Loss/seq after 02600 batchs: 981.2742919921875
INFO:root:Train (Epoch 33): Loss/seq after 02650 batchs: 976.02001953125
INFO:root:Train (Epoch 33): Loss/seq after 02700 batchs: 973.2745361328125
INFO:root:Train (Epoch 33): Loss/seq after 02750 batchs: 996.9578857421875
INFO:root:Train (Epoch 33): Loss/seq after 02800 batchs: 1001.2047119140625
INFO:root:Train (Epoch 33): Loss/seq after 02850 batchs: 1000.252197265625
INFO:root:Train (Epoch 33): Loss/seq after 02900 batchs: 1000.2664794921875
INFO:root:Train (Epoch 33): Loss/seq after 02950 batchs: 995.0742797851562
INFO:root:Train (Epoch 33): Loss/seq after 03000 batchs: 995.1531372070312
INFO:root:Train (Epoch 33): Loss/seq after 03050 batchs: 998.8649291992188
INFO:root:Train (Epoch 33): Loss/seq after 03100 batchs: 1013.3640747070312
INFO:root:Train (Epoch 33): Loss/seq after 03150 batchs: 1021.2463989257812
INFO:root:Train (Epoch 33): Loss/seq after 03200 batchs: 1025.2933349609375
INFO:root:Train (Epoch 33): Loss/seq after 03250 batchs: 1027.1165771484375
INFO:root:Train (Epoch 33): Loss/seq after 03300 batchs: 1026.356689453125
INFO:root:Train (Epoch 33): Loss/seq after 03350 batchs: 1024.708251953125
INFO:root:Train (Epoch 33): Loss/seq after 03400 batchs: 1015.2806396484375
INFO:root:Train (Epoch 33): Loss/seq after 03450 batchs: 1009.8140869140625
INFO:root:Train (Epoch 33): Loss/seq after 03500 batchs: 1010.5999145507812
INFO:root:Train (Epoch 33): Loss/seq after 03550 batchs: 1007.5645751953125
INFO:root:Train (Epoch 33): Loss/seq after 03600 batchs: 1014.9945678710938
INFO:root:Train (Epoch 33): Loss/seq after 03650 batchs: 1011.8135375976562
INFO:root:Train (Epoch 33): Loss/seq after 03700 batchs: 1011.6779174804688
INFO:root:Train (Epoch 33): Loss/seq after 03750 batchs: 1013.7767333984375
INFO:root:Train (Epoch 33): Loss/seq after 03800 batchs: 1007.6309204101562
INFO:root:Train (Epoch 33): Loss/seq after 03850 batchs: 1004.5079956054688
INFO:root:Train (Epoch 33): Loss/seq after 03900 batchs: 1009.2905883789062
INFO:root:Train (Epoch 33): Loss/seq after 03950 batchs: 1014.281005859375
INFO:root:Train (Epoch 33): Loss/seq after 04000 batchs: 1007.328125
INFO:root:Train (Epoch 33): Loss/seq after 04050 batchs: 1000.0548095703125
INFO:root:Train (Epoch 33): Loss/seq after 04100 batchs: 995.9946899414062
INFO:root:Train (Epoch 33): Loss/seq after 04150 batchs: 992.1749267578125
INFO:root:Train (Epoch 33): Loss/seq after 04200 batchs: 989.090576171875
INFO:root:Train (Epoch 33): Loss/seq after 04250 batchs: 985.1795043945312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 33): Loss/seq after 00000 batches: 585.4833984375
INFO:root:# Valid (Epoch 33): Loss/seq after 00050 batches: 787.2228393554688
INFO:root:# Valid (Epoch 33): Loss/seq after 00100 batches: 1087.822265625
INFO:root:# Valid (Epoch 33): Loss/seq after 00150 batches: 851.3893432617188
INFO:root:# Valid (Epoch 33): Loss/seq after 00200 batches: 790.9768676757812
INFO:root:Artifacts: Make stick videos for epoch 33
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_33_on_20220422_021820.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_33_index_1072_on_20220422_021820.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 34): Loss/seq after 00000 batchs: 1411.4310302734375
INFO:root:Train (Epoch 34): Loss/seq after 00050 batchs: 1318.7540283203125
INFO:root:Train (Epoch 34): Loss/seq after 00100 batchs: 1391.497802734375
INFO:root:Train (Epoch 34): Loss/seq after 00150 batchs: 1264.7022705078125
INFO:root:Train (Epoch 34): Loss/seq after 00200 batchs: 1366.4434814453125
INFO:root:Train (Epoch 34): Loss/seq after 00250 batchs: 1469.630126953125
INFO:root:Train (Epoch 34): Loss/seq after 00300 batchs: 1396.668701171875
INFO:root:Train (Epoch 34): Loss/seq after 00350 batchs: 1301.455078125
INFO:root:Train (Epoch 34): Loss/seq after 00400 batchs: 1350.2108154296875
INFO:root:Train (Epoch 34): Loss/seq after 00450 batchs: 1293.5428466796875
INFO:root:Train (Epoch 34): Loss/seq after 00500 batchs: 1318.2144775390625
INFO:root:Train (Epoch 34): Loss/seq after 00550 batchs: 1267.508056640625
INFO:root:Train (Epoch 34): Loss/seq after 00600 batchs: 1228.804931640625
INFO:root:Train (Epoch 34): Loss/seq after 00650 batchs: 1218.33740234375
INFO:root:Train (Epoch 34): Loss/seq after 00700 batchs: 1180.4844970703125
INFO:root:Train (Epoch 34): Loss/seq after 00750 batchs: 1209.320068359375
INFO:root:Train (Epoch 34): Loss/seq after 00800 batchs: 1209.4217529296875
INFO:root:Train (Epoch 34): Loss/seq after 00850 batchs: 1175.731201171875
INFO:root:Train (Epoch 34): Loss/seq after 00900 batchs: 1155.6468505859375
INFO:root:Train (Epoch 34): Loss/seq after 00950 batchs: 1180.4171142578125
INFO:root:Train (Epoch 34): Loss/seq after 01000 batchs: 1172.84033203125
INFO:root:Train (Epoch 34): Loss/seq after 01050 batchs: 1155.75634765625
INFO:root:Train (Epoch 34): Loss/seq after 01100 batchs: 1135.673095703125
INFO:root:Train (Epoch 34): Loss/seq after 01150 batchs: 1104.047607421875
INFO:root:Train (Epoch 34): Loss/seq after 01200 batchs: 1099.0880126953125
INFO:root:Train (Epoch 34): Loss/seq after 01250 batchs: 1094.5784912109375
INFO:root:Train (Epoch 34): Loss/seq after 01300 batchs: 1078.664794921875
INFO:root:Train (Epoch 34): Loss/seq after 01350 batchs: 1063.7379150390625
INFO:root:Train (Epoch 34): Loss/seq after 01400 batchs: 1084.6851806640625
INFO:root:Train (Epoch 34): Loss/seq after 01450 batchs: 1080.7386474609375
INFO:root:Train (Epoch 34): Loss/seq after 01500 batchs: 1077.9619140625
INFO:root:Train (Epoch 34): Loss/seq after 01550 batchs: 1086.3887939453125
INFO:root:Train (Epoch 34): Loss/seq after 01600 batchs: 1074.893798828125
INFO:root:Train (Epoch 34): Loss/seq after 01650 batchs: 1073.2318115234375
INFO:root:Train (Epoch 34): Loss/seq after 01700 batchs: 1068.4300537109375
INFO:root:Train (Epoch 34): Loss/seq after 01750 batchs: 1059.2947998046875
INFO:root:Train (Epoch 34): Loss/seq after 01800 batchs: 1049.271240234375
INFO:root:Train (Epoch 34): Loss/seq after 01850 batchs: 1038.741455078125
INFO:root:Train (Epoch 34): Loss/seq after 01900 batchs: 1042.296142578125
INFO:root:Train (Epoch 34): Loss/seq after 01950 batchs: 1039.427001953125
INFO:root:Train (Epoch 34): Loss/seq after 02000 batchs: 1033.967041015625
INFO:root:Train (Epoch 34): Loss/seq after 02050 batchs: 1029.5843505859375
INFO:root:Train (Epoch 34): Loss/seq after 02100 batchs: 1020.8914184570312
INFO:root:Train (Epoch 34): Loss/seq after 02150 batchs: 1013.9306030273438
INFO:root:Train (Epoch 34): Loss/seq after 02200 batchs: 1005.8402709960938
INFO:root:Train (Epoch 34): Loss/seq after 02250 batchs: 1013.5247802734375
INFO:root:Train (Epoch 34): Loss/seq after 02300 batchs: 1022.8603515625
INFO:root:Train (Epoch 34): Loss/seq after 02350 batchs: 1015.2252197265625
INFO:root:Train (Epoch 34): Loss/seq after 02400 batchs: 1012.7639770507812
INFO:root:Train (Epoch 34): Loss/seq after 02450 batchs: 1003.2504272460938
INFO:root:Train (Epoch 34): Loss/seq after 02500 batchs: 986.942138671875
INFO:root:Train (Epoch 34): Loss/seq after 02550 batchs: 976.1024780273438
INFO:root:Train (Epoch 34): Loss/seq after 02600 batchs: 971.592041015625
INFO:root:Train (Epoch 34): Loss/seq after 02650 batchs: 966.6166381835938
INFO:root:Train (Epoch 34): Loss/seq after 02700 batchs: 963.66162109375
INFO:root:Train (Epoch 34): Loss/seq after 02750 batchs: 986.7198486328125
INFO:root:Train (Epoch 34): Loss/seq after 02800 batchs: 990.13720703125
INFO:root:Train (Epoch 34): Loss/seq after 02850 batchs: 989.178955078125
INFO:root:Train (Epoch 34): Loss/seq after 02900 batchs: 989.2783813476562
INFO:root:Train (Epoch 34): Loss/seq after 02950 batchs: 984.3264770507812
INFO:root:Train (Epoch 34): Loss/seq after 03000 batchs: 984.5568237304688
INFO:root:Train (Epoch 34): Loss/seq after 03050 batchs: 987.8893432617188
INFO:root:Train (Epoch 34): Loss/seq after 03100 batchs: 1002.167724609375
INFO:root:Train (Epoch 34): Loss/seq after 03150 batchs: 1010.1848754882812
INFO:root:Train (Epoch 34): Loss/seq after 03200 batchs: 1013.6468505859375
INFO:root:Train (Epoch 34): Loss/seq after 03250 batchs: 1015.6694946289062
INFO:root:Train (Epoch 34): Loss/seq after 03300 batchs: 1014.8978881835938
INFO:root:Train (Epoch 34): Loss/seq after 03350 batchs: 1013.0855712890625
INFO:root:Train (Epoch 34): Loss/seq after 03400 batchs: 1003.9070434570312
INFO:root:Train (Epoch 34): Loss/seq after 03450 batchs: 998.5449829101562
INFO:root:Train (Epoch 34): Loss/seq after 03500 batchs: 999.418212890625
INFO:root:Train (Epoch 34): Loss/seq after 03550 batchs: 996.4202880859375
INFO:root:Train (Epoch 34): Loss/seq after 03600 batchs: 1003.9620361328125
INFO:root:Train (Epoch 34): Loss/seq after 03650 batchs: 1000.9430541992188
INFO:root:Train (Epoch 34): Loss/seq after 03700 batchs: 1001.0577392578125
INFO:root:Train (Epoch 34): Loss/seq after 03750 batchs: 1003.1965942382812
INFO:root:Train (Epoch 34): Loss/seq after 03800 batchs: 997.1630249023438
INFO:root:Train (Epoch 34): Loss/seq after 03850 batchs: 994.1332397460938
INFO:root:Train (Epoch 34): Loss/seq after 03900 batchs: 999.2780151367188
INFO:root:Train (Epoch 34): Loss/seq after 03950 batchs: 1004.3505249023438
INFO:root:Train (Epoch 34): Loss/seq after 04000 batchs: 997.5082397460938
INFO:root:Train (Epoch 34): Loss/seq after 04050 batchs: 990.3463134765625
INFO:root:Train (Epoch 34): Loss/seq after 04100 batchs: 986.4378051757812
INFO:root:Train (Epoch 34): Loss/seq after 04150 batchs: 982.757568359375
INFO:root:Train (Epoch 34): Loss/seq after 04200 batchs: 979.7173461914062
INFO:root:Train (Epoch 34): Loss/seq after 04250 batchs: 975.8212280273438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 34): Loss/seq after 00000 batches: 598.2396240234375
INFO:root:# Valid (Epoch 34): Loss/seq after 00050 batches: 783.7764282226562
INFO:root:# Valid (Epoch 34): Loss/seq after 00100 batches: 1054.874267578125
INFO:root:# Valid (Epoch 34): Loss/seq after 00150 batches: 841.4260864257812
INFO:root:# Valid (Epoch 34): Loss/seq after 00200 batches: 790.8429565429688
INFO:root:Artifacts: Make stick videos for epoch 34
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_34_on_20220422_022306.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_34_index_1199_on_20220422_022306.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 35): Loss/seq after 00000 batchs: 1497.5321044921875
INFO:root:Train (Epoch 35): Loss/seq after 00050 batchs: 1330.10595703125
INFO:root:Train (Epoch 35): Loss/seq after 00100 batchs: 1385.1429443359375
INFO:root:Train (Epoch 35): Loss/seq after 00150 batchs: 1260.9468994140625
INFO:root:Train (Epoch 35): Loss/seq after 00200 batchs: 1366.5704345703125
INFO:root:Train (Epoch 35): Loss/seq after 00250 batchs: 1468.5096435546875
INFO:root:Train (Epoch 35): Loss/seq after 00300 batchs: 1395.1673583984375
INFO:root:Train (Epoch 35): Loss/seq after 00350 batchs: 1300.719970703125
INFO:root:Train (Epoch 35): Loss/seq after 00400 batchs: 1350.1263427734375
INFO:root:Train (Epoch 35): Loss/seq after 00450 batchs: 1293.485595703125
INFO:root:Train (Epoch 35): Loss/seq after 00500 batchs: 1319.5648193359375
INFO:root:Train (Epoch 35): Loss/seq after 00550 batchs: 1268.54248046875
INFO:root:Train (Epoch 35): Loss/seq after 00600 batchs: 1229.55810546875
INFO:root:Train (Epoch 35): Loss/seq after 00650 batchs: 1218.3970947265625
INFO:root:Train (Epoch 35): Loss/seq after 00700 batchs: 1177.01123046875
INFO:root:Train (Epoch 35): Loss/seq after 00750 batchs: 1204.702880859375
INFO:root:Train (Epoch 35): Loss/seq after 00800 batchs: 1204.82958984375
INFO:root:Train (Epoch 35): Loss/seq after 00850 batchs: 1171.8216552734375
INFO:root:Train (Epoch 35): Loss/seq after 00900 batchs: 1151.5142822265625
INFO:root:Train (Epoch 35): Loss/seq after 00950 batchs: 1173.46923828125
INFO:root:Train (Epoch 35): Loss/seq after 01000 batchs: 1165.4202880859375
INFO:root:Train (Epoch 35): Loss/seq after 01050 batchs: 1150.3128662109375
INFO:root:Train (Epoch 35): Loss/seq after 01100 batchs: 1131.9647216796875
INFO:root:Train (Epoch 35): Loss/seq after 01150 batchs: 1100.95458984375
INFO:root:Train (Epoch 35): Loss/seq after 01200 batchs: 1096.0245361328125
INFO:root:Train (Epoch 35): Loss/seq after 01250 batchs: 1092.1536865234375
INFO:root:Train (Epoch 35): Loss/seq after 01300 batchs: 1076.630126953125
INFO:root:Train (Epoch 35): Loss/seq after 01350 batchs: 1061.1494140625
INFO:root:Train (Epoch 35): Loss/seq after 01400 batchs: 1080.779052734375
INFO:root:Train (Epoch 35): Loss/seq after 01450 batchs: 1077.022216796875
INFO:root:Train (Epoch 35): Loss/seq after 01500 batchs: 1074.2303466796875
INFO:root:Train (Epoch 35): Loss/seq after 01550 batchs: 1082.0499267578125
INFO:root:Train (Epoch 35): Loss/seq after 01600 batchs: 1070.6025390625
INFO:root:Train (Epoch 35): Loss/seq after 01650 batchs: 1068.9505615234375
INFO:root:Train (Epoch 35): Loss/seq after 01700 batchs: 1064.1802978515625
INFO:root:Train (Epoch 35): Loss/seq after 01750 batchs: 1055.1573486328125
INFO:root:Train (Epoch 35): Loss/seq after 01800 batchs: 1045.205322265625
INFO:root:Train (Epoch 35): Loss/seq after 01850 batchs: 1034.7442626953125
INFO:root:Train (Epoch 35): Loss/seq after 01900 batchs: 1038.335693359375
INFO:root:Train (Epoch 35): Loss/seq after 01950 batchs: 1035.3458251953125
INFO:root:Train (Epoch 35): Loss/seq after 02000 batchs: 1030.036865234375
INFO:root:Train (Epoch 35): Loss/seq after 02050 batchs: 1025.737548828125
INFO:root:Train (Epoch 35): Loss/seq after 02100 batchs: 1017.147216796875
INFO:root:Train (Epoch 35): Loss/seq after 02150 batchs: 1010.2171020507812
INFO:root:Train (Epoch 35): Loss/seq after 02200 batchs: 1002.15869140625
INFO:root:Train (Epoch 35): Loss/seq after 02250 batchs: 1009.807861328125
INFO:root:Train (Epoch 35): Loss/seq after 02300 batchs: 1019.7548828125
INFO:root:Train (Epoch 35): Loss/seq after 02350 batchs: 1012.0267944335938
INFO:root:Train (Epoch 35): Loss/seq after 02400 batchs: 1009.5507202148438
INFO:root:Train (Epoch 35): Loss/seq after 02450 batchs: 999.9740600585938
INFO:root:Train (Epoch 35): Loss/seq after 02500 batchs: 983.6461181640625
INFO:root:Train (Epoch 35): Loss/seq after 02550 batchs: 972.8780517578125
INFO:root:Train (Epoch 35): Loss/seq after 02600 batchs: 968.0137329101562
INFO:root:Train (Epoch 35): Loss/seq after 02650 batchs: 962.8447875976562
INFO:root:Train (Epoch 35): Loss/seq after 02700 batchs: 960.4291381835938
INFO:root:Train (Epoch 35): Loss/seq after 02750 batchs: 983.679443359375
INFO:root:Train (Epoch 35): Loss/seq after 02800 batchs: 987.163330078125
INFO:root:Train (Epoch 35): Loss/seq after 02850 batchs: 986.483642578125
INFO:root:Train (Epoch 35): Loss/seq after 02900 batchs: 986.6936645507812
INFO:root:Train (Epoch 35): Loss/seq after 02950 batchs: 981.7086791992188
INFO:root:Train (Epoch 35): Loss/seq after 03000 batchs: 981.9707641601562
INFO:root:Train (Epoch 35): Loss/seq after 03050 batchs: 985.2190551757812
INFO:root:Train (Epoch 35): Loss/seq after 03100 batchs: 999.7752685546875
INFO:root:Train (Epoch 35): Loss/seq after 03150 batchs: 1008.05712890625
INFO:root:Train (Epoch 35): Loss/seq after 03200 batchs: 1011.895751953125
INFO:root:Train (Epoch 35): Loss/seq after 03250 batchs: 1013.6270141601562
INFO:root:Train (Epoch 35): Loss/seq after 03300 batchs: 1012.8229370117188
INFO:root:Train (Epoch 35): Loss/seq after 03350 batchs: 1011.3037109375
INFO:root:Train (Epoch 35): Loss/seq after 03400 batchs: 1002.0986938476562
INFO:root:Train (Epoch 35): Loss/seq after 03450 batchs: 996.9781494140625
INFO:root:Train (Epoch 35): Loss/seq after 03500 batchs: 997.8493041992188
INFO:root:Train (Epoch 35): Loss/seq after 03550 batchs: 994.8409423828125
INFO:root:Train (Epoch 35): Loss/seq after 03600 batchs: 1002.4132690429688
INFO:root:Train (Epoch 35): Loss/seq after 03650 batchs: 999.330078125
INFO:root:Train (Epoch 35): Loss/seq after 03700 batchs: 999.39697265625
INFO:root:Train (Epoch 35): Loss/seq after 03750 batchs: 1001.572509765625
INFO:root:Train (Epoch 35): Loss/seq after 03800 batchs: 995.5861206054688
INFO:root:Train (Epoch 35): Loss/seq after 03850 batchs: 992.6015014648438
INFO:root:Train (Epoch 35): Loss/seq after 03900 batchs: 997.2522583007812
INFO:root:Train (Epoch 35): Loss/seq after 03950 batchs: 1002.067138671875
INFO:root:Train (Epoch 35): Loss/seq after 04000 batchs: 995.2395629882812
INFO:root:Train (Epoch 35): Loss/seq after 04050 batchs: 988.0936889648438
INFO:root:Train (Epoch 35): Loss/seq after 04100 batchs: 984.2012939453125
INFO:root:Train (Epoch 35): Loss/seq after 04150 batchs: 980.5813598632812
INFO:root:Train (Epoch 35): Loss/seq after 04200 batchs: 977.6502685546875
INFO:root:Train (Epoch 35): Loss/seq after 04250 batchs: 973.81640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 35): Loss/seq after 00000 batches: 585.6554565429688
INFO:root:# Valid (Epoch 35): Loss/seq after 00050 batches: 783.4638671875
INFO:root:# Valid (Epoch 35): Loss/seq after 00100 batches: 1056.1602783203125
INFO:root:# Valid (Epoch 35): Loss/seq after 00150 batches: 835.465576171875
INFO:root:# Valid (Epoch 35): Loss/seq after 00200 batches: 783.3406372070312
INFO:root:Artifacts: Make stick videos for epoch 35
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_35_on_20220422_022750.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_35_index_735_on_20220422_022750.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 36): Loss/seq after 00000 batchs: 1350.863037109375
INFO:root:Train (Epoch 36): Loss/seq after 00050 batchs: 1331.244384765625
INFO:root:Train (Epoch 36): Loss/seq after 00100 batchs: 1385.3994140625
INFO:root:Train (Epoch 36): Loss/seq after 00150 batchs: 1261.2457275390625
INFO:root:Train (Epoch 36): Loss/seq after 00200 batchs: 1364.6710205078125
INFO:root:Train (Epoch 36): Loss/seq after 00250 batchs: 1468.37255859375
INFO:root:Train (Epoch 36): Loss/seq after 00300 batchs: 1395.2069091796875
INFO:root:Train (Epoch 36): Loss/seq after 00350 batchs: 1300.1727294921875
INFO:root:Train (Epoch 36): Loss/seq after 00400 batchs: 1346.64208984375
INFO:root:Train (Epoch 36): Loss/seq after 00450 batchs: 1290.4189453125
INFO:root:Train (Epoch 36): Loss/seq after 00500 batchs: 1315.63427734375
INFO:root:Train (Epoch 36): Loss/seq after 00550 batchs: 1265.3846435546875
INFO:root:Train (Epoch 36): Loss/seq after 00600 batchs: 1226.087890625
INFO:root:Train (Epoch 36): Loss/seq after 00650 batchs: 1212.4227294921875
INFO:root:Train (Epoch 36): Loss/seq after 00700 batchs: 1170.444091796875
INFO:root:Train (Epoch 36): Loss/seq after 00750 batchs: 1196.5123291015625
INFO:root:Train (Epoch 36): Loss/seq after 00800 batchs: 1197.1444091796875
INFO:root:Train (Epoch 36): Loss/seq after 00850 batchs: 1164.7484130859375
INFO:root:Train (Epoch 36): Loss/seq after 00900 batchs: 1145.5943603515625
INFO:root:Train (Epoch 36): Loss/seq after 00950 batchs: 1166.4439697265625
INFO:root:Train (Epoch 36): Loss/seq after 01000 batchs: 1156.4940185546875
INFO:root:Train (Epoch 36): Loss/seq after 01050 batchs: 1139.48193359375
INFO:root:Train (Epoch 36): Loss/seq after 01100 batchs: 1122.540283203125
INFO:root:Train (Epoch 36): Loss/seq after 01150 batchs: 1091.0662841796875
INFO:root:Train (Epoch 36): Loss/seq after 01200 batchs: 1086.63720703125
INFO:root:Train (Epoch 36): Loss/seq after 01250 batchs: 1082.876220703125
INFO:root:Train (Epoch 36): Loss/seq after 01300 batchs: 1067.091796875
INFO:root:Train (Epoch 36): Loss/seq after 01350 batchs: 1052.69921875
INFO:root:Train (Epoch 36): Loss/seq after 01400 batchs: 1069.849609375
INFO:root:Train (Epoch 36): Loss/seq after 01450 batchs: 1066.0279541015625
INFO:root:Train (Epoch 36): Loss/seq after 01500 batchs: 1063.63623046875
INFO:root:Train (Epoch 36): Loss/seq after 01550 batchs: 1071.7509765625
INFO:root:Train (Epoch 36): Loss/seq after 01600 batchs: 1060.67529296875
INFO:root:Train (Epoch 36): Loss/seq after 01650 batchs: 1059.279541015625
INFO:root:Train (Epoch 36): Loss/seq after 01700 batchs: 1054.7373046875
INFO:root:Train (Epoch 36): Loss/seq after 01750 batchs: 1045.922607421875
INFO:root:Train (Epoch 36): Loss/seq after 01800 batchs: 1036.0831298828125
INFO:root:Train (Epoch 36): Loss/seq after 01850 batchs: 1025.8509521484375
INFO:root:Train (Epoch 36): Loss/seq after 01900 batchs: 1029.7750244140625
INFO:root:Train (Epoch 36): Loss/seq after 01950 batchs: 1027.1552734375
INFO:root:Train (Epoch 36): Loss/seq after 02000 batchs: 1022.0004272460938
INFO:root:Train (Epoch 36): Loss/seq after 02050 batchs: 1017.931884765625
INFO:root:Train (Epoch 36): Loss/seq after 02100 batchs: 1009.5286865234375
INFO:root:Train (Epoch 36): Loss/seq after 02150 batchs: 1002.7929077148438
INFO:root:Train (Epoch 36): Loss/seq after 02200 batchs: 994.8721313476562
INFO:root:Train (Epoch 36): Loss/seq after 02250 batchs: 1002.68115234375
INFO:root:Train (Epoch 36): Loss/seq after 02300 batchs: 1012.8201904296875
INFO:root:Train (Epoch 36): Loss/seq after 02350 batchs: 1005.3446044921875
INFO:root:Train (Epoch 36): Loss/seq after 02400 batchs: 1003.0853881835938
INFO:root:Train (Epoch 36): Loss/seq after 02450 batchs: 993.751708984375
INFO:root:Train (Epoch 36): Loss/seq after 02500 batchs: 977.532470703125
INFO:root:Train (Epoch 36): Loss/seq after 02550 batchs: 966.9541015625
INFO:root:Train (Epoch 36): Loss/seq after 02600 batchs: 962.3036499023438
INFO:root:Train (Epoch 36): Loss/seq after 02650 batchs: 957.7498168945312
INFO:root:Train (Epoch 36): Loss/seq after 02700 batchs: 954.88916015625
INFO:root:Train (Epoch 36): Loss/seq after 02750 batchs: 978.0280151367188
INFO:root:Train (Epoch 36): Loss/seq after 02800 batchs: 981.7794189453125
INFO:root:Train (Epoch 36): Loss/seq after 02850 batchs: 981.0188598632812
INFO:root:Train (Epoch 36): Loss/seq after 02900 batchs: 981.2172241210938
INFO:root:Train (Epoch 36): Loss/seq after 02950 batchs: 976.5082397460938
INFO:root:Train (Epoch 36): Loss/seq after 03000 batchs: 976.8369750976562
INFO:root:Train (Epoch 36): Loss/seq after 03050 batchs: 980.4261474609375
INFO:root:Train (Epoch 36): Loss/seq after 03100 batchs: 995.2408447265625
INFO:root:Train (Epoch 36): Loss/seq after 03150 batchs: 1003.9147338867188
INFO:root:Train (Epoch 36): Loss/seq after 03200 batchs: 1007.635986328125
INFO:root:Train (Epoch 36): Loss/seq after 03250 batchs: 1009.5015869140625
INFO:root:Train (Epoch 36): Loss/seq after 03300 batchs: 1008.7308959960938
INFO:root:Train (Epoch 36): Loss/seq after 03350 batchs: 1007.350341796875
INFO:root:Train (Epoch 36): Loss/seq after 03400 batchs: 998.2052612304688
INFO:root:Train (Epoch 36): Loss/seq after 03450 batchs: 992.8826293945312
INFO:root:Train (Epoch 36): Loss/seq after 03500 batchs: 993.69091796875
INFO:root:Train (Epoch 36): Loss/seq after 03550 batchs: 990.6796264648438
INFO:root:Train (Epoch 36): Loss/seq after 03600 batchs: 998.27734375
INFO:root:Train (Epoch 36): Loss/seq after 03650 batchs: 995.203369140625
INFO:root:Train (Epoch 36): Loss/seq after 03700 batchs: 995.2901611328125
INFO:root:Train (Epoch 36): Loss/seq after 03750 batchs: 997.5008544921875
INFO:root:Train (Epoch 36): Loss/seq after 03800 batchs: 991.5332641601562
INFO:root:Train (Epoch 36): Loss/seq after 03850 batchs: 988.6412963867188
INFO:root:Train (Epoch 36): Loss/seq after 03900 batchs: 993.4274291992188
INFO:root:Train (Epoch 36): Loss/seq after 03950 batchs: 998.001708984375
INFO:root:Train (Epoch 36): Loss/seq after 04000 batchs: 991.2369384765625
INFO:root:Train (Epoch 36): Loss/seq after 04050 batchs: 984.1242065429688
INFO:root:Train (Epoch 36): Loss/seq after 04100 batchs: 980.2118530273438
INFO:root:Train (Epoch 36): Loss/seq after 04150 batchs: 976.6030883789062
INFO:root:Train (Epoch 36): Loss/seq after 04200 batchs: 973.7225341796875
INFO:root:Train (Epoch 36): Loss/seq after 04250 batchs: 969.9319458007812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 36): Loss/seq after 00000 batches: 627.9097900390625
INFO:root:# Valid (Epoch 36): Loss/seq after 00050 batches: 793.4917602539062
INFO:root:# Valid (Epoch 36): Loss/seq after 00100 batches: 1055.0794677734375
INFO:root:# Valid (Epoch 36): Loss/seq after 00150 batches: 839.1378173828125
INFO:root:# Valid (Epoch 36): Loss/seq after 00200 batches: 788.0912475585938
INFO:root:Artifacts: Make stick videos for epoch 36
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_36_on_20220422_023253.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_36_index_1504_on_20220422_023253.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 37): Loss/seq after 00000 batchs: 1350.0780029296875
INFO:root:Train (Epoch 37): Loss/seq after 00050 batchs: 1320.2371826171875
INFO:root:Train (Epoch 37): Loss/seq after 00100 batchs: 1380.7757568359375
INFO:root:Train (Epoch 37): Loss/seq after 00150 batchs: 1254.843017578125
INFO:root:Train (Epoch 37): Loss/seq after 00200 batchs: 1361.067138671875
INFO:root:Train (Epoch 37): Loss/seq after 00250 batchs: 1464.6207275390625
INFO:root:Train (Epoch 37): Loss/seq after 00300 batchs: 1391.6376953125
INFO:root:Train (Epoch 37): Loss/seq after 00350 batchs: 1297.2606201171875
INFO:root:Train (Epoch 37): Loss/seq after 00400 batchs: 1346.2392578125
INFO:root:Train (Epoch 37): Loss/seq after 00450 batchs: 1290.2120361328125
INFO:root:Train (Epoch 37): Loss/seq after 00500 batchs: 1315.5067138671875
INFO:root:Train (Epoch 37): Loss/seq after 00550 batchs: 1264.9425048828125
INFO:root:Train (Epoch 37): Loss/seq after 00600 batchs: 1225.59912109375
INFO:root:Train (Epoch 37): Loss/seq after 00650 batchs: 1208.630126953125
INFO:root:Train (Epoch 37): Loss/seq after 00700 batchs: 1166.2066650390625
INFO:root:Train (Epoch 37): Loss/seq after 00750 batchs: 1191.4013671875
INFO:root:Train (Epoch 37): Loss/seq after 00800 batchs: 1192.4669189453125
INFO:root:Train (Epoch 37): Loss/seq after 00850 batchs: 1160.433349609375
INFO:root:Train (Epoch 37): Loss/seq after 00900 batchs: 1141.7509765625
INFO:root:Train (Epoch 37): Loss/seq after 00950 batchs: 1164.5799560546875
INFO:root:Train (Epoch 37): Loss/seq after 01000 batchs: 1154.783935546875
INFO:root:Train (Epoch 37): Loss/seq after 01050 batchs: 1138.2205810546875
INFO:root:Train (Epoch 37): Loss/seq after 01100 batchs: 1118.306884765625
INFO:root:Train (Epoch 37): Loss/seq after 01150 batchs: 1086.9168701171875
INFO:root:Train (Epoch 37): Loss/seq after 01200 batchs: 1082.829345703125
INFO:root:Train (Epoch 37): Loss/seq after 01250 batchs: 1078.4737548828125
INFO:root:Train (Epoch 37): Loss/seq after 01300 batchs: 1063.212646484375
INFO:root:Train (Epoch 37): Loss/seq after 01350 batchs: 1047.7130126953125
INFO:root:Train (Epoch 37): Loss/seq after 01400 batchs: 1064.9056396484375
INFO:root:Train (Epoch 37): Loss/seq after 01450 batchs: 1061.306884765625
INFO:root:Train (Epoch 37): Loss/seq after 01500 batchs: 1058.986328125
INFO:root:Train (Epoch 37): Loss/seq after 01550 batchs: 1067.0213623046875
INFO:root:Train (Epoch 37): Loss/seq after 01600 batchs: 1056.028564453125
INFO:root:Train (Epoch 37): Loss/seq after 01650 batchs: 1054.554443359375
INFO:root:Train (Epoch 37): Loss/seq after 01700 batchs: 1050.0579833984375
INFO:root:Train (Epoch 37): Loss/seq after 01750 batchs: 1041.350830078125
INFO:root:Train (Epoch 37): Loss/seq after 01800 batchs: 1031.6416015625
INFO:root:Train (Epoch 37): Loss/seq after 01850 batchs: 1021.4730834960938
INFO:root:Train (Epoch 37): Loss/seq after 01900 batchs: 1025.4913330078125
INFO:root:Train (Epoch 37): Loss/seq after 01950 batchs: 1022.7811279296875
INFO:root:Train (Epoch 37): Loss/seq after 02000 batchs: 1017.7036743164062
INFO:root:Train (Epoch 37): Loss/seq after 02050 batchs: 1013.6056518554688
INFO:root:Train (Epoch 37): Loss/seq after 02100 batchs: 1005.2845458984375
INFO:root:Train (Epoch 37): Loss/seq after 02150 batchs: 998.6448364257812
INFO:root:Train (Epoch 37): Loss/seq after 02200 batchs: 990.8468627929688
INFO:root:Train (Epoch 37): Loss/seq after 02250 batchs: 998.6661376953125
INFO:root:Train (Epoch 37): Loss/seq after 02300 batchs: 1008.4271850585938
INFO:root:Train (Epoch 37): Loss/seq after 02350 batchs: 1000.9227905273438
INFO:root:Train (Epoch 37): Loss/seq after 02400 batchs: 998.6119384765625
INFO:root:Train (Epoch 37): Loss/seq after 02450 batchs: 989.2734375
INFO:root:Train (Epoch 37): Loss/seq after 02500 batchs: 973.1946411132812
INFO:root:Train (Epoch 37): Loss/seq after 02550 batchs: 962.5916137695312
INFO:root:Train (Epoch 37): Loss/seq after 02600 batchs: 957.8321533203125
INFO:root:Train (Epoch 37): Loss/seq after 02650 batchs: 953.1087036132812
INFO:root:Train (Epoch 37): Loss/seq after 02700 batchs: 950.6250610351562
INFO:root:Train (Epoch 37): Loss/seq after 02750 batchs: 971.40087890625
INFO:root:Train (Epoch 37): Loss/seq after 02800 batchs: 975.0303344726562
INFO:root:Train (Epoch 37): Loss/seq after 02850 batchs: 974.3208618164062
INFO:root:Train (Epoch 37): Loss/seq after 02900 batchs: 974.5664672851562
INFO:root:Train (Epoch 37): Loss/seq after 02950 batchs: 969.697021484375
INFO:root:Train (Epoch 37): Loss/seq after 03000 batchs: 970.1779174804688
INFO:root:Train (Epoch 37): Loss/seq after 03050 batchs: 973.49560546875
INFO:root:Train (Epoch 37): Loss/seq after 03100 batchs: 987.521728515625
INFO:root:Train (Epoch 37): Loss/seq after 03150 batchs: 996.7975463867188
INFO:root:Train (Epoch 37): Loss/seq after 03200 batchs: 1000.42919921875
INFO:root:Train (Epoch 37): Loss/seq after 03250 batchs: 1002.3128051757812
INFO:root:Train (Epoch 37): Loss/seq after 03300 batchs: 1001.5533447265625
INFO:root:Train (Epoch 37): Loss/seq after 03350 batchs: 1000.0716552734375
INFO:root:Train (Epoch 37): Loss/seq after 03400 batchs: 991.0232543945312
INFO:root:Train (Epoch 37): Loss/seq after 03450 batchs: 985.6572265625
INFO:root:Train (Epoch 37): Loss/seq after 03500 batchs: 986.4852905273438
INFO:root:Train (Epoch 37): Loss/seq after 03550 batchs: 983.6589965820312
INFO:root:Train (Epoch 37): Loss/seq after 03600 batchs: 991.3712158203125
INFO:root:Train (Epoch 37): Loss/seq after 03650 batchs: 988.4093627929688
INFO:root:Train (Epoch 37): Loss/seq after 03700 batchs: 988.5989379882812
INFO:root:Train (Epoch 37): Loss/seq after 03750 batchs: 990.9088134765625
INFO:root:Train (Epoch 37): Loss/seq after 03800 batchs: 984.987548828125
INFO:root:Train (Epoch 37): Loss/seq after 03850 batchs: 982.0963745117188
INFO:root:Train (Epoch 37): Loss/seq after 03900 batchs: 986.6195678710938
INFO:root:Train (Epoch 37): Loss/seq after 03950 batchs: 991.453125
INFO:root:Train (Epoch 37): Loss/seq after 04000 batchs: 984.7598876953125
INFO:root:Train (Epoch 37): Loss/seq after 04050 batchs: 977.707275390625
INFO:root:Train (Epoch 37): Loss/seq after 04100 batchs: 973.8372802734375
INFO:root:Train (Epoch 37): Loss/seq after 04150 batchs: 970.2679443359375
INFO:root:Train (Epoch 37): Loss/seq after 04200 batchs: 967.3560791015625
INFO:root:Train (Epoch 37): Loss/seq after 04250 batchs: 963.5667114257812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 37): Loss/seq after 00000 batches: 598.06640625
INFO:root:# Valid (Epoch 37): Loss/seq after 00050 batches: 793.614013671875
INFO:root:# Valid (Epoch 37): Loss/seq after 00100 batches: 1049.882080078125
INFO:root:# Valid (Epoch 37): Loss/seq after 00150 batches: 829.2760620117188
INFO:root:# Valid (Epoch 37): Loss/seq after 00200 batches: 776.4938354492188
INFO:root:Artifacts: Make stick videos for epoch 37
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_37_on_20220422_023738.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_37_index_1356_on_20220422_023738.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 38): Loss/seq after 00000 batchs: 1467.450927734375
INFO:root:Train (Epoch 38): Loss/seq after 00050 batchs: 1318.7119140625
INFO:root:Train (Epoch 38): Loss/seq after 00100 batchs: 1382.7574462890625
INFO:root:Train (Epoch 38): Loss/seq after 00150 batchs: 1257.7562255859375
INFO:root:Train (Epoch 38): Loss/seq after 00200 batchs: 1360.215576171875
INFO:root:Train (Epoch 38): Loss/seq after 00250 batchs: 1464.1583251953125
INFO:root:Train (Epoch 38): Loss/seq after 00300 batchs: 1391.3218994140625
INFO:root:Train (Epoch 38): Loss/seq after 00350 batchs: 1297.0067138671875
INFO:root:Train (Epoch 38): Loss/seq after 00400 batchs: 1342.7691650390625
INFO:root:Train (Epoch 38): Loss/seq after 00450 batchs: 1286.8648681640625
INFO:root:Train (Epoch 38): Loss/seq after 00500 batchs: 1312.3173828125
INFO:root:Train (Epoch 38): Loss/seq after 00550 batchs: 1261.763671875
INFO:root:Train (Epoch 38): Loss/seq after 00600 batchs: 1222.3060302734375
INFO:root:Train (Epoch 38): Loss/seq after 00650 batchs: 1203.4642333984375
INFO:root:Train (Epoch 38): Loss/seq after 00700 batchs: 1158.584228515625
INFO:root:Train (Epoch 38): Loss/seq after 00750 batchs: 1183.0880126953125
INFO:root:Train (Epoch 38): Loss/seq after 00800 batchs: 1184.29345703125
INFO:root:Train (Epoch 38): Loss/seq after 00850 batchs: 1152.1759033203125
INFO:root:Train (Epoch 38): Loss/seq after 00900 batchs: 1134.7476806640625
INFO:root:Train (Epoch 38): Loss/seq after 00950 batchs: 1153.8690185546875
INFO:root:Train (Epoch 38): Loss/seq after 01000 batchs: 1143.4029541015625
INFO:root:Train (Epoch 38): Loss/seq after 01050 batchs: 1127.726318359375
INFO:root:Train (Epoch 38): Loss/seq after 01100 batchs: 1108.2044677734375
INFO:root:Train (Epoch 38): Loss/seq after 01150 batchs: 1076.83837890625
INFO:root:Train (Epoch 38): Loss/seq after 01200 batchs: 1073.0146484375
INFO:root:Train (Epoch 38): Loss/seq after 01250 batchs: 1068.9820556640625
INFO:root:Train (Epoch 38): Loss/seq after 01300 batchs: 1054.6907958984375
INFO:root:Train (Epoch 38): Loss/seq after 01350 batchs: 1039.7083740234375
INFO:root:Train (Epoch 38): Loss/seq after 01400 batchs: 1056.2071533203125
INFO:root:Train (Epoch 38): Loss/seq after 01450 batchs: 1052.9825439453125
INFO:root:Train (Epoch 38): Loss/seq after 01500 batchs: 1050.951416015625
INFO:root:Train (Epoch 38): Loss/seq after 01550 batchs: 1059.1533203125
INFO:root:Train (Epoch 38): Loss/seq after 01600 batchs: 1048.2958984375
INFO:root:Train (Epoch 38): Loss/seq after 01650 batchs: 1047.1688232421875
INFO:root:Train (Epoch 38): Loss/seq after 01700 batchs: 1042.8609619140625
INFO:root:Train (Epoch 38): Loss/seq after 01750 batchs: 1034.4193115234375
INFO:root:Train (Epoch 38): Loss/seq after 01800 batchs: 1024.9560546875
INFO:root:Train (Epoch 38): Loss/seq after 01850 batchs: 1015.035888671875
INFO:root:Train (Epoch 38): Loss/seq after 01900 batchs: 1019.0985107421875
INFO:root:Train (Epoch 38): Loss/seq after 01950 batchs: 1016.6345825195312
INFO:root:Train (Epoch 38): Loss/seq after 02000 batchs: 1011.6680297851562
INFO:root:Train (Epoch 38): Loss/seq after 02050 batchs: 1007.7733764648438
INFO:root:Train (Epoch 38): Loss/seq after 02100 batchs: 999.5750122070312
INFO:root:Train (Epoch 38): Loss/seq after 02150 batchs: 993.0604248046875
INFO:root:Train (Epoch 38): Loss/seq after 02200 batchs: 985.3425903320312
INFO:root:Train (Epoch 38): Loss/seq after 02250 batchs: 993.340087890625
INFO:root:Train (Epoch 38): Loss/seq after 02300 batchs: 1003.6884765625
INFO:root:Train (Epoch 38): Loss/seq after 02350 batchs: 996.3890991210938
INFO:root:Train (Epoch 38): Loss/seq after 02400 batchs: 994.28759765625
INFO:root:Train (Epoch 38): Loss/seq after 02450 batchs: 985.1934814453125
INFO:root:Train (Epoch 38): Loss/seq after 02500 batchs: 969.1522216796875
INFO:root:Train (Epoch 38): Loss/seq after 02550 batchs: 958.6797485351562
INFO:root:Train (Epoch 38): Loss/seq after 02600 batchs: 954.4590454101562
INFO:root:Train (Epoch 38): Loss/seq after 02650 batchs: 949.80517578125
INFO:root:Train (Epoch 38): Loss/seq after 02700 batchs: 947.4612426757812
INFO:root:Train (Epoch 38): Loss/seq after 02750 batchs: 968.3984375
INFO:root:Train (Epoch 38): Loss/seq after 02800 batchs: 972.3745727539062
INFO:root:Train (Epoch 38): Loss/seq after 02850 batchs: 971.6732788085938
INFO:root:Train (Epoch 38): Loss/seq after 02900 batchs: 972.0656127929688
INFO:root:Train (Epoch 38): Loss/seq after 02950 batchs: 967.50390625
INFO:root:Train (Epoch 38): Loss/seq after 03000 batchs: 968.0133056640625
INFO:root:Train (Epoch 38): Loss/seq after 03050 batchs: 971.027099609375
INFO:root:Train (Epoch 38): Loss/seq after 03100 batchs: 985.1727905273438
INFO:root:Train (Epoch 38): Loss/seq after 03150 batchs: 993.6119995117188
INFO:root:Train (Epoch 38): Loss/seq after 03200 batchs: 997.601806640625
INFO:root:Train (Epoch 38): Loss/seq after 03250 batchs: 999.4450073242188
INFO:root:Train (Epoch 38): Loss/seq after 03300 batchs: 998.5546875
INFO:root:Train (Epoch 38): Loss/seq after 03350 batchs: 997.14306640625
INFO:root:Train (Epoch 38): Loss/seq after 03400 batchs: 988.0100708007812
INFO:root:Train (Epoch 38): Loss/seq after 03450 batchs: 982.5493774414062
INFO:root:Train (Epoch 38): Loss/seq after 03500 batchs: 983.4207763671875
INFO:root:Train (Epoch 38): Loss/seq after 03550 batchs: 980.482177734375
INFO:root:Train (Epoch 38): Loss/seq after 03600 batchs: 988.1943359375
INFO:root:Train (Epoch 38): Loss/seq after 03650 batchs: 985.3087768554688
INFO:root:Train (Epoch 38): Loss/seq after 03700 batchs: 985.5450439453125
INFO:root:Train (Epoch 38): Loss/seq after 03750 batchs: 987.8673095703125
INFO:root:Train (Epoch 38): Loss/seq after 03800 batchs: 981.969482421875
INFO:root:Train (Epoch 38): Loss/seq after 03850 batchs: 979.0896606445312
INFO:root:Train (Epoch 38): Loss/seq after 03900 batchs: 983.7362060546875
INFO:root:Train (Epoch 38): Loss/seq after 03950 batchs: 988.134033203125
INFO:root:Train (Epoch 38): Loss/seq after 04000 batchs: 981.4819946289062
INFO:root:Train (Epoch 38): Loss/seq after 04050 batchs: 974.4306030273438
INFO:root:Train (Epoch 38): Loss/seq after 04100 batchs: 970.4432983398438
INFO:root:Train (Epoch 38): Loss/seq after 04150 batchs: 966.8651123046875
INFO:root:Train (Epoch 38): Loss/seq after 04200 batchs: 963.9308471679688
INFO:root:Train (Epoch 38): Loss/seq after 04250 batchs: 960.1463623046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 38): Loss/seq after 00000 batches: 594.7542114257812
INFO:root:# Valid (Epoch 38): Loss/seq after 00050 batches: 854.7937622070312
INFO:root:# Valid (Epoch 38): Loss/seq after 00100 batches: 1058.9503173828125
INFO:root:# Valid (Epoch 38): Loss/seq after 00150 batches: 839.25390625
INFO:root:# Valid (Epoch 38): Loss/seq after 00200 batches: 783.216064453125
INFO:root:Artifacts: Make stick videos for epoch 38
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_38_on_20220422_024232.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_38_index_231_on_20220422_024232.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 39): Loss/seq after 00000 batchs: 1469.3282470703125
INFO:root:Train (Epoch 39): Loss/seq after 00050 batchs: 1327.2703857421875
INFO:root:Train (Epoch 39): Loss/seq after 00100 batchs: 1380.8438720703125
INFO:root:Train (Epoch 39): Loss/seq after 00150 batchs: 1255.187744140625
INFO:root:Train (Epoch 39): Loss/seq after 00200 batchs: 1359.411865234375
INFO:root:Train (Epoch 39): Loss/seq after 00250 batchs: 1462.2935791015625
INFO:root:Train (Epoch 39): Loss/seq after 00300 batchs: 1389.6173095703125
INFO:root:Train (Epoch 39): Loss/seq after 00350 batchs: 1296.021240234375
INFO:root:Train (Epoch 39): Loss/seq after 00400 batchs: 1340.325927734375
INFO:root:Train (Epoch 39): Loss/seq after 00450 batchs: 1284.572509765625
INFO:root:Train (Epoch 39): Loss/seq after 00500 batchs: 1309.0772705078125
INFO:root:Train (Epoch 39): Loss/seq after 00550 batchs: 1259.1337890625
INFO:root:Train (Epoch 39): Loss/seq after 00600 batchs: 1219.6031494140625
INFO:root:Train (Epoch 39): Loss/seq after 00650 batchs: 1196.2127685546875
INFO:root:Train (Epoch 39): Loss/seq after 00700 batchs: 1152.2105712890625
INFO:root:Train (Epoch 39): Loss/seq after 00750 batchs: 1179.8375244140625
INFO:root:Train (Epoch 39): Loss/seq after 00800 batchs: 1181.258056640625
INFO:root:Train (Epoch 39): Loss/seq after 00850 batchs: 1149.5792236328125
INFO:root:Train (Epoch 39): Loss/seq after 00900 batchs: 1130.6422119140625
INFO:root:Train (Epoch 39): Loss/seq after 00950 batchs: 1151.8255615234375
INFO:root:Train (Epoch 39): Loss/seq after 01000 batchs: 1141.5244140625
INFO:root:Train (Epoch 39): Loss/seq after 01050 batchs: 1126.6768798828125
INFO:root:Train (Epoch 39): Loss/seq after 01100 batchs: 1108.1749267578125
INFO:root:Train (Epoch 39): Loss/seq after 01150 batchs: 1077.33642578125
INFO:root:Train (Epoch 39): Loss/seq after 01200 batchs: 1073.9627685546875
INFO:root:Train (Epoch 39): Loss/seq after 01250 batchs: 1071.1044921875
INFO:root:Train (Epoch 39): Loss/seq after 01300 batchs: 1055.690185546875
INFO:root:Train (Epoch 39): Loss/seq after 01350 batchs: 1041.6956787109375
INFO:root:Train (Epoch 39): Loss/seq after 01400 batchs: 1060.2518310546875
INFO:root:Train (Epoch 39): Loss/seq after 01450 batchs: 1057.0814208984375
INFO:root:Train (Epoch 39): Loss/seq after 01500 batchs: 1054.864501953125
INFO:root:Train (Epoch 39): Loss/seq after 01550 batchs: 1063.6519775390625
INFO:root:Train (Epoch 39): Loss/seq after 01600 batchs: 1052.6580810546875
INFO:root:Train (Epoch 39): Loss/seq after 01650 batchs: 1051.4024658203125
INFO:root:Train (Epoch 39): Loss/seq after 01700 batchs: 1046.9688720703125
INFO:root:Train (Epoch 39): Loss/seq after 01750 batchs: 1038.345947265625
INFO:root:Train (Epoch 39): Loss/seq after 01800 batchs: 1028.7733154296875
INFO:root:Train (Epoch 39): Loss/seq after 01850 batchs: 1018.6388549804688
INFO:root:Train (Epoch 39): Loss/seq after 01900 batchs: 1022.5625610351562
INFO:root:Train (Epoch 39): Loss/seq after 01950 batchs: 1020.07373046875
INFO:root:Train (Epoch 39): Loss/seq after 02000 batchs: 1014.9326171875
INFO:root:Train (Epoch 39): Loss/seq after 02050 batchs: 1010.8511962890625
INFO:root:Train (Epoch 39): Loss/seq after 02100 batchs: 1002.5563354492188
INFO:root:Train (Epoch 39): Loss/seq after 02150 batchs: 995.9423828125
INFO:root:Train (Epoch 39): Loss/seq after 02200 batchs: 988.1237182617188
INFO:root:Train (Epoch 39): Loss/seq after 02250 batchs: 996.0464477539062
INFO:root:Train (Epoch 39): Loss/seq after 02300 batchs: 1005.1583862304688
INFO:root:Train (Epoch 39): Loss/seq after 02350 batchs: 997.8594360351562
INFO:root:Train (Epoch 39): Loss/seq after 02400 batchs: 995.7986450195312
INFO:root:Train (Epoch 39): Loss/seq after 02450 batchs: 986.6650390625
INFO:root:Train (Epoch 39): Loss/seq after 02500 batchs: 970.5767822265625
INFO:root:Train (Epoch 39): Loss/seq after 02550 batchs: 960.0390014648438
INFO:root:Train (Epoch 39): Loss/seq after 02600 batchs: 955.5756225585938
INFO:root:Train (Epoch 39): Loss/seq after 02650 batchs: 950.4802856445312
INFO:root:Train (Epoch 39): Loss/seq after 02700 batchs: 948.0765991210938
INFO:root:Train (Epoch 39): Loss/seq after 02750 batchs: 965.5186767578125
INFO:root:Train (Epoch 39): Loss/seq after 02800 batchs: 969.6015625
INFO:root:Train (Epoch 39): Loss/seq after 02850 batchs: 969.0525512695312
INFO:root:Train (Epoch 39): Loss/seq after 02900 batchs: 969.4471435546875
INFO:root:Train (Epoch 39): Loss/seq after 02950 batchs: 964.8997192382812
INFO:root:Train (Epoch 39): Loss/seq after 03000 batchs: 965.4716186523438
INFO:root:Train (Epoch 39): Loss/seq after 03050 batchs: 968.1754760742188
INFO:root:Train (Epoch 39): Loss/seq after 03100 batchs: 981.5878295898438
INFO:root:Train (Epoch 39): Loss/seq after 03150 batchs: 990.318603515625
INFO:root:Train (Epoch 39): Loss/seq after 03200 batchs: 993.7935791015625
INFO:root:Train (Epoch 39): Loss/seq after 03250 batchs: 995.3214111328125
INFO:root:Train (Epoch 39): Loss/seq after 03300 batchs: 994.460205078125
INFO:root:Train (Epoch 39): Loss/seq after 03350 batchs: 993.1238403320312
INFO:root:Train (Epoch 39): Loss/seq after 03400 batchs: 984.1558227539062
INFO:root:Train (Epoch 39): Loss/seq after 03450 batchs: 978.7713623046875
INFO:root:Train (Epoch 39): Loss/seq after 03500 batchs: 979.7528686523438
INFO:root:Train (Epoch 39): Loss/seq after 03550 batchs: 976.9187622070312
INFO:root:Train (Epoch 39): Loss/seq after 03600 batchs: 984.6768798828125
INFO:root:Train (Epoch 39): Loss/seq after 03650 batchs: 981.7733154296875
INFO:root:Train (Epoch 39): Loss/seq after 03700 batchs: 981.99267578125
INFO:root:Train (Epoch 39): Loss/seq after 03750 batchs: 984.3302612304688
INFO:root:Train (Epoch 39): Loss/seq after 03800 batchs: 978.4708251953125
INFO:root:Train (Epoch 39): Loss/seq after 03850 batchs: 975.6168823242188
INFO:root:Train (Epoch 39): Loss/seq after 03900 batchs: 980.0454711914062
INFO:root:Train (Epoch 39): Loss/seq after 03950 batchs: 984.4382934570312
INFO:root:Train (Epoch 39): Loss/seq after 04000 batchs: 977.8558959960938
INFO:root:Train (Epoch 39): Loss/seq after 04050 batchs: 970.822021484375
INFO:root:Train (Epoch 39): Loss/seq after 04100 batchs: 967.0581665039062
INFO:root:Train (Epoch 39): Loss/seq after 04150 batchs: 963.5858764648438
INFO:root:Train (Epoch 39): Loss/seq after 04200 batchs: 960.79833984375
INFO:root:Train (Epoch 39): Loss/seq after 04250 batchs: 957.1070556640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 39): Loss/seq after 00000 batches: 620.5629272460938
INFO:root:# Valid (Epoch 39): Loss/seq after 00050 batches: 786.3336791992188
INFO:root:# Valid (Epoch 39): Loss/seq after 00100 batches: 1001.369384765625
INFO:root:# Valid (Epoch 39): Loss/seq after 00150 batches: 795.1948852539062
INFO:root:# Valid (Epoch 39): Loss/seq after 00200 batches: 752.0039672851562
INFO:root:Artifacts: Make stick videos for epoch 39
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_39_on_20220422_024734.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_39_index_1870_on_20220422_024734.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 40): Loss/seq after 00000 batchs: 1481.2884521484375
INFO:root:Train (Epoch 40): Loss/seq after 00050 batchs: 1330.280517578125
INFO:root:Train (Epoch 40): Loss/seq after 00100 batchs: 1384.619873046875
INFO:root:Train (Epoch 40): Loss/seq after 00150 batchs: 1258.33251953125
INFO:root:Train (Epoch 40): Loss/seq after 00200 batchs: 1364.3472900390625
INFO:root:Train (Epoch 40): Loss/seq after 00250 batchs: 1466.4107666015625
INFO:root:Train (Epoch 40): Loss/seq after 00300 batchs: 1392.5775146484375
INFO:root:Train (Epoch 40): Loss/seq after 00350 batchs: 1298.43896484375
INFO:root:Train (Epoch 40): Loss/seq after 00400 batchs: 1344.3585205078125
INFO:root:Train (Epoch 40): Loss/seq after 00450 batchs: 1288.111328125
INFO:root:Train (Epoch 40): Loss/seq after 00500 batchs: 1311.8787841796875
INFO:root:Train (Epoch 40): Loss/seq after 00550 batchs: 1261.348876953125
INFO:root:Train (Epoch 40): Loss/seq after 00600 batchs: 1221.377197265625
INFO:root:Train (Epoch 40): Loss/seq after 00650 batchs: 1195.06396484375
INFO:root:Train (Epoch 40): Loss/seq after 00700 batchs: 1147.9031982421875
INFO:root:Train (Epoch 40): Loss/seq after 00750 batchs: 1171.959716796875
INFO:root:Train (Epoch 40): Loss/seq after 00800 batchs: 1173.83984375
INFO:root:Train (Epoch 40): Loss/seq after 00850 batchs: 1142.139404296875
INFO:root:Train (Epoch 40): Loss/seq after 00900 batchs: 1123.9044189453125
INFO:root:Train (Epoch 40): Loss/seq after 00950 batchs: 1144.520263671875
INFO:root:Train (Epoch 40): Loss/seq after 01000 batchs: 1133.9088134765625
INFO:root:Train (Epoch 40): Loss/seq after 01050 batchs: 1117.53076171875
INFO:root:Train (Epoch 40): Loss/seq after 01100 batchs: 1098.0489501953125
INFO:root:Train (Epoch 40): Loss/seq after 01150 batchs: 1067.2198486328125
INFO:root:Train (Epoch 40): Loss/seq after 01200 batchs: 1063.9671630859375
INFO:root:Train (Epoch 40): Loss/seq after 01250 batchs: 1060.339599609375
INFO:root:Train (Epoch 40): Loss/seq after 01300 batchs: 1045.55859375
INFO:root:Train (Epoch 40): Loss/seq after 01350 batchs: 1031.3956298828125
INFO:root:Train (Epoch 40): Loss/seq after 01400 batchs: 1048.91455078125
INFO:root:Train (Epoch 40): Loss/seq after 01450 batchs: 1045.9322509765625
INFO:root:Train (Epoch 40): Loss/seq after 01500 batchs: 1044.0177001953125
INFO:root:Train (Epoch 40): Loss/seq after 01550 batchs: 1052.8165283203125
INFO:root:Train (Epoch 40): Loss/seq after 01600 batchs: 1042.0987548828125
INFO:root:Train (Epoch 40): Loss/seq after 01650 batchs: 1040.9913330078125
INFO:root:Train (Epoch 40): Loss/seq after 01700 batchs: 1036.8544921875
INFO:root:Train (Epoch 40): Loss/seq after 01750 batchs: 1028.4249267578125
INFO:root:Train (Epoch 40): Loss/seq after 01800 batchs: 1019.1260986328125
INFO:root:Train (Epoch 40): Loss/seq after 01850 batchs: 1009.2353515625
INFO:root:Train (Epoch 40): Loss/seq after 01900 batchs: 1013.3360595703125
INFO:root:Train (Epoch 40): Loss/seq after 01950 batchs: 1010.8604125976562
INFO:root:Train (Epoch 40): Loss/seq after 02000 batchs: 1005.8346557617188
INFO:root:Train (Epoch 40): Loss/seq after 02050 batchs: 1001.9278564453125
INFO:root:Train (Epoch 40): Loss/seq after 02100 batchs: 993.8766479492188
INFO:root:Train (Epoch 40): Loss/seq after 02150 batchs: 987.4326171875
INFO:root:Train (Epoch 40): Loss/seq after 02200 batchs: 979.7999877929688
INFO:root:Train (Epoch 40): Loss/seq after 02250 batchs: 987.8363037109375
INFO:root:Train (Epoch 40): Loss/seq after 02300 batchs: 995.7394409179688
INFO:root:Train (Epoch 40): Loss/seq after 02350 batchs: 988.538818359375
INFO:root:Train (Epoch 40): Loss/seq after 02400 batchs: 986.4666748046875
INFO:root:Train (Epoch 40): Loss/seq after 02450 batchs: 977.5082397460938
INFO:root:Train (Epoch 40): Loss/seq after 02500 batchs: 961.6278686523438
INFO:root:Train (Epoch 40): Loss/seq after 02550 batchs: 951.3119506835938
INFO:root:Train (Epoch 40): Loss/seq after 02600 batchs: 946.6806640625
INFO:root:Train (Epoch 40): Loss/seq after 02650 batchs: 941.9901733398438
INFO:root:Train (Epoch 40): Loss/seq after 02700 batchs: 939.778564453125
INFO:root:Train (Epoch 40): Loss/seq after 02750 batchs: 954.1472778320312
INFO:root:Train (Epoch 40): Loss/seq after 02800 batchs: 958.2573852539062
INFO:root:Train (Epoch 40): Loss/seq after 02850 batchs: 958.29052734375
INFO:root:Train (Epoch 40): Loss/seq after 02900 batchs: 958.6513671875
INFO:root:Train (Epoch 40): Loss/seq after 02950 batchs: 954.1817016601562
INFO:root:Train (Epoch 40): Loss/seq after 03000 batchs: 954.948974609375
INFO:root:Train (Epoch 40): Loss/seq after 03050 batchs: 957.8792724609375
INFO:root:Train (Epoch 40): Loss/seq after 03100 batchs: 971.4961547851562
INFO:root:Train (Epoch 40): Loss/seq after 03150 batchs: 979.8499755859375
INFO:root:Train (Epoch 40): Loss/seq after 03200 batchs: 983.2883911132812
INFO:root:Train (Epoch 40): Loss/seq after 03250 batchs: 984.745849609375
INFO:root:Train (Epoch 40): Loss/seq after 03300 batchs: 983.8037109375
INFO:root:Train (Epoch 40): Loss/seq after 03350 batchs: 982.508544921875
INFO:root:Train (Epoch 40): Loss/seq after 03400 batchs: 973.6190185546875
INFO:root:Train (Epoch 40): Loss/seq after 03450 batchs: 968.3552856445312
INFO:root:Train (Epoch 40): Loss/seq after 03500 batchs: 969.3345336914062
INFO:root:Train (Epoch 40): Loss/seq after 03550 batchs: 966.5343017578125
INFO:root:Train (Epoch 40): Loss/seq after 03600 batchs: 974.4541625976562
INFO:root:Train (Epoch 40): Loss/seq after 03650 batchs: 971.6526489257812
INFO:root:Train (Epoch 40): Loss/seq after 03700 batchs: 971.932373046875
INFO:root:Train (Epoch 40): Loss/seq after 03750 batchs: 974.3780517578125
INFO:root:Train (Epoch 40): Loss/seq after 03800 batchs: 968.581787109375
INFO:root:Train (Epoch 40): Loss/seq after 03850 batchs: 965.8132934570312
INFO:root:Train (Epoch 40): Loss/seq after 03900 batchs: 970.5655517578125
INFO:root:Train (Epoch 40): Loss/seq after 03950 batchs: 974.5895385742188
INFO:root:Train (Epoch 40): Loss/seq after 04000 batchs: 968.1202392578125
INFO:root:Train (Epoch 40): Loss/seq after 04050 batchs: 961.1697998046875
INFO:root:Train (Epoch 40): Loss/seq after 04100 batchs: 957.286376953125
INFO:root:Train (Epoch 40): Loss/seq after 04150 batchs: 953.8742065429688
INFO:root:Train (Epoch 40): Loss/seq after 04200 batchs: 951.0894775390625
INFO:root:Train (Epoch 40): Loss/seq after 04250 batchs: 947.4339599609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 40): Loss/seq after 00000 batches: 578.751953125
INFO:root:# Valid (Epoch 40): Loss/seq after 00050 batches: 776.4495239257812
INFO:root:# Valid (Epoch 40): Loss/seq after 00100 batches: 1010.6240844726562
INFO:root:# Valid (Epoch 40): Loss/seq after 00150 batches: 795.0787963867188
INFO:root:# Valid (Epoch 40): Loss/seq after 00200 batches: 748.0685424804688
INFO:root:Artifacts: Make stick videos for epoch 40
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_40_on_20220422_025230.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_40_index_498_on_20220422_025230.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 41): Loss/seq after 00000 batchs: 1396.2052001953125
INFO:root:Train (Epoch 41): Loss/seq after 00050 batchs: 1318.468017578125
INFO:root:Train (Epoch 41): Loss/seq after 00100 batchs: 1369.8328857421875
INFO:root:Train (Epoch 41): Loss/seq after 00150 batchs: 1244.1243896484375
INFO:root:Train (Epoch 41): Loss/seq after 00200 batchs: 1349.11767578125
INFO:root:Train (Epoch 41): Loss/seq after 00250 batchs: 1454.3289794921875
INFO:root:Train (Epoch 41): Loss/seq after 00300 batchs: 1381.92822265625
INFO:root:Train (Epoch 41): Loss/seq after 00350 batchs: 1288.502197265625
INFO:root:Train (Epoch 41): Loss/seq after 00400 batchs: 1332.491943359375
INFO:root:Train (Epoch 41): Loss/seq after 00450 batchs: 1276.8822021484375
INFO:root:Train (Epoch 41): Loss/seq after 00500 batchs: 1301.4588623046875
INFO:root:Train (Epoch 41): Loss/seq after 00550 batchs: 1251.40478515625
INFO:root:Train (Epoch 41): Loss/seq after 00600 batchs: 1211.427734375
INFO:root:Train (Epoch 41): Loss/seq after 00650 batchs: 1183.804443359375
INFO:root:Train (Epoch 41): Loss/seq after 00700 batchs: 1136.7998046875
INFO:root:Train (Epoch 41): Loss/seq after 00750 batchs: 1159.4913330078125
INFO:root:Train (Epoch 41): Loss/seq after 00800 batchs: 1162.0357666015625
INFO:root:Train (Epoch 41): Loss/seq after 00850 batchs: 1130.75244140625
INFO:root:Train (Epoch 41): Loss/seq after 00900 batchs: 1113.0430908203125
INFO:root:Train (Epoch 41): Loss/seq after 00950 batchs: 1130.1319580078125
INFO:root:Train (Epoch 41): Loss/seq after 01000 batchs: 1119.032958984375
INFO:root:Train (Epoch 41): Loss/seq after 01050 batchs: 1103.77392578125
INFO:root:Train (Epoch 41): Loss/seq after 01100 batchs: 1084.7677001953125
INFO:root:Train (Epoch 41): Loss/seq after 01150 batchs: 1054.7371826171875
INFO:root:Train (Epoch 41): Loss/seq after 01200 batchs: 1051.49462890625
INFO:root:Train (Epoch 41): Loss/seq after 01250 batchs: 1047.6490478515625
INFO:root:Train (Epoch 41): Loss/seq after 01300 batchs: 1032.1707763671875
INFO:root:Train (Epoch 41): Loss/seq after 01350 batchs: 1017.2178344726562
INFO:root:Train (Epoch 41): Loss/seq after 01400 batchs: 1032.099853515625
INFO:root:Train (Epoch 41): Loss/seq after 01450 batchs: 1029.859375
INFO:root:Train (Epoch 41): Loss/seq after 01500 batchs: 1028.3348388671875
INFO:root:Train (Epoch 41): Loss/seq after 01550 batchs: 1037.3775634765625
INFO:root:Train (Epoch 41): Loss/seq after 01600 batchs: 1027.249267578125
INFO:root:Train (Epoch 41): Loss/seq after 01650 batchs: 1026.5374755859375
INFO:root:Train (Epoch 41): Loss/seq after 01700 batchs: 1022.7930908203125
INFO:root:Train (Epoch 41): Loss/seq after 01750 batchs: 1014.6124267578125
INFO:root:Train (Epoch 41): Loss/seq after 01800 batchs: 1005.6024780273438
INFO:root:Train (Epoch 41): Loss/seq after 01850 batchs: 995.9970092773438
INFO:root:Train (Epoch 41): Loss/seq after 01900 batchs: 1000.0844116210938
INFO:root:Train (Epoch 41): Loss/seq after 01950 batchs: 997.7761840820312
INFO:root:Train (Epoch 41): Loss/seq after 02000 batchs: 992.9502563476562
INFO:root:Train (Epoch 41): Loss/seq after 02050 batchs: 989.109619140625
INFO:root:Train (Epoch 41): Loss/seq after 02100 batchs: 981.2218627929688
INFO:root:Train (Epoch 41): Loss/seq after 02150 batchs: 974.9901123046875
INFO:root:Train (Epoch 41): Loss/seq after 02200 batchs: 967.4730834960938
INFO:root:Train (Epoch 41): Loss/seq after 02250 batchs: 975.3878173828125
INFO:root:Train (Epoch 41): Loss/seq after 02300 batchs: 981.8070068359375
INFO:root:Train (Epoch 41): Loss/seq after 02350 batchs: 974.6326904296875
INFO:root:Train (Epoch 41): Loss/seq after 02400 batchs: 972.6077880859375
INFO:root:Train (Epoch 41): Loss/seq after 02450 batchs: 963.370849609375
INFO:root:Train (Epoch 41): Loss/seq after 02500 batchs: 947.7171020507812
INFO:root:Train (Epoch 41): Loss/seq after 02550 batchs: 937.5484008789062
INFO:root:Train (Epoch 41): Loss/seq after 02600 batchs: 932.7215576171875
INFO:root:Train (Epoch 41): Loss/seq after 02650 batchs: 927.9475708007812
INFO:root:Train (Epoch 41): Loss/seq after 02700 batchs: 925.3773803710938
INFO:root:Train (Epoch 41): Loss/seq after 02750 batchs: 938.1380615234375
INFO:root:Train (Epoch 41): Loss/seq after 02800 batchs: 942.4673461914062
INFO:root:Train (Epoch 41): Loss/seq after 02850 batchs: 942.7549438476562
INFO:root:Train (Epoch 41): Loss/seq after 02900 batchs: 943.3120727539062
INFO:root:Train (Epoch 41): Loss/seq after 02950 batchs: 939.2276611328125
INFO:root:Train (Epoch 41): Loss/seq after 03000 batchs: 940.1889038085938
INFO:root:Train (Epoch 41): Loss/seq after 03050 batchs: 943.5751953125
INFO:root:Train (Epoch 41): Loss/seq after 03100 batchs: 956.9678344726562
INFO:root:Train (Epoch 41): Loss/seq after 03150 batchs: 965.6361694335938
INFO:root:Train (Epoch 41): Loss/seq after 03200 batchs: 968.9695434570312
INFO:root:Train (Epoch 41): Loss/seq after 03250 batchs: 971.27392578125
INFO:root:Train (Epoch 41): Loss/seq after 03300 batchs: 970.5020751953125
INFO:root:Train (Epoch 41): Loss/seq after 03350 batchs: 969.4971923828125
INFO:root:Train (Epoch 41): Loss/seq after 03400 batchs: 960.679443359375
INFO:root:Train (Epoch 41): Loss/seq after 03450 batchs: 955.6660766601562
INFO:root:Train (Epoch 41): Loss/seq after 03500 batchs: 956.8555297851562
INFO:root:Train (Epoch 41): Loss/seq after 03550 batchs: 954.1214599609375
INFO:root:Train (Epoch 41): Loss/seq after 03600 batchs: 962.1461791992188
INFO:root:Train (Epoch 41): Loss/seq after 03650 batchs: 959.29443359375
INFO:root:Train (Epoch 41): Loss/seq after 03700 batchs: 959.6964721679688
INFO:root:Train (Epoch 41): Loss/seq after 03750 batchs: 962.1484985351562
INFO:root:Train (Epoch 41): Loss/seq after 03800 batchs: 956.4457397460938
INFO:root:Train (Epoch 41): Loss/seq after 03850 batchs: 953.7530517578125
INFO:root:Train (Epoch 41): Loss/seq after 03900 batchs: 958.5911254882812
INFO:root:Train (Epoch 41): Loss/seq after 03950 batchs: 962.7822875976562
INFO:root:Train (Epoch 41): Loss/seq after 04000 batchs: 956.45361328125
INFO:root:Train (Epoch 41): Loss/seq after 04050 batchs: 949.5706787109375
INFO:root:Train (Epoch 41): Loss/seq after 04100 batchs: 945.9083251953125
INFO:root:Train (Epoch 41): Loss/seq after 04150 batchs: 942.6150512695312
INFO:root:Train (Epoch 41): Loss/seq after 04200 batchs: 939.8010864257812
INFO:root:Train (Epoch 41): Loss/seq after 04250 batchs: 936.1566772460938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 41): Loss/seq after 00000 batches: 663.7222290039062
INFO:root:# Valid (Epoch 41): Loss/seq after 00050 batches: 783.889892578125
INFO:root:# Valid (Epoch 41): Loss/seq after 00100 batches: 994.0952758789062
INFO:root:# Valid (Epoch 41): Loss/seq after 00150 batches: 798.5654296875
INFO:root:# Valid (Epoch 41): Loss/seq after 00200 batches: 753.2224731445312
INFO:root:Artifacts: Make stick videos for epoch 41
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_41_on_20220422_025721.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_41_index_1841_on_20220422_025721.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 42): Loss/seq after 00000 batchs: 1417.37353515625
INFO:root:Train (Epoch 42): Loss/seq after 00050 batchs: 1298.0380859375
INFO:root:Train (Epoch 42): Loss/seq after 00100 batchs: 1350.6436767578125
INFO:root:Train (Epoch 42): Loss/seq after 00150 batchs: 1224.2108154296875
INFO:root:Train (Epoch 42): Loss/seq after 00200 batchs: 1337.4228515625
INFO:root:Train (Epoch 42): Loss/seq after 00250 batchs: 1442.9278564453125
INFO:root:Train (Epoch 42): Loss/seq after 00300 batchs: 1370.9744873046875
INFO:root:Train (Epoch 42): Loss/seq after 00350 batchs: 1275.8074951171875
INFO:root:Train (Epoch 42): Loss/seq after 00400 batchs: 1316.4913330078125
INFO:root:Train (Epoch 42): Loss/seq after 00450 batchs: 1262.2799072265625
INFO:root:Train (Epoch 42): Loss/seq after 00500 batchs: 1282.83203125
INFO:root:Train (Epoch 42): Loss/seq after 00550 batchs: 1232.4517822265625
INFO:root:Train (Epoch 42): Loss/seq after 00600 batchs: 1192.95166015625
INFO:root:Train (Epoch 42): Loss/seq after 00650 batchs: 1165.898193359375
INFO:root:Train (Epoch 42): Loss/seq after 00700 batchs: 1120.2774658203125
INFO:root:Train (Epoch 42): Loss/seq after 00750 batchs: 1142.5322265625
INFO:root:Train (Epoch 42): Loss/seq after 00800 batchs: 1145.085205078125
INFO:root:Train (Epoch 42): Loss/seq after 00850 batchs: 1114.1302490234375
INFO:root:Train (Epoch 42): Loss/seq after 00900 batchs: 1097.8441162109375
INFO:root:Train (Epoch 42): Loss/seq after 00950 batchs: 1117.9779052734375
INFO:root:Train (Epoch 42): Loss/seq after 01000 batchs: 1106.505615234375
INFO:root:Train (Epoch 42): Loss/seq after 01050 batchs: 1090.661865234375
INFO:root:Train (Epoch 42): Loss/seq after 01100 batchs: 1072.529296875
INFO:root:Train (Epoch 42): Loss/seq after 01150 batchs: 1042.926025390625
INFO:root:Train (Epoch 42): Loss/seq after 01200 batchs: 1040.8858642578125
INFO:root:Train (Epoch 42): Loss/seq after 01250 batchs: 1036.3570556640625
INFO:root:Train (Epoch 42): Loss/seq after 01300 batchs: 1021.0596313476562
INFO:root:Train (Epoch 42): Loss/seq after 01350 batchs: 1007.8630981445312
INFO:root:Train (Epoch 42): Loss/seq after 01400 batchs: 1021.6109619140625
INFO:root:Train (Epoch 42): Loss/seq after 01450 batchs: 1018.6935424804688
INFO:root:Train (Epoch 42): Loss/seq after 01500 batchs: 1017.1256713867188
INFO:root:Train (Epoch 42): Loss/seq after 01550 batchs: 1024.5040283203125
INFO:root:Train (Epoch 42): Loss/seq after 01600 batchs: 1014.3733520507812
INFO:root:Train (Epoch 42): Loss/seq after 01650 batchs: 1013.0951538085938
INFO:root:Train (Epoch 42): Loss/seq after 01700 batchs: 1008.9188842773438
INFO:root:Train (Epoch 42): Loss/seq after 01750 batchs: 1000.8018188476562
INFO:root:Train (Epoch 42): Loss/seq after 01800 batchs: 991.908203125
INFO:root:Train (Epoch 42): Loss/seq after 01850 batchs: 982.5200805664062
INFO:root:Train (Epoch 42): Loss/seq after 01900 batchs: 985.9061279296875
INFO:root:Train (Epoch 42): Loss/seq after 01950 batchs: 983.896728515625
INFO:root:Train (Epoch 42): Loss/seq after 02000 batchs: 979.0677490234375
INFO:root:Train (Epoch 42): Loss/seq after 02050 batchs: 975.24169921875
INFO:root:Train (Epoch 42): Loss/seq after 02100 batchs: 967.35546875
INFO:root:Train (Epoch 42): Loss/seq after 02150 batchs: 961.1742553710938
INFO:root:Train (Epoch 42): Loss/seq after 02200 batchs: 953.6861572265625
INFO:root:Train (Epoch 42): Loss/seq after 02250 batchs: 960.2269287109375
INFO:root:Train (Epoch 42): Loss/seq after 02300 batchs: 965.8160400390625
INFO:root:Train (Epoch 42): Loss/seq after 02350 batchs: 958.42626953125
INFO:root:Train (Epoch 42): Loss/seq after 02400 batchs: 956.38525390625
INFO:root:Train (Epoch 42): Loss/seq after 02450 batchs: 947.6641845703125
INFO:root:Train (Epoch 42): Loss/seq after 02500 batchs: 932.4120483398438
INFO:root:Train (Epoch 42): Loss/seq after 02550 batchs: 922.18994140625
INFO:root:Train (Epoch 42): Loss/seq after 02600 batchs: 918.33935546875
INFO:root:Train (Epoch 42): Loss/seq after 02650 batchs: 913.9135131835938
INFO:root:Train (Epoch 42): Loss/seq after 02700 batchs: 911.4877319335938
INFO:root:Train (Epoch 42): Loss/seq after 02750 batchs: 923.2826538085938
INFO:root:Train (Epoch 42): Loss/seq after 02800 batchs: 925.9474487304688
INFO:root:Train (Epoch 42): Loss/seq after 02850 batchs: 925.7084350585938
INFO:root:Train (Epoch 42): Loss/seq after 02900 batchs: 926.1661376953125
INFO:root:Train (Epoch 42): Loss/seq after 02950 batchs: 922.0967407226562
INFO:root:Train (Epoch 42): Loss/seq after 03000 batchs: 923.1898193359375
INFO:root:Train (Epoch 42): Loss/seq after 03050 batchs: 925.8729248046875
INFO:root:Train (Epoch 42): Loss/seq after 03100 batchs: 938.8900756835938
INFO:root:Train (Epoch 42): Loss/seq after 03150 batchs: 947.0192260742188
INFO:root:Train (Epoch 42): Loss/seq after 03200 batchs: 950.4694213867188
INFO:root:Train (Epoch 42): Loss/seq after 03250 batchs: 952.303955078125
INFO:root:Train (Epoch 42): Loss/seq after 03300 batchs: 950.9715576171875
INFO:root:Train (Epoch 42): Loss/seq after 03350 batchs: 950.6014404296875
INFO:root:Train (Epoch 42): Loss/seq after 03400 batchs: 942.1658935546875
INFO:root:Train (Epoch 42): Loss/seq after 03450 batchs: 937.1245727539062
INFO:root:Train (Epoch 42): Loss/seq after 03500 batchs: 937.9639282226562
INFO:root:Train (Epoch 42): Loss/seq after 03550 batchs: 935.3533325195312
INFO:root:Train (Epoch 42): Loss/seq after 03600 batchs: 943.4860229492188
INFO:root:Train (Epoch 42): Loss/seq after 03650 batchs: 940.0489501953125
INFO:root:Train (Epoch 42): Loss/seq after 03700 batchs: 940.9092407226562
INFO:root:Train (Epoch 42): Loss/seq after 03750 batchs: 943.6572265625
INFO:root:Train (Epoch 42): Loss/seq after 03800 batchs: 938.0386352539062
INFO:root:Train (Epoch 42): Loss/seq after 03850 batchs: 935.5057373046875
INFO:root:Train (Epoch 42): Loss/seq after 03900 batchs: 940.2523803710938
INFO:root:Train (Epoch 42): Loss/seq after 03950 batchs: 943.9290771484375
INFO:root:Train (Epoch 42): Loss/seq after 04000 batchs: 937.7484741210938
INFO:root:Train (Epoch 42): Loss/seq after 04050 batchs: 931.0325927734375
INFO:root:Train (Epoch 42): Loss/seq after 04100 batchs: 927.4893798828125
INFO:root:Train (Epoch 42): Loss/seq after 04150 batchs: 924.441650390625
INFO:root:Train (Epoch 42): Loss/seq after 04200 batchs: 921.5509643554688
INFO:root:Train (Epoch 42): Loss/seq after 04250 batchs: 918.2206420898438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 42): Loss/seq after 00000 batches: 645.5645141601562
INFO:root:# Valid (Epoch 42): Loss/seq after 00050 batches: 779.2176513671875
INFO:root:# Valid (Epoch 42): Loss/seq after 00100 batches: 986.7433471679688
INFO:root:# Valid (Epoch 42): Loss/seq after 00150 batches: 771.3223876953125
INFO:root:# Valid (Epoch 42): Loss/seq after 00200 batches: 726.1126098632812
INFO:root:Artifacts: Make stick videos for epoch 42
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_42_on_20220422_030205.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_42_index_1854_on_20220422_030205.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 43): Loss/seq after 00000 batchs: 1448.527587890625
INFO:root:Train (Epoch 43): Loss/seq after 00050 batchs: 1252.7471923828125
INFO:root:Train (Epoch 43): Loss/seq after 00100 batchs: 1316.718994140625
INFO:root:Train (Epoch 43): Loss/seq after 00150 batchs: 1225.9656982421875
INFO:root:Train (Epoch 43): Loss/seq after 00200 batchs: 1328.2020263671875
INFO:root:Train (Epoch 43): Loss/seq after 00250 batchs: 1428.760009765625
INFO:root:Train (Epoch 43): Loss/seq after 00300 batchs: 1359.8226318359375
INFO:root:Train (Epoch 43): Loss/seq after 00350 batchs: 1265.3372802734375
INFO:root:Train (Epoch 43): Loss/seq after 00400 batchs: 1299.9412841796875
INFO:root:Train (Epoch 43): Loss/seq after 00450 batchs: 1246.6732177734375
INFO:root:Train (Epoch 43): Loss/seq after 00500 batchs: 1260.769287109375
INFO:root:Train (Epoch 43): Loss/seq after 00550 batchs: 1210.4095458984375
INFO:root:Train (Epoch 43): Loss/seq after 00600 batchs: 1166.44140625
INFO:root:Train (Epoch 43): Loss/seq after 00650 batchs: 1140.6324462890625
INFO:root:Train (Epoch 43): Loss/seq after 00700 batchs: 1096.7850341796875
INFO:root:Train (Epoch 43): Loss/seq after 00750 batchs: 1119.919921875
INFO:root:Train (Epoch 43): Loss/seq after 00800 batchs: 1119.2896728515625
INFO:root:Train (Epoch 43): Loss/seq after 00850 batchs: 1090.1993408203125
INFO:root:Train (Epoch 43): Loss/seq after 00900 batchs: 1072.9683837890625
INFO:root:Train (Epoch 43): Loss/seq after 00950 batchs: 1088.768310546875
INFO:root:Train (Epoch 43): Loss/seq after 01000 batchs: 1075.631103515625
INFO:root:Train (Epoch 43): Loss/seq after 01050 batchs: 1062.7239990234375
INFO:root:Train (Epoch 43): Loss/seq after 01100 batchs: 1052.0440673828125
INFO:root:Train (Epoch 43): Loss/seq after 01150 batchs: 1024.4901123046875
INFO:root:Train (Epoch 43): Loss/seq after 01200 batchs: 1023.7269897460938
INFO:root:Train (Epoch 43): Loss/seq after 01250 batchs: 1019.8172607421875
INFO:root:Train (Epoch 43): Loss/seq after 01300 batchs: 1008.61328125
INFO:root:Train (Epoch 43): Loss/seq after 01350 batchs: 995.0289916992188
INFO:root:Train (Epoch 43): Loss/seq after 01400 batchs: 1005.7938842773438
INFO:root:Train (Epoch 43): Loss/seq after 01450 batchs: 1003.9625854492188
INFO:root:Train (Epoch 43): Loss/seq after 01500 batchs: 1003.1897583007812
INFO:root:Train (Epoch 43): Loss/seq after 01550 batchs: 1009.880126953125
INFO:root:Train (Epoch 43): Loss/seq after 01600 batchs: 1000.0392456054688
INFO:root:Train (Epoch 43): Loss/seq after 01650 batchs: 997.8401489257812
INFO:root:Train (Epoch 43): Loss/seq after 01700 batchs: 993.5088500976562
INFO:root:Train (Epoch 43): Loss/seq after 01750 batchs: 985.9827880859375
INFO:root:Train (Epoch 43): Loss/seq after 01800 batchs: 977.5096435546875
INFO:root:Train (Epoch 43): Loss/seq after 01850 batchs: 968.2420043945312
INFO:root:Train (Epoch 43): Loss/seq after 01900 batchs: 971.7787475585938
INFO:root:Train (Epoch 43): Loss/seq after 01950 batchs: 969.0979614257812
INFO:root:Train (Epoch 43): Loss/seq after 02000 batchs: 964.2533569335938
INFO:root:Train (Epoch 43): Loss/seq after 02050 batchs: 960.2630004882812
INFO:root:Train (Epoch 43): Loss/seq after 02100 batchs: 952.6058959960938
INFO:root:Train (Epoch 43): Loss/seq after 02150 batchs: 946.869384765625
INFO:root:Train (Epoch 43): Loss/seq after 02200 batchs: 939.7233276367188
INFO:root:Train (Epoch 43): Loss/seq after 02250 batchs: 943.8925170898438
INFO:root:Train (Epoch 43): Loss/seq after 02300 batchs: 947.1998901367188
INFO:root:Train (Epoch 43): Loss/seq after 02350 batchs: 941.25390625
INFO:root:Train (Epoch 43): Loss/seq after 02400 batchs: 940.8759155273438
INFO:root:Train (Epoch 43): Loss/seq after 02450 batchs: 933.70263671875
INFO:root:Train (Epoch 43): Loss/seq after 02500 batchs: 918.8790283203125
INFO:root:Train (Epoch 43): Loss/seq after 02550 batchs: 910.538818359375
INFO:root:Train (Epoch 43): Loss/seq after 02600 batchs: 908.4957885742188
INFO:root:Train (Epoch 43): Loss/seq after 02650 batchs: 904.9171142578125
INFO:root:Train (Epoch 43): Loss/seq after 02700 batchs: 902.423095703125
INFO:root:Train (Epoch 43): Loss/seq after 02750 batchs: 915.71142578125
INFO:root:Train (Epoch 43): Loss/seq after 02800 batchs: 918.8234252929688
INFO:root:Train (Epoch 43): Loss/seq after 02850 batchs: 918.3576049804688
INFO:root:Train (Epoch 43): Loss/seq after 02900 batchs: 918.4176025390625
INFO:root:Train (Epoch 43): Loss/seq after 02950 batchs: 914.4849853515625
INFO:root:Train (Epoch 43): Loss/seq after 03000 batchs: 915.7714233398438
INFO:root:Train (Epoch 43): Loss/seq after 03050 batchs: 919.52880859375
INFO:root:Train (Epoch 43): Loss/seq after 03100 batchs: 930.9249877929688
INFO:root:Train (Epoch 43): Loss/seq after 03150 batchs: 937.859130859375
INFO:root:Train (Epoch 43): Loss/seq after 03200 batchs: 940.649658203125
INFO:root:Train (Epoch 43): Loss/seq after 03250 batchs: 942.9093017578125
INFO:root:Train (Epoch 43): Loss/seq after 03300 batchs: 941.059326171875
INFO:root:Train (Epoch 43): Loss/seq after 03350 batchs: 940.1998291015625
INFO:root:Train (Epoch 43): Loss/seq after 03400 batchs: 931.7579345703125
INFO:root:Train (Epoch 43): Loss/seq after 03450 batchs: 927.19921875
INFO:root:Train (Epoch 43): Loss/seq after 03500 batchs: 928.0877685546875
INFO:root:Train (Epoch 43): Loss/seq after 03550 batchs: 926.0046997070312
INFO:root:Train (Epoch 43): Loss/seq after 03600 batchs: 934.4200439453125
INFO:root:Train (Epoch 43): Loss/seq after 03650 batchs: 931.07373046875
INFO:root:Train (Epoch 43): Loss/seq after 03700 batchs: 931.7022094726562
INFO:root:Train (Epoch 43): Loss/seq after 03750 batchs: 934.7174682617188
INFO:root:Train (Epoch 43): Loss/seq after 03800 batchs: 929.3135375976562
INFO:root:Train (Epoch 43): Loss/seq after 03850 batchs: 926.9358520507812
INFO:root:Train (Epoch 43): Loss/seq after 03900 batchs: 931.2903442382812
INFO:root:Train (Epoch 43): Loss/seq after 03950 batchs: 934.3257446289062
INFO:root:Train (Epoch 43): Loss/seq after 04000 batchs: 928.2640380859375
INFO:root:Train (Epoch 43): Loss/seq after 04050 batchs: 921.6439819335938
INFO:root:Train (Epoch 43): Loss/seq after 04100 batchs: 918.2499389648438
INFO:root:Train (Epoch 43): Loss/seq after 04150 batchs: 915.1920776367188
INFO:root:Train (Epoch 43): Loss/seq after 04200 batchs: 912.3546142578125
INFO:root:Train (Epoch 43): Loss/seq after 04250 batchs: 908.9545288085938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 43): Loss/seq after 00000 batches: 561.30078125
INFO:root:# Valid (Epoch 43): Loss/seq after 00050 batches: 768.8170166015625
INFO:root:# Valid (Epoch 43): Loss/seq after 00100 batches: 977.5032348632812
INFO:root:# Valid (Epoch 43): Loss/seq after 00150 batches: 765.6064453125
INFO:root:# Valid (Epoch 43): Loss/seq after 00200 batches: 723.133056640625
INFO:root:Artifacts: Make stick videos for epoch 43
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_43_on_20220422_030653.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_43_index_113_on_20220422_030653.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 44): Loss/seq after 00000 batchs: 1552.49658203125
INFO:root:Train (Epoch 44): Loss/seq after 00050 batchs: 1208.1937255859375
INFO:root:Train (Epoch 44): Loss/seq after 00100 batchs: 1236.981689453125
INFO:root:Train (Epoch 44): Loss/seq after 00150 batchs: 1135.9024658203125
INFO:root:Train (Epoch 44): Loss/seq after 00200 batchs: 1235.209716796875
INFO:root:Train (Epoch 44): Loss/seq after 00250 batchs: 1350.4718017578125
INFO:root:Train (Epoch 44): Loss/seq after 00300 batchs: 1293.4730224609375
INFO:root:Train (Epoch 44): Loss/seq after 00350 batchs: 1204.9168701171875
INFO:root:Train (Epoch 44): Loss/seq after 00400 batchs: 1228.742431640625
INFO:root:Train (Epoch 44): Loss/seq after 00450 batchs: 1185.241943359375
INFO:root:Train (Epoch 44): Loss/seq after 00500 batchs: 1192.105712890625
INFO:root:Train (Epoch 44): Loss/seq after 00550 batchs: 1148.4752197265625
INFO:root:Train (Epoch 44): Loss/seq after 00600 batchs: 1104.933837890625
INFO:root:Train (Epoch 44): Loss/seq after 00650 batchs: 1084.6722412109375
INFO:root:Train (Epoch 44): Loss/seq after 00700 batchs: 1045.0062255859375
INFO:root:Train (Epoch 44): Loss/seq after 00750 batchs: 1069.496337890625
INFO:root:Train (Epoch 44): Loss/seq after 00800 batchs: 1071.8486328125
INFO:root:Train (Epoch 44): Loss/seq after 00850 batchs: 1045.6893310546875
INFO:root:Train (Epoch 44): Loss/seq after 00900 batchs: 1031.179931640625
INFO:root:Train (Epoch 44): Loss/seq after 00950 batchs: 1043.76513671875
INFO:root:Train (Epoch 44): Loss/seq after 01000 batchs: 1031.935546875
INFO:root:Train (Epoch 44): Loss/seq after 01050 batchs: 1012.170654296875
INFO:root:Train (Epoch 44): Loss/seq after 01100 batchs: 996.731201171875
INFO:root:Train (Epoch 44): Loss/seq after 01150 batchs: 970.5432739257812
INFO:root:Train (Epoch 44): Loss/seq after 01200 batchs: 970.8090209960938
INFO:root:Train (Epoch 44): Loss/seq after 01250 batchs: 965.2512817382812
INFO:root:Train (Epoch 44): Loss/seq after 01300 batchs: 953.1866455078125
INFO:root:Train (Epoch 44): Loss/seq after 01350 batchs: 940.6881713867188
INFO:root:Train (Epoch 44): Loss/seq after 01400 batchs: 952.5338745117188
INFO:root:Train (Epoch 44): Loss/seq after 01450 batchs: 951.9949951171875
INFO:root:Train (Epoch 44): Loss/seq after 01500 batchs: 952.6703491210938
INFO:root:Train (Epoch 44): Loss/seq after 01550 batchs: 959.4866943359375
INFO:root:Train (Epoch 44): Loss/seq after 01600 batchs: 950.585693359375
INFO:root:Train (Epoch 44): Loss/seq after 01650 batchs: 949.6610717773438
INFO:root:Train (Epoch 44): Loss/seq after 01700 batchs: 946.7282104492188
INFO:root:Train (Epoch 44): Loss/seq after 01750 batchs: 940.3848266601562
INFO:root:Train (Epoch 44): Loss/seq after 01800 batchs: 932.9413452148438
INFO:root:Train (Epoch 44): Loss/seq after 01850 batchs: 924.822509765625
INFO:root:Train (Epoch 44): Loss/seq after 01900 batchs: 929.2413330078125
INFO:root:Train (Epoch 44): Loss/seq after 01950 batchs: 927.1151123046875
INFO:root:Train (Epoch 44): Loss/seq after 02000 batchs: 923.421875
INFO:root:Train (Epoch 44): Loss/seq after 02050 batchs: 920.4157104492188
INFO:root:Train (Epoch 44): Loss/seq after 02100 batchs: 913.6567993164062
INFO:root:Train (Epoch 44): Loss/seq after 02150 batchs: 908.7019653320312
INFO:root:Train (Epoch 44): Loss/seq after 02200 batchs: 902.3358154296875
INFO:root:Train (Epoch 44): Loss/seq after 02250 batchs: 905.9082641601562
INFO:root:Train (Epoch 44): Loss/seq after 02300 batchs: 910.7166137695312
INFO:root:Train (Epoch 44): Loss/seq after 02350 batchs: 906.3543090820312
INFO:root:Train (Epoch 44): Loss/seq after 02400 batchs: 906.1807861328125
INFO:root:Train (Epoch 44): Loss/seq after 02450 batchs: 899.5689697265625
INFO:root:Train (Epoch 44): Loss/seq after 02500 batchs: 885.3841552734375
INFO:root:Train (Epoch 44): Loss/seq after 02550 batchs: 877.4597778320312
INFO:root:Train (Epoch 44): Loss/seq after 02600 batchs: 875.3702392578125
INFO:root:Train (Epoch 44): Loss/seq after 02650 batchs: 872.4976196289062
INFO:root:Train (Epoch 44): Loss/seq after 02700 batchs: 869.9334716796875
INFO:root:Train (Epoch 44): Loss/seq after 02750 batchs: 880.3694458007812
INFO:root:Train (Epoch 44): Loss/seq after 02800 batchs: 883.4082641601562
INFO:root:Train (Epoch 44): Loss/seq after 02850 batchs: 882.8738403320312
INFO:root:Train (Epoch 44): Loss/seq after 02900 batchs: 883.3960571289062
INFO:root:Train (Epoch 44): Loss/seq after 02950 batchs: 880.037353515625
INFO:root:Train (Epoch 44): Loss/seq after 03000 batchs: 881.71337890625
INFO:root:Train (Epoch 44): Loss/seq after 03050 batchs: 885.2929077148438
INFO:root:Train (Epoch 44): Loss/seq after 03100 batchs: 895.3017578125
INFO:root:Train (Epoch 44): Loss/seq after 03150 batchs: 901.1679077148438
INFO:root:Train (Epoch 44): Loss/seq after 03200 batchs: 904.7418212890625
INFO:root:Train (Epoch 44): Loss/seq after 03250 batchs: 907.2706909179688
INFO:root:Train (Epoch 44): Loss/seq after 03300 batchs: 906.0671997070312
INFO:root:Train (Epoch 44): Loss/seq after 03350 batchs: 905.8849487304688
INFO:root:Train (Epoch 44): Loss/seq after 03400 batchs: 898.1182250976562
INFO:root:Train (Epoch 44): Loss/seq after 03450 batchs: 894.4931640625
INFO:root:Train (Epoch 44): Loss/seq after 03500 batchs: 895.1630859375
INFO:root:Train (Epoch 44): Loss/seq after 03550 batchs: 892.91796875
INFO:root:Train (Epoch 44): Loss/seq after 03600 batchs: 901.6679077148438
INFO:root:Train (Epoch 44): Loss/seq after 03650 batchs: 898.6552124023438
INFO:root:Train (Epoch 44): Loss/seq after 03700 batchs: 899.4863891601562
INFO:root:Train (Epoch 44): Loss/seq after 03750 batchs: 902.6123046875
INFO:root:Train (Epoch 44): Loss/seq after 03800 batchs: 897.549072265625
INFO:root:Train (Epoch 44): Loss/seq after 03850 batchs: 895.3806762695312
INFO:root:Train (Epoch 44): Loss/seq after 03900 batchs: 899.2326049804688
INFO:root:Train (Epoch 44): Loss/seq after 03950 batchs: 902.2750854492188
INFO:root:Train (Epoch 44): Loss/seq after 04000 batchs: 896.6290283203125
INFO:root:Train (Epoch 44): Loss/seq after 04050 batchs: 890.3424682617188
INFO:root:Train (Epoch 44): Loss/seq after 04100 batchs: 887.4193115234375
INFO:root:Train (Epoch 44): Loss/seq after 04150 batchs: 884.71533203125
INFO:root:Train (Epoch 44): Loss/seq after 04200 batchs: 882.2136840820312
INFO:root:Train (Epoch 44): Loss/seq after 04250 batchs: 879.290771484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 44): Loss/seq after 00000 batches: 575.111572265625
INFO:root:# Valid (Epoch 44): Loss/seq after 00050 batches: 761.87841796875
INFO:root:# Valid (Epoch 44): Loss/seq after 00100 batches: 929.8021850585938
INFO:root:# Valid (Epoch 44): Loss/seq after 00150 batches: 727.0502319335938
INFO:root:# Valid (Epoch 44): Loss/seq after 00200 batches: 686.0130615234375
INFO:root:Artifacts: Make stick videos for epoch 44
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_44_on_20220422_031137.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_44_index_548_on_20220422_031137.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 45): Loss/seq after 00000 batchs: 1330.64306640625
INFO:root:Train (Epoch 45): Loss/seq after 00050 batchs: 1123.6624755859375
INFO:root:Train (Epoch 45): Loss/seq after 00100 batchs: 1180.960205078125
INFO:root:Train (Epoch 45): Loss/seq after 00150 batchs: 1099.2952880859375
INFO:root:Train (Epoch 45): Loss/seq after 00200 batchs: 1200.2406005859375
INFO:root:Train (Epoch 45): Loss/seq after 00250 batchs: 1321.5247802734375
INFO:root:Train (Epoch 45): Loss/seq after 00300 batchs: 1268.9056396484375
INFO:root:Train (Epoch 45): Loss/seq after 00350 batchs: 1180.717041015625
INFO:root:Train (Epoch 45): Loss/seq after 00400 batchs: 1210.84130859375
INFO:root:Train (Epoch 45): Loss/seq after 00450 batchs: 1166.2509765625
INFO:root:Train (Epoch 45): Loss/seq after 00500 batchs: 1170.9549560546875
INFO:root:Train (Epoch 45): Loss/seq after 00550 batchs: 1127.4788818359375
INFO:root:Train (Epoch 45): Loss/seq after 00600 batchs: 1086.296630859375
INFO:root:Train (Epoch 45): Loss/seq after 00650 batchs: 1068.340087890625
INFO:root:Train (Epoch 45): Loss/seq after 00700 batchs: 1029.817138671875
INFO:root:Train (Epoch 45): Loss/seq after 00750 batchs: 1050.7939453125
INFO:root:Train (Epoch 45): Loss/seq after 00800 batchs: 1051.2144775390625
INFO:root:Train (Epoch 45): Loss/seq after 00850 batchs: 1024.8955078125
INFO:root:Train (Epoch 45): Loss/seq after 00900 batchs: 1010.0543212890625
INFO:root:Train (Epoch 45): Loss/seq after 00950 batchs: 1021.2486572265625
INFO:root:Train (Epoch 45): Loss/seq after 01000 batchs: 1011.6054077148438
INFO:root:Train (Epoch 45): Loss/seq after 01050 batchs: 992.4752807617188
INFO:root:Train (Epoch 45): Loss/seq after 01100 batchs: 979.97607421875
INFO:root:Train (Epoch 45): Loss/seq after 01150 batchs: 954.7022705078125
INFO:root:Train (Epoch 45): Loss/seq after 01200 batchs: 956.7218017578125
INFO:root:Train (Epoch 45): Loss/seq after 01250 batchs: 952.882080078125
INFO:root:Train (Epoch 45): Loss/seq after 01300 batchs: 941.64794921875
INFO:root:Train (Epoch 45): Loss/seq after 01350 batchs: 929.415771484375
INFO:root:Train (Epoch 45): Loss/seq after 01400 batchs: 940.2911376953125
INFO:root:Train (Epoch 45): Loss/seq after 01450 batchs: 939.35595703125
INFO:root:Train (Epoch 45): Loss/seq after 01500 batchs: 940.0764770507812
INFO:root:Train (Epoch 45): Loss/seq after 01550 batchs: 946.8828735351562
INFO:root:Train (Epoch 45): Loss/seq after 01600 batchs: 938.4906005859375
INFO:root:Train (Epoch 45): Loss/seq after 01650 batchs: 936.9049682617188
INFO:root:Train (Epoch 45): Loss/seq after 01700 batchs: 933.8477783203125
INFO:root:Train (Epoch 45): Loss/seq after 01750 batchs: 927.6264038085938
INFO:root:Train (Epoch 45): Loss/seq after 01800 batchs: 920.5709228515625
INFO:root:Train (Epoch 45): Loss/seq after 01850 batchs: 912.7694091796875
INFO:root:Train (Epoch 45): Loss/seq after 01900 batchs: 916.6320190429688
INFO:root:Train (Epoch 45): Loss/seq after 01950 batchs: 914.41650390625
INFO:root:Train (Epoch 45): Loss/seq after 02000 batchs: 910.4697265625
INFO:root:Train (Epoch 45): Loss/seq after 02050 batchs: 907.580810546875
INFO:root:Train (Epoch 45): Loss/seq after 02100 batchs: 900.8157348632812
INFO:root:Train (Epoch 45): Loss/seq after 02150 batchs: 896.2130126953125
INFO:root:Train (Epoch 45): Loss/seq after 02200 batchs: 889.866943359375
INFO:root:Train (Epoch 45): Loss/seq after 02250 batchs: 893.4948120117188
INFO:root:Train (Epoch 45): Loss/seq after 02300 batchs: 895.5571899414062
INFO:root:Train (Epoch 45): Loss/seq after 02350 batchs: 890.2529907226562
INFO:root:Train (Epoch 45): Loss/seq after 02400 batchs: 889.5260620117188
INFO:root:Train (Epoch 45): Loss/seq after 02450 batchs: 882.7183837890625
INFO:root:Train (Epoch 45): Loss/seq after 02500 batchs: 868.7518920898438
INFO:root:Train (Epoch 45): Loss/seq after 02550 batchs: 860.072509765625
INFO:root:Train (Epoch 45): Loss/seq after 02600 batchs: 856.8451538085938
INFO:root:Train (Epoch 45): Loss/seq after 02650 batchs: 853.2177734375
INFO:root:Train (Epoch 45): Loss/seq after 02700 batchs: 850.4330444335938
INFO:root:Train (Epoch 45): Loss/seq after 02750 batchs: 858.2233276367188
INFO:root:Train (Epoch 45): Loss/seq after 02800 batchs: 862.1841430664062
INFO:root:Train (Epoch 45): Loss/seq after 02850 batchs: 861.5733032226562
INFO:root:Train (Epoch 45): Loss/seq after 02900 batchs: 862.6025390625
INFO:root:Train (Epoch 45): Loss/seq after 02950 batchs: 859.4502563476562
INFO:root:Train (Epoch 45): Loss/seq after 03000 batchs: 861.3948974609375
INFO:root:Train (Epoch 45): Loss/seq after 03050 batchs: 864.400146484375
INFO:root:Train (Epoch 45): Loss/seq after 03100 batchs: 874.304931640625
INFO:root:Train (Epoch 45): Loss/seq after 03150 batchs: 882.6327514648438
INFO:root:Train (Epoch 45): Loss/seq after 03200 batchs: 886.544189453125
INFO:root:Train (Epoch 45): Loss/seq after 03250 batchs: 889.0524291992188
INFO:root:Train (Epoch 45): Loss/seq after 03300 batchs: 887.6849975585938
INFO:root:Train (Epoch 45): Loss/seq after 03350 batchs: 887.408935546875
INFO:root:Train (Epoch 45): Loss/seq after 03400 batchs: 879.7985229492188
INFO:root:Train (Epoch 45): Loss/seq after 03450 batchs: 875.9745483398438
INFO:root:Train (Epoch 45): Loss/seq after 03500 batchs: 876.5969848632812
INFO:root:Train (Epoch 45): Loss/seq after 03550 batchs: 874.7220458984375
INFO:root:Train (Epoch 45): Loss/seq after 03600 batchs: 883.5681762695312
INFO:root:Train (Epoch 45): Loss/seq after 03650 batchs: 880.560791015625
INFO:root:Train (Epoch 45): Loss/seq after 03700 batchs: 881.4572143554688
INFO:root:Train (Epoch 45): Loss/seq after 03750 batchs: 884.6770629882812
INFO:root:Train (Epoch 45): Loss/seq after 03800 batchs: 879.5650634765625
INFO:root:Train (Epoch 45): Loss/seq after 03850 batchs: 877.598876953125
INFO:root:Train (Epoch 45): Loss/seq after 03900 batchs: 881.333251953125
INFO:root:Train (Epoch 45): Loss/seq after 03950 batchs: 884.2816772460938
INFO:root:Train (Epoch 45): Loss/seq after 04000 batchs: 878.65673828125
INFO:root:Train (Epoch 45): Loss/seq after 04050 batchs: 872.4383544921875
INFO:root:Train (Epoch 45): Loss/seq after 04100 batchs: 869.97900390625
INFO:root:Train (Epoch 45): Loss/seq after 04150 batchs: 867.5302734375
INFO:root:Train (Epoch 45): Loss/seq after 04200 batchs: 865.1197509765625
INFO:root:Train (Epoch 45): Loss/seq after 04250 batchs: 862.1669921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 45): Loss/seq after 00000 batches: 598.4779663085938
INFO:root:# Valid (Epoch 45): Loss/seq after 00050 batches: 776.7970581054688
INFO:root:# Valid (Epoch 45): Loss/seq after 00100 batches: 975.2937622070312
INFO:root:# Valid (Epoch 45): Loss/seq after 00150 batches: 754.9823608398438
INFO:root:# Valid (Epoch 45): Loss/seq after 00200 batches: 706.1014404296875
INFO:root:Artifacts: Make stick videos for epoch 45
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_45_on_20220422_031646.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_45_index_1590_on_20220422_031646.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 46): Loss/seq after 00000 batchs: 1357.6329345703125
INFO:root:Train (Epoch 46): Loss/seq after 00050 batchs: 1120.21484375
INFO:root:Train (Epoch 46): Loss/seq after 00100 batchs: 1153.1871337890625
INFO:root:Train (Epoch 46): Loss/seq after 00150 batchs: 1066.8880615234375
INFO:root:Train (Epoch 46): Loss/seq after 00200 batchs: 1168.8604736328125
INFO:root:Train (Epoch 46): Loss/seq after 00250 batchs: 1293.15966796875
INFO:root:Train (Epoch 46): Loss/seq after 00300 batchs: 1244.1710205078125
INFO:root:Train (Epoch 46): Loss/seq after 00350 batchs: 1157.341064453125
INFO:root:Train (Epoch 46): Loss/seq after 00400 batchs: 1185.8543701171875
INFO:root:Train (Epoch 46): Loss/seq after 00450 batchs: 1142.4942626953125
INFO:root:Train (Epoch 46): Loss/seq after 00500 batchs: 1141.8941650390625
INFO:root:Train (Epoch 46): Loss/seq after 00550 batchs: 1101.7684326171875
INFO:root:Train (Epoch 46): Loss/seq after 00600 batchs: 1061.4039306640625
INFO:root:Train (Epoch 46): Loss/seq after 00650 batchs: 1043.3453369140625
INFO:root:Train (Epoch 46): Loss/seq after 00700 batchs: 1002.904296875
INFO:root:Train (Epoch 46): Loss/seq after 00750 batchs: 1025.771240234375
INFO:root:Train (Epoch 46): Loss/seq after 00800 batchs: 1026.68994140625
INFO:root:Train (Epoch 46): Loss/seq after 00850 batchs: 1001.4985961914062
INFO:root:Train (Epoch 46): Loss/seq after 00900 batchs: 983.4833984375
INFO:root:Train (Epoch 46): Loss/seq after 00950 batchs: 997.5842895507812
INFO:root:Train (Epoch 46): Loss/seq after 01000 batchs: 988.8621826171875
INFO:root:Train (Epoch 46): Loss/seq after 01050 batchs: 970.5001831054688
INFO:root:Train (Epoch 46): Loss/seq after 01100 batchs: 955.818359375
INFO:root:Train (Epoch 46): Loss/seq after 01150 batchs: 931.3214721679688
INFO:root:Train (Epoch 46): Loss/seq after 01200 batchs: 931.8479614257812
INFO:root:Train (Epoch 46): Loss/seq after 01250 batchs: 927.0833129882812
INFO:root:Train (Epoch 46): Loss/seq after 01300 batchs: 915.8714599609375
INFO:root:Train (Epoch 46): Loss/seq after 01350 batchs: 903.7679443359375
INFO:root:Train (Epoch 46): Loss/seq after 01400 batchs: 914.8784790039062
INFO:root:Train (Epoch 46): Loss/seq after 01450 batchs: 913.9207153320312
INFO:root:Train (Epoch 46): Loss/seq after 01500 batchs: 915.2403564453125
INFO:root:Train (Epoch 46): Loss/seq after 01550 batchs: 920.5367431640625
INFO:root:Train (Epoch 46): Loss/seq after 01600 batchs: 912.1141357421875
INFO:root:Train (Epoch 46): Loss/seq after 01650 batchs: 910.4243774414062
INFO:root:Train (Epoch 46): Loss/seq after 01700 batchs: 909.2650146484375
INFO:root:Train (Epoch 46): Loss/seq after 01750 batchs: 903.419677734375
INFO:root:Train (Epoch 46): Loss/seq after 01800 batchs: 896.6608276367188
INFO:root:Train (Epoch 46): Loss/seq after 01850 batchs: 889.3842163085938
INFO:root:Train (Epoch 46): Loss/seq after 01900 batchs: 893.2595825195312
INFO:root:Train (Epoch 46): Loss/seq after 01950 batchs: 891.36083984375
INFO:root:Train (Epoch 46): Loss/seq after 02000 batchs: 887.5364990234375
INFO:root:Train (Epoch 46): Loss/seq after 02050 batchs: 884.418701171875
INFO:root:Train (Epoch 46): Loss/seq after 02100 batchs: 878.2276000976562
INFO:root:Train (Epoch 46): Loss/seq after 02150 batchs: 873.6027221679688
INFO:root:Train (Epoch 46): Loss/seq after 02200 batchs: 867.6995849609375
INFO:root:Train (Epoch 46): Loss/seq after 02250 batchs: 870.8230590820312
INFO:root:Train (Epoch 46): Loss/seq after 02300 batchs: 871.921630859375
INFO:root:Train (Epoch 46): Loss/seq after 02350 batchs: 866.5178833007812
INFO:root:Train (Epoch 46): Loss/seq after 02400 batchs: 865.742431640625
INFO:root:Train (Epoch 46): Loss/seq after 02450 batchs: 858.4555053710938
INFO:root:Train (Epoch 46): Loss/seq after 02500 batchs: 844.9918212890625
INFO:root:Train (Epoch 46): Loss/seq after 02550 batchs: 836.3848266601562
INFO:root:Train (Epoch 46): Loss/seq after 02600 batchs: 833.4672241210938
INFO:root:Train (Epoch 46): Loss/seq after 02650 batchs: 829.8880615234375
INFO:root:Train (Epoch 46): Loss/seq after 02700 batchs: 827.1404418945312
INFO:root:Train (Epoch 46): Loss/seq after 02750 batchs: 834.6907958984375
INFO:root:Train (Epoch 46): Loss/seq after 02800 batchs: 837.9552001953125
INFO:root:Train (Epoch 46): Loss/seq after 02850 batchs: 837.4757080078125
INFO:root:Train (Epoch 46): Loss/seq after 02900 batchs: 838.1284790039062
INFO:root:Train (Epoch 46): Loss/seq after 02950 batchs: 835.1360473632812
INFO:root:Train (Epoch 46): Loss/seq after 03000 batchs: 837.2530517578125
INFO:root:Train (Epoch 46): Loss/seq after 03050 batchs: 840.50341796875
INFO:root:Train (Epoch 46): Loss/seq after 03100 batchs: 849.7141723632812
INFO:root:Train (Epoch 46): Loss/seq after 03150 batchs: 855.8828125
INFO:root:Train (Epoch 46): Loss/seq after 03200 batchs: 860.0504760742188
INFO:root:Train (Epoch 46): Loss/seq after 03250 batchs: 863.1183471679688
INFO:root:Train (Epoch 46): Loss/seq after 03300 batchs: 861.86181640625
INFO:root:Train (Epoch 46): Loss/seq after 03350 batchs: 861.3489379882812
INFO:root:Train (Epoch 46): Loss/seq after 03400 batchs: 853.9085693359375
INFO:root:Train (Epoch 46): Loss/seq after 03450 batchs: 850.06689453125
INFO:root:Train (Epoch 46): Loss/seq after 03500 batchs: 850.260009765625
INFO:root:Train (Epoch 46): Loss/seq after 03550 batchs: 847.6376953125
INFO:root:Train (Epoch 46): Loss/seq after 03600 batchs: 856.3571166992188
INFO:root:Train (Epoch 46): Loss/seq after 03650 batchs: 853.0507202148438
INFO:root:Train (Epoch 46): Loss/seq after 03700 batchs: 853.851806640625
INFO:root:Train (Epoch 46): Loss/seq after 03750 batchs: 857.4681396484375
INFO:root:Train (Epoch 46): Loss/seq after 03800 batchs: 852.55322265625
INFO:root:Train (Epoch 46): Loss/seq after 03850 batchs: 850.7303466796875
INFO:root:Train (Epoch 46): Loss/seq after 03900 batchs: 855.0873413085938
INFO:root:Train (Epoch 46): Loss/seq after 03950 batchs: 858.2045288085938
INFO:root:Train (Epoch 46): Loss/seq after 04000 batchs: 852.9354248046875
INFO:root:Train (Epoch 46): Loss/seq after 04050 batchs: 847.0780639648438
INFO:root:Train (Epoch 46): Loss/seq after 04100 batchs: 844.403564453125
INFO:root:Train (Epoch 46): Loss/seq after 04150 batchs: 842.1763916015625
INFO:root:Train (Epoch 46): Loss/seq after 04200 batchs: 839.9525146484375
INFO:root:Train (Epoch 46): Loss/seq after 04250 batchs: 837.4072265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 46): Loss/seq after 00000 batches: 560.0062866210938
INFO:root:# Valid (Epoch 46): Loss/seq after 00050 batches: 742.6334228515625
INFO:root:# Valid (Epoch 46): Loss/seq after 00100 batches: 903.9658203125
INFO:root:# Valid (Epoch 46): Loss/seq after 00150 batches: 709.14990234375
INFO:root:# Valid (Epoch 46): Loss/seq after 00200 batches: 673.0023193359375
INFO:root:Artifacts: Make stick videos for epoch 46
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_46_on_20220422_032137.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_46_index_24_on_20220422_032137.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 47): Loss/seq after 00000 batchs: 1339.688232421875
INFO:root:Train (Epoch 47): Loss/seq after 00050 batchs: 1115.5152587890625
INFO:root:Train (Epoch 47): Loss/seq after 00100 batchs: 1164.8572998046875
INFO:root:Train (Epoch 47): Loss/seq after 00150 batchs: 1073.07568359375
INFO:root:Train (Epoch 47): Loss/seq after 00200 batchs: 1182.6329345703125
INFO:root:Train (Epoch 47): Loss/seq after 00250 batchs: 1300.3050537109375
INFO:root:Train (Epoch 47): Loss/seq after 00300 batchs: 1249.9578857421875
INFO:root:Train (Epoch 47): Loss/seq after 00350 batchs: 1160.01025390625
INFO:root:Train (Epoch 47): Loss/seq after 00400 batchs: 1182.707275390625
INFO:root:Train (Epoch 47): Loss/seq after 00450 batchs: 1139.33740234375
INFO:root:Train (Epoch 47): Loss/seq after 00500 batchs: 1140.16455078125
INFO:root:Train (Epoch 47): Loss/seq after 00550 batchs: 1098.68212890625
INFO:root:Train (Epoch 47): Loss/seq after 00600 batchs: 1056.1878662109375
INFO:root:Train (Epoch 47): Loss/seq after 00650 batchs: 1035.7860107421875
INFO:root:Train (Epoch 47): Loss/seq after 00700 batchs: 996.9120483398438
INFO:root:Train (Epoch 47): Loss/seq after 00750 batchs: 1018.5282592773438
INFO:root:Train (Epoch 47): Loss/seq after 00800 batchs: 1020.1298217773438
INFO:root:Train (Epoch 47): Loss/seq after 00850 batchs: 994.8352661132812
INFO:root:Train (Epoch 47): Loss/seq after 00900 batchs: 978.4898071289062
INFO:root:Train (Epoch 47): Loss/seq after 00950 batchs: 995.9711303710938
INFO:root:Train (Epoch 47): Loss/seq after 01000 batchs: 991.8956909179688
INFO:root:Train (Epoch 47): Loss/seq after 01050 batchs: 974.97607421875
INFO:root:Train (Epoch 47): Loss/seq after 01100 batchs: 966.9024047851562
INFO:root:Train (Epoch 47): Loss/seq after 01150 batchs: 942.6658935546875
INFO:root:Train (Epoch 47): Loss/seq after 01200 batchs: 942.8215942382812
INFO:root:Train (Epoch 47): Loss/seq after 01250 batchs: 938.4491577148438
INFO:root:Train (Epoch 47): Loss/seq after 01300 batchs: 925.5687866210938
INFO:root:Train (Epoch 47): Loss/seq after 01350 batchs: 913.5411376953125
INFO:root:Train (Epoch 47): Loss/seq after 01400 batchs: 925.0213012695312
INFO:root:Train (Epoch 47): Loss/seq after 01450 batchs: 924.35888671875
INFO:root:Train (Epoch 47): Loss/seq after 01500 batchs: 925.1954956054688
INFO:root:Train (Epoch 47): Loss/seq after 01550 batchs: 931.1094360351562
INFO:root:Train (Epoch 47): Loss/seq after 01600 batchs: 922.0616455078125
INFO:root:Train (Epoch 47): Loss/seq after 01650 batchs: 919.6762084960938
INFO:root:Train (Epoch 47): Loss/seq after 01700 batchs: 917.351806640625
INFO:root:Train (Epoch 47): Loss/seq after 01750 batchs: 911.042724609375
INFO:root:Train (Epoch 47): Loss/seq after 01800 batchs: 904.361083984375
INFO:root:Train (Epoch 47): Loss/seq after 01850 batchs: 897.0175170898438
INFO:root:Train (Epoch 47): Loss/seq after 01900 batchs: 900.9496459960938
INFO:root:Train (Epoch 47): Loss/seq after 01950 batchs: 898.47607421875
INFO:root:Train (Epoch 47): Loss/seq after 02000 batchs: 894.166259765625
INFO:root:Train (Epoch 47): Loss/seq after 02050 batchs: 891.2177124023438
INFO:root:Train (Epoch 47): Loss/seq after 02100 batchs: 884.6012573242188
INFO:root:Train (Epoch 47): Loss/seq after 02150 batchs: 879.7178344726562
INFO:root:Train (Epoch 47): Loss/seq after 02200 batchs: 873.4707641601562
INFO:root:Train (Epoch 47): Loss/seq after 02250 batchs: 875.4514770507812
INFO:root:Train (Epoch 47): Loss/seq after 02300 batchs: 877.4007568359375
INFO:root:Train (Epoch 47): Loss/seq after 02350 batchs: 871.1862182617188
INFO:root:Train (Epoch 47): Loss/seq after 02400 batchs: 869.9879760742188
INFO:root:Train (Epoch 47): Loss/seq after 02450 batchs: 861.9811401367188
INFO:root:Train (Epoch 47): Loss/seq after 02500 batchs: 848.3631591796875
INFO:root:Train (Epoch 47): Loss/seq after 02550 batchs: 838.9480590820312
INFO:root:Train (Epoch 47): Loss/seq after 02600 batchs: 835.680908203125
INFO:root:Train (Epoch 47): Loss/seq after 02650 batchs: 832.0681762695312
INFO:root:Train (Epoch 47): Loss/seq after 02700 batchs: 829.8182373046875
INFO:root:Train (Epoch 47): Loss/seq after 02750 batchs: 836.5361938476562
INFO:root:Train (Epoch 47): Loss/seq after 02800 batchs: 839.8002319335938
INFO:root:Train (Epoch 47): Loss/seq after 02850 batchs: 839.5128784179688
INFO:root:Train (Epoch 47): Loss/seq after 02900 batchs: 840.9458618164062
INFO:root:Train (Epoch 47): Loss/seq after 02950 batchs: 837.925537109375
INFO:root:Train (Epoch 47): Loss/seq after 03000 batchs: 839.9933471679688
INFO:root:Train (Epoch 47): Loss/seq after 03050 batchs: 843.1881103515625
INFO:root:Train (Epoch 47): Loss/seq after 03100 batchs: 851.8634033203125
INFO:root:Train (Epoch 47): Loss/seq after 03150 batchs: 858.2222290039062
INFO:root:Train (Epoch 47): Loss/seq after 03200 batchs: 862.23876953125
INFO:root:Train (Epoch 47): Loss/seq after 03250 batchs: 865.2694091796875
INFO:root:Train (Epoch 47): Loss/seq after 03300 batchs: 864.9180297851562
INFO:root:Train (Epoch 47): Loss/seq after 03350 batchs: 865.2413940429688
INFO:root:Train (Epoch 47): Loss/seq after 03400 batchs: 857.6131591796875
INFO:root:Train (Epoch 47): Loss/seq after 03450 batchs: 853.63671875
INFO:root:Train (Epoch 47): Loss/seq after 03500 batchs: 854.3683471679688
INFO:root:Train (Epoch 47): Loss/seq after 03550 batchs: 852.0383911132812
INFO:root:Train (Epoch 47): Loss/seq after 03600 batchs: 860.785888671875
INFO:root:Train (Epoch 47): Loss/seq after 03650 batchs: 857.7689819335938
INFO:root:Train (Epoch 47): Loss/seq after 03700 batchs: 859.2620849609375
INFO:root:Train (Epoch 47): Loss/seq after 03750 batchs: 862.7071533203125
INFO:root:Train (Epoch 47): Loss/seq after 03800 batchs: 857.8361206054688
INFO:root:Train (Epoch 47): Loss/seq after 03850 batchs: 855.969970703125
INFO:root:Train (Epoch 47): Loss/seq after 03900 batchs: 859.622802734375
INFO:root:Train (Epoch 47): Loss/seq after 03950 batchs: 862.7666625976562
INFO:root:Train (Epoch 47): Loss/seq after 04000 batchs: 857.2730712890625
INFO:root:Train (Epoch 47): Loss/seq after 04050 batchs: 851.18896484375
INFO:root:Train (Epoch 47): Loss/seq after 04100 batchs: 848.66455078125
INFO:root:Train (Epoch 47): Loss/seq after 04150 batchs: 846.3157958984375
INFO:root:Train (Epoch 47): Loss/seq after 04200 batchs: 843.769287109375
INFO:root:Train (Epoch 47): Loss/seq after 04250 batchs: 840.9091186523438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 47): Loss/seq after 00000 batches: 562.3117065429688
INFO:root:# Valid (Epoch 47): Loss/seq after 00050 batches: 844.6282958984375
INFO:root:# Valid (Epoch 47): Loss/seq after 00100 batches: 958.9405517578125
INFO:root:# Valid (Epoch 47): Loss/seq after 00150 batches: 749.6429443359375
INFO:root:# Valid (Epoch 47): Loss/seq after 00200 batches: 705.2188110351562
INFO:root:Artifacts: Make stick videos for epoch 47
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_47_on_20220422_032630.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_47_index_1414_on_20220422_032630.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 48): Loss/seq after 00000 batchs: 1516.4454345703125
INFO:root:Train (Epoch 48): Loss/seq after 00050 batchs: 1111.2724609375
INFO:root:Train (Epoch 48): Loss/seq after 00100 batchs: 1155.09912109375
INFO:root:Train (Epoch 48): Loss/seq after 00150 batchs: 1069.26806640625
INFO:root:Train (Epoch 48): Loss/seq after 00200 batchs: 1174.605224609375
INFO:root:Train (Epoch 48): Loss/seq after 00250 batchs: 1290.90087890625
INFO:root:Train (Epoch 48): Loss/seq after 00300 batchs: 1242.5147705078125
INFO:root:Train (Epoch 48): Loss/seq after 00350 batchs: 1155.5179443359375
INFO:root:Train (Epoch 48): Loss/seq after 00400 batchs: 1179.031005859375
INFO:root:Train (Epoch 48): Loss/seq after 00450 batchs: 1136.1160888671875
INFO:root:Train (Epoch 48): Loss/seq after 00500 batchs: 1139.5333251953125
INFO:root:Train (Epoch 48): Loss/seq after 00550 batchs: 1096.2733154296875
INFO:root:Train (Epoch 48): Loss/seq after 00600 batchs: 1055.8636474609375
INFO:root:Train (Epoch 48): Loss/seq after 00650 batchs: 1035.0146484375
INFO:root:Train (Epoch 48): Loss/seq after 00700 batchs: 995.9967041015625
INFO:root:Train (Epoch 48): Loss/seq after 00750 batchs: 1015.7904052734375
INFO:root:Train (Epoch 48): Loss/seq after 00800 batchs: 1018.3062133789062
INFO:root:Train (Epoch 48): Loss/seq after 00850 batchs: 993.6976318359375
INFO:root:Train (Epoch 48): Loss/seq after 00900 batchs: 981.6319580078125
INFO:root:Train (Epoch 48): Loss/seq after 00950 batchs: 989.8826293945312
INFO:root:Train (Epoch 48): Loss/seq after 01000 batchs: 980.6751708984375
INFO:root:Train (Epoch 48): Loss/seq after 01050 batchs: 962.170166015625
INFO:root:Train (Epoch 48): Loss/seq after 01100 batchs: 949.5211181640625
INFO:root:Train (Epoch 48): Loss/seq after 01150 batchs: 924.5911254882812
INFO:root:Train (Epoch 48): Loss/seq after 01200 batchs: 926.41943359375
INFO:root:Train (Epoch 48): Loss/seq after 01250 batchs: 923.8136596679688
INFO:root:Train (Epoch 48): Loss/seq after 01300 batchs: 912.4827880859375
INFO:root:Train (Epoch 48): Loss/seq after 01350 batchs: 900.8060302734375
INFO:root:Train (Epoch 48): Loss/seq after 01400 batchs: 914.5498657226562
INFO:root:Train (Epoch 48): Loss/seq after 01450 batchs: 914.4558715820312
INFO:root:Train (Epoch 48): Loss/seq after 01500 batchs: 915.5438842773438
INFO:root:Train (Epoch 48): Loss/seq after 01550 batchs: 920.8365478515625
INFO:root:Train (Epoch 48): Loss/seq after 01600 batchs: 911.8742065429688
INFO:root:Train (Epoch 48): Loss/seq after 01650 batchs: 908.8042602539062
INFO:root:Train (Epoch 48): Loss/seq after 01700 batchs: 905.7998657226562
INFO:root:Train (Epoch 48): Loss/seq after 01750 batchs: 899.520751953125
INFO:root:Train (Epoch 48): Loss/seq after 01800 batchs: 892.4993286132812
INFO:root:Train (Epoch 48): Loss/seq after 01850 batchs: 885.2396850585938
INFO:root:Train (Epoch 48): Loss/seq after 01900 batchs: 888.8431396484375
INFO:root:Train (Epoch 48): Loss/seq after 01950 batchs: 886.54931640625
INFO:root:Train (Epoch 48): Loss/seq after 02000 batchs: 883.178466796875
INFO:root:Train (Epoch 48): Loss/seq after 02050 batchs: 880.4888916015625
INFO:root:Train (Epoch 48): Loss/seq after 02100 batchs: 874.1029663085938
INFO:root:Train (Epoch 48): Loss/seq after 02150 batchs: 869.309326171875
INFO:root:Train (Epoch 48): Loss/seq after 02200 batchs: 863.25244140625
INFO:root:Train (Epoch 48): Loss/seq after 02250 batchs: 865.9729614257812
INFO:root:Train (Epoch 48): Loss/seq after 02300 batchs: 866.8486328125
INFO:root:Train (Epoch 48): Loss/seq after 02350 batchs: 860.8473510742188
INFO:root:Train (Epoch 48): Loss/seq after 02400 batchs: 859.8485717773438
INFO:root:Train (Epoch 48): Loss/seq after 02450 batchs: 851.7272338867188
INFO:root:Train (Epoch 48): Loss/seq after 02500 batchs: 838.3587646484375
INFO:root:Train (Epoch 48): Loss/seq after 02550 batchs: 829.2531127929688
INFO:root:Train (Epoch 48): Loss/seq after 02600 batchs: 825.9432983398438
INFO:root:Train (Epoch 48): Loss/seq after 02650 batchs: 822.1897583007812
INFO:root:Train (Epoch 48): Loss/seq after 02700 batchs: 819.427490234375
INFO:root:Train (Epoch 48): Loss/seq after 02750 batchs: 826.6339721679688
INFO:root:Train (Epoch 48): Loss/seq after 02800 batchs: 828.9867553710938
INFO:root:Train (Epoch 48): Loss/seq after 02850 batchs: 828.2686157226562
INFO:root:Train (Epoch 48): Loss/seq after 02900 batchs: 829.169189453125
INFO:root:Train (Epoch 48): Loss/seq after 02950 batchs: 825.9930419921875
INFO:root:Train (Epoch 48): Loss/seq after 03000 batchs: 828.224365234375
INFO:root:Train (Epoch 48): Loss/seq after 03050 batchs: 831.7662353515625
INFO:root:Train (Epoch 48): Loss/seq after 03100 batchs: 841.0401000976562
INFO:root:Train (Epoch 48): Loss/seq after 03150 batchs: 847.069580078125
INFO:root:Train (Epoch 48): Loss/seq after 03200 batchs: 851.3045043945312
INFO:root:Train (Epoch 48): Loss/seq after 03250 batchs: 854.34326171875
INFO:root:Train (Epoch 48): Loss/seq after 03300 batchs: 854.2269287109375
INFO:root:Train (Epoch 48): Loss/seq after 03350 batchs: 854.05322265625
INFO:root:Train (Epoch 48): Loss/seq after 03400 batchs: 846.6285400390625
INFO:root:Train (Epoch 48): Loss/seq after 03450 batchs: 842.6774291992188
INFO:root:Train (Epoch 48): Loss/seq after 03500 batchs: 843.1539306640625
INFO:root:Train (Epoch 48): Loss/seq after 03550 batchs: 840.783935546875
INFO:root:Train (Epoch 48): Loss/seq after 03600 batchs: 849.4365234375
INFO:root:Train (Epoch 48): Loss/seq after 03650 batchs: 846.1430053710938
INFO:root:Train (Epoch 48): Loss/seq after 03700 batchs: 847.2762451171875
INFO:root:Train (Epoch 48): Loss/seq after 03750 batchs: 850.91845703125
INFO:root:Train (Epoch 48): Loss/seq after 03800 batchs: 846.1487426757812
INFO:root:Train (Epoch 48): Loss/seq after 03850 batchs: 844.3416748046875
INFO:root:Train (Epoch 48): Loss/seq after 03900 batchs: 847.832763671875
INFO:root:Train (Epoch 48): Loss/seq after 03950 batchs: 850.6826171875
INFO:root:Train (Epoch 48): Loss/seq after 04000 batchs: 845.2793579101562
INFO:root:Train (Epoch 48): Loss/seq after 04050 batchs: 839.3426513671875
INFO:root:Train (Epoch 48): Loss/seq after 04100 batchs: 836.7415771484375
INFO:root:Train (Epoch 48): Loss/seq after 04150 batchs: 834.4927978515625
INFO:root:Train (Epoch 48): Loss/seq after 04200 batchs: 831.9581909179688
INFO:root:Train (Epoch 48): Loss/seq after 04250 batchs: 829.2822265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 48): Loss/seq after 00000 batches: 591.2106323242188
INFO:root:# Valid (Epoch 48): Loss/seq after 00050 batches: 770.6439208984375
INFO:root:# Valid (Epoch 48): Loss/seq after 00100 batches: 938.1923828125
INFO:root:# Valid (Epoch 48): Loss/seq after 00150 batches: 733.9049072265625
INFO:root:# Valid (Epoch 48): Loss/seq after 00200 batches: 694.6329345703125
INFO:root:Artifacts: Make stick videos for epoch 48
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_48_on_20220422_033135.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_48_index_1739_on_20220422_033135.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 49): Loss/seq after 00000 batchs: 1354.310546875
INFO:root:Train (Epoch 49): Loss/seq after 00050 batchs: 1119.189208984375
INFO:root:Train (Epoch 49): Loss/seq after 00100 batchs: 1145.06884765625
INFO:root:Train (Epoch 49): Loss/seq after 00150 batchs: 1056.4373779296875
INFO:root:Train (Epoch 49): Loss/seq after 00200 batchs: 1151.8394775390625
INFO:root:Train (Epoch 49): Loss/seq after 00250 batchs: 1270.396728515625
INFO:root:Train (Epoch 49): Loss/seq after 00300 batchs: 1224.5623779296875
INFO:root:Train (Epoch 49): Loss/seq after 00350 batchs: 1139.380859375
INFO:root:Train (Epoch 49): Loss/seq after 00400 batchs: 1154.39892578125
INFO:root:Train (Epoch 49): Loss/seq after 00450 batchs: 1112.3768310546875
INFO:root:Train (Epoch 49): Loss/seq after 00500 batchs: 1107.620361328125
INFO:root:Train (Epoch 49): Loss/seq after 00550 batchs: 1067.857421875
INFO:root:Train (Epoch 49): Loss/seq after 00600 batchs: 1028.720458984375
INFO:root:Train (Epoch 49): Loss/seq after 00650 batchs: 1009.5479736328125
INFO:root:Train (Epoch 49): Loss/seq after 00700 batchs: 973.44580078125
INFO:root:Train (Epoch 49): Loss/seq after 00750 batchs: 993.6011352539062
INFO:root:Train (Epoch 49): Loss/seq after 00800 batchs: 995.6825561523438
INFO:root:Train (Epoch 49): Loss/seq after 00850 batchs: 971.7777709960938
INFO:root:Train (Epoch 49): Loss/seq after 00900 batchs: 954.6480712890625
INFO:root:Train (Epoch 49): Loss/seq after 00950 batchs: 960.7529907226562
INFO:root:Train (Epoch 49): Loss/seq after 01000 batchs: 951.9031372070312
INFO:root:Train (Epoch 49): Loss/seq after 01050 batchs: 932.8941040039062
INFO:root:Train (Epoch 49): Loss/seq after 01100 batchs: 917.5843505859375
INFO:root:Train (Epoch 49): Loss/seq after 01150 batchs: 894.1065673828125
INFO:root:Train (Epoch 49): Loss/seq after 01200 batchs: 895.6431884765625
INFO:root:Train (Epoch 49): Loss/seq after 01250 batchs: 892.53369140625
INFO:root:Train (Epoch 49): Loss/seq after 01300 batchs: 880.2706298828125
INFO:root:Train (Epoch 49): Loss/seq after 01350 batchs: 869.8967895507812
INFO:root:Train (Epoch 49): Loss/seq after 01400 batchs: 880.3410034179688
INFO:root:Train (Epoch 49): Loss/seq after 01450 batchs: 880.2803344726562
INFO:root:Train (Epoch 49): Loss/seq after 01500 batchs: 882.2949829101562
INFO:root:Train (Epoch 49): Loss/seq after 01550 batchs: 887.6334228515625
INFO:root:Train (Epoch 49): Loss/seq after 01600 batchs: 879.8233032226562
INFO:root:Train (Epoch 49): Loss/seq after 01650 batchs: 877.5071411132812
INFO:root:Train (Epoch 49): Loss/seq after 01700 batchs: 875.79443359375
INFO:root:Train (Epoch 49): Loss/seq after 01750 batchs: 870.6178588867188
INFO:root:Train (Epoch 49): Loss/seq after 01800 batchs: 864.8109130859375
INFO:root:Train (Epoch 49): Loss/seq after 01850 batchs: 858.530029296875
INFO:root:Train (Epoch 49): Loss/seq after 01900 batchs: 862.7521362304688
INFO:root:Train (Epoch 49): Loss/seq after 01950 batchs: 861.6177978515625
INFO:root:Train (Epoch 49): Loss/seq after 02000 batchs: 858.4267578125
INFO:root:Train (Epoch 49): Loss/seq after 02050 batchs: 856.4614868164062
INFO:root:Train (Epoch 49): Loss/seq after 02100 batchs: 850.7584228515625
INFO:root:Train (Epoch 49): Loss/seq after 02150 batchs: 846.6666870117188
INFO:root:Train (Epoch 49): Loss/seq after 02200 batchs: 841.2423095703125
INFO:root:Train (Epoch 49): Loss/seq after 02250 batchs: 842.6600952148438
INFO:root:Train (Epoch 49): Loss/seq after 02300 batchs: 843.1868896484375
INFO:root:Train (Epoch 49): Loss/seq after 02350 batchs: 837.6925048828125
INFO:root:Train (Epoch 49): Loss/seq after 02400 batchs: 837.08935546875
INFO:root:Train (Epoch 49): Loss/seq after 02450 batchs: 829.3460083007812
INFO:root:Train (Epoch 49): Loss/seq after 02500 batchs: 816.3759155273438
INFO:root:Train (Epoch 49): Loss/seq after 02550 batchs: 807.571044921875
INFO:root:Train (Epoch 49): Loss/seq after 02600 batchs: 804.918212890625
INFO:root:Train (Epoch 49): Loss/seq after 02650 batchs: 801.6900024414062
INFO:root:Train (Epoch 49): Loss/seq after 02700 batchs: 799.1185302734375
INFO:root:Train (Epoch 49): Loss/seq after 02750 batchs: 804.2503051757812
INFO:root:Train (Epoch 49): Loss/seq after 02800 batchs: 806.648681640625
INFO:root:Train (Epoch 49): Loss/seq after 02850 batchs: 806.0830688476562
INFO:root:Train (Epoch 49): Loss/seq after 02900 batchs: 807.3825073242188
INFO:root:Train (Epoch 49): Loss/seq after 02950 batchs: 804.8087158203125
INFO:root:Train (Epoch 49): Loss/seq after 03000 batchs: 807.459228515625
INFO:root:Train (Epoch 49): Loss/seq after 03050 batchs: 810.961669921875
INFO:root:Train (Epoch 49): Loss/seq after 03100 batchs: 819.3674926757812
INFO:root:Train (Epoch 49): Loss/seq after 03150 batchs: 826.1213989257812
INFO:root:Train (Epoch 49): Loss/seq after 03200 batchs: 830.3709106445312
INFO:root:Train (Epoch 49): Loss/seq after 03250 batchs: 833.7839965820312
INFO:root:Train (Epoch 49): Loss/seq after 03300 batchs: 834.5238647460938
INFO:root:Train (Epoch 49): Loss/seq after 03350 batchs: 834.8218994140625
INFO:root:Train (Epoch 49): Loss/seq after 03400 batchs: 827.661865234375
INFO:root:Train (Epoch 49): Loss/seq after 03450 batchs: 824.6250610351562
INFO:root:Train (Epoch 49): Loss/seq after 03500 batchs: 825.4890747070312
INFO:root:Train (Epoch 49): Loss/seq after 03550 batchs: 822.69140625
INFO:root:Train (Epoch 49): Loss/seq after 03600 batchs: 831.7880249023438
INFO:root:Train (Epoch 49): Loss/seq after 03650 batchs: 828.912841796875
INFO:root:Train (Epoch 49): Loss/seq after 03700 batchs: 829.841064453125
INFO:root:Train (Epoch 49): Loss/seq after 03750 batchs: 833.4746704101562
INFO:root:Train (Epoch 49): Loss/seq after 03800 batchs: 828.8160400390625
INFO:root:Train (Epoch 49): Loss/seq after 03850 batchs: 827.300537109375
INFO:root:Train (Epoch 49): Loss/seq after 03900 batchs: 830.717041015625
INFO:root:Train (Epoch 49): Loss/seq after 03950 batchs: 833.3175048828125
INFO:root:Train (Epoch 49): Loss/seq after 04000 batchs: 828.1827392578125
INFO:root:Train (Epoch 49): Loss/seq after 04050 batchs: 822.4117431640625
INFO:root:Train (Epoch 49): Loss/seq after 04100 batchs: 820.1202392578125
INFO:root:Train (Epoch 49): Loss/seq after 04150 batchs: 818.1119384765625
INFO:root:Train (Epoch 49): Loss/seq after 04200 batchs: 815.6627197265625
INFO:root:Train (Epoch 49): Loss/seq after 04250 batchs: 813.0132446289062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 49): Loss/seq after 00000 batches: 613.250732421875
INFO:root:# Valid (Epoch 49): Loss/seq after 00050 batches: 775.4190063476562
INFO:root:# Valid (Epoch 49): Loss/seq after 00100 batches: 921.0159301757812
INFO:root:# Valid (Epoch 49): Loss/seq after 00150 batches: 730.9364624023438
INFO:root:# Valid (Epoch 49): Loss/seq after 00200 batches: 692.913330078125
INFO:root:Artifacts: Make stick videos for epoch 49
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_49_on_20220422_033626.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_49_index_1851_on_20220422_033626.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 50): Loss/seq after 00000 batchs: 1347.84619140625
INFO:root:Train (Epoch 50): Loss/seq after 00050 batchs: 1093.2708740234375
INFO:root:Train (Epoch 50): Loss/seq after 00100 batchs: 1148.7542724609375
INFO:root:Train (Epoch 50): Loss/seq after 00150 batchs: 1059.3912353515625
INFO:root:Train (Epoch 50): Loss/seq after 00200 batchs: 1156.5556640625
INFO:root:Train (Epoch 50): Loss/seq after 00250 batchs: 1268.7977294921875
INFO:root:Train (Epoch 50): Loss/seq after 00300 batchs: 1222.3857421875
INFO:root:Train (Epoch 50): Loss/seq after 00350 batchs: 1133.759521484375
INFO:root:Train (Epoch 50): Loss/seq after 00400 batchs: 1147.80859375
INFO:root:Train (Epoch 50): Loss/seq after 00450 batchs: 1107.0438232421875
INFO:root:Train (Epoch 50): Loss/seq after 00500 batchs: 1107.8931884765625
INFO:root:Train (Epoch 50): Loss/seq after 00550 batchs: 1066.6964111328125
INFO:root:Train (Epoch 50): Loss/seq after 00600 batchs: 1027.3387451171875
INFO:root:Train (Epoch 50): Loss/seq after 00650 batchs: 1007.5174560546875
INFO:root:Train (Epoch 50): Loss/seq after 00700 batchs: 970.0006713867188
INFO:root:Train (Epoch 50): Loss/seq after 00750 batchs: 993.337158203125
INFO:root:Train (Epoch 50): Loss/seq after 00800 batchs: 995.521728515625
INFO:root:Train (Epoch 50): Loss/seq after 00850 batchs: 971.7233276367188
INFO:root:Train (Epoch 50): Loss/seq after 00900 batchs: 953.5969848632812
INFO:root:Train (Epoch 50): Loss/seq after 00950 batchs: 957.670166015625
INFO:root:Train (Epoch 50): Loss/seq after 01000 batchs: 948.5200805664062
INFO:root:Train (Epoch 50): Loss/seq after 01050 batchs: 935.9657592773438
INFO:root:Train (Epoch 50): Loss/seq after 01100 batchs: 924.3681030273438
INFO:root:Train (Epoch 50): Loss/seq after 01150 batchs: 900.6557006835938
INFO:root:Train (Epoch 50): Loss/seq after 01200 batchs: 902.6477661132812
INFO:root:Train (Epoch 50): Loss/seq after 01250 batchs: 899.9564208984375
INFO:root:Train (Epoch 50): Loss/seq after 01300 batchs: 888.346435546875
INFO:root:Train (Epoch 50): Loss/seq after 01350 batchs: 877.567626953125
INFO:root:Train (Epoch 50): Loss/seq after 01400 batchs: 888.7412719726562
INFO:root:Train (Epoch 50): Loss/seq after 01450 batchs: 888.45703125
INFO:root:Train (Epoch 50): Loss/seq after 01500 batchs: 889.9575805664062
INFO:root:Train (Epoch 50): Loss/seq after 01550 batchs: 895.1200561523438
INFO:root:Train (Epoch 50): Loss/seq after 01600 batchs: 886.7603149414062
INFO:root:Train (Epoch 50): Loss/seq after 01650 batchs: 885.1207885742188
INFO:root:Train (Epoch 50): Loss/seq after 01700 batchs: 882.5773315429688
INFO:root:Train (Epoch 50): Loss/seq after 01750 batchs: 877.1455078125
INFO:root:Train (Epoch 50): Loss/seq after 01800 batchs: 870.9385986328125
INFO:root:Train (Epoch 50): Loss/seq after 01850 batchs: 864.3162231445312
INFO:root:Train (Epoch 50): Loss/seq after 01900 batchs: 867.919921875
INFO:root:Train (Epoch 50): Loss/seq after 01950 batchs: 866.1329345703125
INFO:root:Train (Epoch 50): Loss/seq after 02000 batchs: 862.5696411132812
INFO:root:Train (Epoch 50): Loss/seq after 02050 batchs: 860.18408203125
INFO:root:Train (Epoch 50): Loss/seq after 02100 batchs: 854.1814575195312
INFO:root:Train (Epoch 50): Loss/seq after 02150 batchs: 849.7615356445312
INFO:root:Train (Epoch 50): Loss/seq after 02200 batchs: 844.1526489257812
INFO:root:Train (Epoch 50): Loss/seq after 02250 batchs: 846.357666015625
INFO:root:Train (Epoch 50): Loss/seq after 02300 batchs: 845.7544555664062
INFO:root:Train (Epoch 50): Loss/seq after 02350 batchs: 839.5477905273438
INFO:root:Train (Epoch 50): Loss/seq after 02400 batchs: 838.4945068359375
INFO:root:Train (Epoch 50): Loss/seq after 02450 batchs: 830.6213989257812
INFO:root:Train (Epoch 50): Loss/seq after 02500 batchs: 817.5805053710938
INFO:root:Train (Epoch 50): Loss/seq after 02550 batchs: 808.7396240234375
INFO:root:Train (Epoch 50): Loss/seq after 02600 batchs: 806.017822265625
INFO:root:Train (Epoch 50): Loss/seq after 02650 batchs: 802.9931030273438
INFO:root:Train (Epoch 50): Loss/seq after 02700 batchs: 800.643798828125
INFO:root:Train (Epoch 50): Loss/seq after 02750 batchs: 806.798095703125
INFO:root:Train (Epoch 50): Loss/seq after 02800 batchs: 810.3053588867188
INFO:root:Train (Epoch 50): Loss/seq after 02850 batchs: 811.010009765625
INFO:root:Train (Epoch 50): Loss/seq after 02900 batchs: 812.4645385742188
INFO:root:Train (Epoch 50): Loss/seq after 02950 batchs: 810.114013671875
INFO:root:Train (Epoch 50): Loss/seq after 03000 batchs: 812.73828125
INFO:root:Train (Epoch 50): Loss/seq after 03050 batchs: 816.23681640625
INFO:root:Train (Epoch 50): Loss/seq after 03100 batchs: 824.074462890625
INFO:root:Train (Epoch 50): Loss/seq after 03150 batchs: 829.782958984375
INFO:root:Train (Epoch 50): Loss/seq after 03200 batchs: 833.9734497070312
INFO:root:Train (Epoch 50): Loss/seq after 03250 batchs: 837.2572631835938
INFO:root:Train (Epoch 50): Loss/seq after 03300 batchs: 836.1948852539062
INFO:root:Train (Epoch 50): Loss/seq after 03350 batchs: 836.166748046875
INFO:root:Train (Epoch 50): Loss/seq after 03400 batchs: 828.8963012695312
INFO:root:Train (Epoch 50): Loss/seq after 03450 batchs: 825.1915283203125
INFO:root:Train (Epoch 50): Loss/seq after 03500 batchs: 825.53076171875
INFO:root:Train (Epoch 50): Loss/seq after 03550 batchs: 822.8486938476562
INFO:root:Train (Epoch 50): Loss/seq after 03600 batchs: 831.8037719726562
INFO:root:Train (Epoch 50): Loss/seq after 03650 batchs: 828.7205200195312
INFO:root:Train (Epoch 50): Loss/seq after 03700 batchs: 829.8782348632812
INFO:root:Train (Epoch 50): Loss/seq after 03750 batchs: 833.5152587890625
INFO:root:Train (Epoch 50): Loss/seq after 03800 batchs: 828.7959594726562
INFO:root:Train (Epoch 50): Loss/seq after 03850 batchs: 827.191650390625
INFO:root:Train (Epoch 50): Loss/seq after 03900 batchs: 830.25927734375
INFO:root:Train (Epoch 50): Loss/seq after 03950 batchs: 832.9225463867188
INFO:root:Train (Epoch 50): Loss/seq after 04000 batchs: 827.7640991210938
INFO:root:Train (Epoch 50): Loss/seq after 04050 batchs: 821.9696044921875
INFO:root:Train (Epoch 50): Loss/seq after 04100 batchs: 819.5093994140625
INFO:root:Train (Epoch 50): Loss/seq after 04150 batchs: 817.4025268554688
INFO:root:Train (Epoch 50): Loss/seq after 04200 batchs: 814.9669799804688
INFO:root:Train (Epoch 50): Loss/seq after 04250 batchs: 812.3798217773438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 50): Loss/seq after 00000 batches: 588.6983642578125
INFO:root:# Valid (Epoch 50): Loss/seq after 00050 batches: 830.283447265625
INFO:root:# Valid (Epoch 50): Loss/seq after 00100 batches: 985.9622192382812
INFO:root:# Valid (Epoch 50): Loss/seq after 00150 batches: 766.75341796875
INFO:root:# Valid (Epoch 50): Loss/seq after 00200 batches: 716.0731201171875
INFO:root:Artifacts: Make stick videos for epoch 50
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_50_on_20220422_034110.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_50_index_1619_on_20220422_034110.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 51): Loss/seq after 00000 batchs: 1456.546630859375
INFO:root:Train (Epoch 51): Loss/seq after 00050 batchs: 1126.6138916015625
INFO:root:Train (Epoch 51): Loss/seq after 00100 batchs: 1134.564697265625
INFO:root:Train (Epoch 51): Loss/seq after 00150 batchs: 1046.1080322265625
INFO:root:Train (Epoch 51): Loss/seq after 00200 batchs: 1138.407958984375
INFO:root:Train (Epoch 51): Loss/seq after 00250 batchs: 1252.8631591796875
INFO:root:Train (Epoch 51): Loss/seq after 00300 batchs: 1207.9986572265625
INFO:root:Train (Epoch 51): Loss/seq after 00350 batchs: 1123.074951171875
INFO:root:Train (Epoch 51): Loss/seq after 00400 batchs: 1136.6595458984375
INFO:root:Train (Epoch 51): Loss/seq after 00450 batchs: 1096.41357421875
INFO:root:Train (Epoch 51): Loss/seq after 00500 batchs: 1089.4957275390625
INFO:root:Train (Epoch 51): Loss/seq after 00550 batchs: 1050.4466552734375
INFO:root:Train (Epoch 51): Loss/seq after 00600 batchs: 1011.2239990234375
INFO:root:Train (Epoch 51): Loss/seq after 00650 batchs: 992.8505249023438
INFO:root:Train (Epoch 51): Loss/seq after 00700 batchs: 957.2146606445312
INFO:root:Train (Epoch 51): Loss/seq after 00750 batchs: 975.3839721679688
INFO:root:Train (Epoch 51): Loss/seq after 00800 batchs: 976.9343872070312
INFO:root:Train (Epoch 51): Loss/seq after 00850 batchs: 953.033447265625
INFO:root:Train (Epoch 51): Loss/seq after 00900 batchs: 934.0930786132812
INFO:root:Train (Epoch 51): Loss/seq after 00950 batchs: 936.8245239257812
INFO:root:Train (Epoch 51): Loss/seq after 01000 batchs: 927.6646118164062
INFO:root:Train (Epoch 51): Loss/seq after 01050 batchs: 910.324462890625
INFO:root:Train (Epoch 51): Loss/seq after 01100 batchs: 898.6776733398438
INFO:root:Train (Epoch 51): Loss/seq after 01150 batchs: 875.7434692382812
INFO:root:Train (Epoch 51): Loss/seq after 01200 batchs: 877.1660766601562
INFO:root:Train (Epoch 51): Loss/seq after 01250 batchs: 873.8742065429688
INFO:root:Train (Epoch 51): Loss/seq after 01300 batchs: 861.9954833984375
INFO:root:Train (Epoch 51): Loss/seq after 01350 batchs: 851.0307006835938
INFO:root:Train (Epoch 51): Loss/seq after 01400 batchs: 862.0385131835938
INFO:root:Train (Epoch 51): Loss/seq after 01450 batchs: 861.5364379882812
INFO:root:Train (Epoch 51): Loss/seq after 01500 batchs: 863.8718872070312
INFO:root:Train (Epoch 51): Loss/seq after 01550 batchs: 869.3350830078125
INFO:root:Train (Epoch 51): Loss/seq after 01600 batchs: 861.5336303710938
INFO:root:Train (Epoch 51): Loss/seq after 01650 batchs: 859.8635864257812
INFO:root:Train (Epoch 51): Loss/seq after 01700 batchs: 858.2314453125
INFO:root:Train (Epoch 51): Loss/seq after 01750 batchs: 853.2293090820312
INFO:root:Train (Epoch 51): Loss/seq after 01800 batchs: 847.3518676757812
INFO:root:Train (Epoch 51): Loss/seq after 01850 batchs: 841.0758666992188
INFO:root:Train (Epoch 51): Loss/seq after 01900 batchs: 845.1970825195312
INFO:root:Train (Epoch 51): Loss/seq after 01950 batchs: 844.7266235351562
INFO:root:Train (Epoch 51): Loss/seq after 02000 batchs: 841.375732421875
INFO:root:Train (Epoch 51): Loss/seq after 02050 batchs: 838.7154541015625
INFO:root:Train (Epoch 51): Loss/seq after 02100 batchs: 833.225830078125
INFO:root:Train (Epoch 51): Loss/seq after 02150 batchs: 829.4163818359375
INFO:root:Train (Epoch 51): Loss/seq after 02200 batchs: 824.3588256835938
INFO:root:Train (Epoch 51): Loss/seq after 02250 batchs: 825.787841796875
INFO:root:Train (Epoch 51): Loss/seq after 02300 batchs: 825.7572631835938
INFO:root:Train (Epoch 51): Loss/seq after 02350 batchs: 819.9931030273438
INFO:root:Train (Epoch 51): Loss/seq after 02400 batchs: 819.0886840820312
INFO:root:Train (Epoch 51): Loss/seq after 02450 batchs: 811.51904296875
INFO:root:Train (Epoch 51): Loss/seq after 02500 batchs: 798.8780517578125
INFO:root:Train (Epoch 51): Loss/seq after 02550 batchs: 790.0836791992188
INFO:root:Train (Epoch 51): Loss/seq after 02600 batchs: 787.8781127929688
INFO:root:Train (Epoch 51): Loss/seq after 02650 batchs: 784.9368896484375
INFO:root:Train (Epoch 51): Loss/seq after 02700 batchs: 782.5762939453125
INFO:root:Train (Epoch 51): Loss/seq after 02750 batchs: 787.7786254882812
INFO:root:Train (Epoch 51): Loss/seq after 02800 batchs: 790.4952392578125
INFO:root:Train (Epoch 51): Loss/seq after 02850 batchs: 790.2206420898438
INFO:root:Train (Epoch 51): Loss/seq after 02900 batchs: 792.17333984375
INFO:root:Train (Epoch 51): Loss/seq after 02950 batchs: 790.2969970703125
INFO:root:Train (Epoch 51): Loss/seq after 03000 batchs: 793.1170654296875
INFO:root:Train (Epoch 51): Loss/seq after 03050 batchs: 796.9683837890625
INFO:root:Train (Epoch 51): Loss/seq after 03100 batchs: 805.029541015625
INFO:root:Train (Epoch 51): Loss/seq after 03150 batchs: 812.2533569335938
INFO:root:Train (Epoch 51): Loss/seq after 03200 batchs: 816.4566650390625
INFO:root:Train (Epoch 51): Loss/seq after 03250 batchs: 819.9010620117188
INFO:root:Train (Epoch 51): Loss/seq after 03300 batchs: 818.3629150390625
INFO:root:Train (Epoch 51): Loss/seq after 03350 batchs: 818.1017456054688
INFO:root:Train (Epoch 51): Loss/seq after 03400 batchs: 811.0423583984375
INFO:root:Train (Epoch 51): Loss/seq after 03450 batchs: 807.5359497070312
INFO:root:Train (Epoch 51): Loss/seq after 03500 batchs: 807.9310913085938
INFO:root:Train (Epoch 51): Loss/seq after 03550 batchs: 804.9691162109375
INFO:root:Train (Epoch 51): Loss/seq after 03600 batchs: 813.9205322265625
INFO:root:Train (Epoch 51): Loss/seq after 03650 batchs: 810.587158203125
INFO:root:Train (Epoch 51): Loss/seq after 03700 batchs: 811.6563720703125
INFO:root:Train (Epoch 51): Loss/seq after 03750 batchs: 815.4385986328125
INFO:root:Train (Epoch 51): Loss/seq after 03800 batchs: 810.8963012695312
INFO:root:Train (Epoch 51): Loss/seq after 03850 batchs: 809.4122924804688
INFO:root:Train (Epoch 51): Loss/seq after 03900 batchs: 812.5244140625
INFO:root:Train (Epoch 51): Loss/seq after 03950 batchs: 815.15576171875
INFO:root:Train (Epoch 51): Loss/seq after 04000 batchs: 810.1826171875
INFO:root:Train (Epoch 51): Loss/seq after 04050 batchs: 804.5393676757812
INFO:root:Train (Epoch 51): Loss/seq after 04100 batchs: 801.9338989257812
INFO:root:Train (Epoch 51): Loss/seq after 04150 batchs: 800.1683959960938
INFO:root:Train (Epoch 51): Loss/seq after 04200 batchs: 797.9900512695312
INFO:root:Train (Epoch 51): Loss/seq after 04250 batchs: 795.5062255859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 51): Loss/seq after 00000 batches: 612.6964111328125
INFO:root:# Valid (Epoch 51): Loss/seq after 00050 batches: 789.4412231445312
INFO:root:# Valid (Epoch 51): Loss/seq after 00100 batches: 920.7274169921875
INFO:root:# Valid (Epoch 51): Loss/seq after 00150 batches: 724.1969604492188
INFO:root:# Valid (Epoch 51): Loss/seq after 00200 batches: 690.2262573242188
INFO:root:Artifacts: Make stick videos for epoch 51
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_51_on_20220422_034608.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_51_index_1266_on_20220422_034608.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 52): Loss/seq after 00000 batchs: 1404.1578369140625
INFO:root:Train (Epoch 52): Loss/seq after 00050 batchs: 1080.423095703125
INFO:root:Train (Epoch 52): Loss/seq after 00100 batchs: 1117.718994140625
INFO:root:Train (Epoch 52): Loss/seq after 00150 batchs: 1018.7437744140625
INFO:root:Train (Epoch 52): Loss/seq after 00200 batchs: 1115.9642333984375
INFO:root:Train (Epoch 52): Loss/seq after 00250 batchs: 1233.5238037109375
INFO:root:Train (Epoch 52): Loss/seq after 00300 batchs: 1191.887939453125
INFO:root:Train (Epoch 52): Loss/seq after 00350 batchs: 1107.3953857421875
INFO:root:Train (Epoch 52): Loss/seq after 00400 batchs: 1125.7371826171875
INFO:root:Train (Epoch 52): Loss/seq after 00450 batchs: 1086.1080322265625
INFO:root:Train (Epoch 52): Loss/seq after 00500 batchs: 1086.01025390625
INFO:root:Train (Epoch 52): Loss/seq after 00550 batchs: 1047.9730224609375
INFO:root:Train (Epoch 52): Loss/seq after 00600 batchs: 1010.8809204101562
INFO:root:Train (Epoch 52): Loss/seq after 00650 batchs: 990.4431762695312
INFO:root:Train (Epoch 52): Loss/seq after 00700 batchs: 953.75244140625
INFO:root:Train (Epoch 52): Loss/seq after 00750 batchs: 973.439697265625
INFO:root:Train (Epoch 52): Loss/seq after 00800 batchs: 977.3956298828125
INFO:root:Train (Epoch 52): Loss/seq after 00850 batchs: 955.40478515625
INFO:root:Train (Epoch 52): Loss/seq after 00900 batchs: 935.9384155273438
INFO:root:Train (Epoch 52): Loss/seq after 00950 batchs: 942.9951782226562
INFO:root:Train (Epoch 52): Loss/seq after 01000 batchs: 933.8980712890625
INFO:root:Train (Epoch 52): Loss/seq after 01050 batchs: 916.9740600585938
INFO:root:Train (Epoch 52): Loss/seq after 01100 batchs: 905.1846923828125
INFO:root:Train (Epoch 52): Loss/seq after 01150 batchs: 882.0208740234375
INFO:root:Train (Epoch 52): Loss/seq after 01200 batchs: 884.4307861328125
INFO:root:Train (Epoch 52): Loss/seq after 01250 batchs: 880.4287719726562
INFO:root:Train (Epoch 52): Loss/seq after 01300 batchs: 866.4461059570312
INFO:root:Train (Epoch 52): Loss/seq after 01350 batchs: 853.855712890625
INFO:root:Train (Epoch 52): Loss/seq after 01400 batchs: 864.1935424804688
INFO:root:Train (Epoch 52): Loss/seq after 01450 batchs: 864.5824584960938
INFO:root:Train (Epoch 52): Loss/seq after 01500 batchs: 866.92529296875
INFO:root:Train (Epoch 52): Loss/seq after 01550 batchs: 871.1519775390625
INFO:root:Train (Epoch 52): Loss/seq after 01600 batchs: 863.5001831054688
INFO:root:Train (Epoch 52): Loss/seq after 01650 batchs: 861.2177734375
INFO:root:Train (Epoch 52): Loss/seq after 01700 batchs: 859.36474609375
INFO:root:Train (Epoch 52): Loss/seq after 01750 batchs: 854.3348999023438
INFO:root:Train (Epoch 52): Loss/seq after 01800 batchs: 848.6411743164062
INFO:root:Train (Epoch 52): Loss/seq after 01850 batchs: 842.3641967773438
INFO:root:Train (Epoch 52): Loss/seq after 01900 batchs: 846.303466796875
INFO:root:Train (Epoch 52): Loss/seq after 01950 batchs: 844.745361328125
INFO:root:Train (Epoch 52): Loss/seq after 02000 batchs: 841.512451171875
INFO:root:Train (Epoch 52): Loss/seq after 02050 batchs: 839.7080078125
INFO:root:Train (Epoch 52): Loss/seq after 02100 batchs: 834.0824584960938
INFO:root:Train (Epoch 52): Loss/seq after 02150 batchs: 830.1903076171875
INFO:root:Train (Epoch 52): Loss/seq after 02200 batchs: 824.8013305664062
INFO:root:Train (Epoch 52): Loss/seq after 02250 batchs: 828.0645751953125
INFO:root:Train (Epoch 52): Loss/seq after 02300 batchs: 828.07177734375
INFO:root:Train (Epoch 52): Loss/seq after 02350 batchs: 822.8704223632812
INFO:root:Train (Epoch 52): Loss/seq after 02400 batchs: 822.3692016601562
INFO:root:Train (Epoch 52): Loss/seq after 02450 batchs: 814.8516235351562
INFO:root:Train (Epoch 52): Loss/seq after 02500 batchs: 802.1318969726562
INFO:root:Train (Epoch 52): Loss/seq after 02550 batchs: 793.2200317382812
INFO:root:Train (Epoch 52): Loss/seq after 02600 batchs: 790.427490234375
INFO:root:Train (Epoch 52): Loss/seq after 02650 batchs: 787.07666015625
INFO:root:Train (Epoch 52): Loss/seq after 02700 batchs: 784.5633544921875
INFO:root:Train (Epoch 52): Loss/seq after 02750 batchs: 788.1094360351562
INFO:root:Train (Epoch 52): Loss/seq after 02800 batchs: 789.31494140625
INFO:root:Train (Epoch 52): Loss/seq after 02850 batchs: 789.3386840820312
INFO:root:Train (Epoch 52): Loss/seq after 02900 batchs: 790.6620483398438
INFO:root:Train (Epoch 52): Loss/seq after 02950 batchs: 788.37158203125
INFO:root:Train (Epoch 52): Loss/seq after 03000 batchs: 791.1381225585938
INFO:root:Train (Epoch 52): Loss/seq after 03050 batchs: 794.8540649414062
INFO:root:Train (Epoch 52): Loss/seq after 03100 batchs: 802.2149047851562
INFO:root:Train (Epoch 52): Loss/seq after 03150 batchs: 809.680419921875
INFO:root:Train (Epoch 52): Loss/seq after 03200 batchs: 813.765380859375
INFO:root:Train (Epoch 52): Loss/seq after 03250 batchs: 817.3077392578125
INFO:root:Train (Epoch 52): Loss/seq after 03300 batchs: 816.3646240234375
INFO:root:Train (Epoch 52): Loss/seq after 03350 batchs: 817.0126342773438
INFO:root:Train (Epoch 52): Loss/seq after 03400 batchs: 810.0200805664062
INFO:root:Train (Epoch 52): Loss/seq after 03450 batchs: 806.8054809570312
INFO:root:Train (Epoch 52): Loss/seq after 03500 batchs: 807.5270385742188
INFO:root:Train (Epoch 52): Loss/seq after 03550 batchs: 804.4168701171875
INFO:root:Train (Epoch 52): Loss/seq after 03600 batchs: 813.2188110351562
INFO:root:Train (Epoch 52): Loss/seq after 03650 batchs: 809.9720458984375
INFO:root:Train (Epoch 52): Loss/seq after 03700 batchs: 811.2211303710938
INFO:root:Train (Epoch 52): Loss/seq after 03750 batchs: 815.1123657226562
INFO:root:Train (Epoch 52): Loss/seq after 03800 batchs: 810.6625366210938
INFO:root:Train (Epoch 52): Loss/seq after 03850 batchs: 809.2317504882812
INFO:root:Train (Epoch 52): Loss/seq after 03900 batchs: 812.2886962890625
INFO:root:Train (Epoch 52): Loss/seq after 03950 batchs: 815.1019287109375
INFO:root:Train (Epoch 52): Loss/seq after 04000 batchs: 810.1284790039062
INFO:root:Train (Epoch 52): Loss/seq after 04050 batchs: 804.5298461914062
INFO:root:Train (Epoch 52): Loss/seq after 04100 batchs: 802.2886962890625
INFO:root:Train (Epoch 52): Loss/seq after 04150 batchs: 800.5108642578125
INFO:root:Train (Epoch 52): Loss/seq after 04200 batchs: 798.0220336914062
INFO:root:Train (Epoch 52): Loss/seq after 04250 batchs: 795.4657592773438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 52): Loss/seq after 00000 batches: 557.6178588867188
INFO:root:# Valid (Epoch 52): Loss/seq after 00050 batches: 731.030029296875
INFO:root:# Valid (Epoch 52): Loss/seq after 00100 batches: 915.2437744140625
INFO:root:# Valid (Epoch 52): Loss/seq after 00150 batches: 715.7505493164062
INFO:root:# Valid (Epoch 52): Loss/seq after 00200 batches: 682.9143676757812
INFO:root:Artifacts: Make stick videos for epoch 52
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_52_on_20220422_035051.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_52_index_1358_on_20220422_035051.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 53): Loss/seq after 00000 batchs: 1401.13671875
INFO:root:Train (Epoch 53): Loss/seq after 00050 batchs: 1052.737060546875
INFO:root:Train (Epoch 53): Loss/seq after 00100 batchs: 1094.773193359375
INFO:root:Train (Epoch 53): Loss/seq after 00150 batchs: 1005.0260009765625
INFO:root:Train (Epoch 53): Loss/seq after 00200 batchs: 1108.3294677734375
INFO:root:Train (Epoch 53): Loss/seq after 00250 batchs: 1225.283935546875
INFO:root:Train (Epoch 53): Loss/seq after 00300 batchs: 1186.1165771484375
INFO:root:Train (Epoch 53): Loss/seq after 00350 batchs: 1101.994384765625
INFO:root:Train (Epoch 53): Loss/seq after 00400 batchs: 1113.6612548828125
INFO:root:Train (Epoch 53): Loss/seq after 00450 batchs: 1075.5042724609375
INFO:root:Train (Epoch 53): Loss/seq after 00500 batchs: 1072.3626708984375
INFO:root:Train (Epoch 53): Loss/seq after 00550 batchs: 1035.2442626953125
INFO:root:Train (Epoch 53): Loss/seq after 00600 batchs: 997.130615234375
INFO:root:Train (Epoch 53): Loss/seq after 00650 batchs: 976.7086181640625
INFO:root:Train (Epoch 53): Loss/seq after 00700 batchs: 940.1154174804688
INFO:root:Train (Epoch 53): Loss/seq after 00750 batchs: 956.8961181640625
INFO:root:Train (Epoch 53): Loss/seq after 00800 batchs: 958.5966796875
INFO:root:Train (Epoch 53): Loss/seq after 00850 batchs: 936.7969970703125
INFO:root:Train (Epoch 53): Loss/seq after 00900 batchs: 919.3229370117188
INFO:root:Train (Epoch 53): Loss/seq after 00950 batchs: 926.7317504882812
INFO:root:Train (Epoch 53): Loss/seq after 01000 batchs: 918.574462890625
INFO:root:Train (Epoch 53): Loss/seq after 01050 batchs: 902.5098876953125
INFO:root:Train (Epoch 53): Loss/seq after 01100 batchs: 888.9702758789062
INFO:root:Train (Epoch 53): Loss/seq after 01150 batchs: 865.9112548828125
INFO:root:Train (Epoch 53): Loss/seq after 01200 batchs: 867.8856201171875
INFO:root:Train (Epoch 53): Loss/seq after 01250 batchs: 864.0339965820312
INFO:root:Train (Epoch 53): Loss/seq after 01300 batchs: 849.392578125
INFO:root:Train (Epoch 53): Loss/seq after 01350 batchs: 837.6058959960938
INFO:root:Train (Epoch 53): Loss/seq after 01400 batchs: 847.711181640625
INFO:root:Train (Epoch 53): Loss/seq after 01450 batchs: 848.005615234375
INFO:root:Train (Epoch 53): Loss/seq after 01500 batchs: 850.7341918945312
INFO:root:Train (Epoch 53): Loss/seq after 01550 batchs: 855.9241333007812
INFO:root:Train (Epoch 53): Loss/seq after 01600 batchs: 848.56494140625
INFO:root:Train (Epoch 53): Loss/seq after 01650 batchs: 846.448486328125
INFO:root:Train (Epoch 53): Loss/seq after 01700 batchs: 845.5093994140625
INFO:root:Train (Epoch 53): Loss/seq after 01750 batchs: 840.608642578125
INFO:root:Train (Epoch 53): Loss/seq after 01800 batchs: 835.3929443359375
INFO:root:Train (Epoch 53): Loss/seq after 01850 batchs: 829.5576782226562
INFO:root:Train (Epoch 53): Loss/seq after 01900 batchs: 833.3951416015625
INFO:root:Train (Epoch 53): Loss/seq after 01950 batchs: 832.468505859375
INFO:root:Train (Epoch 53): Loss/seq after 02000 batchs: 829.2783203125
INFO:root:Train (Epoch 53): Loss/seq after 02050 batchs: 827.6343383789062
INFO:root:Train (Epoch 53): Loss/seq after 02100 batchs: 822.423583984375
INFO:root:Train (Epoch 53): Loss/seq after 02150 batchs: 818.6761474609375
INFO:root:Train (Epoch 53): Loss/seq after 02200 batchs: 813.5421142578125
INFO:root:Train (Epoch 53): Loss/seq after 02250 batchs: 815.0585327148438
INFO:root:Train (Epoch 53): Loss/seq after 02300 batchs: 814.2879638671875
INFO:root:Train (Epoch 53): Loss/seq after 02350 batchs: 808.5782470703125
INFO:root:Train (Epoch 53): Loss/seq after 02400 batchs: 808.1703491210938
INFO:root:Train (Epoch 53): Loss/seq after 02450 batchs: 800.8577880859375
INFO:root:Train (Epoch 53): Loss/seq after 02500 batchs: 788.4049682617188
INFO:root:Train (Epoch 53): Loss/seq after 02550 batchs: 779.7269897460938
INFO:root:Train (Epoch 53): Loss/seq after 02600 batchs: 776.9098510742188
INFO:root:Train (Epoch 53): Loss/seq after 02650 batchs: 773.9960327148438
INFO:root:Train (Epoch 53): Loss/seq after 02700 batchs: 771.5995483398438
INFO:root:Train (Epoch 53): Loss/seq after 02750 batchs: 775.4776000976562
INFO:root:Train (Epoch 53): Loss/seq after 02800 batchs: 777.1867065429688
INFO:root:Train (Epoch 53): Loss/seq after 02850 batchs: 777.0821533203125
INFO:root:Train (Epoch 53): Loss/seq after 02900 batchs: 778.143798828125
INFO:root:Train (Epoch 53): Loss/seq after 02950 batchs: 775.8203735351562
INFO:root:Train (Epoch 53): Loss/seq after 03000 batchs: 778.865966796875
INFO:root:Train (Epoch 53): Loss/seq after 03050 batchs: 783.1800537109375
INFO:root:Train (Epoch 53): Loss/seq after 03100 batchs: 790.4746704101562
INFO:root:Train (Epoch 53): Loss/seq after 03150 batchs: 796.5023193359375
INFO:root:Train (Epoch 53): Loss/seq after 03200 batchs: 800.9264526367188
INFO:root:Train (Epoch 53): Loss/seq after 03250 batchs: 804.6959838867188
INFO:root:Train (Epoch 53): Loss/seq after 03300 batchs: 804.991455078125
INFO:root:Train (Epoch 53): Loss/seq after 03350 batchs: 804.9776611328125
INFO:root:Train (Epoch 53): Loss/seq after 03400 batchs: 798.1529541015625
INFO:root:Train (Epoch 53): Loss/seq after 03450 batchs: 794.7022705078125
INFO:root:Train (Epoch 53): Loss/seq after 03500 batchs: 795.001708984375
INFO:root:Train (Epoch 53): Loss/seq after 03550 batchs: 792.253173828125
INFO:root:Train (Epoch 53): Loss/seq after 03600 batchs: 801.4642944335938
INFO:root:Train (Epoch 53): Loss/seq after 03650 batchs: 798.60205078125
INFO:root:Train (Epoch 53): Loss/seq after 03700 batchs: 799.9666137695312
INFO:root:Train (Epoch 53): Loss/seq after 03750 batchs: 803.7486572265625
INFO:root:Train (Epoch 53): Loss/seq after 03800 batchs: 799.3802490234375
INFO:root:Train (Epoch 53): Loss/seq after 03850 batchs: 797.9443359375
INFO:root:Train (Epoch 53): Loss/seq after 03900 batchs: 801.095703125
INFO:root:Train (Epoch 53): Loss/seq after 03950 batchs: 803.6905517578125
INFO:root:Train (Epoch 53): Loss/seq after 04000 batchs: 798.8042602539062
INFO:root:Train (Epoch 53): Loss/seq after 04050 batchs: 793.2353515625
INFO:root:Train (Epoch 53): Loss/seq after 04100 batchs: 790.8816528320312
INFO:root:Train (Epoch 53): Loss/seq after 04150 batchs: 789.222412109375
INFO:root:Train (Epoch 53): Loss/seq after 04200 batchs: 786.856689453125
INFO:root:Train (Epoch 53): Loss/seq after 04250 batchs: 784.2462158203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 53): Loss/seq after 00000 batches: 650.548583984375
INFO:root:# Valid (Epoch 53): Loss/seq after 00050 batches: 811.357177734375
INFO:root:# Valid (Epoch 53): Loss/seq after 00100 batches: 925.45263671875
INFO:root:# Valid (Epoch 53): Loss/seq after 00150 batches: 716.4207153320312
INFO:root:# Valid (Epoch 53): Loss/seq after 00200 batches: 672.864013671875
INFO:root:Artifacts: Make stick videos for epoch 53
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_53_on_20220422_035539.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_53_index_10_on_20220422_035539.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 54): Loss/seq after 00000 batchs: 1435.94775390625
INFO:root:Train (Epoch 54): Loss/seq after 00050 batchs: 1061.7032470703125
INFO:root:Train (Epoch 54): Loss/seq after 00100 batchs: 1095.596923828125
INFO:root:Train (Epoch 54): Loss/seq after 00150 batchs: 1016.1377563476562
INFO:root:Train (Epoch 54): Loss/seq after 00200 batchs: 1113.2935791015625
INFO:root:Train (Epoch 54): Loss/seq after 00250 batchs: 1226.27392578125
INFO:root:Train (Epoch 54): Loss/seq after 00300 batchs: 1185.1640625
INFO:root:Train (Epoch 54): Loss/seq after 00350 batchs: 1101.44921875
INFO:root:Train (Epoch 54): Loss/seq after 00400 batchs: 1111.345947265625
INFO:root:Train (Epoch 54): Loss/seq after 00450 batchs: 1072.7586669921875
INFO:root:Train (Epoch 54): Loss/seq after 00500 batchs: 1063.294189453125
INFO:root:Train (Epoch 54): Loss/seq after 00550 batchs: 1026.3419189453125
INFO:root:Train (Epoch 54): Loss/seq after 00600 batchs: 988.44775390625
INFO:root:Train (Epoch 54): Loss/seq after 00650 batchs: 968.4036254882812
INFO:root:Train (Epoch 54): Loss/seq after 00700 batchs: 933.8118286132812
INFO:root:Train (Epoch 54): Loss/seq after 00750 batchs: 951.5348510742188
INFO:root:Train (Epoch 54): Loss/seq after 00800 batchs: 954.5039672851562
INFO:root:Train (Epoch 54): Loss/seq after 00850 batchs: 930.8340454101562
INFO:root:Train (Epoch 54): Loss/seq after 00900 batchs: 912.1802368164062
INFO:root:Train (Epoch 54): Loss/seq after 00950 batchs: 916.59521484375
INFO:root:Train (Epoch 54): Loss/seq after 01000 batchs: 908.4017333984375
INFO:root:Train (Epoch 54): Loss/seq after 01050 batchs: 890.9739379882812
INFO:root:Train (Epoch 54): Loss/seq after 01100 batchs: 881.2620849609375
INFO:root:Train (Epoch 54): Loss/seq after 01150 batchs: 858.0281982421875
INFO:root:Train (Epoch 54): Loss/seq after 01200 batchs: 860.106201171875
INFO:root:Train (Epoch 54): Loss/seq after 01250 batchs: 855.2249145507812
INFO:root:Train (Epoch 54): Loss/seq after 01300 batchs: 840.4826049804688
INFO:root:Train (Epoch 54): Loss/seq after 01350 batchs: 827.8663940429688
INFO:root:Train (Epoch 54): Loss/seq after 01400 batchs: 838.0718994140625
INFO:root:Train (Epoch 54): Loss/seq after 01450 batchs: 838.2368774414062
INFO:root:Train (Epoch 54): Loss/seq after 01500 batchs: 841.1427612304688
INFO:root:Train (Epoch 54): Loss/seq after 01550 batchs: 846.4488525390625
INFO:root:Train (Epoch 54): Loss/seq after 01600 batchs: 838.8480224609375
INFO:root:Train (Epoch 54): Loss/seq after 01650 batchs: 837.6617431640625
INFO:root:Train (Epoch 54): Loss/seq after 01700 batchs: 836.5732421875
INFO:root:Train (Epoch 54): Loss/seq after 01750 batchs: 831.8543090820312
INFO:root:Train (Epoch 54): Loss/seq after 01800 batchs: 826.4988403320312
INFO:root:Train (Epoch 54): Loss/seq after 01850 batchs: 820.84130859375
INFO:root:Train (Epoch 54): Loss/seq after 01900 batchs: 825.7445678710938
INFO:root:Train (Epoch 54): Loss/seq after 01950 batchs: 825.310546875
INFO:root:Train (Epoch 54): Loss/seq after 02000 batchs: 822.0646362304688
INFO:root:Train (Epoch 54): Loss/seq after 02050 batchs: 820.861083984375
INFO:root:Train (Epoch 54): Loss/seq after 02100 batchs: 815.9050903320312
INFO:root:Train (Epoch 54): Loss/seq after 02150 batchs: 812.2882080078125
INFO:root:Train (Epoch 54): Loss/seq after 02200 batchs: 807.296142578125
INFO:root:Train (Epoch 54): Loss/seq after 02250 batchs: 809.5491943359375
INFO:root:Train (Epoch 54): Loss/seq after 02300 batchs: 809.038330078125
INFO:root:Train (Epoch 54): Loss/seq after 02350 batchs: 803.6295166015625
INFO:root:Train (Epoch 54): Loss/seq after 02400 batchs: 803.0617065429688
INFO:root:Train (Epoch 54): Loss/seq after 02450 batchs: 795.57177734375
INFO:root:Train (Epoch 54): Loss/seq after 02500 batchs: 783.145263671875
INFO:root:Train (Epoch 54): Loss/seq after 02550 batchs: 774.5938110351562
INFO:root:Train (Epoch 54): Loss/seq after 02600 batchs: 772.0577392578125
INFO:root:Train (Epoch 54): Loss/seq after 02650 batchs: 768.92724609375
INFO:root:Train (Epoch 54): Loss/seq after 02700 batchs: 766.6608276367188
INFO:root:Train (Epoch 54): Loss/seq after 02750 batchs: 771.1763305664062
INFO:root:Train (Epoch 54): Loss/seq after 02800 batchs: 772.8057861328125
INFO:root:Train (Epoch 54): Loss/seq after 02850 batchs: 773.0947875976562
INFO:root:Train (Epoch 54): Loss/seq after 02900 batchs: 774.0488891601562
INFO:root:Train (Epoch 54): Loss/seq after 02950 batchs: 771.6687622070312
INFO:root:Train (Epoch 54): Loss/seq after 03000 batchs: 774.6873168945312
INFO:root:Train (Epoch 54): Loss/seq after 03050 batchs: 778.6580200195312
INFO:root:Train (Epoch 54): Loss/seq after 03100 batchs: 785.647216796875
INFO:root:Train (Epoch 54): Loss/seq after 03150 batchs: 790.988525390625
INFO:root:Train (Epoch 54): Loss/seq after 03200 batchs: 795.1317749023438
INFO:root:Train (Epoch 54): Loss/seq after 03250 batchs: 798.9764404296875
INFO:root:Train (Epoch 54): Loss/seq after 03300 batchs: 797.9471435546875
INFO:root:Train (Epoch 54): Loss/seq after 03350 batchs: 797.791748046875
INFO:root:Train (Epoch 54): Loss/seq after 03400 batchs: 790.93701171875
INFO:root:Train (Epoch 54): Loss/seq after 03450 batchs: 787.7144165039062
INFO:root:Train (Epoch 54): Loss/seq after 03500 batchs: 788.1083374023438
INFO:root:Train (Epoch 54): Loss/seq after 03550 batchs: 785.1798706054688
INFO:root:Train (Epoch 54): Loss/seq after 03600 batchs: 794.2520141601562
INFO:root:Train (Epoch 54): Loss/seq after 03650 batchs: 791.0167236328125
INFO:root:Train (Epoch 54): Loss/seq after 03700 batchs: 792.2014770507812
INFO:root:Train (Epoch 54): Loss/seq after 03750 batchs: 796.1403198242188
INFO:root:Train (Epoch 54): Loss/seq after 03800 batchs: 791.7244262695312
INFO:root:Train (Epoch 54): Loss/seq after 03850 batchs: 790.3948364257812
INFO:root:Train (Epoch 54): Loss/seq after 03900 batchs: 793.40869140625
INFO:root:Train (Epoch 54): Loss/seq after 03950 batchs: 795.9373168945312
INFO:root:Train (Epoch 54): Loss/seq after 04000 batchs: 791.1168212890625
INFO:root:Train (Epoch 54): Loss/seq after 04050 batchs: 785.6323852539062
INFO:root:Train (Epoch 54): Loss/seq after 04100 batchs: 783.3504638671875
INFO:root:Train (Epoch 54): Loss/seq after 04150 batchs: 781.6253051757812
INFO:root:Train (Epoch 54): Loss/seq after 04200 batchs: 779.358154296875
INFO:root:Train (Epoch 54): Loss/seq after 04250 batchs: 776.957275390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 54): Loss/seq after 00000 batches: 615.158447265625
INFO:root:# Valid (Epoch 54): Loss/seq after 00050 batches: 767.0718994140625
INFO:root:# Valid (Epoch 54): Loss/seq after 00100 batches: 891.4124145507812
INFO:root:# Valid (Epoch 54): Loss/seq after 00150 batches: 696.93017578125
INFO:root:# Valid (Epoch 54): Loss/seq after 00200 batches: 663.4032592773438
INFO:root:Artifacts: Make stick videos for epoch 54
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_54_on_20220422_040024.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_54_index_1195_on_20220422_040024.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 55): Loss/seq after 00000 batchs: 1335.7144775390625
INFO:root:Train (Epoch 55): Loss/seq after 00050 batchs: 1072.96875
INFO:root:Train (Epoch 55): Loss/seq after 00100 batchs: 1105.9979248046875
INFO:root:Train (Epoch 55): Loss/seq after 00150 batchs: 1005.4594116210938
INFO:root:Train (Epoch 55): Loss/seq after 00200 batchs: 1103.7177734375
INFO:root:Train (Epoch 55): Loss/seq after 00250 batchs: 1212.6854248046875
INFO:root:Train (Epoch 55): Loss/seq after 00300 batchs: 1175.203125
INFO:root:Train (Epoch 55): Loss/seq after 00350 batchs: 1094.865234375
INFO:root:Train (Epoch 55): Loss/seq after 00400 batchs: 1108.0123291015625
INFO:root:Train (Epoch 55): Loss/seq after 00450 batchs: 1069.7908935546875
INFO:root:Train (Epoch 55): Loss/seq after 00500 batchs: 1065.5797119140625
INFO:root:Train (Epoch 55): Loss/seq after 00550 batchs: 1027.4437255859375
INFO:root:Train (Epoch 55): Loss/seq after 00600 batchs: 991.8457641601562
INFO:root:Train (Epoch 55): Loss/seq after 00650 batchs: 970.9652709960938
INFO:root:Train (Epoch 55): Loss/seq after 00700 batchs: 935.8151245117188
INFO:root:Train (Epoch 55): Loss/seq after 00750 batchs: 955.4426879882812
INFO:root:Train (Epoch 55): Loss/seq after 00800 batchs: 956.7125854492188
INFO:root:Train (Epoch 55): Loss/seq after 00850 batchs: 932.5018920898438
INFO:root:Train (Epoch 55): Loss/seq after 00900 batchs: 911.8123779296875
INFO:root:Train (Epoch 55): Loss/seq after 00950 batchs: 915.0009155273438
INFO:root:Train (Epoch 55): Loss/seq after 01000 batchs: 904.1390991210938
INFO:root:Train (Epoch 55): Loss/seq after 01050 batchs: 891.7908935546875
INFO:root:Train (Epoch 55): Loss/seq after 01100 batchs: 877.6665649414062
INFO:root:Train (Epoch 55): Loss/seq after 01150 batchs: 855.4127807617188
INFO:root:Train (Epoch 55): Loss/seq after 01200 batchs: 859.4492797851562
INFO:root:Train (Epoch 55): Loss/seq after 01250 batchs: 856.5584716796875
INFO:root:Train (Epoch 55): Loss/seq after 01300 batchs: 841.9461669921875
INFO:root:Train (Epoch 55): Loss/seq after 01350 batchs: 829.02734375
INFO:root:Train (Epoch 55): Loss/seq after 01400 batchs: 837.7672729492188
INFO:root:Train (Epoch 55): Loss/seq after 01450 batchs: 838.3038330078125
INFO:root:Train (Epoch 55): Loss/seq after 01500 batchs: 841.5741577148438
INFO:root:Train (Epoch 55): Loss/seq after 01550 batchs: 848.3619995117188
INFO:root:Train (Epoch 55): Loss/seq after 01600 batchs: 841.0703735351562
INFO:root:Train (Epoch 55): Loss/seq after 01650 batchs: 840.1522827148438
INFO:root:Train (Epoch 55): Loss/seq after 01700 batchs: 838.5480346679688
INFO:root:Train (Epoch 55): Loss/seq after 01750 batchs: 833.482666015625
INFO:root:Train (Epoch 55): Loss/seq after 01800 batchs: 828.0192260742188
INFO:root:Train (Epoch 55): Loss/seq after 01850 batchs: 822.3422241210938
INFO:root:Train (Epoch 55): Loss/seq after 01900 batchs: 826.4862060546875
INFO:root:Train (Epoch 55): Loss/seq after 01950 batchs: 825.2572021484375
INFO:root:Train (Epoch 55): Loss/seq after 02000 batchs: 822.4713745117188
INFO:root:Train (Epoch 55): Loss/seq after 02050 batchs: 820.3605346679688
INFO:root:Train (Epoch 55): Loss/seq after 02100 batchs: 815.03076171875
INFO:root:Train (Epoch 55): Loss/seq after 02150 batchs: 811.4359130859375
INFO:root:Train (Epoch 55): Loss/seq after 02200 batchs: 806.3681640625
INFO:root:Train (Epoch 55): Loss/seq after 02250 batchs: 807.5369262695312
INFO:root:Train (Epoch 55): Loss/seq after 02300 batchs: 806.509765625
INFO:root:Train (Epoch 55): Loss/seq after 02350 batchs: 801.3614501953125
INFO:root:Train (Epoch 55): Loss/seq after 02400 batchs: 800.9275512695312
INFO:root:Train (Epoch 55): Loss/seq after 02450 batchs: 793.5836181640625
INFO:root:Train (Epoch 55): Loss/seq after 02500 batchs: 781.2543334960938
INFO:root:Train (Epoch 55): Loss/seq after 02550 batchs: 772.6337890625
INFO:root:Train (Epoch 55): Loss/seq after 02600 batchs: 770.2857666015625
INFO:root:Train (Epoch 55): Loss/seq after 02650 batchs: 767.3243408203125
INFO:root:Train (Epoch 55): Loss/seq after 02700 batchs: 765.1235961914062
INFO:root:Train (Epoch 55): Loss/seq after 02750 batchs: 769.3117065429688
INFO:root:Train (Epoch 55): Loss/seq after 02800 batchs: 770.6417236328125
INFO:root:Train (Epoch 55): Loss/seq after 02850 batchs: 771.0156860351562
INFO:root:Train (Epoch 55): Loss/seq after 02900 batchs: 772.2991943359375
INFO:root:Train (Epoch 55): Loss/seq after 02950 batchs: 769.9810791015625
INFO:root:Train (Epoch 55): Loss/seq after 03000 batchs: 773.055419921875
INFO:root:Train (Epoch 55): Loss/seq after 03050 batchs: 776.5188598632812
INFO:root:Train (Epoch 55): Loss/seq after 03100 batchs: 784.029541015625
INFO:root:Train (Epoch 55): Loss/seq after 03150 batchs: 789.6129760742188
INFO:root:Train (Epoch 55): Loss/seq after 03200 batchs: 793.9409790039062
INFO:root:Train (Epoch 55): Loss/seq after 03250 batchs: 797.5728149414062
INFO:root:Train (Epoch 55): Loss/seq after 03300 batchs: 796.09326171875
INFO:root:Train (Epoch 55): Loss/seq after 03350 batchs: 795.5949096679688
INFO:root:Train (Epoch 55): Loss/seq after 03400 batchs: 788.7543334960938
INFO:root:Train (Epoch 55): Loss/seq after 03450 batchs: 785.3229370117188
INFO:root:Train (Epoch 55): Loss/seq after 03500 batchs: 785.7673950195312
INFO:root:Train (Epoch 55): Loss/seq after 03550 batchs: 783.0459594726562
INFO:root:Train (Epoch 55): Loss/seq after 03600 batchs: 791.979248046875
INFO:root:Train (Epoch 55): Loss/seq after 03650 batchs: 788.562255859375
INFO:root:Train (Epoch 55): Loss/seq after 03700 batchs: 789.7837524414062
INFO:root:Train (Epoch 55): Loss/seq after 03750 batchs: 793.67919921875
INFO:root:Train (Epoch 55): Loss/seq after 03800 batchs: 789.3607177734375
INFO:root:Train (Epoch 55): Loss/seq after 03850 batchs: 787.9760131835938
INFO:root:Train (Epoch 55): Loss/seq after 03900 batchs: 791.065673828125
INFO:root:Train (Epoch 55): Loss/seq after 03950 batchs: 793.7131958007812
INFO:root:Train (Epoch 55): Loss/seq after 04000 batchs: 788.7543334960938
INFO:root:Train (Epoch 55): Loss/seq after 04050 batchs: 783.2559204101562
INFO:root:Train (Epoch 55): Loss/seq after 04100 batchs: 780.9697265625
INFO:root:Train (Epoch 55): Loss/seq after 04150 batchs: 779.4043579101562
INFO:root:Train (Epoch 55): Loss/seq after 04200 batchs: 777.3065795898438
INFO:root:Train (Epoch 55): Loss/seq after 04250 batchs: 774.8250122070312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 55): Loss/seq after 00000 batches: 623.5349731445312
INFO:root:# Valid (Epoch 55): Loss/seq after 00050 batches: 851.92724609375
INFO:root:# Valid (Epoch 55): Loss/seq after 00100 batches: 913.279052734375
INFO:root:# Valid (Epoch 55): Loss/seq after 00150 batches: 709.012939453125
INFO:root:# Valid (Epoch 55): Loss/seq after 00200 batches: 668.2100830078125
INFO:root:Artifacts: Make stick videos for epoch 55
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_55_on_20220422_040513.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_55_index_156_on_20220422_040513.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 56): Loss/seq after 00000 batchs: 1407.5576171875
INFO:root:Train (Epoch 56): Loss/seq after 00050 batchs: 1082.3438720703125
INFO:root:Train (Epoch 56): Loss/seq after 00100 batchs: 1121.8812255859375
INFO:root:Train (Epoch 56): Loss/seq after 00150 batchs: 1019.8638305664062
INFO:root:Train (Epoch 56): Loss/seq after 00200 batchs: 1111.0738525390625
INFO:root:Train (Epoch 56): Loss/seq after 00250 batchs: 1219.6192626953125
INFO:root:Train (Epoch 56): Loss/seq after 00300 batchs: 1179.9036865234375
INFO:root:Train (Epoch 56): Loss/seq after 00350 batchs: 1095.126708984375
INFO:root:Train (Epoch 56): Loss/seq after 00400 batchs: 1101.67333984375
INFO:root:Train (Epoch 56): Loss/seq after 00450 batchs: 1063.6370849609375
INFO:root:Train (Epoch 56): Loss/seq after 00500 batchs: 1053.328369140625
INFO:root:Train (Epoch 56): Loss/seq after 00550 batchs: 1015.7978515625
INFO:root:Train (Epoch 56): Loss/seq after 00600 batchs: 978.0993041992188
INFO:root:Train (Epoch 56): Loss/seq after 00650 batchs: 956.5025024414062
INFO:root:Train (Epoch 56): Loss/seq after 00700 batchs: 920.8612670898438
INFO:root:Train (Epoch 56): Loss/seq after 00750 batchs: 937.46435546875
INFO:root:Train (Epoch 56): Loss/seq after 00800 batchs: 939.17529296875
INFO:root:Train (Epoch 56): Loss/seq after 00850 batchs: 915.1100463867188
INFO:root:Train (Epoch 56): Loss/seq after 00900 batchs: 895.9716186523438
INFO:root:Train (Epoch 56): Loss/seq after 00950 batchs: 901.1881713867188
INFO:root:Train (Epoch 56): Loss/seq after 01000 batchs: 891.5031127929688
INFO:root:Train (Epoch 56): Loss/seq after 01050 batchs: 875.1716918945312
INFO:root:Train (Epoch 56): Loss/seq after 01100 batchs: 863.0657348632812
INFO:root:Train (Epoch 56): Loss/seq after 01150 batchs: 839.87939453125
INFO:root:Train (Epoch 56): Loss/seq after 01200 batchs: 842.9074096679688
INFO:root:Train (Epoch 56): Loss/seq after 01250 batchs: 838.8724975585938
INFO:root:Train (Epoch 56): Loss/seq after 01300 batchs: 823.4359130859375
INFO:root:Train (Epoch 56): Loss/seq after 01350 batchs: 811.0811157226562
INFO:root:Train (Epoch 56): Loss/seq after 01400 batchs: 820.9880981445312
INFO:root:Train (Epoch 56): Loss/seq after 01450 batchs: 821.113525390625
INFO:root:Train (Epoch 56): Loss/seq after 01500 batchs: 824.2593383789062
INFO:root:Train (Epoch 56): Loss/seq after 01550 batchs: 829.6207275390625
INFO:root:Train (Epoch 56): Loss/seq after 01600 batchs: 822.5845336914062
INFO:root:Train (Epoch 56): Loss/seq after 01650 batchs: 820.3876953125
INFO:root:Train (Epoch 56): Loss/seq after 01700 batchs: 819.3759155273438
INFO:root:Train (Epoch 56): Loss/seq after 01750 batchs: 814.5512084960938
INFO:root:Train (Epoch 56): Loss/seq after 01800 batchs: 809.510009765625
INFO:root:Train (Epoch 56): Loss/seq after 01850 batchs: 803.7135009765625
INFO:root:Train (Epoch 56): Loss/seq after 01900 batchs: 807.5245361328125
INFO:root:Train (Epoch 56): Loss/seq after 01950 batchs: 805.9121704101562
INFO:root:Train (Epoch 56): Loss/seq after 02000 batchs: 802.7840576171875
INFO:root:Train (Epoch 56): Loss/seq after 02050 batchs: 800.8024291992188
INFO:root:Train (Epoch 56): Loss/seq after 02100 batchs: 795.98583984375
INFO:root:Train (Epoch 56): Loss/seq after 02150 batchs: 792.5140380859375
INFO:root:Train (Epoch 56): Loss/seq after 02200 batchs: 787.8076782226562
INFO:root:Train (Epoch 56): Loss/seq after 02250 batchs: 789.3994750976562
INFO:root:Train (Epoch 56): Loss/seq after 02300 batchs: 788.7581176757812
INFO:root:Train (Epoch 56): Loss/seq after 02350 batchs: 783.5897827148438
INFO:root:Train (Epoch 56): Loss/seq after 02400 batchs: 784.0270385742188
INFO:root:Train (Epoch 56): Loss/seq after 02450 batchs: 776.8975219726562
INFO:root:Train (Epoch 56): Loss/seq after 02500 batchs: 764.8749389648438
INFO:root:Train (Epoch 56): Loss/seq after 02550 batchs: 756.5169677734375
INFO:root:Train (Epoch 56): Loss/seq after 02600 batchs: 754.1458740234375
INFO:root:Train (Epoch 56): Loss/seq after 02650 batchs: 751.3513793945312
INFO:root:Train (Epoch 56): Loss/seq after 02700 batchs: 749.3597412109375
INFO:root:Train (Epoch 56): Loss/seq after 02750 batchs: 753.6504516601562
INFO:root:Train (Epoch 56): Loss/seq after 02800 batchs: 755.6561889648438
INFO:root:Train (Epoch 56): Loss/seq after 02850 batchs: 755.52587890625
INFO:root:Train (Epoch 56): Loss/seq after 02900 batchs: 756.6790161132812
INFO:root:Train (Epoch 56): Loss/seq after 02950 batchs: 754.279052734375
INFO:root:Train (Epoch 56): Loss/seq after 03000 batchs: 757.4973754882812
INFO:root:Train (Epoch 56): Loss/seq after 03050 batchs: 763.0150146484375
INFO:root:Train (Epoch 56): Loss/seq after 03100 batchs: 770.983154296875
INFO:root:Train (Epoch 56): Loss/seq after 03150 batchs: 776.517578125
INFO:root:Train (Epoch 56): Loss/seq after 03200 batchs: 780.9630126953125
INFO:root:Train (Epoch 56): Loss/seq after 03250 batchs: 784.783447265625
INFO:root:Train (Epoch 56): Loss/seq after 03300 batchs: 784.8892822265625
INFO:root:Train (Epoch 56): Loss/seq after 03350 batchs: 784.8905639648438
INFO:root:Train (Epoch 56): Loss/seq after 03400 batchs: 778.2492065429688
INFO:root:Train (Epoch 56): Loss/seq after 03450 batchs: 775.146728515625
INFO:root:Train (Epoch 56): Loss/seq after 03500 batchs: 775.9937744140625
INFO:root:Train (Epoch 56): Loss/seq after 03550 batchs: 773.478271484375
INFO:root:Train (Epoch 56): Loss/seq after 03600 batchs: 782.6531982421875
INFO:root:Train (Epoch 56): Loss/seq after 03650 batchs: 779.204833984375
INFO:root:Train (Epoch 56): Loss/seq after 03700 batchs: 780.464599609375
INFO:root:Train (Epoch 56): Loss/seq after 03750 batchs: 784.327392578125
INFO:root:Train (Epoch 56): Loss/seq after 03800 batchs: 779.9735717773438
INFO:root:Train (Epoch 56): Loss/seq after 03850 batchs: 778.7044067382812
INFO:root:Train (Epoch 56): Loss/seq after 03900 batchs: 781.7526245117188
INFO:root:Train (Epoch 56): Loss/seq after 03950 batchs: 784.4241333007812
INFO:root:Train (Epoch 56): Loss/seq after 04000 batchs: 779.6609497070312
INFO:root:Train (Epoch 56): Loss/seq after 04050 batchs: 774.1828002929688
INFO:root:Train (Epoch 56): Loss/seq after 04100 batchs: 771.9368286132812
INFO:root:Train (Epoch 56): Loss/seq after 04150 batchs: 770.31005859375
INFO:root:Train (Epoch 56): Loss/seq after 04200 batchs: 767.8727416992188
INFO:root:Train (Epoch 56): Loss/seq after 04250 batchs: 765.5401000976562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 56): Loss/seq after 00000 batches: 645.6696166992188
INFO:root:# Valid (Epoch 56): Loss/seq after 00050 batches: 803.1600952148438
INFO:root:# Valid (Epoch 56): Loss/seq after 00100 batches: 925.7528686523438
INFO:root:# Valid (Epoch 56): Loss/seq after 00150 batches: 722.4144897460938
INFO:root:# Valid (Epoch 56): Loss/seq after 00200 batches: 682.2515258789062
INFO:root:Artifacts: Make stick videos for epoch 56
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_56_on_20220422_041013.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_56_index_287_on_20220422_041013.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 57): Loss/seq after 00000 batchs: 1295.6953125
INFO:root:Train (Epoch 57): Loss/seq after 00050 batchs: 1044.24951171875
INFO:root:Train (Epoch 57): Loss/seq after 00100 batchs: 1093.1510009765625
INFO:root:Train (Epoch 57): Loss/seq after 00150 batchs: 997.8468627929688
INFO:root:Train (Epoch 57): Loss/seq after 00200 batchs: 1091.9329833984375
INFO:root:Train (Epoch 57): Loss/seq after 00250 batchs: 1205.6864013671875
INFO:root:Train (Epoch 57): Loss/seq after 00300 batchs: 1167.373291015625
INFO:root:Train (Epoch 57): Loss/seq after 00350 batchs: 1082.3114013671875
INFO:root:Train (Epoch 57): Loss/seq after 00400 batchs: 1095.04541015625
INFO:root:Train (Epoch 57): Loss/seq after 00450 batchs: 1059.20556640625
INFO:root:Train (Epoch 57): Loss/seq after 00500 batchs: 1056.74951171875
INFO:root:Train (Epoch 57): Loss/seq after 00550 batchs: 1019.706787109375
INFO:root:Train (Epoch 57): Loss/seq after 00600 batchs: 982.8388671875
INFO:root:Train (Epoch 57): Loss/seq after 00650 batchs: 959.6849365234375
INFO:root:Train (Epoch 57): Loss/seq after 00700 batchs: 925.3494262695312
INFO:root:Train (Epoch 57): Loss/seq after 00750 batchs: 941.3862915039062
INFO:root:Train (Epoch 57): Loss/seq after 00800 batchs: 943.9697875976562
INFO:root:Train (Epoch 57): Loss/seq after 00850 batchs: 918.8541259765625
INFO:root:Train (Epoch 57): Loss/seq after 00900 batchs: 901.8307495117188
INFO:root:Train (Epoch 57): Loss/seq after 00950 batchs: 904.19140625
INFO:root:Train (Epoch 57): Loss/seq after 01000 batchs: 893.1759033203125
INFO:root:Train (Epoch 57): Loss/seq after 01050 batchs: 878.0299682617188
INFO:root:Train (Epoch 57): Loss/seq after 01100 batchs: 863.6550903320312
INFO:root:Train (Epoch 57): Loss/seq after 01150 batchs: 840.620361328125
INFO:root:Train (Epoch 57): Loss/seq after 01200 batchs: 843.1375732421875
INFO:root:Train (Epoch 57): Loss/seq after 01250 batchs: 838.2113037109375
INFO:root:Train (Epoch 57): Loss/seq after 01300 batchs: 822.1793823242188
INFO:root:Train (Epoch 57): Loss/seq after 01350 batchs: 809.1260986328125
INFO:root:Train (Epoch 57): Loss/seq after 01400 batchs: 818.1152954101562
INFO:root:Train (Epoch 57): Loss/seq after 01450 batchs: 817.8771362304688
INFO:root:Train (Epoch 57): Loss/seq after 01500 batchs: 820.9600219726562
INFO:root:Train (Epoch 57): Loss/seq after 01550 batchs: 825.4619140625
INFO:root:Train (Epoch 57): Loss/seq after 01600 batchs: 817.9017944335938
INFO:root:Train (Epoch 57): Loss/seq after 01650 batchs: 815.7532958984375
INFO:root:Train (Epoch 57): Loss/seq after 01700 batchs: 814.3167114257812
INFO:root:Train (Epoch 57): Loss/seq after 01750 batchs: 809.6852416992188
INFO:root:Train (Epoch 57): Loss/seq after 01800 batchs: 804.529541015625
INFO:root:Train (Epoch 57): Loss/seq after 01850 batchs: 798.7350463867188
INFO:root:Train (Epoch 57): Loss/seq after 01900 batchs: 802.2177734375
INFO:root:Train (Epoch 57): Loss/seq after 01950 batchs: 800.4744873046875
INFO:root:Train (Epoch 57): Loss/seq after 02000 batchs: 797.1309814453125
INFO:root:Train (Epoch 57): Loss/seq after 02050 batchs: 794.89111328125
INFO:root:Train (Epoch 57): Loss/seq after 02100 batchs: 789.974853515625
INFO:root:Train (Epoch 57): Loss/seq after 02150 batchs: 786.4329223632812
INFO:root:Train (Epoch 57): Loss/seq after 02200 batchs: 781.672119140625
INFO:root:Train (Epoch 57): Loss/seq after 02250 batchs: 782.7132568359375
INFO:root:Train (Epoch 57): Loss/seq after 02300 batchs: 781.9446411132812
INFO:root:Train (Epoch 57): Loss/seq after 02350 batchs: 776.6895141601562
INFO:root:Train (Epoch 57): Loss/seq after 02400 batchs: 776.0106811523438
INFO:root:Train (Epoch 57): Loss/seq after 02450 batchs: 769.2442016601562
INFO:root:Train (Epoch 57): Loss/seq after 02500 batchs: 757.40771484375
INFO:root:Train (Epoch 57): Loss/seq after 02550 batchs: 749.4410400390625
INFO:root:Train (Epoch 57): Loss/seq after 02600 batchs: 747.7322387695312
INFO:root:Train (Epoch 57): Loss/seq after 02650 batchs: 744.8531494140625
INFO:root:Train (Epoch 57): Loss/seq after 02700 batchs: 742.844482421875
INFO:root:Train (Epoch 57): Loss/seq after 02750 batchs: 747.5609741210938
INFO:root:Train (Epoch 57): Loss/seq after 02800 batchs: 748.6878051757812
INFO:root:Train (Epoch 57): Loss/seq after 02850 batchs: 749.1589965820312
INFO:root:Train (Epoch 57): Loss/seq after 02900 batchs: 750.0634765625
INFO:root:Train (Epoch 57): Loss/seq after 02950 batchs: 747.6548461914062
INFO:root:Train (Epoch 57): Loss/seq after 03000 batchs: 750.9298706054688
INFO:root:Train (Epoch 57): Loss/seq after 03050 batchs: 755.541748046875
INFO:root:Train (Epoch 57): Loss/seq after 03100 batchs: 762.4652099609375
INFO:root:Train (Epoch 57): Loss/seq after 03150 batchs: 767.5194702148438
INFO:root:Train (Epoch 57): Loss/seq after 03200 batchs: 772.1183471679688
INFO:root:Train (Epoch 57): Loss/seq after 03250 batchs: 776.0615844726562
INFO:root:Train (Epoch 57): Loss/seq after 03300 batchs: 774.7172241210938
INFO:root:Train (Epoch 57): Loss/seq after 03350 batchs: 774.5337524414062
INFO:root:Train (Epoch 57): Loss/seq after 03400 batchs: 768.0028076171875
INFO:root:Train (Epoch 57): Loss/seq after 03450 batchs: 764.7477416992188
INFO:root:Train (Epoch 57): Loss/seq after 03500 batchs: 765.0831298828125
INFO:root:Train (Epoch 57): Loss/seq after 03550 batchs: 761.7742309570312
INFO:root:Train (Epoch 57): Loss/seq after 03600 batchs: 770.6179809570312
INFO:root:Train (Epoch 57): Loss/seq after 03650 batchs: 767.3257446289062
INFO:root:Train (Epoch 57): Loss/seq after 03700 batchs: 768.7159423828125
INFO:root:Train (Epoch 57): Loss/seq after 03750 batchs: 772.8463745117188
INFO:root:Train (Epoch 57): Loss/seq after 03800 batchs: 768.5973510742188
INFO:root:Train (Epoch 57): Loss/seq after 03850 batchs: 767.4334716796875
INFO:root:Train (Epoch 57): Loss/seq after 03900 batchs: 770.6956787109375
INFO:root:Train (Epoch 57): Loss/seq after 03950 batchs: 773.3246459960938
INFO:root:Train (Epoch 57): Loss/seq after 04000 batchs: 768.7277221679688
INFO:root:Train (Epoch 57): Loss/seq after 04050 batchs: 763.4158935546875
INFO:root:Train (Epoch 57): Loss/seq after 04100 batchs: 760.9890747070312
INFO:root:Train (Epoch 57): Loss/seq after 04150 batchs: 759.52978515625
INFO:root:Train (Epoch 57): Loss/seq after 04200 batchs: 757.2542114257812
INFO:root:Train (Epoch 57): Loss/seq after 04250 batchs: 754.769287109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 57): Loss/seq after 00000 batches: 646.909423828125
INFO:root:# Valid (Epoch 57): Loss/seq after 00050 batches: 774.9229125976562
INFO:root:# Valid (Epoch 57): Loss/seq after 00100 batches: 884.2010498046875
INFO:root:# Valid (Epoch 57): Loss/seq after 00150 batches: 683.83984375
INFO:root:# Valid (Epoch 57): Loss/seq after 00200 batches: 646.7686157226562
INFO:root:Artifacts: Make stick videos for epoch 57
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_57_on_20220422_041505.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_57_index_1722_on_20220422_041505.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 58): Loss/seq after 00000 batchs: 1440.2958984375
INFO:root:Train (Epoch 58): Loss/seq after 00050 batchs: 1038.500244140625
INFO:root:Train (Epoch 58): Loss/seq after 00100 batchs: 1074.4334716796875
INFO:root:Train (Epoch 58): Loss/seq after 00150 batchs: 986.8687133789062
INFO:root:Train (Epoch 58): Loss/seq after 00200 batchs: 1082.52294921875
INFO:root:Train (Epoch 58): Loss/seq after 00250 batchs: 1192.3037109375
INFO:root:Train (Epoch 58): Loss/seq after 00300 batchs: 1156.62255859375
INFO:root:Train (Epoch 58): Loss/seq after 00350 batchs: 1073.3634033203125
INFO:root:Train (Epoch 58): Loss/seq after 00400 batchs: 1085.572021484375
INFO:root:Train (Epoch 58): Loss/seq after 00450 batchs: 1049.4404296875
INFO:root:Train (Epoch 58): Loss/seq after 00500 batchs: 1044.4586181640625
INFO:root:Train (Epoch 58): Loss/seq after 00550 batchs: 1010.3181762695312
INFO:root:Train (Epoch 58): Loss/seq after 00600 batchs: 974.2444458007812
INFO:root:Train (Epoch 58): Loss/seq after 00650 batchs: 952.8778686523438
INFO:root:Train (Epoch 58): Loss/seq after 00700 batchs: 919.6793823242188
INFO:root:Train (Epoch 58): Loss/seq after 00750 batchs: 935.2555541992188
INFO:root:Train (Epoch 58): Loss/seq after 00800 batchs: 936.669677734375
INFO:root:Train (Epoch 58): Loss/seq after 00850 batchs: 911.7453002929688
INFO:root:Train (Epoch 58): Loss/seq after 00900 batchs: 891.5628051757812
INFO:root:Train (Epoch 58): Loss/seq after 00950 batchs: 893.3263549804688
INFO:root:Train (Epoch 58): Loss/seq after 01000 batchs: 884.2036743164062
INFO:root:Train (Epoch 58): Loss/seq after 01050 batchs: 867.3187866210938
INFO:root:Train (Epoch 58): Loss/seq after 01100 batchs: 855.6024169921875
INFO:root:Train (Epoch 58): Loss/seq after 01150 batchs: 833.2293090820312
INFO:root:Train (Epoch 58): Loss/seq after 01200 batchs: 836.0057373046875
INFO:root:Train (Epoch 58): Loss/seq after 01250 batchs: 832.19287109375
INFO:root:Train (Epoch 58): Loss/seq after 01300 batchs: 815.9488525390625
INFO:root:Train (Epoch 58): Loss/seq after 01350 batchs: 803.3094482421875
INFO:root:Train (Epoch 58): Loss/seq after 01400 batchs: 812.81298828125
INFO:root:Train (Epoch 58): Loss/seq after 01450 batchs: 812.8804321289062
INFO:root:Train (Epoch 58): Loss/seq after 01500 batchs: 816.2330322265625
INFO:root:Train (Epoch 58): Loss/seq after 01550 batchs: 821.6339721679688
INFO:root:Train (Epoch 58): Loss/seq after 01600 batchs: 815.134765625
INFO:root:Train (Epoch 58): Loss/seq after 01650 batchs: 814.1455078125
INFO:root:Train (Epoch 58): Loss/seq after 01700 batchs: 813.9356689453125
INFO:root:Train (Epoch 58): Loss/seq after 01750 batchs: 809.642822265625
INFO:root:Train (Epoch 58): Loss/seq after 01800 batchs: 804.6888427734375
INFO:root:Train (Epoch 58): Loss/seq after 01850 batchs: 799.223388671875
INFO:root:Train (Epoch 58): Loss/seq after 01900 batchs: 803.4959716796875
INFO:root:Train (Epoch 58): Loss/seq after 01950 batchs: 801.9349975585938
INFO:root:Train (Epoch 58): Loss/seq after 02000 batchs: 798.7084350585938
INFO:root:Train (Epoch 58): Loss/seq after 02050 batchs: 796.2088623046875
INFO:root:Train (Epoch 58): Loss/seq after 02100 batchs: 791.1981201171875
INFO:root:Train (Epoch 58): Loss/seq after 02150 batchs: 787.4970703125
INFO:root:Train (Epoch 58): Loss/seq after 02200 batchs: 782.7205810546875
INFO:root:Train (Epoch 58): Loss/seq after 02250 batchs: 783.9063110351562
INFO:root:Train (Epoch 58): Loss/seq after 02300 batchs: 782.3080444335938
INFO:root:Train (Epoch 58): Loss/seq after 02350 batchs: 776.5374145507812
INFO:root:Train (Epoch 58): Loss/seq after 02400 batchs: 775.9269409179688
INFO:root:Train (Epoch 58): Loss/seq after 02450 batchs: 768.6176147460938
INFO:root:Train (Epoch 58): Loss/seq after 02500 batchs: 756.6217041015625
INFO:root:Train (Epoch 58): Loss/seq after 02550 batchs: 748.1822509765625
INFO:root:Train (Epoch 58): Loss/seq after 02600 batchs: 745.8826904296875
INFO:root:Train (Epoch 58): Loss/seq after 02650 batchs: 742.9056396484375
INFO:root:Train (Epoch 58): Loss/seq after 02700 batchs: 740.518798828125
INFO:root:Train (Epoch 58): Loss/seq after 02750 batchs: 743.4450073242188
INFO:root:Train (Epoch 58): Loss/seq after 02800 batchs: 744.9280395507812
INFO:root:Train (Epoch 58): Loss/seq after 02850 batchs: 745.1754760742188
INFO:root:Train (Epoch 58): Loss/seq after 02900 batchs: 746.5076293945312
INFO:root:Train (Epoch 58): Loss/seq after 02950 batchs: 744.3993530273438
INFO:root:Train (Epoch 58): Loss/seq after 03000 batchs: 747.7523803710938
INFO:root:Train (Epoch 58): Loss/seq after 03050 batchs: 752.5111694335938
INFO:root:Train (Epoch 58): Loss/seq after 03100 batchs: 759.874755859375
INFO:root:Train (Epoch 58): Loss/seq after 03150 batchs: 764.5281982421875
INFO:root:Train (Epoch 58): Loss/seq after 03200 batchs: 768.77294921875
INFO:root:Train (Epoch 58): Loss/seq after 03250 batchs: 772.73974609375
INFO:root:Train (Epoch 58): Loss/seq after 03300 batchs: 771.9266357421875
INFO:root:Train (Epoch 58): Loss/seq after 03350 batchs: 772.021240234375
INFO:root:Train (Epoch 58): Loss/seq after 03400 batchs: 765.4362182617188
INFO:root:Train (Epoch 58): Loss/seq after 03450 batchs: 762.3276977539062
INFO:root:Train (Epoch 58): Loss/seq after 03500 batchs: 762.80078125
INFO:root:Train (Epoch 58): Loss/seq after 03550 batchs: 759.8744506835938
INFO:root:Train (Epoch 58): Loss/seq after 03600 batchs: 768.7119750976562
INFO:root:Train (Epoch 58): Loss/seq after 03650 batchs: 765.1339111328125
INFO:root:Train (Epoch 58): Loss/seq after 03700 batchs: 766.7340087890625
INFO:root:Train (Epoch 58): Loss/seq after 03750 batchs: 770.7699584960938
INFO:root:Train (Epoch 58): Loss/seq after 03800 batchs: 766.59033203125
INFO:root:Train (Epoch 58): Loss/seq after 03850 batchs: 765.3840942382812
INFO:root:Train (Epoch 58): Loss/seq after 03900 batchs: 768.4613037109375
INFO:root:Train (Epoch 58): Loss/seq after 03950 batchs: 771.3864135742188
INFO:root:Train (Epoch 58): Loss/seq after 04000 batchs: 766.6674194335938
INFO:root:Train (Epoch 58): Loss/seq after 04050 batchs: 761.3457641601562
INFO:root:Train (Epoch 58): Loss/seq after 04100 batchs: 758.989990234375
INFO:root:Train (Epoch 58): Loss/seq after 04150 batchs: 757.4974365234375
INFO:root:Train (Epoch 58): Loss/seq after 04200 batchs: 755.2387084960938
INFO:root:Train (Epoch 58): Loss/seq after 04250 batchs: 752.7874145507812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 58): Loss/seq after 00000 batches: 602.4549560546875
INFO:root:# Valid (Epoch 58): Loss/seq after 00050 batches: 773.5845947265625
INFO:root:# Valid (Epoch 58): Loss/seq after 00100 batches: 892.443115234375
INFO:root:# Valid (Epoch 58): Loss/seq after 00150 batches: 692.1481323242188
INFO:root:# Valid (Epoch 58): Loss/seq after 00200 batches: 656.8331909179688
INFO:root:Artifacts: Make stick videos for epoch 58
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_58_on_20220422_042004.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_58_index_524_on_20220422_042004.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 59): Loss/seq after 00000 batchs: 1371.0865478515625
INFO:root:Train (Epoch 59): Loss/seq after 00050 batchs: 1022.8246459960938
INFO:root:Train (Epoch 59): Loss/seq after 00100 batchs: 1049.36962890625
INFO:root:Train (Epoch 59): Loss/seq after 00150 batchs: 973.2610473632812
INFO:root:Train (Epoch 59): Loss/seq after 00200 batchs: 1100.271484375
INFO:root:Train (Epoch 59): Loss/seq after 00250 batchs: 1211.3681640625
INFO:root:Train (Epoch 59): Loss/seq after 00300 batchs: 1171.3531494140625
INFO:root:Train (Epoch 59): Loss/seq after 00350 batchs: 1086.7034912109375
INFO:root:Train (Epoch 59): Loss/seq after 00400 batchs: 1093.3701171875
INFO:root:Train (Epoch 59): Loss/seq after 00450 batchs: 1055.797607421875
INFO:root:Train (Epoch 59): Loss/seq after 00500 batchs: 1047.5433349609375
INFO:root:Train (Epoch 59): Loss/seq after 00550 batchs: 1013.00341796875
INFO:root:Train (Epoch 59): Loss/seq after 00600 batchs: 979.8247680664062
INFO:root:Train (Epoch 59): Loss/seq after 00650 batchs: 955.9918212890625
INFO:root:Train (Epoch 59): Loss/seq after 00700 batchs: 920.8174438476562
INFO:root:Train (Epoch 59): Loss/seq after 00750 batchs: 937.0484008789062
INFO:root:Train (Epoch 59): Loss/seq after 00800 batchs: 938.956298828125
INFO:root:Train (Epoch 59): Loss/seq after 00850 batchs: 914.7887573242188
INFO:root:Train (Epoch 59): Loss/seq after 00900 batchs: 896.2172241210938
INFO:root:Train (Epoch 59): Loss/seq after 00950 batchs: 900.0394287109375
INFO:root:Train (Epoch 59): Loss/seq after 01000 batchs: 894.0927734375
INFO:root:Train (Epoch 59): Loss/seq after 01050 batchs: 877.4777221679688
INFO:root:Train (Epoch 59): Loss/seq after 01100 batchs: 867.802490234375
INFO:root:Train (Epoch 59): Loss/seq after 01150 batchs: 844.8970947265625
INFO:root:Train (Epoch 59): Loss/seq after 01200 batchs: 847.6680297851562
INFO:root:Train (Epoch 59): Loss/seq after 01250 batchs: 842.7700805664062
INFO:root:Train (Epoch 59): Loss/seq after 01300 batchs: 826.1546020507812
INFO:root:Train (Epoch 59): Loss/seq after 01350 batchs: 812.8984985351562
INFO:root:Train (Epoch 59): Loss/seq after 01400 batchs: 822.5482788085938
INFO:root:Train (Epoch 59): Loss/seq after 01450 batchs: 822.0479736328125
INFO:root:Train (Epoch 59): Loss/seq after 01500 batchs: 824.7860717773438
INFO:root:Train (Epoch 59): Loss/seq after 01550 batchs: 828.7853393554688
INFO:root:Train (Epoch 59): Loss/seq after 01600 batchs: 820.8718872070312
INFO:root:Train (Epoch 59): Loss/seq after 01650 batchs: 819.4063110351562
INFO:root:Train (Epoch 59): Loss/seq after 01700 batchs: 817.683349609375
INFO:root:Train (Epoch 59): Loss/seq after 01750 batchs: 812.5648803710938
INFO:root:Train (Epoch 59): Loss/seq after 01800 batchs: 807.177490234375
INFO:root:Train (Epoch 59): Loss/seq after 01850 batchs: 801.121826171875
INFO:root:Train (Epoch 59): Loss/seq after 01900 batchs: 803.888671875
INFO:root:Train (Epoch 59): Loss/seq after 01950 batchs: 801.98974609375
INFO:root:Train (Epoch 59): Loss/seq after 02000 batchs: 798.4318237304688
INFO:root:Train (Epoch 59): Loss/seq after 02050 batchs: 795.8949584960938
INFO:root:Train (Epoch 59): Loss/seq after 02100 batchs: 790.762451171875
INFO:root:Train (Epoch 59): Loss/seq after 02150 batchs: 787.15185546875
INFO:root:Train (Epoch 59): Loss/seq after 02200 batchs: 782.089111328125
INFO:root:Train (Epoch 59): Loss/seq after 02250 batchs: 783.5425415039062
INFO:root:Train (Epoch 59): Loss/seq after 02300 batchs: 782.1641235351562
INFO:root:Train (Epoch 59): Loss/seq after 02350 batchs: 776.1812744140625
INFO:root:Train (Epoch 59): Loss/seq after 02400 batchs: 775.1283569335938
INFO:root:Train (Epoch 59): Loss/seq after 02450 batchs: 767.7054443359375
INFO:root:Train (Epoch 59): Loss/seq after 02500 batchs: 755.726318359375
INFO:root:Train (Epoch 59): Loss/seq after 02550 batchs: 747.4180908203125
INFO:root:Train (Epoch 59): Loss/seq after 02600 batchs: 745.2796020507812
INFO:root:Train (Epoch 59): Loss/seq after 02650 batchs: 742.4251708984375
INFO:root:Train (Epoch 59): Loss/seq after 02700 batchs: 740.00439453125
INFO:root:Train (Epoch 59): Loss/seq after 02750 batchs: 743.517333984375
INFO:root:Train (Epoch 59): Loss/seq after 02800 batchs: 744.5418090820312
INFO:root:Train (Epoch 59): Loss/seq after 02850 batchs: 744.6627807617188
INFO:root:Train (Epoch 59): Loss/seq after 02900 batchs: 745.4463500976562
INFO:root:Train (Epoch 59): Loss/seq after 02950 batchs: 743.2592163085938
INFO:root:Train (Epoch 59): Loss/seq after 03000 batchs: 746.51025390625
INFO:root:Train (Epoch 59): Loss/seq after 03050 batchs: 750.4649047851562
INFO:root:Train (Epoch 59): Loss/seq after 03100 batchs: 757.1207275390625
INFO:root:Train (Epoch 59): Loss/seq after 03150 batchs: 762.2092895507812
INFO:root:Train (Epoch 59): Loss/seq after 03200 batchs: 766.4309692382812
INFO:root:Train (Epoch 59): Loss/seq after 03250 batchs: 770.5587158203125
INFO:root:Train (Epoch 59): Loss/seq after 03300 batchs: 770.1637573242188
INFO:root:Train (Epoch 59): Loss/seq after 03350 batchs: 769.8822631835938
INFO:root:Train (Epoch 59): Loss/seq after 03400 batchs: 763.4108276367188
INFO:root:Train (Epoch 59): Loss/seq after 03450 batchs: 760.3405151367188
INFO:root:Train (Epoch 59): Loss/seq after 03500 batchs: 761.1570434570312
INFO:root:Train (Epoch 59): Loss/seq after 03550 batchs: 757.94091796875
INFO:root:Train (Epoch 59): Loss/seq after 03600 batchs: 766.5868530273438
INFO:root:Train (Epoch 59): Loss/seq after 03650 batchs: 762.91748046875
INFO:root:Train (Epoch 59): Loss/seq after 03700 batchs: 764.2964477539062
INFO:root:Train (Epoch 59): Loss/seq after 03750 batchs: 768.2423095703125
INFO:root:Train (Epoch 59): Loss/seq after 03800 batchs: 764.0573120117188
INFO:root:Train (Epoch 59): Loss/seq after 03850 batchs: 762.8240966796875
INFO:root:Train (Epoch 59): Loss/seq after 03900 batchs: 766.543212890625
INFO:root:Train (Epoch 59): Loss/seq after 03950 batchs: 769.4948120117188
INFO:root:Train (Epoch 59): Loss/seq after 04000 batchs: 764.9291381835938
INFO:root:Train (Epoch 59): Loss/seq after 04050 batchs: 759.6372680664062
INFO:root:Train (Epoch 59): Loss/seq after 04100 batchs: 757.2172241210938
INFO:root:Train (Epoch 59): Loss/seq after 04150 batchs: 755.6708984375
INFO:root:Train (Epoch 59): Loss/seq after 04200 batchs: 753.41796875
INFO:root:Train (Epoch 59): Loss/seq after 04250 batchs: 750.9817504882812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 59): Loss/seq after 00000 batches: 743.0557250976562
INFO:root:# Valid (Epoch 59): Loss/seq after 00050 batches: 929.551513671875
INFO:root:# Valid (Epoch 59): Loss/seq after 00100 batches: 962.2105102539062
INFO:root:# Valid (Epoch 59): Loss/seq after 00150 batches: 731.8090209960938
INFO:root:# Valid (Epoch 59): Loss/seq after 00200 batches: 683.742919921875
INFO:root:Artifacts: Make stick videos for epoch 59
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_59_on_20220422_042459.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_59_index_1028_on_20220422_042459.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 60): Loss/seq after 00000 batchs: 1291.5313720703125
INFO:root:Train (Epoch 60): Loss/seq after 00050 batchs: 1014.2520751953125
INFO:root:Train (Epoch 60): Loss/seq after 00100 batchs: 1057.2777099609375
INFO:root:Train (Epoch 60): Loss/seq after 00150 batchs: 964.98046875
INFO:root:Train (Epoch 60): Loss/seq after 00200 batchs: 1065.7025146484375
INFO:root:Train (Epoch 60): Loss/seq after 00250 batchs: 1178.603759765625
INFO:root:Train (Epoch 60): Loss/seq after 00300 batchs: 1144.187744140625
INFO:root:Train (Epoch 60): Loss/seq after 00350 batchs: 1061.779296875
INFO:root:Train (Epoch 60): Loss/seq after 00400 batchs: 1068.1109619140625
INFO:root:Train (Epoch 60): Loss/seq after 00450 batchs: 1032.592529296875
INFO:root:Train (Epoch 60): Loss/seq after 00500 batchs: 1017.2176513671875
INFO:root:Train (Epoch 60): Loss/seq after 00550 batchs: 982.1996459960938
INFO:root:Train (Epoch 60): Loss/seq after 00600 batchs: 946.4730224609375
INFO:root:Train (Epoch 60): Loss/seq after 00650 batchs: 924.80517578125
INFO:root:Train (Epoch 60): Loss/seq after 00700 batchs: 892.1055908203125
INFO:root:Train (Epoch 60): Loss/seq after 00750 batchs: 907.9085083007812
INFO:root:Train (Epoch 60): Loss/seq after 00800 batchs: 909.7431640625
INFO:root:Train (Epoch 60): Loss/seq after 00850 batchs: 884.7068481445312
INFO:root:Train (Epoch 60): Loss/seq after 00900 batchs: 864.369140625
INFO:root:Train (Epoch 60): Loss/seq after 00950 batchs: 866.2601928710938
INFO:root:Train (Epoch 60): Loss/seq after 01000 batchs: 856.2191772460938
INFO:root:Train (Epoch 60): Loss/seq after 01050 batchs: 838.7069091796875
INFO:root:Train (Epoch 60): Loss/seq after 01100 batchs: 827.135009765625
INFO:root:Train (Epoch 60): Loss/seq after 01150 batchs: 805.1329345703125
INFO:root:Train (Epoch 60): Loss/seq after 01200 batchs: 808.122802734375
INFO:root:Train (Epoch 60): Loss/seq after 01250 batchs: 803.7581787109375
INFO:root:Train (Epoch 60): Loss/seq after 01300 batchs: 788.1015625
INFO:root:Train (Epoch 60): Loss/seq after 01350 batchs: 775.5905151367188
INFO:root:Train (Epoch 60): Loss/seq after 01400 batchs: 785.1364135742188
INFO:root:Train (Epoch 60): Loss/seq after 01450 batchs: 785.2221069335938
INFO:root:Train (Epoch 60): Loss/seq after 01500 batchs: 788.8892822265625
INFO:root:Train (Epoch 60): Loss/seq after 01550 batchs: 792.8836669921875
INFO:root:Train (Epoch 60): Loss/seq after 01600 batchs: 785.5599975585938
INFO:root:Train (Epoch 60): Loss/seq after 01650 batchs: 783.1268310546875
INFO:root:Train (Epoch 60): Loss/seq after 01700 batchs: 782.3735961914062
INFO:root:Train (Epoch 60): Loss/seq after 01750 batchs: 778.1474609375
INFO:root:Train (Epoch 60): Loss/seq after 01800 batchs: 773.7571411132812
INFO:root:Train (Epoch 60): Loss/seq after 01850 batchs: 768.5614013671875
INFO:root:Train (Epoch 60): Loss/seq after 01900 batchs: 771.4317016601562
INFO:root:Train (Epoch 60): Loss/seq after 01950 batchs: 770.5180053710938
INFO:root:Train (Epoch 60): Loss/seq after 02000 batchs: 768.6754150390625
INFO:root:Train (Epoch 60): Loss/seq after 02050 batchs: 766.6862182617188
INFO:root:Train (Epoch 60): Loss/seq after 02100 batchs: 762.1334228515625
INFO:root:Train (Epoch 60): Loss/seq after 02150 batchs: 759.2481079101562
INFO:root:Train (Epoch 60): Loss/seq after 02200 batchs: 754.847900390625
INFO:root:Train (Epoch 60): Loss/seq after 02250 batchs: 755.5855712890625
INFO:root:Train (Epoch 60): Loss/seq after 02300 batchs: 753.9151611328125
INFO:root:Train (Epoch 60): Loss/seq after 02350 batchs: 748.142333984375
INFO:root:Train (Epoch 60): Loss/seq after 02400 batchs: 747.5958251953125
INFO:root:Train (Epoch 60): Loss/seq after 02450 batchs: 740.63134765625
INFO:root:Train (Epoch 60): Loss/seq after 02500 batchs: 729.16259765625
INFO:root:Train (Epoch 60): Loss/seq after 02550 batchs: 721.2599487304688
INFO:root:Train (Epoch 60): Loss/seq after 02600 batchs: 719.32861328125
INFO:root:Train (Epoch 60): Loss/seq after 02650 batchs: 716.7908325195312
INFO:root:Train (Epoch 60): Loss/seq after 02700 batchs: 714.4647827148438
INFO:root:Train (Epoch 60): Loss/seq after 02750 batchs: 717.8716430664062
INFO:root:Train (Epoch 60): Loss/seq after 02800 batchs: 718.5678100585938
INFO:root:Train (Epoch 60): Loss/seq after 02850 batchs: 718.5767822265625
INFO:root:Train (Epoch 60): Loss/seq after 02900 batchs: 720.0890502929688
INFO:root:Train (Epoch 60): Loss/seq after 02950 batchs: 718.077880859375
INFO:root:Train (Epoch 60): Loss/seq after 03000 batchs: 721.7403564453125
INFO:root:Train (Epoch 60): Loss/seq after 03050 batchs: 725.8305053710938
INFO:root:Train (Epoch 60): Loss/seq after 03100 batchs: 732.9334716796875
INFO:root:Train (Epoch 60): Loss/seq after 03150 batchs: 738.4931030273438
INFO:root:Train (Epoch 60): Loss/seq after 03200 batchs: 742.657958984375
INFO:root:Train (Epoch 60): Loss/seq after 03250 batchs: 746.9885864257812
INFO:root:Train (Epoch 60): Loss/seq after 03300 batchs: 746.287353515625
INFO:root:Train (Epoch 60): Loss/seq after 03350 batchs: 746.5543212890625
INFO:root:Train (Epoch 60): Loss/seq after 03400 batchs: 740.508544921875
INFO:root:Train (Epoch 60): Loss/seq after 03450 batchs: 737.778076171875
INFO:root:Train (Epoch 60): Loss/seq after 03500 batchs: 739.3076782226562
INFO:root:Train (Epoch 60): Loss/seq after 03550 batchs: 736.7521362304688
INFO:root:Train (Epoch 60): Loss/seq after 03600 batchs: 745.92333984375
INFO:root:Train (Epoch 60): Loss/seq after 03650 batchs: 742.7164916992188
INFO:root:Train (Epoch 60): Loss/seq after 03700 batchs: 744.3131103515625
INFO:root:Train (Epoch 60): Loss/seq after 03750 batchs: 748.4109497070312
INFO:root:Train (Epoch 60): Loss/seq after 03800 batchs: 744.4048461914062
INFO:root:Train (Epoch 60): Loss/seq after 03850 batchs: 743.400146484375
INFO:root:Train (Epoch 60): Loss/seq after 03900 batchs: 746.5964965820312
INFO:root:Train (Epoch 60): Loss/seq after 03950 batchs: 749.5907592773438
INFO:root:Train (Epoch 60): Loss/seq after 04000 batchs: 745.140869140625
INFO:root:Train (Epoch 60): Loss/seq after 04050 batchs: 740.079833984375
INFO:root:Train (Epoch 60): Loss/seq after 04100 batchs: 737.8781127929688
INFO:root:Train (Epoch 60): Loss/seq after 04150 batchs: 736.5187377929688
INFO:root:Train (Epoch 60): Loss/seq after 04200 batchs: 734.54736328125
INFO:root:Train (Epoch 60): Loss/seq after 04250 batchs: 732.120361328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 60): Loss/seq after 00000 batches: 685.4478759765625
INFO:root:# Valid (Epoch 60): Loss/seq after 00050 batches: 779.2186279296875
INFO:root:# Valid (Epoch 60): Loss/seq after 00100 batches: 865.2120971679688
INFO:root:# Valid (Epoch 60): Loss/seq after 00150 batches: 663.5464477539062
INFO:root:# Valid (Epoch 60): Loss/seq after 00200 batches: 627.4667358398438
INFO:root:Artifacts: Make stick videos for epoch 60
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_60_on_20220422_042949.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_60_index_342_on_20220422_042949.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 61): Loss/seq after 00000 batchs: 1284.672607421875
INFO:root:Train (Epoch 61): Loss/seq after 00050 batchs: 1013.4397583007812
INFO:root:Train (Epoch 61): Loss/seq after 00100 batchs: 1061.672119140625
INFO:root:Train (Epoch 61): Loss/seq after 00150 batchs: 977.591796875
INFO:root:Train (Epoch 61): Loss/seq after 00200 batchs: 1075.3280029296875
INFO:root:Train (Epoch 61): Loss/seq after 00250 batchs: 1189.3958740234375
INFO:root:Train (Epoch 61): Loss/seq after 00300 batchs: 1153.5322265625
INFO:root:Train (Epoch 61): Loss/seq after 00350 batchs: 1071.219482421875
INFO:root:Train (Epoch 61): Loss/seq after 00400 batchs: 1077.2120361328125
INFO:root:Train (Epoch 61): Loss/seq after 00450 batchs: 1040.7454833984375
INFO:root:Train (Epoch 61): Loss/seq after 00500 batchs: 1027.7154541015625
INFO:root:Train (Epoch 61): Loss/seq after 00550 batchs: 991.4675903320312
INFO:root:Train (Epoch 61): Loss/seq after 00600 batchs: 954.898681640625
INFO:root:Train (Epoch 61): Loss/seq after 00650 batchs: 931.6224975585938
INFO:root:Train (Epoch 61): Loss/seq after 00700 batchs: 897.2928466796875
INFO:root:Train (Epoch 61): Loss/seq after 00750 batchs: 911.87548828125
INFO:root:Train (Epoch 61): Loss/seq after 00800 batchs: 914.5610961914062
INFO:root:Train (Epoch 61): Loss/seq after 00850 batchs: 889.0650024414062
INFO:root:Train (Epoch 61): Loss/seq after 00900 batchs: 867.788818359375
INFO:root:Train (Epoch 61): Loss/seq after 00950 batchs: 869.2018432617188
INFO:root:Train (Epoch 61): Loss/seq after 01000 batchs: 859.8736572265625
INFO:root:Train (Epoch 61): Loss/seq after 01050 batchs: 841.4658203125
INFO:root:Train (Epoch 61): Loss/seq after 01100 batchs: 830.0762939453125
INFO:root:Train (Epoch 61): Loss/seq after 01150 batchs: 808.5844116210938
INFO:root:Train (Epoch 61): Loss/seq after 01200 batchs: 811.732421875
INFO:root:Train (Epoch 61): Loss/seq after 01250 batchs: 807.9365234375
INFO:root:Train (Epoch 61): Loss/seq after 01300 batchs: 792.0274047851562
INFO:root:Train (Epoch 61): Loss/seq after 01350 batchs: 779.4754638671875
INFO:root:Train (Epoch 61): Loss/seq after 01400 batchs: 788.1300659179688
INFO:root:Train (Epoch 61): Loss/seq after 01450 batchs: 788.4280395507812
INFO:root:Train (Epoch 61): Loss/seq after 01500 batchs: 792.4085693359375
INFO:root:Train (Epoch 61): Loss/seq after 01550 batchs: 797.0904541015625
INFO:root:Train (Epoch 61): Loss/seq after 01600 batchs: 789.9166259765625
INFO:root:Train (Epoch 61): Loss/seq after 01650 batchs: 787.9414672851562
INFO:root:Train (Epoch 61): Loss/seq after 01700 batchs: 787.6171875
INFO:root:Train (Epoch 61): Loss/seq after 01750 batchs: 783.4730224609375
INFO:root:Train (Epoch 61): Loss/seq after 01800 batchs: 778.8383178710938
INFO:root:Train (Epoch 61): Loss/seq after 01850 batchs: 773.4421997070312
INFO:root:Train (Epoch 61): Loss/seq after 01900 batchs: 775.9255981445312
INFO:root:Train (Epoch 61): Loss/seq after 01950 batchs: 774.2509765625
INFO:root:Train (Epoch 61): Loss/seq after 02000 batchs: 771.3712158203125
INFO:root:Train (Epoch 61): Loss/seq after 02050 batchs: 769.129638671875
INFO:root:Train (Epoch 61): Loss/seq after 02100 batchs: 764.906494140625
INFO:root:Train (Epoch 61): Loss/seq after 02150 batchs: 762.0131225585938
INFO:root:Train (Epoch 61): Loss/seq after 02200 batchs: 757.4210205078125
INFO:root:Train (Epoch 61): Loss/seq after 02250 batchs: 758.1414184570312
INFO:root:Train (Epoch 61): Loss/seq after 02300 batchs: 757.0516357421875
INFO:root:Train (Epoch 61): Loss/seq after 02350 batchs: 751.5219116210938
INFO:root:Train (Epoch 61): Loss/seq after 02400 batchs: 751.3382568359375
INFO:root:Train (Epoch 61): Loss/seq after 02450 batchs: 744.3287963867188
INFO:root:Train (Epoch 61): Loss/seq after 02500 batchs: 732.8281860351562
INFO:root:Train (Epoch 61): Loss/seq after 02550 batchs: 725.0164184570312
INFO:root:Train (Epoch 61): Loss/seq after 02600 batchs: 723.05126953125
INFO:root:Train (Epoch 61): Loss/seq after 02650 batchs: 720.2735595703125
INFO:root:Train (Epoch 61): Loss/seq after 02700 batchs: 717.9390258789062
INFO:root:Train (Epoch 61): Loss/seq after 02750 batchs: 719.8997192382812
INFO:root:Train (Epoch 61): Loss/seq after 02800 batchs: 721.0110473632812
INFO:root:Train (Epoch 61): Loss/seq after 02850 batchs: 721.1264038085938
INFO:root:Train (Epoch 61): Loss/seq after 02900 batchs: 723.0184936523438
INFO:root:Train (Epoch 61): Loss/seq after 02950 batchs: 721.114013671875
INFO:root:Train (Epoch 61): Loss/seq after 03000 batchs: 724.7632446289062
INFO:root:Train (Epoch 61): Loss/seq after 03050 batchs: 728.333251953125
INFO:root:Train (Epoch 61): Loss/seq after 03100 batchs: 734.7482299804688
INFO:root:Train (Epoch 61): Loss/seq after 03150 batchs: 739.6758422851562
INFO:root:Train (Epoch 61): Loss/seq after 03200 batchs: 743.7695922851562
INFO:root:Train (Epoch 61): Loss/seq after 03250 batchs: 748.0204467773438
INFO:root:Train (Epoch 61): Loss/seq after 03300 batchs: 747.3564453125
INFO:root:Train (Epoch 61): Loss/seq after 03350 batchs: 748.125732421875
INFO:root:Train (Epoch 61): Loss/seq after 03400 batchs: 741.9329833984375
INFO:root:Train (Epoch 61): Loss/seq after 03450 batchs: 739.1986694335938
INFO:root:Train (Epoch 61): Loss/seq after 03500 batchs: 740.3599243164062
INFO:root:Train (Epoch 61): Loss/seq after 03550 batchs: 737.1734619140625
INFO:root:Train (Epoch 61): Loss/seq after 03600 batchs: 746.5610961914062
INFO:root:Train (Epoch 61): Loss/seq after 03650 batchs: 742.9697875976562
INFO:root:Train (Epoch 61): Loss/seq after 03700 batchs: 744.4080810546875
INFO:root:Train (Epoch 61): Loss/seq after 03750 batchs: 748.558837890625
INFO:root:Train (Epoch 61): Loss/seq after 03800 batchs: 744.5199584960938
INFO:root:Train (Epoch 61): Loss/seq after 03850 batchs: 743.4383544921875
INFO:root:Train (Epoch 61): Loss/seq after 03900 batchs: 746.4426879882812
INFO:root:Train (Epoch 61): Loss/seq after 03950 batchs: 749.0689086914062
INFO:root:Train (Epoch 61): Loss/seq after 04000 batchs: 744.579345703125
INFO:root:Train (Epoch 61): Loss/seq after 04050 batchs: 739.4110107421875
INFO:root:Train (Epoch 61): Loss/seq after 04100 batchs: 736.882080078125
INFO:root:Train (Epoch 61): Loss/seq after 04150 batchs: 735.527587890625
INFO:root:Train (Epoch 61): Loss/seq after 04200 batchs: 733.4389038085938
INFO:root:Train (Epoch 61): Loss/seq after 04250 batchs: 731.0653076171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 61): Loss/seq after 00000 batches: 697.687255859375
INFO:root:# Valid (Epoch 61): Loss/seq after 00050 batches: 848.1793212890625
INFO:root:# Valid (Epoch 61): Loss/seq after 00100 batches: 915.6446533203125
INFO:root:# Valid (Epoch 61): Loss/seq after 00150 batches: 702.2091064453125
INFO:root:# Valid (Epoch 61): Loss/seq after 00200 batches: 660.4736938476562
INFO:root:Artifacts: Make stick videos for epoch 61
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_61_on_20220422_043432.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_61_index_346_on_20220422_043432.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 62): Loss/seq after 00000 batchs: 1312.2320556640625
INFO:root:Train (Epoch 62): Loss/seq after 00050 batchs: 1020.9676513671875
INFO:root:Train (Epoch 62): Loss/seq after 00100 batchs: 1063.2012939453125
INFO:root:Train (Epoch 62): Loss/seq after 00150 batchs: 976.0607299804688
INFO:root:Train (Epoch 62): Loss/seq after 00200 batchs: 1078.7655029296875
INFO:root:Train (Epoch 62): Loss/seq after 00250 batchs: 1193.1160888671875
INFO:root:Train (Epoch 62): Loss/seq after 00300 batchs: 1156.19482421875
INFO:root:Train (Epoch 62): Loss/seq after 00350 batchs: 1073.41259765625
INFO:root:Train (Epoch 62): Loss/seq after 00400 batchs: 1079.8853759765625
INFO:root:Train (Epoch 62): Loss/seq after 00450 batchs: 1042.5059814453125
INFO:root:Train (Epoch 62): Loss/seq after 00500 batchs: 1027.8172607421875
INFO:root:Train (Epoch 62): Loss/seq after 00550 batchs: 990.1002807617188
INFO:root:Train (Epoch 62): Loss/seq after 00600 batchs: 951.34033203125
INFO:root:Train (Epoch 62): Loss/seq after 00650 batchs: 926.7662353515625
INFO:root:Train (Epoch 62): Loss/seq after 00700 batchs: 892.7271118164062
INFO:root:Train (Epoch 62): Loss/seq after 00750 batchs: 907.2974853515625
INFO:root:Train (Epoch 62): Loss/seq after 00800 batchs: 907.2130126953125
INFO:root:Train (Epoch 62): Loss/seq after 00850 batchs: 881.2637329101562
INFO:root:Train (Epoch 62): Loss/seq after 00900 batchs: 862.015869140625
INFO:root:Train (Epoch 62): Loss/seq after 00950 batchs: 865.0167846679688
INFO:root:Train (Epoch 62): Loss/seq after 01000 batchs: 856.3602905273438
INFO:root:Train (Epoch 62): Loss/seq after 01050 batchs: 843.6094360351562
INFO:root:Train (Epoch 62): Loss/seq after 01100 batchs: 830.7964477539062
INFO:root:Train (Epoch 62): Loss/seq after 01150 batchs: 808.62548828125
INFO:root:Train (Epoch 62): Loss/seq after 01200 batchs: 811.3258056640625
INFO:root:Train (Epoch 62): Loss/seq after 01250 batchs: 806.621337890625
INFO:root:Train (Epoch 62): Loss/seq after 01300 batchs: 789.9298706054688
INFO:root:Train (Epoch 62): Loss/seq after 01350 batchs: 777.461669921875
INFO:root:Train (Epoch 62): Loss/seq after 01400 batchs: 785.5977783203125
INFO:root:Train (Epoch 62): Loss/seq after 01450 batchs: 785.525146484375
INFO:root:Train (Epoch 62): Loss/seq after 01500 batchs: 789.3536376953125
INFO:root:Train (Epoch 62): Loss/seq after 01550 batchs: 793.254150390625
INFO:root:Train (Epoch 62): Loss/seq after 01600 batchs: 786.19140625
INFO:root:Train (Epoch 62): Loss/seq after 01650 batchs: 783.5542602539062
INFO:root:Train (Epoch 62): Loss/seq after 01700 batchs: 782.5496826171875
INFO:root:Train (Epoch 62): Loss/seq after 01750 batchs: 777.8844604492188
INFO:root:Train (Epoch 62): Loss/seq after 01800 batchs: 773.3099975585938
INFO:root:Train (Epoch 62): Loss/seq after 01850 batchs: 767.8801879882812
INFO:root:Train (Epoch 62): Loss/seq after 01900 batchs: 769.3023071289062
INFO:root:Train (Epoch 62): Loss/seq after 01950 batchs: 767.458740234375
INFO:root:Train (Epoch 62): Loss/seq after 02000 batchs: 766.0469360351562
INFO:root:Train (Epoch 62): Loss/seq after 02050 batchs: 764.0689697265625
INFO:root:Train (Epoch 62): Loss/seq after 02100 batchs: 759.3607788085938
INFO:root:Train (Epoch 62): Loss/seq after 02150 batchs: 755.9210815429688
INFO:root:Train (Epoch 62): Loss/seq after 02200 batchs: 751.2340087890625
INFO:root:Train (Epoch 62): Loss/seq after 02250 batchs: 752.4930419921875
INFO:root:Train (Epoch 62): Loss/seq after 02300 batchs: 751.9976196289062
INFO:root:Train (Epoch 62): Loss/seq after 02350 batchs: 746.6356201171875
INFO:root:Train (Epoch 62): Loss/seq after 02400 batchs: 746.6790161132812
INFO:root:Train (Epoch 62): Loss/seq after 02450 batchs: 739.626953125
INFO:root:Train (Epoch 62): Loss/seq after 02500 batchs: 728.1695556640625
INFO:root:Train (Epoch 62): Loss/seq after 02550 batchs: 720.2698974609375
INFO:root:Train (Epoch 62): Loss/seq after 02600 batchs: 717.8920288085938
INFO:root:Train (Epoch 62): Loss/seq after 02650 batchs: 714.7845458984375
INFO:root:Train (Epoch 62): Loss/seq after 02700 batchs: 712.3026733398438
INFO:root:Train (Epoch 62): Loss/seq after 02750 batchs: 714.8406372070312
INFO:root:Train (Epoch 62): Loss/seq after 02800 batchs: 715.74755859375
INFO:root:Train (Epoch 62): Loss/seq after 02850 batchs: 716.239990234375
INFO:root:Train (Epoch 62): Loss/seq after 02900 batchs: 717.402099609375
INFO:root:Train (Epoch 62): Loss/seq after 02950 batchs: 715.4556884765625
INFO:root:Train (Epoch 62): Loss/seq after 03000 batchs: 719.1373901367188
INFO:root:Train (Epoch 62): Loss/seq after 03050 batchs: 725.9391479492188
INFO:root:Train (Epoch 62): Loss/seq after 03100 batchs: 732.1380004882812
INFO:root:Train (Epoch 62): Loss/seq after 03150 batchs: 737.4674682617188
INFO:root:Train (Epoch 62): Loss/seq after 03200 batchs: 741.6670532226562
INFO:root:Train (Epoch 62): Loss/seq after 03250 batchs: 745.9539184570312
INFO:root:Train (Epoch 62): Loss/seq after 03300 batchs: 745.0462036132812
INFO:root:Train (Epoch 62): Loss/seq after 03350 batchs: 744.8225708007812
INFO:root:Train (Epoch 62): Loss/seq after 03400 batchs: 738.5908813476562
INFO:root:Train (Epoch 62): Loss/seq after 03450 batchs: 735.4719848632812
INFO:root:Train (Epoch 62): Loss/seq after 03500 batchs: 736.2005004882812
INFO:root:Train (Epoch 62): Loss/seq after 03550 batchs: 732.9229125976562
INFO:root:Train (Epoch 62): Loss/seq after 03600 batchs: 742.0789794921875
INFO:root:Train (Epoch 62): Loss/seq after 03650 batchs: 738.6451416015625
INFO:root:Train (Epoch 62): Loss/seq after 03700 batchs: 740.3548583984375
INFO:root:Train (Epoch 62): Loss/seq after 03750 batchs: 744.4443359375
INFO:root:Train (Epoch 62): Loss/seq after 03800 batchs: 740.4336547851562
INFO:root:Train (Epoch 62): Loss/seq after 03850 batchs: 739.327392578125
INFO:root:Train (Epoch 62): Loss/seq after 03900 batchs: 742.3805541992188
INFO:root:Train (Epoch 62): Loss/seq after 03950 batchs: 745.0013427734375
INFO:root:Train (Epoch 62): Loss/seq after 04000 batchs: 740.2496337890625
INFO:root:Train (Epoch 62): Loss/seq after 04050 batchs: 735.1409301757812
INFO:root:Train (Epoch 62): Loss/seq after 04100 batchs: 732.6580810546875
INFO:root:Train (Epoch 62): Loss/seq after 04150 batchs: 731.34228515625
INFO:root:Train (Epoch 62): Loss/seq after 04200 batchs: 729.2340087890625
INFO:root:Train (Epoch 62): Loss/seq after 04250 batchs: 726.8732299804688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 62): Loss/seq after 00000 batches: 641.3015747070312
INFO:root:# Valid (Epoch 62): Loss/seq after 00050 batches: 777.256103515625
INFO:root:# Valid (Epoch 62): Loss/seq after 00100 batches: 862.3931884765625
INFO:root:# Valid (Epoch 62): Loss/seq after 00150 batches: 664.029052734375
INFO:root:# Valid (Epoch 62): Loss/seq after 00200 batches: 628.705322265625
INFO:root:Artifacts: Make stick videos for epoch 62
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_62_on_20220422_043916.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_62_index_1145_on_20220422_043916.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 63): Loss/seq after 00000 batchs: 1263.1268310546875
INFO:root:Train (Epoch 63): Loss/seq after 00050 batchs: 998.2402954101562
INFO:root:Train (Epoch 63): Loss/seq after 00100 batchs: 1065.0711669921875
INFO:root:Train (Epoch 63): Loss/seq after 00150 batchs: 970.279296875
INFO:root:Train (Epoch 63): Loss/seq after 00200 batchs: 1063.5224609375
INFO:root:Train (Epoch 63): Loss/seq after 00250 batchs: 1174.0213623046875
INFO:root:Train (Epoch 63): Loss/seq after 00300 batchs: 1139.7772216796875
INFO:root:Train (Epoch 63): Loss/seq after 00350 batchs: 1057.0498046875
INFO:root:Train (Epoch 63): Loss/seq after 00400 batchs: 1059.5018310546875
INFO:root:Train (Epoch 63): Loss/seq after 00450 batchs: 1023.31103515625
INFO:root:Train (Epoch 63): Loss/seq after 00500 batchs: 1008.3290405273438
INFO:root:Train (Epoch 63): Loss/seq after 00550 batchs: 973.6884155273438
INFO:root:Train (Epoch 63): Loss/seq after 00600 batchs: 937.6278076171875
INFO:root:Train (Epoch 63): Loss/seq after 00650 batchs: 915.640380859375
INFO:root:Train (Epoch 63): Loss/seq after 00700 batchs: 884.1572265625
INFO:root:Train (Epoch 63): Loss/seq after 00750 batchs: 898.2606201171875
INFO:root:Train (Epoch 63): Loss/seq after 00800 batchs: 900.6376953125
INFO:root:Train (Epoch 63): Loss/seq after 00850 batchs: 876.2900390625
INFO:root:Train (Epoch 63): Loss/seq after 00900 batchs: 857.0279541015625
INFO:root:Train (Epoch 63): Loss/seq after 00950 batchs: 857.5869140625
INFO:root:Train (Epoch 63): Loss/seq after 01000 batchs: 846.8712158203125
INFO:root:Train (Epoch 63): Loss/seq after 01050 batchs: 831.1483764648438
INFO:root:Train (Epoch 63): Loss/seq after 01100 batchs: 817.1472778320312
INFO:root:Train (Epoch 63): Loss/seq after 01150 batchs: 795.2421875
INFO:root:Train (Epoch 63): Loss/seq after 01200 batchs: 797.8367309570312
INFO:root:Train (Epoch 63): Loss/seq after 01250 batchs: 793.0084228515625
INFO:root:Train (Epoch 63): Loss/seq after 01300 batchs: 777.4752807617188
INFO:root:Train (Epoch 63): Loss/seq after 01350 batchs: 765.0284423828125
INFO:root:Train (Epoch 63): Loss/seq after 01400 batchs: 773.0296020507812
INFO:root:Train (Epoch 63): Loss/seq after 01450 batchs: 773.03076171875
INFO:root:Train (Epoch 63): Loss/seq after 01500 batchs: 777.3502807617188
INFO:root:Train (Epoch 63): Loss/seq after 01550 batchs: 780.5836181640625
INFO:root:Train (Epoch 63): Loss/seq after 01600 batchs: 773.444580078125
INFO:root:Train (Epoch 63): Loss/seq after 01650 batchs: 770.5208129882812
INFO:root:Train (Epoch 63): Loss/seq after 01700 batchs: 770.208984375
INFO:root:Train (Epoch 63): Loss/seq after 01750 batchs: 766.2188110351562
INFO:root:Train (Epoch 63): Loss/seq after 01800 batchs: 761.9114990234375
INFO:root:Train (Epoch 63): Loss/seq after 01850 batchs: 756.6406860351562
INFO:root:Train (Epoch 63): Loss/seq after 01900 batchs: 758.8820190429688
INFO:root:Train (Epoch 63): Loss/seq after 01950 batchs: 757.5987548828125
INFO:root:Train (Epoch 63): Loss/seq after 02000 batchs: 754.9795532226562
INFO:root:Train (Epoch 63): Loss/seq after 02050 batchs: 752.6963500976562
INFO:root:Train (Epoch 63): Loss/seq after 02100 batchs: 748.2770385742188
INFO:root:Train (Epoch 63): Loss/seq after 02150 batchs: 745.0673217773438
INFO:root:Train (Epoch 63): Loss/seq after 02200 batchs: 740.6091918945312
INFO:root:Train (Epoch 63): Loss/seq after 02250 batchs: 741.1077880859375
INFO:root:Train (Epoch 63): Loss/seq after 02300 batchs: 739.6825561523438
INFO:root:Train (Epoch 63): Loss/seq after 02350 batchs: 735.1953735351562
INFO:root:Train (Epoch 63): Loss/seq after 02400 batchs: 735.0407104492188
INFO:root:Train (Epoch 63): Loss/seq after 02450 batchs: 728.33935546875
INFO:root:Train (Epoch 63): Loss/seq after 02500 batchs: 717.1212158203125
INFO:root:Train (Epoch 63): Loss/seq after 02550 batchs: 709.3295288085938
INFO:root:Train (Epoch 63): Loss/seq after 02600 batchs: 707.205322265625
INFO:root:Train (Epoch 63): Loss/seq after 02650 batchs: 704.2207641601562
INFO:root:Train (Epoch 63): Loss/seq after 02700 batchs: 701.811279296875
INFO:root:Train (Epoch 63): Loss/seq after 02750 batchs: 705.87255859375
INFO:root:Train (Epoch 63): Loss/seq after 02800 batchs: 706.8798828125
INFO:root:Train (Epoch 63): Loss/seq after 02850 batchs: 707.1843872070312
INFO:root:Train (Epoch 63): Loss/seq after 02900 batchs: 708.362548828125
INFO:root:Train (Epoch 63): Loss/seq after 02950 batchs: 706.4437255859375
INFO:root:Train (Epoch 63): Loss/seq after 03000 batchs: 710.2111206054688
INFO:root:Train (Epoch 63): Loss/seq after 03050 batchs: 714.5176391601562
INFO:root:Train (Epoch 63): Loss/seq after 03100 batchs: 720.5403442382812
INFO:root:Train (Epoch 63): Loss/seq after 03150 batchs: 725.2062377929688
INFO:root:Train (Epoch 63): Loss/seq after 03200 batchs: 729.3138427734375
INFO:root:Train (Epoch 63): Loss/seq after 03250 batchs: 733.78515625
INFO:root:Train (Epoch 63): Loss/seq after 03300 batchs: 732.77392578125
INFO:root:Train (Epoch 63): Loss/seq after 03350 batchs: 732.2807006835938
INFO:root:Train (Epoch 63): Loss/seq after 03400 batchs: 726.1153564453125
INFO:root:Train (Epoch 63): Loss/seq after 03450 batchs: 723.337890625
INFO:root:Train (Epoch 63): Loss/seq after 03500 batchs: 724.1185302734375
INFO:root:Train (Epoch 63): Loss/seq after 03550 batchs: 721.0338745117188
INFO:root:Train (Epoch 63): Loss/seq after 03600 batchs: 729.6239624023438
INFO:root:Train (Epoch 63): Loss/seq after 03650 batchs: 726.2844848632812
INFO:root:Train (Epoch 63): Loss/seq after 03700 batchs: 728.6365356445312
INFO:root:Train (Epoch 63): Loss/seq after 03750 batchs: 732.8946533203125
INFO:root:Train (Epoch 63): Loss/seq after 03800 batchs: 729.1220703125
INFO:root:Train (Epoch 63): Loss/seq after 03850 batchs: 728.120849609375
INFO:root:Train (Epoch 63): Loss/seq after 03900 batchs: 731.7141723632812
INFO:root:Train (Epoch 63): Loss/seq after 03950 batchs: 734.830322265625
INFO:root:Train (Epoch 63): Loss/seq after 04000 batchs: 730.23681640625
INFO:root:Train (Epoch 63): Loss/seq after 04050 batchs: 725.216552734375
INFO:root:Train (Epoch 63): Loss/seq after 04100 batchs: 722.9844970703125
INFO:root:Train (Epoch 63): Loss/seq after 04150 batchs: 721.7393798828125
INFO:root:Train (Epoch 63): Loss/seq after 04200 batchs: 719.5927124023438
INFO:root:Train (Epoch 63): Loss/seq after 04250 batchs: 717.3102416992188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 63): Loss/seq after 00000 batches: 570.037353515625
INFO:root:# Valid (Epoch 63): Loss/seq after 00050 batches: 744.3994750976562
INFO:root:# Valid (Epoch 63): Loss/seq after 00100 batches: 861.8654174804688
INFO:root:# Valid (Epoch 63): Loss/seq after 00150 batches: 661.658447265625
INFO:root:# Valid (Epoch 63): Loss/seq after 00200 batches: 626.4993896484375
INFO:root:Artifacts: Make stick videos for epoch 63
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_63_on_20220422_044418.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_63_index_1700_on_20220422_044418.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 64): Loss/seq after 00000 batchs: 1350.38330078125
INFO:root:Train (Epoch 64): Loss/seq after 00050 batchs: 1024.426025390625
INFO:root:Train (Epoch 64): Loss/seq after 00100 batchs: 1069.96142578125
INFO:root:Train (Epoch 64): Loss/seq after 00150 batchs: 968.9227294921875
INFO:root:Train (Epoch 64): Loss/seq after 00200 batchs: 1065.177001953125
INFO:root:Train (Epoch 64): Loss/seq after 00250 batchs: 1180.4185791015625
INFO:root:Train (Epoch 64): Loss/seq after 00300 batchs: 1144.355712890625
INFO:root:Train (Epoch 64): Loss/seq after 00350 batchs: 1060.2451171875
INFO:root:Train (Epoch 64): Loss/seq after 00400 batchs: 1065.098876953125
INFO:root:Train (Epoch 64): Loss/seq after 00450 batchs: 1028.787841796875
INFO:root:Train (Epoch 64): Loss/seq after 00500 batchs: 1008.875244140625
INFO:root:Train (Epoch 64): Loss/seq after 00550 batchs: 972.0308837890625
INFO:root:Train (Epoch 64): Loss/seq after 00600 batchs: 934.1885375976562
INFO:root:Train (Epoch 64): Loss/seq after 00650 batchs: 910.3627319335938
INFO:root:Train (Epoch 64): Loss/seq after 00700 batchs: 875.640380859375
INFO:root:Train (Epoch 64): Loss/seq after 00750 batchs: 888.7810668945312
INFO:root:Train (Epoch 64): Loss/seq after 00800 batchs: 889.1561279296875
INFO:root:Train (Epoch 64): Loss/seq after 00850 batchs: 864.614501953125
INFO:root:Train (Epoch 64): Loss/seq after 00900 batchs: 846.324462890625
INFO:root:Train (Epoch 64): Loss/seq after 00950 batchs: 847.7357177734375
INFO:root:Train (Epoch 64): Loss/seq after 01000 batchs: 839.0184936523438
INFO:root:Train (Epoch 64): Loss/seq after 01050 batchs: 825.0709838867188
INFO:root:Train (Epoch 64): Loss/seq after 01100 batchs: 812.974609375
INFO:root:Train (Epoch 64): Loss/seq after 01150 batchs: 791.5951538085938
INFO:root:Train (Epoch 64): Loss/seq after 01200 batchs: 794.5231323242188
INFO:root:Train (Epoch 64): Loss/seq after 01250 batchs: 789.9690551757812
INFO:root:Train (Epoch 64): Loss/seq after 01300 batchs: 774.0255737304688
INFO:root:Train (Epoch 64): Loss/seq after 01350 batchs: 761.5764770507812
INFO:root:Train (Epoch 64): Loss/seq after 01400 batchs: 769.8005981445312
INFO:root:Train (Epoch 64): Loss/seq after 01450 batchs: 769.8760375976562
INFO:root:Train (Epoch 64): Loss/seq after 01500 batchs: 774.1073608398438
INFO:root:Train (Epoch 64): Loss/seq after 01550 batchs: 777.1560668945312
INFO:root:Train (Epoch 64): Loss/seq after 01600 batchs: 769.8516235351562
INFO:root:Train (Epoch 64): Loss/seq after 01650 batchs: 766.513916015625
INFO:root:Train (Epoch 64): Loss/seq after 01700 batchs: 765.9364013671875
INFO:root:Train (Epoch 64): Loss/seq after 01750 batchs: 761.8944702148438
INFO:root:Train (Epoch 64): Loss/seq after 01800 batchs: 757.55517578125
INFO:root:Train (Epoch 64): Loss/seq after 01850 batchs: 752.2233276367188
INFO:root:Train (Epoch 64): Loss/seq after 01900 batchs: 753.4591674804688
INFO:root:Train (Epoch 64): Loss/seq after 01950 batchs: 751.4209594726562
INFO:root:Train (Epoch 64): Loss/seq after 02000 batchs: 748.662109375
INFO:root:Train (Epoch 64): Loss/seq after 02050 batchs: 746.5294799804688
INFO:root:Train (Epoch 64): Loss/seq after 02100 batchs: 742.168212890625
INFO:root:Train (Epoch 64): Loss/seq after 02150 batchs: 739.1537475585938
INFO:root:Train (Epoch 64): Loss/seq after 02200 batchs: 734.7115478515625
INFO:root:Train (Epoch 64): Loss/seq after 02250 batchs: 735.706298828125
INFO:root:Train (Epoch 64): Loss/seq after 02300 batchs: 734.4212646484375
INFO:root:Train (Epoch 64): Loss/seq after 02350 batchs: 729.2645874023438
INFO:root:Train (Epoch 64): Loss/seq after 02400 batchs: 729.2593994140625
INFO:root:Train (Epoch 64): Loss/seq after 02450 batchs: 722.4765625
INFO:root:Train (Epoch 64): Loss/seq after 02500 batchs: 711.3349609375
INFO:root:Train (Epoch 64): Loss/seq after 02550 batchs: 703.8892211914062
INFO:root:Train (Epoch 64): Loss/seq after 02600 batchs: 701.9710693359375
INFO:root:Train (Epoch 64): Loss/seq after 02650 batchs: 699.3610229492188
INFO:root:Train (Epoch 64): Loss/seq after 02700 batchs: 696.9966430664062
INFO:root:Train (Epoch 64): Loss/seq after 02750 batchs: 699.1956176757812
INFO:root:Train (Epoch 64): Loss/seq after 02800 batchs: 700.2166748046875
INFO:root:Train (Epoch 64): Loss/seq after 02850 batchs: 700.515869140625
INFO:root:Train (Epoch 64): Loss/seq after 02900 batchs: 702.087646484375
INFO:root:Train (Epoch 64): Loss/seq after 02950 batchs: 700.34619140625
INFO:root:Train (Epoch 64): Loss/seq after 03000 batchs: 704.1289672851562
INFO:root:Train (Epoch 64): Loss/seq after 03050 batchs: 708.5660400390625
INFO:root:Train (Epoch 64): Loss/seq after 03100 batchs: 715.1654663085938
INFO:root:Train (Epoch 64): Loss/seq after 03150 batchs: 720.166015625
INFO:root:Train (Epoch 64): Loss/seq after 03200 batchs: 724.3088989257812
INFO:root:Train (Epoch 64): Loss/seq after 03250 batchs: 728.7601318359375
INFO:root:Train (Epoch 64): Loss/seq after 03300 batchs: 728.2179565429688
INFO:root:Train (Epoch 64): Loss/seq after 03350 batchs: 728.9608154296875
INFO:root:Train (Epoch 64): Loss/seq after 03400 batchs: 722.9603881835938
INFO:root:Train (Epoch 64): Loss/seq after 03450 batchs: 720.2630615234375
INFO:root:Train (Epoch 64): Loss/seq after 03500 batchs: 721.389404296875
INFO:root:Train (Epoch 64): Loss/seq after 03550 batchs: 718.1991577148438
INFO:root:Train (Epoch 64): Loss/seq after 03600 batchs: 726.4739990234375
INFO:root:Train (Epoch 64): Loss/seq after 03650 batchs: 723.3077392578125
INFO:root:Train (Epoch 64): Loss/seq after 03700 batchs: 726.04638671875
INFO:root:Train (Epoch 64): Loss/seq after 03750 batchs: 730.2597045898438
INFO:root:Train (Epoch 64): Loss/seq after 03800 batchs: 726.4427490234375
INFO:root:Train (Epoch 64): Loss/seq after 03850 batchs: 725.4365844726562
INFO:root:Train (Epoch 64): Loss/seq after 03900 batchs: 728.6660766601562
INFO:root:Train (Epoch 64): Loss/seq after 03950 batchs: 731.5573120117188
INFO:root:Train (Epoch 64): Loss/seq after 04000 batchs: 726.999267578125
INFO:root:Train (Epoch 64): Loss/seq after 04050 batchs: 721.9840087890625
INFO:root:Train (Epoch 64): Loss/seq after 04100 batchs: 719.5980834960938
INFO:root:Train (Epoch 64): Loss/seq after 04150 batchs: 718.3333740234375
INFO:root:Train (Epoch 64): Loss/seq after 04200 batchs: 716.1815185546875
INFO:root:Train (Epoch 64): Loss/seq after 04250 batchs: 714.2085571289062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 64): Loss/seq after 00000 batches: 596.1708984375
INFO:root:# Valid (Epoch 64): Loss/seq after 00050 batches: 710.2765502929688
INFO:root:# Valid (Epoch 64): Loss/seq after 00100 batches: 880.6226806640625
INFO:root:# Valid (Epoch 64): Loss/seq after 00150 batches: 667.0565185546875
INFO:root:# Valid (Epoch 64): Loss/seq after 00200 batches: 624.7493286132812
INFO:root:Artifacts: Make stick videos for epoch 64
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_64_on_20220422_044916.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_64_index_418_on_20220422_044916.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 65): Loss/seq after 00000 batchs: 1273.4163818359375
INFO:root:Train (Epoch 65): Loss/seq after 00050 batchs: 1022.5677490234375
INFO:root:Train (Epoch 65): Loss/seq after 00100 batchs: 1099.9185791015625
INFO:root:Train (Epoch 65): Loss/seq after 00150 batchs: 997.7413940429688
INFO:root:Train (Epoch 65): Loss/seq after 00200 batchs: 1086.613037109375
INFO:root:Train (Epoch 65): Loss/seq after 00250 batchs: 1191.3277587890625
INFO:root:Train (Epoch 65): Loss/seq after 00300 batchs: 1152.72119140625
INFO:root:Train (Epoch 65): Loss/seq after 00350 batchs: 1066.54296875
INFO:root:Train (Epoch 65): Loss/seq after 00400 batchs: 1071.014892578125
INFO:root:Train (Epoch 65): Loss/seq after 00450 batchs: 1033.5673828125
INFO:root:Train (Epoch 65): Loss/seq after 00500 batchs: 1017.606201171875
INFO:root:Train (Epoch 65): Loss/seq after 00550 batchs: 979.7815551757812
INFO:root:Train (Epoch 65): Loss/seq after 00600 batchs: 941.9752197265625
INFO:root:Train (Epoch 65): Loss/seq after 00650 batchs: 916.6130981445312
INFO:root:Train (Epoch 65): Loss/seq after 00700 batchs: 881.727294921875
INFO:root:Train (Epoch 65): Loss/seq after 00750 batchs: 892.98681640625
INFO:root:Train (Epoch 65): Loss/seq after 00800 batchs: 894.7501220703125
INFO:root:Train (Epoch 65): Loss/seq after 00850 batchs: 870.3453979492188
INFO:root:Train (Epoch 65): Loss/seq after 00900 batchs: 849.887451171875
INFO:root:Train (Epoch 65): Loss/seq after 00950 batchs: 852.3056030273438
INFO:root:Train (Epoch 65): Loss/seq after 01000 batchs: 842.14111328125
INFO:root:Train (Epoch 65): Loss/seq after 01050 batchs: 825.4701538085938
INFO:root:Train (Epoch 65): Loss/seq after 01100 batchs: 814.5425415039062
INFO:root:Train (Epoch 65): Loss/seq after 01150 batchs: 792.208984375
INFO:root:Train (Epoch 65): Loss/seq after 01200 batchs: 795.0610961914062
INFO:root:Train (Epoch 65): Loss/seq after 01250 batchs: 791.2451782226562
INFO:root:Train (Epoch 65): Loss/seq after 01300 batchs: 775.8828125
INFO:root:Train (Epoch 65): Loss/seq after 01350 batchs: 763.703125
INFO:root:Train (Epoch 65): Loss/seq after 01400 batchs: 772.6253662109375
INFO:root:Train (Epoch 65): Loss/seq after 01450 batchs: 772.6533203125
INFO:root:Train (Epoch 65): Loss/seq after 01500 batchs: 776.3865356445312
INFO:root:Train (Epoch 65): Loss/seq after 01550 batchs: 778.8569946289062
INFO:root:Train (Epoch 65): Loss/seq after 01600 batchs: 771.2344970703125
INFO:root:Train (Epoch 65): Loss/seq after 01650 batchs: 768.4548950195312
INFO:root:Train (Epoch 65): Loss/seq after 01700 batchs: 767.7890014648438
INFO:root:Train (Epoch 65): Loss/seq after 01750 batchs: 763.6539306640625
INFO:root:Train (Epoch 65): Loss/seq after 01800 batchs: 759.1497802734375
INFO:root:Train (Epoch 65): Loss/seq after 01850 batchs: 753.776123046875
INFO:root:Train (Epoch 65): Loss/seq after 01900 batchs: 755.0120849609375
INFO:root:Train (Epoch 65): Loss/seq after 01950 batchs: 752.4913330078125
INFO:root:Train (Epoch 65): Loss/seq after 02000 batchs: 749.6087036132812
INFO:root:Train (Epoch 65): Loss/seq after 02050 batchs: 747.2576293945312
INFO:root:Train (Epoch 65): Loss/seq after 02100 batchs: 742.6774291992188
INFO:root:Train (Epoch 65): Loss/seq after 02150 batchs: 739.4917602539062
INFO:root:Train (Epoch 65): Loss/seq after 02200 batchs: 735.0824584960938
INFO:root:Train (Epoch 65): Loss/seq after 02250 batchs: 735.4755249023438
INFO:root:Train (Epoch 65): Loss/seq after 02300 batchs: 733.59619140625
INFO:root:Train (Epoch 65): Loss/seq after 02350 batchs: 727.4927368164062
INFO:root:Train (Epoch 65): Loss/seq after 02400 batchs: 727.3883666992188
INFO:root:Train (Epoch 65): Loss/seq after 02450 batchs: 720.7706298828125
INFO:root:Train (Epoch 65): Loss/seq after 02500 batchs: 709.7000122070312
INFO:root:Train (Epoch 65): Loss/seq after 02550 batchs: 701.6326904296875
INFO:root:Train (Epoch 65): Loss/seq after 02600 batchs: 699.7060546875
INFO:root:Train (Epoch 65): Loss/seq after 02650 batchs: 696.8043823242188
INFO:root:Train (Epoch 65): Loss/seq after 02700 batchs: 694.4683227539062
INFO:root:Train (Epoch 65): Loss/seq after 02750 batchs: 696.2003173828125
INFO:root:Train (Epoch 65): Loss/seq after 02800 batchs: 696.916259765625
INFO:root:Train (Epoch 65): Loss/seq after 02850 batchs: 697.0695190429688
INFO:root:Train (Epoch 65): Loss/seq after 02900 batchs: 698.1331176757812
INFO:root:Train (Epoch 65): Loss/seq after 02950 batchs: 696.2766723632812
INFO:root:Train (Epoch 65): Loss/seq after 03000 batchs: 700.1111450195312
INFO:root:Train (Epoch 65): Loss/seq after 03050 batchs: 704.2855224609375
INFO:root:Train (Epoch 65): Loss/seq after 03100 batchs: 710.1141357421875
INFO:root:Train (Epoch 65): Loss/seq after 03150 batchs: 714.15283203125
INFO:root:Train (Epoch 65): Loss/seq after 03200 batchs: 718.5513916015625
INFO:root:Train (Epoch 65): Loss/seq after 03250 batchs: 723.3683471679688
INFO:root:Train (Epoch 65): Loss/seq after 03300 batchs: 721.998291015625
INFO:root:Train (Epoch 65): Loss/seq after 03350 batchs: 722.3794555664062
INFO:root:Train (Epoch 65): Loss/seq after 03400 batchs: 716.487060546875
INFO:root:Train (Epoch 65): Loss/seq after 03450 batchs: 713.6929931640625
INFO:root:Train (Epoch 65): Loss/seq after 03500 batchs: 714.3768310546875
INFO:root:Train (Epoch 65): Loss/seq after 03550 batchs: 710.8790283203125
INFO:root:Train (Epoch 65): Loss/seq after 03600 batchs: 719.4363403320312
INFO:root:Train (Epoch 65): Loss/seq after 03650 batchs: 716.6837768554688
INFO:root:Train (Epoch 65): Loss/seq after 03700 batchs: 718.7218017578125
INFO:root:Train (Epoch 65): Loss/seq after 03750 batchs: 723.1561889648438
INFO:root:Train (Epoch 65): Loss/seq after 03800 batchs: 719.4063720703125
INFO:root:Train (Epoch 65): Loss/seq after 03850 batchs: 718.5783081054688
INFO:root:Train (Epoch 65): Loss/seq after 03900 batchs: 721.8103637695312
INFO:root:Train (Epoch 65): Loss/seq after 03950 batchs: 724.6699829101562
INFO:root:Train (Epoch 65): Loss/seq after 04000 batchs: 720.1921997070312
INFO:root:Train (Epoch 65): Loss/seq after 04050 batchs: 715.2725830078125
INFO:root:Train (Epoch 65): Loss/seq after 04100 batchs: 712.7861938476562
INFO:root:Train (Epoch 65): Loss/seq after 04150 batchs: 711.760009765625
INFO:root:Train (Epoch 65): Loss/seq after 04200 batchs: 709.7195434570312
INFO:root:Train (Epoch 65): Loss/seq after 04250 batchs: 707.5238037109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 65): Loss/seq after 00000 batches: 584.4610595703125
INFO:root:# Valid (Epoch 65): Loss/seq after 00050 batches: 766.2254638671875
INFO:root:# Valid (Epoch 65): Loss/seq after 00100 batches: 848.415771484375
INFO:root:# Valid (Epoch 65): Loss/seq after 00150 batches: 647.6199340820312
INFO:root:# Valid (Epoch 65): Loss/seq after 00200 batches: 612.1294555664062
INFO:root:Artifacts: Make stick videos for epoch 65
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_65_on_20220422_045424.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_65_index_651_on_20220422_045424.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 66): Loss/seq after 00000 batchs: 1338.775146484375
INFO:root:Train (Epoch 66): Loss/seq after 00050 batchs: 988.2168579101562
INFO:root:Train (Epoch 66): Loss/seq after 00100 batchs: 1053.9073486328125
INFO:root:Train (Epoch 66): Loss/seq after 00150 batchs: 961.9862670898438
INFO:root:Train (Epoch 66): Loss/seq after 00200 batchs: 1053.73291015625
INFO:root:Train (Epoch 66): Loss/seq after 00250 batchs: 1170.0679931640625
INFO:root:Train (Epoch 66): Loss/seq after 00300 batchs: 1137.073486328125
INFO:root:Train (Epoch 66): Loss/seq after 00350 batchs: 1057.4215087890625
INFO:root:Train (Epoch 66): Loss/seq after 00400 batchs: 1062.0302734375
INFO:root:Train (Epoch 66): Loss/seq after 00450 batchs: 1025.62939453125
INFO:root:Train (Epoch 66): Loss/seq after 00500 batchs: 1005.6375732421875
INFO:root:Train (Epoch 66): Loss/seq after 00550 batchs: 968.4884033203125
INFO:root:Train (Epoch 66): Loss/seq after 00600 batchs: 930.8275756835938
INFO:root:Train (Epoch 66): Loss/seq after 00650 batchs: 905.9674682617188
INFO:root:Train (Epoch 66): Loss/seq after 00700 batchs: 872.724365234375
INFO:root:Train (Epoch 66): Loss/seq after 00750 batchs: 888.4166870117188
INFO:root:Train (Epoch 66): Loss/seq after 00800 batchs: 889.3993530273438
INFO:root:Train (Epoch 66): Loss/seq after 00850 batchs: 864.220703125
INFO:root:Train (Epoch 66): Loss/seq after 00900 batchs: 843.6618041992188
INFO:root:Train (Epoch 66): Loss/seq after 00950 batchs: 841.3759155273438
INFO:root:Train (Epoch 66): Loss/seq after 01000 batchs: 831.995849609375
INFO:root:Train (Epoch 66): Loss/seq after 01050 batchs: 818.4156494140625
INFO:root:Train (Epoch 66): Loss/seq after 01100 batchs: 804.9185791015625
INFO:root:Train (Epoch 66): Loss/seq after 01150 batchs: 784.4437866210938
INFO:root:Train (Epoch 66): Loss/seq after 01200 batchs: 787.1392822265625
INFO:root:Train (Epoch 66): Loss/seq after 01250 batchs: 782.6939697265625
INFO:root:Train (Epoch 66): Loss/seq after 01300 batchs: 766.9240112304688
INFO:root:Train (Epoch 66): Loss/seq after 01350 batchs: 754.82373046875
INFO:root:Train (Epoch 66): Loss/seq after 01400 batchs: 763.6051635742188
INFO:root:Train (Epoch 66): Loss/seq after 01450 batchs: 763.6216430664062
INFO:root:Train (Epoch 66): Loss/seq after 01500 batchs: 767.6548461914062
INFO:root:Train (Epoch 66): Loss/seq after 01550 batchs: 770.9435424804688
INFO:root:Train (Epoch 66): Loss/seq after 01600 batchs: 763.8349609375
INFO:root:Train (Epoch 66): Loss/seq after 01650 batchs: 760.1544799804688
INFO:root:Train (Epoch 66): Loss/seq after 01700 batchs: 759.7468872070312
INFO:root:Train (Epoch 66): Loss/seq after 01750 batchs: 755.3407592773438
INFO:root:Train (Epoch 66): Loss/seq after 01800 batchs: 751.0897216796875
INFO:root:Train (Epoch 66): Loss/seq after 01850 batchs: 745.83642578125
INFO:root:Train (Epoch 66): Loss/seq after 01900 batchs: 746.7850341796875
INFO:root:Train (Epoch 66): Loss/seq after 01950 batchs: 746.1928100585938
INFO:root:Train (Epoch 66): Loss/seq after 02000 batchs: 744.6339111328125
INFO:root:Train (Epoch 66): Loss/seq after 02050 batchs: 742.1803588867188
INFO:root:Train (Epoch 66): Loss/seq after 02100 batchs: 738.0438842773438
INFO:root:Train (Epoch 66): Loss/seq after 02150 batchs: 734.9185180664062
INFO:root:Train (Epoch 66): Loss/seq after 02200 batchs: 730.7998657226562
INFO:root:Train (Epoch 66): Loss/seq after 02250 batchs: 731.0709228515625
INFO:root:Train (Epoch 66): Loss/seq after 02300 batchs: 728.5947875976562
INFO:root:Train (Epoch 66): Loss/seq after 02350 batchs: 723.15771484375
INFO:root:Train (Epoch 66): Loss/seq after 02400 batchs: 723.1177978515625
INFO:root:Train (Epoch 66): Loss/seq after 02450 batchs: 716.65625
INFO:root:Train (Epoch 66): Loss/seq after 02500 batchs: 705.6478271484375
INFO:root:Train (Epoch 66): Loss/seq after 02550 batchs: 697.9846801757812
INFO:root:Train (Epoch 66): Loss/seq after 02600 batchs: 696.3778686523438
INFO:root:Train (Epoch 66): Loss/seq after 02650 batchs: 693.7562866210938
INFO:root:Train (Epoch 66): Loss/seq after 02700 batchs: 691.43017578125
INFO:root:Train (Epoch 66): Loss/seq after 02750 batchs: 693.862060546875
INFO:root:Train (Epoch 66): Loss/seq after 02800 batchs: 694.9307861328125
INFO:root:Train (Epoch 66): Loss/seq after 02850 batchs: 695.1092529296875
INFO:root:Train (Epoch 66): Loss/seq after 02900 batchs: 696.160888671875
INFO:root:Train (Epoch 66): Loss/seq after 02950 batchs: 694.0687255859375
INFO:root:Train (Epoch 66): Loss/seq after 03000 batchs: 697.922607421875
INFO:root:Train (Epoch 66): Loss/seq after 03050 batchs: 702.4041748046875
INFO:root:Train (Epoch 66): Loss/seq after 03100 batchs: 708.3031005859375
INFO:root:Train (Epoch 66): Loss/seq after 03150 batchs: 713.5689697265625
INFO:root:Train (Epoch 66): Loss/seq after 03200 batchs: 717.653076171875
INFO:root:Train (Epoch 66): Loss/seq after 03250 batchs: 722.3176879882812
INFO:root:Train (Epoch 66): Loss/seq after 03300 batchs: 721.544189453125
INFO:root:Train (Epoch 66): Loss/seq after 03350 batchs: 722.9757690429688
INFO:root:Train (Epoch 66): Loss/seq after 03400 batchs: 717.2632446289062
INFO:root:Train (Epoch 66): Loss/seq after 03450 batchs: 714.3439331054688
INFO:root:Train (Epoch 66): Loss/seq after 03500 batchs: 714.9873046875
INFO:root:Train (Epoch 66): Loss/seq after 03550 batchs: 711.42919921875
INFO:root:Train (Epoch 66): Loss/seq after 03600 batchs: 720.0239868164062
INFO:root:Train (Epoch 66): Loss/seq after 03650 batchs: 716.3143310546875
INFO:root:Train (Epoch 66): Loss/seq after 03700 batchs: 717.843017578125
INFO:root:Train (Epoch 66): Loss/seq after 03750 batchs: 722.0054321289062
INFO:root:Train (Epoch 66): Loss/seq after 03800 batchs: 718.2153930664062
INFO:root:Train (Epoch 66): Loss/seq after 03850 batchs: 717.3435668945312
INFO:root:Train (Epoch 66): Loss/seq after 03900 batchs: 720.2734375
INFO:root:Train (Epoch 66): Loss/seq after 03950 batchs: 723.0742797851562
INFO:root:Train (Epoch 66): Loss/seq after 04000 batchs: 718.4249877929688
INFO:root:Train (Epoch 66): Loss/seq after 04050 batchs: 713.4061889648438
INFO:root:Train (Epoch 66): Loss/seq after 04100 batchs: 710.997314453125
INFO:root:Train (Epoch 66): Loss/seq after 04150 batchs: 709.7659301757812
INFO:root:Train (Epoch 66): Loss/seq after 04200 batchs: 707.7876586914062
INFO:root:Train (Epoch 66): Loss/seq after 04250 batchs: 705.6218872070312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 66): Loss/seq after 00000 batches: 653.7771606445312
INFO:root:# Valid (Epoch 66): Loss/seq after 00050 batches: 755.0321655273438
INFO:root:# Valid (Epoch 66): Loss/seq after 00100 batches: 833.5689697265625
INFO:root:# Valid (Epoch 66): Loss/seq after 00150 batches: 643.0928955078125
INFO:root:# Valid (Epoch 66): Loss/seq after 00200 batches: 613.65380859375
INFO:root:Artifacts: Make stick videos for epoch 66
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_66_on_20220422_045909.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_66_index_411_on_20220422_045909.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 67): Loss/seq after 00000 batchs: 1284.1402587890625
INFO:root:Train (Epoch 67): Loss/seq after 00050 batchs: 969.0902709960938
INFO:root:Train (Epoch 67): Loss/seq after 00100 batchs: 1017.9303588867188
INFO:root:Train (Epoch 67): Loss/seq after 00150 batchs: 929.0818481445312
INFO:root:Train (Epoch 67): Loss/seq after 00200 batchs: 1027.2518310546875
INFO:root:Train (Epoch 67): Loss/seq after 00250 batchs: 1143.0396728515625
INFO:root:Train (Epoch 67): Loss/seq after 00300 batchs: 1111.353515625
INFO:root:Train (Epoch 67): Loss/seq after 00350 batchs: 1029.5958251953125
INFO:root:Train (Epoch 67): Loss/seq after 00400 batchs: 1027.1292724609375
INFO:root:Train (Epoch 67): Loss/seq after 00450 batchs: 993.9739379882812
INFO:root:Train (Epoch 67): Loss/seq after 00500 batchs: 974.6143188476562
INFO:root:Train (Epoch 67): Loss/seq after 00550 batchs: 939.5389404296875
INFO:root:Train (Epoch 67): Loss/seq after 00600 batchs: 903.0016479492188
INFO:root:Train (Epoch 67): Loss/seq after 00650 batchs: 879.5169677734375
INFO:root:Train (Epoch 67): Loss/seq after 00700 batchs: 848.0982666015625
INFO:root:Train (Epoch 67): Loss/seq after 00750 batchs: 858.853271484375
INFO:root:Train (Epoch 67): Loss/seq after 00800 batchs: 859.4094848632812
INFO:root:Train (Epoch 67): Loss/seq after 00850 batchs: 835.6453247070312
INFO:root:Train (Epoch 67): Loss/seq after 00900 batchs: 816.6639404296875
INFO:root:Train (Epoch 67): Loss/seq after 00950 batchs: 815.1263427734375
INFO:root:Train (Epoch 67): Loss/seq after 01000 batchs: 804.47265625
INFO:root:Train (Epoch 67): Loss/seq after 01050 batchs: 789.5968627929688
INFO:root:Train (Epoch 67): Loss/seq after 01100 batchs: 777.556884765625
INFO:root:Train (Epoch 67): Loss/seq after 01150 batchs: 756.95068359375
INFO:root:Train (Epoch 67): Loss/seq after 01200 batchs: 760.7911376953125
INFO:root:Train (Epoch 67): Loss/seq after 01250 batchs: 756.4791870117188
INFO:root:Train (Epoch 67): Loss/seq after 01300 batchs: 741.1238403320312
INFO:root:Train (Epoch 67): Loss/seq after 01350 batchs: 729.705810546875
INFO:root:Train (Epoch 67): Loss/seq after 01400 batchs: 738.1278076171875
INFO:root:Train (Epoch 67): Loss/seq after 01450 batchs: 738.9244384765625
INFO:root:Train (Epoch 67): Loss/seq after 01500 batchs: 743.6189575195312
INFO:root:Train (Epoch 67): Loss/seq after 01550 batchs: 747.8123779296875
INFO:root:Train (Epoch 67): Loss/seq after 01600 batchs: 741.6720581054688
INFO:root:Train (Epoch 67): Loss/seq after 01650 batchs: 739.1697998046875
INFO:root:Train (Epoch 67): Loss/seq after 01700 batchs: 739.2808227539062
INFO:root:Train (Epoch 67): Loss/seq after 01750 batchs: 735.3865356445312
INFO:root:Train (Epoch 67): Loss/seq after 01800 batchs: 731.5497436523438
INFO:root:Train (Epoch 67): Loss/seq after 01850 batchs: 726.604736328125
INFO:root:Train (Epoch 67): Loss/seq after 01900 batchs: 727.9589233398438
INFO:root:Train (Epoch 67): Loss/seq after 01950 batchs: 726.1068725585938
INFO:root:Train (Epoch 67): Loss/seq after 02000 batchs: 725.5303344726562
INFO:root:Train (Epoch 67): Loss/seq after 02050 batchs: 724.2006225585938
INFO:root:Train (Epoch 67): Loss/seq after 02100 batchs: 720.4105224609375
INFO:root:Train (Epoch 67): Loss/seq after 02150 batchs: 717.730712890625
INFO:root:Train (Epoch 67): Loss/seq after 02200 batchs: 713.7633666992188
INFO:root:Train (Epoch 67): Loss/seq after 02250 batchs: 714.9041137695312
INFO:root:Train (Epoch 67): Loss/seq after 02300 batchs: 713.2012329101562
INFO:root:Train (Epoch 67): Loss/seq after 02350 batchs: 707.5875244140625
INFO:root:Train (Epoch 67): Loss/seq after 02400 batchs: 707.4314575195312
INFO:root:Train (Epoch 67): Loss/seq after 02450 batchs: 700.9797973632812
INFO:root:Train (Epoch 67): Loss/seq after 02500 batchs: 690.2509765625
INFO:root:Train (Epoch 67): Loss/seq after 02550 batchs: 682.7911987304688
INFO:root:Train (Epoch 67): Loss/seq after 02600 batchs: 681.1535034179688
INFO:root:Train (Epoch 67): Loss/seq after 02650 batchs: 678.6531372070312
INFO:root:Train (Epoch 67): Loss/seq after 02700 batchs: 676.3278198242188
INFO:root:Train (Epoch 67): Loss/seq after 02750 batchs: 678.0225830078125
INFO:root:Train (Epoch 67): Loss/seq after 02800 batchs: 679.1707763671875
INFO:root:Train (Epoch 67): Loss/seq after 02850 batchs: 680.05859375
INFO:root:Train (Epoch 67): Loss/seq after 02900 batchs: 681.6885986328125
INFO:root:Train (Epoch 67): Loss/seq after 02950 batchs: 680.135498046875
INFO:root:Train (Epoch 67): Loss/seq after 03000 batchs: 684.23779296875
INFO:root:Train (Epoch 67): Loss/seq after 03050 batchs: 688.2386474609375
INFO:root:Train (Epoch 67): Loss/seq after 03100 batchs: 694.3070678710938
INFO:root:Train (Epoch 67): Loss/seq after 03150 batchs: 699.5224609375
INFO:root:Train (Epoch 67): Loss/seq after 03200 batchs: 703.6400146484375
INFO:root:Train (Epoch 67): Loss/seq after 03250 batchs: 708.2346801757812
INFO:root:Train (Epoch 67): Loss/seq after 03300 batchs: 707.0589599609375
INFO:root:Train (Epoch 67): Loss/seq after 03350 batchs: 706.8347778320312
INFO:root:Train (Epoch 67): Loss/seq after 03400 batchs: 701.0636596679688
INFO:root:Train (Epoch 67): Loss/seq after 03450 batchs: 698.38427734375
INFO:root:Train (Epoch 67): Loss/seq after 03500 batchs: 699.171142578125
INFO:root:Train (Epoch 67): Loss/seq after 03550 batchs: 695.7448120117188
INFO:root:Train (Epoch 67): Loss/seq after 03600 batchs: 704.3392333984375
INFO:root:Train (Epoch 67): Loss/seq after 03650 batchs: 701.3251342773438
INFO:root:Train (Epoch 67): Loss/seq after 03700 batchs: 703.4189453125
INFO:root:Train (Epoch 67): Loss/seq after 03750 batchs: 707.9561767578125
INFO:root:Train (Epoch 67): Loss/seq after 03800 batchs: 704.3553466796875
INFO:root:Train (Epoch 67): Loss/seq after 03850 batchs: 703.5800170898438
INFO:root:Train (Epoch 67): Loss/seq after 03900 batchs: 706.5162963867188
INFO:root:Train (Epoch 67): Loss/seq after 03950 batchs: 709.31982421875
INFO:root:Train (Epoch 67): Loss/seq after 04000 batchs: 704.7364501953125
INFO:root:Train (Epoch 67): Loss/seq after 04050 batchs: 699.9281005859375
INFO:root:Train (Epoch 67): Loss/seq after 04100 batchs: 697.7340698242188
INFO:root:Train (Epoch 67): Loss/seq after 04150 batchs: 696.7017211914062
INFO:root:Train (Epoch 67): Loss/seq after 04200 batchs: 694.8583984375
INFO:root:Train (Epoch 67): Loss/seq after 04250 batchs: 692.89697265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 67): Loss/seq after 00000 batches: 588.0670776367188
INFO:root:# Valid (Epoch 67): Loss/seq after 00050 batches: 729.7922973632812
INFO:root:# Valid (Epoch 67): Loss/seq after 00100 batches: 827.4483032226562
INFO:root:# Valid (Epoch 67): Loss/seq after 00150 batches: 636.1190795898438
INFO:root:# Valid (Epoch 67): Loss/seq after 00200 batches: 606.302734375
INFO:root:Artifacts: Make stick videos for epoch 67
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_67_on_20220422_050411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_67_index_1402_on_20220422_050411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 68): Loss/seq after 00000 batchs: 1276.2044677734375
INFO:root:Train (Epoch 68): Loss/seq after 00050 batchs: 979.5693359375
INFO:root:Train (Epoch 68): Loss/seq after 00100 batchs: 1000.2472534179688
INFO:root:Train (Epoch 68): Loss/seq after 00150 batchs: 910.8328857421875
INFO:root:Train (Epoch 68): Loss/seq after 00200 batchs: 1009.9814453125
INFO:root:Train (Epoch 68): Loss/seq after 00250 batchs: 1126.90283203125
INFO:root:Train (Epoch 68): Loss/seq after 00300 batchs: 1098.1953125
INFO:root:Train (Epoch 68): Loss/seq after 00350 batchs: 1018.2554321289062
INFO:root:Train (Epoch 68): Loss/seq after 00400 batchs: 1016.7720336914062
INFO:root:Train (Epoch 68): Loss/seq after 00450 batchs: 983.90673828125
INFO:root:Train (Epoch 68): Loss/seq after 00500 batchs: 964.3521118164062
INFO:root:Train (Epoch 68): Loss/seq after 00550 batchs: 930.8107299804688
INFO:root:Train (Epoch 68): Loss/seq after 00600 batchs: 895.6780395507812
INFO:root:Train (Epoch 68): Loss/seq after 00650 batchs: 872.3693237304688
INFO:root:Train (Epoch 68): Loss/seq after 00700 batchs: 839.4993896484375
INFO:root:Train (Epoch 68): Loss/seq after 00750 batchs: 852.7796630859375
INFO:root:Train (Epoch 68): Loss/seq after 00800 batchs: 854.0988159179688
INFO:root:Train (Epoch 68): Loss/seq after 00850 batchs: 829.4228515625
INFO:root:Train (Epoch 68): Loss/seq after 00900 batchs: 810.5835571289062
INFO:root:Train (Epoch 68): Loss/seq after 00950 batchs: 809.067138671875
INFO:root:Train (Epoch 68): Loss/seq after 01000 batchs: 799.6329956054688
INFO:root:Train (Epoch 68): Loss/seq after 01050 batchs: 785.8748779296875
INFO:root:Train (Epoch 68): Loss/seq after 01100 batchs: 775.2134399414062
INFO:root:Train (Epoch 68): Loss/seq after 01150 batchs: 754.1318359375
INFO:root:Train (Epoch 68): Loss/seq after 01200 batchs: 757.1428833007812
INFO:root:Train (Epoch 68): Loss/seq after 01250 batchs: 753.0262451171875
INFO:root:Train (Epoch 68): Loss/seq after 01300 batchs: 738.025390625
INFO:root:Train (Epoch 68): Loss/seq after 01350 batchs: 727.0643310546875
INFO:root:Train (Epoch 68): Loss/seq after 01400 batchs: 735.1202392578125
INFO:root:Train (Epoch 68): Loss/seq after 01450 batchs: 735.4494018554688
INFO:root:Train (Epoch 68): Loss/seq after 01500 batchs: 740.1309204101562
INFO:root:Train (Epoch 68): Loss/seq after 01550 batchs: 743.7374877929688
INFO:root:Train (Epoch 68): Loss/seq after 01600 batchs: 737.0978393554688
INFO:root:Train (Epoch 68): Loss/seq after 01650 batchs: 733.983642578125
INFO:root:Train (Epoch 68): Loss/seq after 01700 batchs: 734.0924682617188
INFO:root:Train (Epoch 68): Loss/seq after 01750 batchs: 730.4331665039062
INFO:root:Train (Epoch 68): Loss/seq after 01800 batchs: 726.5836791992188
INFO:root:Train (Epoch 68): Loss/seq after 01850 batchs: 721.9158325195312
INFO:root:Train (Epoch 68): Loss/seq after 01900 batchs: 723.1094360351562
INFO:root:Train (Epoch 68): Loss/seq after 01950 batchs: 721.4067993164062
INFO:root:Train (Epoch 68): Loss/seq after 02000 batchs: 721.3191528320312
INFO:root:Train (Epoch 68): Loss/seq after 02050 batchs: 719.9762573242188
INFO:root:Train (Epoch 68): Loss/seq after 02100 batchs: 716.1411743164062
INFO:root:Train (Epoch 68): Loss/seq after 02150 batchs: 713.3086547851562
INFO:root:Train (Epoch 68): Loss/seq after 02200 batchs: 709.2981567382812
INFO:root:Train (Epoch 68): Loss/seq after 02250 batchs: 709.2448120117188
INFO:root:Train (Epoch 68): Loss/seq after 02300 batchs: 707.2246704101562
INFO:root:Train (Epoch 68): Loss/seq after 02350 batchs: 701.8762817382812
INFO:root:Train (Epoch 68): Loss/seq after 02400 batchs: 702.11376953125
INFO:root:Train (Epoch 68): Loss/seq after 02450 batchs: 695.6470947265625
INFO:root:Train (Epoch 68): Loss/seq after 02500 batchs: 685.0277709960938
INFO:root:Train (Epoch 68): Loss/seq after 02550 batchs: 677.3429565429688
INFO:root:Train (Epoch 68): Loss/seq after 02600 batchs: 675.6207275390625
INFO:root:Train (Epoch 68): Loss/seq after 02650 batchs: 673.0464477539062
INFO:root:Train (Epoch 68): Loss/seq after 02700 batchs: 671.086669921875
INFO:root:Train (Epoch 68): Loss/seq after 02750 batchs: 673.7466430664062
INFO:root:Train (Epoch 68): Loss/seq after 02800 batchs: 675.6992797851562
INFO:root:Train (Epoch 68): Loss/seq after 02850 batchs: 676.052978515625
INFO:root:Train (Epoch 68): Loss/seq after 02900 batchs: 677.596923828125
INFO:root:Train (Epoch 68): Loss/seq after 02950 batchs: 675.9329223632812
INFO:root:Train (Epoch 68): Loss/seq after 03000 batchs: 680.029296875
INFO:root:Train (Epoch 68): Loss/seq after 03050 batchs: 684.2883911132812
INFO:root:Train (Epoch 68): Loss/seq after 03100 batchs: 690.7633666992188
INFO:root:Train (Epoch 68): Loss/seq after 03150 batchs: 695.1644897460938
INFO:root:Train (Epoch 68): Loss/seq after 03200 batchs: 698.9094848632812
INFO:root:Train (Epoch 68): Loss/seq after 03250 batchs: 703.4107055664062
INFO:root:Train (Epoch 68): Loss/seq after 03300 batchs: 702.852783203125
INFO:root:Train (Epoch 68): Loss/seq after 03350 batchs: 704.1485595703125
INFO:root:Train (Epoch 68): Loss/seq after 03400 batchs: 698.6182250976562
INFO:root:Train (Epoch 68): Loss/seq after 03450 batchs: 696.0358276367188
INFO:root:Train (Epoch 68): Loss/seq after 03500 batchs: 697.2723999023438
INFO:root:Train (Epoch 68): Loss/seq after 03550 batchs: 694.0924682617188
INFO:root:Train (Epoch 68): Loss/seq after 03600 batchs: 702.6340942382812
INFO:root:Train (Epoch 68): Loss/seq after 03650 batchs: 699.630615234375
INFO:root:Train (Epoch 68): Loss/seq after 03700 batchs: 702.4024047851562
INFO:root:Train (Epoch 68): Loss/seq after 03750 batchs: 706.6448974609375
INFO:root:Train (Epoch 68): Loss/seq after 03800 batchs: 702.9537353515625
INFO:root:Train (Epoch 68): Loss/seq after 03850 batchs: 702.0780639648438
INFO:root:Train (Epoch 68): Loss/seq after 03900 batchs: 705.0760498046875
INFO:root:Train (Epoch 68): Loss/seq after 03950 batchs: 708.1721801757812
INFO:root:Train (Epoch 68): Loss/seq after 04000 batchs: 703.6521606445312
INFO:root:Train (Epoch 68): Loss/seq after 04050 batchs: 698.8629150390625
INFO:root:Train (Epoch 68): Loss/seq after 04100 batchs: 696.6649169921875
INFO:root:Train (Epoch 68): Loss/seq after 04150 batchs: 695.6463012695312
INFO:root:Train (Epoch 68): Loss/seq after 04200 batchs: 693.8037109375
INFO:root:Train (Epoch 68): Loss/seq after 04250 batchs: 691.7601318359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 68): Loss/seq after 00000 batches: 674.8252563476562
INFO:root:# Valid (Epoch 68): Loss/seq after 00050 batches: 766.4010620117188
INFO:root:# Valid (Epoch 68): Loss/seq after 00100 batches: 869.834228515625
INFO:root:# Valid (Epoch 68): Loss/seq after 00150 batches: 658.8764038085938
INFO:root:# Valid (Epoch 68): Loss/seq after 00200 batches: 616.1290893554688
INFO:root:Artifacts: Make stick videos for epoch 68
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_68_on_20220422_050907.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_68_index_689_on_20220422_050907.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 69): Loss/seq after 00000 batchs: 1258.3187255859375
INFO:root:Train (Epoch 69): Loss/seq after 00050 batchs: 976.2537231445312
INFO:root:Train (Epoch 69): Loss/seq after 00100 batchs: 1002.3068237304688
INFO:root:Train (Epoch 69): Loss/seq after 00150 batchs: 916.9575805664062
INFO:root:Train (Epoch 69): Loss/seq after 00200 batchs: 1023.7658081054688
INFO:root:Train (Epoch 69): Loss/seq after 00250 batchs: 1134.9830322265625
INFO:root:Train (Epoch 69): Loss/seq after 00300 batchs: 1104.1351318359375
INFO:root:Train (Epoch 69): Loss/seq after 00350 batchs: 1024.05078125
INFO:root:Train (Epoch 69): Loss/seq after 00400 batchs: 1024.37548828125
INFO:root:Train (Epoch 69): Loss/seq after 00450 batchs: 990.3539428710938
INFO:root:Train (Epoch 69): Loss/seq after 00500 batchs: 968.9854125976562
INFO:root:Train (Epoch 69): Loss/seq after 00550 batchs: 935.1600341796875
INFO:root:Train (Epoch 69): Loss/seq after 00600 batchs: 902.77880859375
INFO:root:Train (Epoch 69): Loss/seq after 00650 batchs: 878.9566040039062
INFO:root:Train (Epoch 69): Loss/seq after 00700 batchs: 845.6529541015625
INFO:root:Train (Epoch 69): Loss/seq after 00750 batchs: 855.8349609375
INFO:root:Train (Epoch 69): Loss/seq after 00800 batchs: 856.6557006835938
INFO:root:Train (Epoch 69): Loss/seq after 00850 batchs: 832.678466796875
INFO:root:Train (Epoch 69): Loss/seq after 00900 batchs: 813.9067993164062
INFO:root:Train (Epoch 69): Loss/seq after 00950 batchs: 811.568115234375
INFO:root:Train (Epoch 69): Loss/seq after 01000 batchs: 801.0740966796875
INFO:root:Train (Epoch 69): Loss/seq after 01050 batchs: 784.9024047851562
INFO:root:Train (Epoch 69): Loss/seq after 01100 batchs: 771.1114501953125
INFO:root:Train (Epoch 69): Loss/seq after 01150 batchs: 750.3214721679688
INFO:root:Train (Epoch 69): Loss/seq after 01200 batchs: 752.9255981445312
INFO:root:Train (Epoch 69): Loss/seq after 01250 batchs: 748.962158203125
INFO:root:Train (Epoch 69): Loss/seq after 01300 batchs: 734.125732421875
INFO:root:Train (Epoch 69): Loss/seq after 01350 batchs: 722.561279296875
INFO:root:Train (Epoch 69): Loss/seq after 01400 batchs: 730.1865844726562
INFO:root:Train (Epoch 69): Loss/seq after 01450 batchs: 730.8912963867188
INFO:root:Train (Epoch 69): Loss/seq after 01500 batchs: 735.5867309570312
INFO:root:Train (Epoch 69): Loss/seq after 01550 batchs: 738.6768188476562
INFO:root:Train (Epoch 69): Loss/seq after 01600 batchs: 731.9862060546875
INFO:root:Train (Epoch 69): Loss/seq after 01650 batchs: 728.8152465820312
INFO:root:Train (Epoch 69): Loss/seq after 01700 batchs: 729.0237426757812
INFO:root:Train (Epoch 69): Loss/seq after 01750 batchs: 725.2868041992188
INFO:root:Train (Epoch 69): Loss/seq after 01800 batchs: 721.6522827148438
INFO:root:Train (Epoch 69): Loss/seq after 01850 batchs: 716.8158569335938
INFO:root:Train (Epoch 69): Loss/seq after 01900 batchs: 717.9932250976562
INFO:root:Train (Epoch 69): Loss/seq after 01950 batchs: 716.3211669921875
INFO:root:Train (Epoch 69): Loss/seq after 02000 batchs: 715.1134033203125
INFO:root:Train (Epoch 69): Loss/seq after 02050 batchs: 713.6632080078125
INFO:root:Train (Epoch 69): Loss/seq after 02100 batchs: 709.7317504882812
INFO:root:Train (Epoch 69): Loss/seq after 02150 batchs: 706.7869873046875
INFO:root:Train (Epoch 69): Loss/seq after 02200 batchs: 703.0035400390625
INFO:root:Train (Epoch 69): Loss/seq after 02250 batchs: 704.7666625976562
INFO:root:Train (Epoch 69): Loss/seq after 02300 batchs: 703.4107055664062
INFO:root:Train (Epoch 69): Loss/seq after 02350 batchs: 698.3843383789062
INFO:root:Train (Epoch 69): Loss/seq after 02400 batchs: 698.3861083984375
INFO:root:Train (Epoch 69): Loss/seq after 02450 batchs: 692.0811157226562
INFO:root:Train (Epoch 69): Loss/seq after 02500 batchs: 681.503662109375
INFO:root:Train (Epoch 69): Loss/seq after 02550 batchs: 673.855712890625
INFO:root:Train (Epoch 69): Loss/seq after 02600 batchs: 672.0230102539062
INFO:root:Train (Epoch 69): Loss/seq after 02650 batchs: 669.4750366210938
INFO:root:Train (Epoch 69): Loss/seq after 02700 batchs: 667.3197021484375
INFO:root:Train (Epoch 69): Loss/seq after 02750 batchs: 669.6463623046875
INFO:root:Train (Epoch 69): Loss/seq after 02800 batchs: 669.99755859375
INFO:root:Train (Epoch 69): Loss/seq after 02850 batchs: 670.4553833007812
INFO:root:Train (Epoch 69): Loss/seq after 02900 batchs: 671.867431640625
INFO:root:Train (Epoch 69): Loss/seq after 02950 batchs: 669.9661254882812
INFO:root:Train (Epoch 69): Loss/seq after 03000 batchs: 674.0523071289062
INFO:root:Train (Epoch 69): Loss/seq after 03050 batchs: 678.0047607421875
INFO:root:Train (Epoch 69): Loss/seq after 03100 batchs: 683.9246215820312
INFO:root:Train (Epoch 69): Loss/seq after 03150 batchs: 686.9827880859375
INFO:root:Train (Epoch 69): Loss/seq after 03200 batchs: 690.6134033203125
INFO:root:Train (Epoch 69): Loss/seq after 03250 batchs: 695.1456909179688
INFO:root:Train (Epoch 69): Loss/seq after 03300 batchs: 693.8267211914062
INFO:root:Train (Epoch 69): Loss/seq after 03350 batchs: 693.4103393554688
INFO:root:Train (Epoch 69): Loss/seq after 03400 batchs: 687.8421020507812
INFO:root:Train (Epoch 69): Loss/seq after 03450 batchs: 685.437744140625
INFO:root:Train (Epoch 69): Loss/seq after 03500 batchs: 686.3197021484375
INFO:root:Train (Epoch 69): Loss/seq after 03550 batchs: 682.8941040039062
INFO:root:Train (Epoch 69): Loss/seq after 03600 batchs: 691.3848876953125
INFO:root:Train (Epoch 69): Loss/seq after 03650 batchs: 689.4644775390625
INFO:root:Train (Epoch 69): Loss/seq after 03700 batchs: 691.99853515625
INFO:root:Train (Epoch 69): Loss/seq after 03750 batchs: 696.5634155273438
INFO:root:Train (Epoch 69): Loss/seq after 03800 batchs: 693.064453125
INFO:root:Train (Epoch 69): Loss/seq after 03850 batchs: 692.2804565429688
INFO:root:Train (Epoch 69): Loss/seq after 03900 batchs: 695.6162719726562
INFO:root:Train (Epoch 69): Loss/seq after 03950 batchs: 698.7872314453125
INFO:root:Train (Epoch 69): Loss/seq after 04000 batchs: 694.2542114257812
INFO:root:Train (Epoch 69): Loss/seq after 04050 batchs: 689.5654296875
INFO:root:Train (Epoch 69): Loss/seq after 04100 batchs: 687.4288330078125
INFO:root:Train (Epoch 69): Loss/seq after 04150 batchs: 686.54931640625
INFO:root:Train (Epoch 69): Loss/seq after 04200 batchs: 684.5855102539062
INFO:root:Train (Epoch 69): Loss/seq after 04250 batchs: 682.4718017578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 69): Loss/seq after 00000 batches: 575.9624633789062
INFO:root:# Valid (Epoch 69): Loss/seq after 00050 batches: 779.4365234375
INFO:root:# Valid (Epoch 69): Loss/seq after 00100 batches: 863.5818481445312
INFO:root:# Valid (Epoch 69): Loss/seq after 00150 batches: 655.8541870117188
INFO:root:# Valid (Epoch 69): Loss/seq after 00200 batches: 614.6316528320312
INFO:root:Artifacts: Make stick videos for epoch 69
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_69_on_20220422_051414.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_69_index_346_on_20220422_051414.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 70): Loss/seq after 00000 batchs: 1330.5771484375
INFO:root:Train (Epoch 70): Loss/seq after 00050 batchs: 969.1484985351562
INFO:root:Train (Epoch 70): Loss/seq after 00100 batchs: 1015.484130859375
INFO:root:Train (Epoch 70): Loss/seq after 00150 batchs: 930.39111328125
INFO:root:Train (Epoch 70): Loss/seq after 00200 batchs: 1030.6888427734375
INFO:root:Train (Epoch 70): Loss/seq after 00250 batchs: 1144.280029296875
INFO:root:Train (Epoch 70): Loss/seq after 00300 batchs: 1112.200439453125
INFO:root:Train (Epoch 70): Loss/seq after 00350 batchs: 1031.8349609375
INFO:root:Train (Epoch 70): Loss/seq after 00400 batchs: 1032.64306640625
INFO:root:Train (Epoch 70): Loss/seq after 00450 batchs: 998.0126953125
INFO:root:Train (Epoch 70): Loss/seq after 00500 batchs: 984.5928955078125
INFO:root:Train (Epoch 70): Loss/seq after 00550 batchs: 948.6359252929688
INFO:root:Train (Epoch 70): Loss/seq after 00600 batchs: 911.708984375
INFO:root:Train (Epoch 70): Loss/seq after 00650 batchs: 887.0032348632812
INFO:root:Train (Epoch 70): Loss/seq after 00700 batchs: 853.0839233398438
INFO:root:Train (Epoch 70): Loss/seq after 00750 batchs: 863.1686401367188
INFO:root:Train (Epoch 70): Loss/seq after 00800 batchs: 864.706298828125
INFO:root:Train (Epoch 70): Loss/seq after 00850 batchs: 839.57568359375
INFO:root:Train (Epoch 70): Loss/seq after 00900 batchs: 820.5202026367188
INFO:root:Train (Epoch 70): Loss/seq after 00950 batchs: 820.1293334960938
INFO:root:Train (Epoch 70): Loss/seq after 01000 batchs: 810.4733276367188
INFO:root:Train (Epoch 70): Loss/seq after 01050 batchs: 794.804443359375
INFO:root:Train (Epoch 70): Loss/seq after 01100 batchs: 782.1503295898438
INFO:root:Train (Epoch 70): Loss/seq after 01150 batchs: 761.0499877929688
INFO:root:Train (Epoch 70): Loss/seq after 01200 batchs: 763.6642456054688
INFO:root:Train (Epoch 70): Loss/seq after 01250 batchs: 759.6358642578125
INFO:root:Train (Epoch 70): Loss/seq after 01300 batchs: 744.3595581054688
INFO:root:Train (Epoch 70): Loss/seq after 01350 batchs: 732.0438232421875
INFO:root:Train (Epoch 70): Loss/seq after 01400 batchs: 740.1805419921875
INFO:root:Train (Epoch 70): Loss/seq after 01450 batchs: 740.308837890625
INFO:root:Train (Epoch 70): Loss/seq after 01500 batchs: 744.66455078125
INFO:root:Train (Epoch 70): Loss/seq after 01550 batchs: 747.4820556640625
INFO:root:Train (Epoch 70): Loss/seq after 01600 batchs: 740.5178833007812
INFO:root:Train (Epoch 70): Loss/seq after 01650 batchs: 737.7568359375
INFO:root:Train (Epoch 70): Loss/seq after 01700 batchs: 737.35205078125
INFO:root:Train (Epoch 70): Loss/seq after 01750 batchs: 733.2259521484375
INFO:root:Train (Epoch 70): Loss/seq after 01800 batchs: 729.1412963867188
INFO:root:Train (Epoch 70): Loss/seq after 01850 batchs: 724.3076171875
INFO:root:Train (Epoch 70): Loss/seq after 01900 batchs: 724.9176025390625
INFO:root:Train (Epoch 70): Loss/seq after 01950 batchs: 723.4575805664062
INFO:root:Train (Epoch 70): Loss/seq after 02000 batchs: 720.875244140625
INFO:root:Train (Epoch 70): Loss/seq after 02050 batchs: 718.7348022460938
INFO:root:Train (Epoch 70): Loss/seq after 02100 batchs: 714.5891723632812
INFO:root:Train (Epoch 70): Loss/seq after 02150 batchs: 711.4834594726562
INFO:root:Train (Epoch 70): Loss/seq after 02200 batchs: 707.4305419921875
INFO:root:Train (Epoch 70): Loss/seq after 02250 batchs: 708.9513549804688
INFO:root:Train (Epoch 70): Loss/seq after 02300 batchs: 707.2039184570312
INFO:root:Train (Epoch 70): Loss/seq after 02350 batchs: 701.6557006835938
INFO:root:Train (Epoch 70): Loss/seq after 02400 batchs: 701.7510375976562
INFO:root:Train (Epoch 70): Loss/seq after 02450 batchs: 695.2485961914062
INFO:root:Train (Epoch 70): Loss/seq after 02500 batchs: 684.5885009765625
INFO:root:Train (Epoch 70): Loss/seq after 02550 batchs: 676.7589721679688
INFO:root:Train (Epoch 70): Loss/seq after 02600 batchs: 674.8666381835938
INFO:root:Train (Epoch 70): Loss/seq after 02650 batchs: 672.0796508789062
INFO:root:Train (Epoch 70): Loss/seq after 02700 batchs: 669.651123046875
INFO:root:Train (Epoch 70): Loss/seq after 02750 batchs: 671.0379028320312
INFO:root:Train (Epoch 70): Loss/seq after 02800 batchs: 671.6882934570312
INFO:root:Train (Epoch 70): Loss/seq after 02850 batchs: 672.0956420898438
INFO:root:Train (Epoch 70): Loss/seq after 02900 batchs: 673.7211303710938
INFO:root:Train (Epoch 70): Loss/seq after 02950 batchs: 671.9681396484375
INFO:root:Train (Epoch 70): Loss/seq after 03000 batchs: 676.025146484375
INFO:root:Train (Epoch 70): Loss/seq after 03050 batchs: 680.6693725585938
INFO:root:Train (Epoch 70): Loss/seq after 03100 batchs: 686.4601440429688
INFO:root:Train (Epoch 70): Loss/seq after 03150 batchs: 689.5702514648438
INFO:root:Train (Epoch 70): Loss/seq after 03200 batchs: 692.6388549804688
INFO:root:Train (Epoch 70): Loss/seq after 03250 batchs: 697.2620849609375
INFO:root:Train (Epoch 70): Loss/seq after 03300 batchs: 696.4160766601562
INFO:root:Train (Epoch 70): Loss/seq after 03350 batchs: 696.2565307617188
INFO:root:Train (Epoch 70): Loss/seq after 03400 batchs: 690.5751953125
INFO:root:Train (Epoch 70): Loss/seq after 03450 batchs: 688.1129150390625
INFO:root:Train (Epoch 70): Loss/seq after 03500 batchs: 688.770263671875
INFO:root:Train (Epoch 70): Loss/seq after 03550 batchs: 685.2780151367188
INFO:root:Train (Epoch 70): Loss/seq after 03600 batchs: 693.82470703125
INFO:root:Train (Epoch 70): Loss/seq after 03650 batchs: 690.5869750976562
INFO:root:Train (Epoch 70): Loss/seq after 03700 batchs: 693.3075561523438
INFO:root:Train (Epoch 70): Loss/seq after 03750 batchs: 697.693359375
INFO:root:Train (Epoch 70): Loss/seq after 03800 batchs: 694.1306762695312
INFO:root:Train (Epoch 70): Loss/seq after 03850 batchs: 693.2670288085938
INFO:root:Train (Epoch 70): Loss/seq after 03900 batchs: 696.242919921875
INFO:root:Train (Epoch 70): Loss/seq after 03950 batchs: 698.9571533203125
INFO:root:Train (Epoch 70): Loss/seq after 04000 batchs: 694.3239135742188
INFO:root:Train (Epoch 70): Loss/seq after 04050 batchs: 689.5992431640625
INFO:root:Train (Epoch 70): Loss/seq after 04100 batchs: 687.2769775390625
INFO:root:Train (Epoch 70): Loss/seq after 04150 batchs: 686.34619140625
INFO:root:Train (Epoch 70): Loss/seq after 04200 batchs: 684.2852783203125
INFO:root:Train (Epoch 70): Loss/seq after 04250 batchs: 682.1165161132812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 70): Loss/seq after 00000 batches: 637.7433471679688
INFO:root:# Valid (Epoch 70): Loss/seq after 00050 batches: 755.7245483398438
INFO:root:# Valid (Epoch 70): Loss/seq after 00100 batches: 872.4173583984375
INFO:root:# Valid (Epoch 70): Loss/seq after 00150 batches: 657.950927734375
INFO:root:# Valid (Epoch 70): Loss/seq after 00200 batches: 613.6126098632812
INFO:root:Artifacts: Make stick videos for epoch 70
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_70_on_20220422_051902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_70_index_745_on_20220422_051902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 71): Loss/seq after 00000 batchs: 1273.6605224609375
INFO:root:Train (Epoch 71): Loss/seq after 00050 batchs: 965.832275390625
INFO:root:Train (Epoch 71): Loss/seq after 00100 batchs: 990.1738891601562
INFO:root:Train (Epoch 71): Loss/seq after 00150 batchs: 904.3251342773438
INFO:root:Train (Epoch 71): Loss/seq after 00200 batchs: 996.6804809570312
INFO:root:Train (Epoch 71): Loss/seq after 00250 batchs: 1108.9237060546875
INFO:root:Train (Epoch 71): Loss/seq after 00300 batchs: 1081.099853515625
INFO:root:Train (Epoch 71): Loss/seq after 00350 batchs: 1003.5547485351562
INFO:root:Train (Epoch 71): Loss/seq after 00400 batchs: 1004.5506591796875
INFO:root:Train (Epoch 71): Loss/seq after 00450 batchs: 971.849609375
INFO:root:Train (Epoch 71): Loss/seq after 00500 batchs: 955.5299682617188
INFO:root:Train (Epoch 71): Loss/seq after 00550 batchs: 923.18310546875
INFO:root:Train (Epoch 71): Loss/seq after 00600 batchs: 889.9389038085938
INFO:root:Train (Epoch 71): Loss/seq after 00650 batchs: 868.2672729492188
INFO:root:Train (Epoch 71): Loss/seq after 00700 batchs: 835.6768188476562
INFO:root:Train (Epoch 71): Loss/seq after 00750 batchs: 847.9927978515625
INFO:root:Train (Epoch 71): Loss/seq after 00800 batchs: 847.4799194335938
INFO:root:Train (Epoch 71): Loss/seq after 00850 batchs: 824.0193481445312
INFO:root:Train (Epoch 71): Loss/seq after 00900 batchs: 807.1329956054688
INFO:root:Train (Epoch 71): Loss/seq after 00950 batchs: 807.9217529296875
INFO:root:Train (Epoch 71): Loss/seq after 01000 batchs: 797.1017456054688
INFO:root:Train (Epoch 71): Loss/seq after 01050 batchs: 783.1107177734375
INFO:root:Train (Epoch 71): Loss/seq after 01100 batchs: 769.5332641601562
INFO:root:Train (Epoch 71): Loss/seq after 01150 batchs: 748.9716796875
INFO:root:Train (Epoch 71): Loss/seq after 01200 batchs: 751.9819946289062
INFO:root:Train (Epoch 71): Loss/seq after 01250 batchs: 747.7301635742188
INFO:root:Train (Epoch 71): Loss/seq after 01300 batchs: 733.2068481445312
INFO:root:Train (Epoch 71): Loss/seq after 01350 batchs: 721.6035766601562
INFO:root:Train (Epoch 71): Loss/seq after 01400 batchs: 729.3485107421875
INFO:root:Train (Epoch 71): Loss/seq after 01450 batchs: 730.0669555664062
INFO:root:Train (Epoch 71): Loss/seq after 01500 batchs: 734.8101196289062
INFO:root:Train (Epoch 71): Loss/seq after 01550 batchs: 738.5254516601562
INFO:root:Train (Epoch 71): Loss/seq after 01600 batchs: 732.1151733398438
INFO:root:Train (Epoch 71): Loss/seq after 01650 batchs: 729.460693359375
INFO:root:Train (Epoch 71): Loss/seq after 01700 batchs: 729.53857421875
INFO:root:Train (Epoch 71): Loss/seq after 01750 batchs: 725.7286987304688
INFO:root:Train (Epoch 71): Loss/seq after 01800 batchs: 721.9949951171875
INFO:root:Train (Epoch 71): Loss/seq after 01850 batchs: 717.2332763671875
INFO:root:Train (Epoch 71): Loss/seq after 01900 batchs: 718.9054565429688
INFO:root:Train (Epoch 71): Loss/seq after 01950 batchs: 716.9541015625
INFO:root:Train (Epoch 71): Loss/seq after 02000 batchs: 714.2528686523438
INFO:root:Train (Epoch 71): Loss/seq after 02050 batchs: 712.1991577148438
INFO:root:Train (Epoch 71): Loss/seq after 02100 batchs: 708.1622314453125
INFO:root:Train (Epoch 71): Loss/seq after 02150 batchs: 705.3367309570312
INFO:root:Train (Epoch 71): Loss/seq after 02200 batchs: 701.2371826171875
INFO:root:Train (Epoch 71): Loss/seq after 02250 batchs: 701.4359741210938
INFO:root:Train (Epoch 71): Loss/seq after 02300 batchs: 699.0081176757812
INFO:root:Train (Epoch 71): Loss/seq after 02350 batchs: 693.2433471679688
INFO:root:Train (Epoch 71): Loss/seq after 02400 batchs: 693.0972290039062
INFO:root:Train (Epoch 71): Loss/seq after 02450 batchs: 686.8106079101562
INFO:root:Train (Epoch 71): Loss/seq after 02500 batchs: 676.3501586914062
INFO:root:Train (Epoch 71): Loss/seq after 02550 batchs: 668.69775390625
INFO:root:Train (Epoch 71): Loss/seq after 02600 batchs: 666.9447021484375
INFO:root:Train (Epoch 71): Loss/seq after 02650 batchs: 664.2919921875
INFO:root:Train (Epoch 71): Loss/seq after 02700 batchs: 661.9038696289062
INFO:root:Train (Epoch 71): Loss/seq after 02750 batchs: 663.3944091796875
INFO:root:Train (Epoch 71): Loss/seq after 02800 batchs: 665.4093627929688
INFO:root:Train (Epoch 71): Loss/seq after 02850 batchs: 666.0050048828125
INFO:root:Train (Epoch 71): Loss/seq after 02900 batchs: 668.455078125
INFO:root:Train (Epoch 71): Loss/seq after 02950 batchs: 666.8723754882812
INFO:root:Train (Epoch 71): Loss/seq after 03000 batchs: 671.0079956054688
INFO:root:Train (Epoch 71): Loss/seq after 03050 batchs: 675.0377197265625
INFO:root:Train (Epoch 71): Loss/seq after 03100 batchs: 680.8450317382812
INFO:root:Train (Epoch 71): Loss/seq after 03150 batchs: 684.9804077148438
INFO:root:Train (Epoch 71): Loss/seq after 03200 batchs: 688.3414916992188
INFO:root:Train (Epoch 71): Loss/seq after 03250 batchs: 693.0579223632812
INFO:root:Train (Epoch 71): Loss/seq after 03300 batchs: 693.1036376953125
INFO:root:Train (Epoch 71): Loss/seq after 03350 batchs: 693.4173583984375
INFO:root:Train (Epoch 71): Loss/seq after 03400 batchs: 687.7611694335938
INFO:root:Train (Epoch 71): Loss/seq after 03450 batchs: 685.2346801757812
INFO:root:Train (Epoch 71): Loss/seq after 03500 batchs: 686.023681640625
INFO:root:Train (Epoch 71): Loss/seq after 03550 batchs: 682.4624633789062
INFO:root:Train (Epoch 71): Loss/seq after 03600 batchs: 690.910888671875
INFO:root:Train (Epoch 71): Loss/seq after 03650 batchs: 687.6176147460938
INFO:root:Train (Epoch 71): Loss/seq after 03700 batchs: 689.4400024414062
INFO:root:Train (Epoch 71): Loss/seq after 03750 batchs: 693.8301391601562
INFO:root:Train (Epoch 71): Loss/seq after 03800 batchs: 690.2596435546875
INFO:root:Train (Epoch 71): Loss/seq after 03850 batchs: 689.4702758789062
INFO:root:Train (Epoch 71): Loss/seq after 03900 batchs: 692.4301147460938
INFO:root:Train (Epoch 71): Loss/seq after 03950 batchs: 695.2066040039062
INFO:root:Train (Epoch 71): Loss/seq after 04000 batchs: 690.6683349609375
INFO:root:Train (Epoch 71): Loss/seq after 04050 batchs: 685.9476318359375
INFO:root:Train (Epoch 71): Loss/seq after 04100 batchs: 683.51513671875
INFO:root:Train (Epoch 71): Loss/seq after 04150 batchs: 682.592041015625
INFO:root:Train (Epoch 71): Loss/seq after 04200 batchs: 680.6228637695312
INFO:root:Train (Epoch 71): Loss/seq after 04250 batchs: 678.4169921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 71): Loss/seq after 00000 batches: 622.2591552734375
INFO:root:# Valid (Epoch 71): Loss/seq after 00050 batches: 775.0669555664062
INFO:root:# Valid (Epoch 71): Loss/seq after 00100 batches: 828.2362670898438
INFO:root:# Valid (Epoch 71): Loss/seq after 00150 batches: 629.105712890625
INFO:root:# Valid (Epoch 71): Loss/seq after 00200 batches: 592.8677368164062
INFO:root:Artifacts: Make stick videos for epoch 71
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_71_on_20220422_052351.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_71_index_1625_on_20220422_052351.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 72): Loss/seq after 00000 batchs: 1287.2957763671875
INFO:root:Train (Epoch 72): Loss/seq after 00050 batchs: 967.365478515625
INFO:root:Train (Epoch 72): Loss/seq after 00100 batchs: 985.23583984375
INFO:root:Train (Epoch 72): Loss/seq after 00150 batchs: 892.4625244140625
INFO:root:Train (Epoch 72): Loss/seq after 00200 batchs: 986.9759521484375
INFO:root:Train (Epoch 72): Loss/seq after 00250 batchs: 1102.58837890625
INFO:root:Train (Epoch 72): Loss/seq after 00300 batchs: 1076.0203857421875
INFO:root:Train (Epoch 72): Loss/seq after 00350 batchs: 1001.111572265625
INFO:root:Train (Epoch 72): Loss/seq after 00400 batchs: 1004.9703369140625
INFO:root:Train (Epoch 72): Loss/seq after 00450 batchs: 972.224609375
INFO:root:Train (Epoch 72): Loss/seq after 00500 batchs: 950.029296875
INFO:root:Train (Epoch 72): Loss/seq after 00550 batchs: 916.2234497070312
INFO:root:Train (Epoch 72): Loss/seq after 00600 batchs: 881.6317138671875
INFO:root:Train (Epoch 72): Loss/seq after 00650 batchs: 857.3357543945312
INFO:root:Train (Epoch 72): Loss/seq after 00700 batchs: 825.5991821289062
INFO:root:Train (Epoch 72): Loss/seq after 00750 batchs: 836.8228149414062
INFO:root:Train (Epoch 72): Loss/seq after 00800 batchs: 837.9221801757812
INFO:root:Train (Epoch 72): Loss/seq after 00850 batchs: 813.9163818359375
INFO:root:Train (Epoch 72): Loss/seq after 00900 batchs: 794.8990478515625
INFO:root:Train (Epoch 72): Loss/seq after 00950 batchs: 792.5090942382812
INFO:root:Train (Epoch 72): Loss/seq after 01000 batchs: 782.1136474609375
INFO:root:Train (Epoch 72): Loss/seq after 01050 batchs: 766.525146484375
INFO:root:Train (Epoch 72): Loss/seq after 01100 batchs: 754.7964477539062
INFO:root:Train (Epoch 72): Loss/seq after 01150 batchs: 734.7591552734375
INFO:root:Train (Epoch 72): Loss/seq after 01200 batchs: 737.8934936523438
INFO:root:Train (Epoch 72): Loss/seq after 01250 batchs: 733.794189453125
INFO:root:Train (Epoch 72): Loss/seq after 01300 batchs: 719.1179809570312
INFO:root:Train (Epoch 72): Loss/seq after 01350 batchs: 708.6937866210938
INFO:root:Train (Epoch 72): Loss/seq after 01400 batchs: 716.519775390625
INFO:root:Train (Epoch 72): Loss/seq after 01450 batchs: 717.1387939453125
INFO:root:Train (Epoch 72): Loss/seq after 01500 batchs: 722.0527954101562
INFO:root:Train (Epoch 72): Loss/seq after 01550 batchs: 725.2933959960938
INFO:root:Train (Epoch 72): Loss/seq after 01600 batchs: 719.1824951171875
INFO:root:Train (Epoch 72): Loss/seq after 01650 batchs: 716.145263671875
INFO:root:Train (Epoch 72): Loss/seq after 01700 batchs: 716.729248046875
INFO:root:Train (Epoch 72): Loss/seq after 01750 batchs: 712.8668823242188
INFO:root:Train (Epoch 72): Loss/seq after 01800 batchs: 709.2656860351562
INFO:root:Train (Epoch 72): Loss/seq after 01850 batchs: 704.552001953125
INFO:root:Train (Epoch 72): Loss/seq after 01900 batchs: 705.6390380859375
INFO:root:Train (Epoch 72): Loss/seq after 01950 batchs: 703.4678955078125
INFO:root:Train (Epoch 72): Loss/seq after 02000 batchs: 701.0632934570312
INFO:root:Train (Epoch 72): Loss/seq after 02050 batchs: 699.4490966796875
INFO:root:Train (Epoch 72): Loss/seq after 02100 batchs: 695.6657104492188
INFO:root:Train (Epoch 72): Loss/seq after 02150 batchs: 692.823486328125
INFO:root:Train (Epoch 72): Loss/seq after 02200 batchs: 689.0967407226562
INFO:root:Train (Epoch 72): Loss/seq after 02250 batchs: 688.6376953125
INFO:root:Train (Epoch 72): Loss/seq after 02300 batchs: 685.7219848632812
INFO:root:Train (Epoch 72): Loss/seq after 02350 batchs: 681.1736450195312
INFO:root:Train (Epoch 72): Loss/seq after 02400 batchs: 681.8373413085938
INFO:root:Train (Epoch 72): Loss/seq after 02450 batchs: 675.7699584960938
INFO:root:Train (Epoch 72): Loss/seq after 02500 batchs: 665.4795532226562
INFO:root:Train (Epoch 72): Loss/seq after 02550 batchs: 657.9419555664062
INFO:root:Train (Epoch 72): Loss/seq after 02600 batchs: 656.176513671875
INFO:root:Train (Epoch 72): Loss/seq after 02650 batchs: 653.3826293945312
INFO:root:Train (Epoch 72): Loss/seq after 02700 batchs: 651.013916015625
INFO:root:Train (Epoch 72): Loss/seq after 02750 batchs: 652.0360717773438
INFO:root:Train (Epoch 72): Loss/seq after 02800 batchs: 653.4312133789062
INFO:root:Train (Epoch 72): Loss/seq after 02850 batchs: 653.8855590820312
INFO:root:Train (Epoch 72): Loss/seq after 02900 batchs: 655.4835205078125
INFO:root:Train (Epoch 72): Loss/seq after 02950 batchs: 653.8523559570312
INFO:root:Train (Epoch 72): Loss/seq after 03000 batchs: 658.1358642578125
INFO:root:Train (Epoch 72): Loss/seq after 03050 batchs: 662.14111328125
INFO:root:Train (Epoch 72): Loss/seq after 03100 batchs: 669.3841552734375
INFO:root:Train (Epoch 72): Loss/seq after 03150 batchs: 672.19482421875
INFO:root:Train (Epoch 72): Loss/seq after 03200 batchs: 675.0330200195312
INFO:root:Train (Epoch 72): Loss/seq after 03250 batchs: 679.3731079101562
INFO:root:Train (Epoch 72): Loss/seq after 03300 batchs: 678.3228759765625
INFO:root:Train (Epoch 72): Loss/seq after 03350 batchs: 678.2119750976562
INFO:root:Train (Epoch 72): Loss/seq after 03400 batchs: 672.9112548828125
INFO:root:Train (Epoch 72): Loss/seq after 03450 batchs: 670.5377807617188
INFO:root:Train (Epoch 72): Loss/seq after 03500 batchs: 671.3146362304688
INFO:root:Train (Epoch 72): Loss/seq after 03550 batchs: 668.087646484375
INFO:root:Train (Epoch 72): Loss/seq after 03600 batchs: 676.9573974609375
INFO:root:Train (Epoch 72): Loss/seq after 03650 batchs: 673.6520385742188
INFO:root:Train (Epoch 72): Loss/seq after 03700 batchs: 675.9341430664062
INFO:root:Train (Epoch 72): Loss/seq after 03750 batchs: 680.3682250976562
INFO:root:Train (Epoch 72): Loss/seq after 03800 batchs: 677.0202026367188
INFO:root:Train (Epoch 72): Loss/seq after 03850 batchs: 676.3666381835938
INFO:root:Train (Epoch 72): Loss/seq after 03900 batchs: 679.6841430664062
INFO:root:Train (Epoch 72): Loss/seq after 03950 batchs: 682.5115356445312
INFO:root:Train (Epoch 72): Loss/seq after 04000 batchs: 678.03271484375
INFO:root:Train (Epoch 72): Loss/seq after 04050 batchs: 673.4760131835938
INFO:root:Train (Epoch 72): Loss/seq after 04100 batchs: 671.3468627929688
INFO:root:Train (Epoch 72): Loss/seq after 04150 batchs: 670.5993041992188
INFO:root:Train (Epoch 72): Loss/seq after 04200 batchs: 668.7338256835938
INFO:root:Train (Epoch 72): Loss/seq after 04250 batchs: 666.6483154296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 72): Loss/seq after 00000 batches: 631.5231323242188
INFO:root:# Valid (Epoch 72): Loss/seq after 00050 batches: 780.7981567382812
INFO:root:# Valid (Epoch 72): Loss/seq after 00100 batches: 872.772705078125
INFO:root:# Valid (Epoch 72): Loss/seq after 00150 batches: 664.427978515625
INFO:root:# Valid (Epoch 72): Loss/seq after 00200 batches: 624.4099731445312
INFO:root:Artifacts: Make stick videos for epoch 72
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_72_on_20220422_052836.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_72_index_1364_on_20220422_052836.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 73): Loss/seq after 00000 batchs: 1342.5296630859375
INFO:root:Train (Epoch 73): Loss/seq after 00050 batchs: 982.3560180664062
INFO:root:Train (Epoch 73): Loss/seq after 00100 batchs: 992.8598022460938
INFO:root:Train (Epoch 73): Loss/seq after 00150 batchs: 921.0712890625
INFO:root:Train (Epoch 73): Loss/seq after 00200 batchs: 1031.2230224609375
INFO:root:Train (Epoch 73): Loss/seq after 00250 batchs: 1140.6435546875
INFO:root:Train (Epoch 73): Loss/seq after 00300 batchs: 1107.517578125
INFO:root:Train (Epoch 73): Loss/seq after 00350 batchs: 1028.4593505859375
INFO:root:Train (Epoch 73): Loss/seq after 00400 batchs: 1031.230224609375
INFO:root:Train (Epoch 73): Loss/seq after 00450 batchs: 996.1716918945312
INFO:root:Train (Epoch 73): Loss/seq after 00500 batchs: 974.123046875
INFO:root:Train (Epoch 73): Loss/seq after 00550 batchs: 939.2398071289062
INFO:root:Train (Epoch 73): Loss/seq after 00600 batchs: 906.2053833007812
INFO:root:Train (Epoch 73): Loss/seq after 00650 batchs: 879.4382934570312
INFO:root:Train (Epoch 73): Loss/seq after 00700 batchs: 847.0376586914062
INFO:root:Train (Epoch 73): Loss/seq after 00750 batchs: 857.6456909179688
INFO:root:Train (Epoch 73): Loss/seq after 00800 batchs: 857.3526611328125
INFO:root:Train (Epoch 73): Loss/seq after 00850 batchs: 831.9909057617188
INFO:root:Train (Epoch 73): Loss/seq after 00900 batchs: 812.74755859375
INFO:root:Train (Epoch 73): Loss/seq after 00950 batchs: 811.2342529296875
INFO:root:Train (Epoch 73): Loss/seq after 01000 batchs: 799.967529296875
INFO:root:Train (Epoch 73): Loss/seq after 01050 batchs: 783.2527465820312
INFO:root:Train (Epoch 73): Loss/seq after 01100 batchs: 770.0440673828125
INFO:root:Train (Epoch 73): Loss/seq after 01150 batchs: 750.1509399414062
INFO:root:Train (Epoch 73): Loss/seq after 01200 batchs: 752.4982299804688
INFO:root:Train (Epoch 73): Loss/seq after 01250 batchs: 747.8040771484375
INFO:root:Train (Epoch 73): Loss/seq after 01300 batchs: 732.6353149414062
INFO:root:Train (Epoch 73): Loss/seq after 01350 batchs: 721.087646484375
INFO:root:Train (Epoch 73): Loss/seq after 01400 batchs: 726.783203125
INFO:root:Train (Epoch 73): Loss/seq after 01450 batchs: 726.7789306640625
INFO:root:Train (Epoch 73): Loss/seq after 01500 batchs: 731.3555908203125
INFO:root:Train (Epoch 73): Loss/seq after 01550 batchs: 733.7557983398438
INFO:root:Train (Epoch 73): Loss/seq after 01600 batchs: 726.7821044921875
INFO:root:Train (Epoch 73): Loss/seq after 01650 batchs: 723.656005859375
INFO:root:Train (Epoch 73): Loss/seq after 01700 batchs: 723.7337646484375
INFO:root:Train (Epoch 73): Loss/seq after 01750 batchs: 719.6629638671875
INFO:root:Train (Epoch 73): Loss/seq after 01800 batchs: 715.7593383789062
INFO:root:Train (Epoch 73): Loss/seq after 01850 batchs: 711.0188598632812
INFO:root:Train (Epoch 73): Loss/seq after 01900 batchs: 712.0248413085938
INFO:root:Train (Epoch 73): Loss/seq after 01950 batchs: 710.0838012695312
INFO:root:Train (Epoch 73): Loss/seq after 02000 batchs: 707.42822265625
INFO:root:Train (Epoch 73): Loss/seq after 02050 batchs: 705.5374145507812
INFO:root:Train (Epoch 73): Loss/seq after 02100 batchs: 701.511962890625
INFO:root:Train (Epoch 73): Loss/seq after 02150 batchs: 698.7269897460938
INFO:root:Train (Epoch 73): Loss/seq after 02200 batchs: 694.7493286132812
INFO:root:Train (Epoch 73): Loss/seq after 02250 batchs: 694.343017578125
INFO:root:Train (Epoch 73): Loss/seq after 02300 batchs: 691.9484252929688
INFO:root:Train (Epoch 73): Loss/seq after 02350 batchs: 686.1998291015625
INFO:root:Train (Epoch 73): Loss/seq after 02400 batchs: 686.2371215820312
INFO:root:Train (Epoch 73): Loss/seq after 02450 batchs: 679.8515625
INFO:root:Train (Epoch 73): Loss/seq after 02500 batchs: 669.4172973632812
INFO:root:Train (Epoch 73): Loss/seq after 02550 batchs: 661.7286987304688
INFO:root:Train (Epoch 73): Loss/seq after 02600 batchs: 659.9281005859375
INFO:root:Train (Epoch 73): Loss/seq after 02650 batchs: 657.13671875
INFO:root:Train (Epoch 73): Loss/seq after 02700 batchs: 654.5640869140625
INFO:root:Train (Epoch 73): Loss/seq after 02750 batchs: 655.4909057617188
INFO:root:Train (Epoch 73): Loss/seq after 02800 batchs: 655.9783325195312
INFO:root:Train (Epoch 73): Loss/seq after 02850 batchs: 656.2095947265625
INFO:root:Train (Epoch 73): Loss/seq after 02900 batchs: 657.578857421875
INFO:root:Train (Epoch 73): Loss/seq after 02950 batchs: 655.8543701171875
INFO:root:Train (Epoch 73): Loss/seq after 03000 batchs: 660.0906372070312
INFO:root:Train (Epoch 73): Loss/seq after 03050 batchs: 665.01806640625
INFO:root:Train (Epoch 73): Loss/seq after 03100 batchs: 671.0328979492188
INFO:root:Train (Epoch 73): Loss/seq after 03150 batchs: 673.6671142578125
INFO:root:Train (Epoch 73): Loss/seq after 03200 batchs: 676.368408203125
INFO:root:Train (Epoch 73): Loss/seq after 03250 batchs: 680.8157958984375
INFO:root:Train (Epoch 73): Loss/seq after 03300 batchs: 680.6390380859375
INFO:root:Train (Epoch 73): Loss/seq after 03350 batchs: 680.7520141601562
INFO:root:Train (Epoch 73): Loss/seq after 03400 batchs: 675.2403564453125
INFO:root:Train (Epoch 73): Loss/seq after 03450 batchs: 673.3267211914062
INFO:root:Train (Epoch 73): Loss/seq after 03500 batchs: 675.385009765625
INFO:root:Train (Epoch 73): Loss/seq after 03550 batchs: 673.24267578125
INFO:root:Train (Epoch 73): Loss/seq after 03600 batchs: 682.6780395507812
INFO:root:Train (Epoch 73): Loss/seq after 03650 batchs: 680.8306274414062
INFO:root:Train (Epoch 73): Loss/seq after 03700 batchs: 683.0521850585938
INFO:root:Train (Epoch 73): Loss/seq after 03750 batchs: 687.4584350585938
INFO:root:Train (Epoch 73): Loss/seq after 03800 batchs: 684.0255126953125
INFO:root:Train (Epoch 73): Loss/seq after 03850 batchs: 683.333984375
INFO:root:Train (Epoch 73): Loss/seq after 03900 batchs: 686.5486450195312
INFO:root:Train (Epoch 73): Loss/seq after 03950 batchs: 689.8040771484375
INFO:root:Train (Epoch 73): Loss/seq after 04000 batchs: 685.3320922851562
INFO:root:Train (Epoch 73): Loss/seq after 04050 batchs: 680.759033203125
INFO:root:Train (Epoch 73): Loss/seq after 04100 batchs: 678.5231323242188
INFO:root:Train (Epoch 73): Loss/seq after 04150 batchs: 677.6649780273438
INFO:root:Train (Epoch 73): Loss/seq after 04200 batchs: 675.8165893554688
INFO:root:Train (Epoch 73): Loss/seq after 04250 batchs: 673.6304321289062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 73): Loss/seq after 00000 batches: 580.024658203125
INFO:root:# Valid (Epoch 73): Loss/seq after 00050 batches: 769.73583984375
INFO:root:# Valid (Epoch 73): Loss/seq after 00100 batches: 836.719970703125
INFO:root:# Valid (Epoch 73): Loss/seq after 00150 batches: 638.9469604492188
INFO:root:# Valid (Epoch 73): Loss/seq after 00200 batches: 601.5897216796875
INFO:root:Artifacts: Make stick videos for epoch 73
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_73_on_20220422_053345.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_73_index_1533_on_20220422_053345.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 74): Loss/seq after 00000 batchs: 1297.263671875
INFO:root:Train (Epoch 74): Loss/seq after 00050 batchs: 979.5896606445312
INFO:root:Train (Epoch 74): Loss/seq after 00100 batchs: 992.1604614257812
INFO:root:Train (Epoch 74): Loss/seq after 00150 batchs: 900.8513793945312
INFO:root:Train (Epoch 74): Loss/seq after 00200 batchs: 984.2514038085938
INFO:root:Train (Epoch 74): Loss/seq after 00250 batchs: 1099.8409423828125
INFO:root:Train (Epoch 74): Loss/seq after 00300 batchs: 1073.4974365234375
INFO:root:Train (Epoch 74): Loss/seq after 00350 batchs: 997.85205078125
INFO:root:Train (Epoch 74): Loss/seq after 00400 batchs: 994.4588623046875
INFO:root:Train (Epoch 74): Loss/seq after 00450 batchs: 962.813720703125
INFO:root:Train (Epoch 74): Loss/seq after 00500 batchs: 940.6661376953125
INFO:root:Train (Epoch 74): Loss/seq after 00550 batchs: 909.0460815429688
INFO:root:Train (Epoch 74): Loss/seq after 00600 batchs: 875.6946411132812
INFO:root:Train (Epoch 74): Loss/seq after 00650 batchs: 850.8639526367188
INFO:root:Train (Epoch 74): Loss/seq after 00700 batchs: 818.8865966796875
INFO:root:Train (Epoch 74): Loss/seq after 00750 batchs: 828.7935180664062
INFO:root:Train (Epoch 74): Loss/seq after 00800 batchs: 829.806396484375
INFO:root:Train (Epoch 74): Loss/seq after 00850 batchs: 806.53173828125
INFO:root:Train (Epoch 74): Loss/seq after 00900 batchs: 788.664306640625
INFO:root:Train (Epoch 74): Loss/seq after 00950 batchs: 787.4434814453125
INFO:root:Train (Epoch 74): Loss/seq after 01000 batchs: 776.6713256835938
INFO:root:Train (Epoch 74): Loss/seq after 01050 batchs: 761.2200927734375
INFO:root:Train (Epoch 74): Loss/seq after 01100 batchs: 750.219482421875
INFO:root:Train (Epoch 74): Loss/seq after 01150 batchs: 730.017578125
INFO:root:Train (Epoch 74): Loss/seq after 01200 batchs: 733.3823852539062
INFO:root:Train (Epoch 74): Loss/seq after 01250 batchs: 728.9588623046875
INFO:root:Train (Epoch 74): Loss/seq after 01300 batchs: 714.1357421875
INFO:root:Train (Epoch 74): Loss/seq after 01350 batchs: 702.9782104492188
INFO:root:Train (Epoch 74): Loss/seq after 01400 batchs: 709.87060546875
INFO:root:Train (Epoch 74): Loss/seq after 01450 batchs: 710.7899780273438
INFO:root:Train (Epoch 74): Loss/seq after 01500 batchs: 716.1534423828125
INFO:root:Train (Epoch 74): Loss/seq after 01550 batchs: 719.0855102539062
INFO:root:Train (Epoch 74): Loss/seq after 01600 batchs: 712.7390747070312
INFO:root:Train (Epoch 74): Loss/seq after 01650 batchs: 709.6904907226562
INFO:root:Train (Epoch 74): Loss/seq after 01700 batchs: 710.0286254882812
INFO:root:Train (Epoch 74): Loss/seq after 01750 batchs: 706.6119384765625
INFO:root:Train (Epoch 74): Loss/seq after 01800 batchs: 703.0895385742188
INFO:root:Train (Epoch 74): Loss/seq after 01850 batchs: 698.773193359375
INFO:root:Train (Epoch 74): Loss/seq after 01900 batchs: 699.8095092773438
INFO:root:Train (Epoch 74): Loss/seq after 01950 batchs: 697.5533447265625
INFO:root:Train (Epoch 74): Loss/seq after 02000 batchs: 695.291748046875
INFO:root:Train (Epoch 74): Loss/seq after 02050 batchs: 693.4984741210938
INFO:root:Train (Epoch 74): Loss/seq after 02100 batchs: 689.9764404296875
INFO:root:Train (Epoch 74): Loss/seq after 02150 batchs: 687.1397094726562
INFO:root:Train (Epoch 74): Loss/seq after 02200 batchs: 683.2450561523438
INFO:root:Train (Epoch 74): Loss/seq after 02250 batchs: 682.2625732421875
INFO:root:Train (Epoch 74): Loss/seq after 02300 batchs: 678.8760986328125
INFO:root:Train (Epoch 74): Loss/seq after 02350 batchs: 673.9090576171875
INFO:root:Train (Epoch 74): Loss/seq after 02400 batchs: 674.38525390625
INFO:root:Train (Epoch 74): Loss/seq after 02450 batchs: 668.2835083007812
INFO:root:Train (Epoch 74): Loss/seq after 02500 batchs: 658.0574951171875
INFO:root:Train (Epoch 74): Loss/seq after 02550 batchs: 650.5155029296875
INFO:root:Train (Epoch 74): Loss/seq after 02600 batchs: 648.9318237304688
INFO:root:Train (Epoch 74): Loss/seq after 02650 batchs: 646.3163452148438
INFO:root:Train (Epoch 74): Loss/seq after 02700 batchs: 643.9004516601562
INFO:root:Train (Epoch 74): Loss/seq after 02750 batchs: 644.0153198242188
INFO:root:Train (Epoch 74): Loss/seq after 02800 batchs: 644.5256958007812
INFO:root:Train (Epoch 74): Loss/seq after 02850 batchs: 645.0185546875
INFO:root:Train (Epoch 74): Loss/seq after 02900 batchs: 646.7774047851562
INFO:root:Train (Epoch 74): Loss/seq after 02950 batchs: 645.3515625
INFO:root:Train (Epoch 74): Loss/seq after 03000 batchs: 649.7781982421875
INFO:root:Train (Epoch 74): Loss/seq after 03050 batchs: 653.3591918945312
INFO:root:Train (Epoch 74): Loss/seq after 03100 batchs: 659.326171875
INFO:root:Train (Epoch 74): Loss/seq after 03150 batchs: 663.4488525390625
INFO:root:Train (Epoch 74): Loss/seq after 03200 batchs: 666.427978515625
INFO:root:Train (Epoch 74): Loss/seq after 03250 batchs: 670.7432861328125
INFO:root:Train (Epoch 74): Loss/seq after 03300 batchs: 670.2105712890625
INFO:root:Train (Epoch 74): Loss/seq after 03350 batchs: 670.2606811523438
INFO:root:Train (Epoch 74): Loss/seq after 03400 batchs: 664.8814086914062
INFO:root:Train (Epoch 74): Loss/seq after 03450 batchs: 662.5982055664062
INFO:root:Train (Epoch 74): Loss/seq after 03500 batchs: 663.3609619140625
INFO:root:Train (Epoch 74): Loss/seq after 03550 batchs: 660.0103149414062
INFO:root:Train (Epoch 74): Loss/seq after 03600 batchs: 668.5250854492188
INFO:root:Train (Epoch 74): Loss/seq after 03650 batchs: 665.4892578125
INFO:root:Train (Epoch 74): Loss/seq after 03700 batchs: 667.75
INFO:root:Train (Epoch 74): Loss/seq after 03750 batchs: 672.469970703125
INFO:root:Train (Epoch 74): Loss/seq after 03800 batchs: 669.19189453125
INFO:root:Train (Epoch 74): Loss/seq after 03850 batchs: 668.5693359375
INFO:root:Train (Epoch 74): Loss/seq after 03900 batchs: 671.9296264648438
INFO:root:Train (Epoch 74): Loss/seq after 03950 batchs: 674.7838134765625
INFO:root:Train (Epoch 74): Loss/seq after 04000 batchs: 670.3445434570312
INFO:root:Train (Epoch 74): Loss/seq after 04050 batchs: 665.8970336914062
INFO:root:Train (Epoch 74): Loss/seq after 04100 batchs: 663.72509765625
INFO:root:Train (Epoch 74): Loss/seq after 04150 batchs: 662.9953002929688
INFO:root:Train (Epoch 74): Loss/seq after 04200 batchs: 661.1842651367188
INFO:root:Train (Epoch 74): Loss/seq after 04250 batchs: 659.1740112304688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 74): Loss/seq after 00000 batches: 561.4076538085938
INFO:root:# Valid (Epoch 74): Loss/seq after 00050 batches: 779.0376586914062
INFO:root:# Valid (Epoch 74): Loss/seq after 00100 batches: 828.32958984375
INFO:root:# Valid (Epoch 74): Loss/seq after 00150 batches: 633.2866821289062
INFO:root:# Valid (Epoch 74): Loss/seq after 00200 batches: 601.5145263671875
INFO:root:Artifacts: Make stick videos for epoch 74
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_74_on_20220422_053829.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_74_index_640_on_20220422_053829.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 75): Loss/seq after 00000 batchs: 1318.791259765625
INFO:root:Train (Epoch 75): Loss/seq after 00050 batchs: 969.5923461914062
INFO:root:Train (Epoch 75): Loss/seq after 00100 batchs: 985.8246459960938
INFO:root:Train (Epoch 75): Loss/seq after 00150 batchs: 902.5037231445312
INFO:root:Train (Epoch 75): Loss/seq after 00200 batchs: 991.683349609375
INFO:root:Train (Epoch 75): Loss/seq after 00250 batchs: 1100.1317138671875
INFO:root:Train (Epoch 75): Loss/seq after 00300 batchs: 1073.682373046875
INFO:root:Train (Epoch 75): Loss/seq after 00350 batchs: 996.4674682617188
INFO:root:Train (Epoch 75): Loss/seq after 00400 batchs: 991.5947875976562
INFO:root:Train (Epoch 75): Loss/seq after 00450 batchs: 960.29345703125
INFO:root:Train (Epoch 75): Loss/seq after 00500 batchs: 933.5582275390625
INFO:root:Train (Epoch 75): Loss/seq after 00550 batchs: 901.145263671875
INFO:root:Train (Epoch 75): Loss/seq after 00600 batchs: 867.19580078125
INFO:root:Train (Epoch 75): Loss/seq after 00650 batchs: 841.9598388671875
INFO:root:Train (Epoch 75): Loss/seq after 00700 batchs: 809.7617797851562
INFO:root:Train (Epoch 75): Loss/seq after 00750 batchs: 820.53955078125
INFO:root:Train (Epoch 75): Loss/seq after 00800 batchs: 820.9046630859375
INFO:root:Train (Epoch 75): Loss/seq after 00850 batchs: 797.7943725585938
INFO:root:Train (Epoch 75): Loss/seq after 00900 batchs: 779.939208984375
INFO:root:Train (Epoch 75): Loss/seq after 00950 batchs: 777.7196655273438
INFO:root:Train (Epoch 75): Loss/seq after 01000 batchs: 767.3544921875
INFO:root:Train (Epoch 75): Loss/seq after 01050 batchs: 752.6360473632812
INFO:root:Train (Epoch 75): Loss/seq after 01100 batchs: 741.0750122070312
INFO:root:Train (Epoch 75): Loss/seq after 01150 batchs: 721.6087036132812
INFO:root:Train (Epoch 75): Loss/seq after 01200 batchs: 724.8153076171875
INFO:root:Train (Epoch 75): Loss/seq after 01250 batchs: 720.4434204101562
INFO:root:Train (Epoch 75): Loss/seq after 01300 batchs: 706.3910522460938
INFO:root:Train (Epoch 75): Loss/seq after 01350 batchs: 695.6024169921875
INFO:root:Train (Epoch 75): Loss/seq after 01400 batchs: 703.171142578125
INFO:root:Train (Epoch 75): Loss/seq after 01450 batchs: 704.63720703125
INFO:root:Train (Epoch 75): Loss/seq after 01500 batchs: 709.9727783203125
INFO:root:Train (Epoch 75): Loss/seq after 01550 batchs: 714.0491943359375
INFO:root:Train (Epoch 75): Loss/seq after 01600 batchs: 707.4920654296875
INFO:root:Train (Epoch 75): Loss/seq after 01650 batchs: 704.8087158203125
INFO:root:Train (Epoch 75): Loss/seq after 01700 batchs: 705.3646240234375
INFO:root:Train (Epoch 75): Loss/seq after 01750 batchs: 701.7307739257812
INFO:root:Train (Epoch 75): Loss/seq after 01800 batchs: 698.1085205078125
INFO:root:Train (Epoch 75): Loss/seq after 01850 batchs: 693.441650390625
INFO:root:Train (Epoch 75): Loss/seq after 01900 batchs: 694.4837036132812
INFO:root:Train (Epoch 75): Loss/seq after 01950 batchs: 692.5293579101562
INFO:root:Train (Epoch 75): Loss/seq after 02000 batchs: 690.2457885742188
INFO:root:Train (Epoch 75): Loss/seq after 02050 batchs: 688.3672485351562
INFO:root:Train (Epoch 75): Loss/seq after 02100 batchs: 684.9273681640625
INFO:root:Train (Epoch 75): Loss/seq after 02150 batchs: 682.2552490234375
INFO:root:Train (Epoch 75): Loss/seq after 02200 batchs: 678.557861328125
INFO:root:Train (Epoch 75): Loss/seq after 02250 batchs: 678.1897583007812
INFO:root:Train (Epoch 75): Loss/seq after 02300 batchs: 674.9097900390625
INFO:root:Train (Epoch 75): Loss/seq after 02350 batchs: 670.1759033203125
INFO:root:Train (Epoch 75): Loss/seq after 02400 batchs: 670.6060180664062
INFO:root:Train (Epoch 75): Loss/seq after 02450 batchs: 664.6566162109375
INFO:root:Train (Epoch 75): Loss/seq after 02500 batchs: 654.506103515625
INFO:root:Train (Epoch 75): Loss/seq after 02550 batchs: 647.0296630859375
INFO:root:Train (Epoch 75): Loss/seq after 02600 batchs: 645.1883544921875
INFO:root:Train (Epoch 75): Loss/seq after 02650 batchs: 642.6021118164062
INFO:root:Train (Epoch 75): Loss/seq after 02700 batchs: 640.0811157226562
INFO:root:Train (Epoch 75): Loss/seq after 02750 batchs: 640.0509643554688
INFO:root:Train (Epoch 75): Loss/seq after 02800 batchs: 640.2614135742188
INFO:root:Train (Epoch 75): Loss/seq after 02850 batchs: 640.7764282226562
INFO:root:Train (Epoch 75): Loss/seq after 02900 batchs: 642.31884765625
INFO:root:Train (Epoch 75): Loss/seq after 02950 batchs: 640.9237670898438
INFO:root:Train (Epoch 75): Loss/seq after 03000 batchs: 645.3857421875
INFO:root:Train (Epoch 75): Loss/seq after 03050 batchs: 649.8068237304688
INFO:root:Train (Epoch 75): Loss/seq after 03100 batchs: 655.828369140625
INFO:root:Train (Epoch 75): Loss/seq after 03150 batchs: 658.88525390625
INFO:root:Train (Epoch 75): Loss/seq after 03200 batchs: 662.1056518554688
INFO:root:Train (Epoch 75): Loss/seq after 03250 batchs: 666.3114013671875
INFO:root:Train (Epoch 75): Loss/seq after 03300 batchs: 665.3197021484375
INFO:root:Train (Epoch 75): Loss/seq after 03350 batchs: 664.9147338867188
INFO:root:Train (Epoch 75): Loss/seq after 03400 batchs: 659.5794067382812
INFO:root:Train (Epoch 75): Loss/seq after 03450 batchs: 657.3858642578125
INFO:root:Train (Epoch 75): Loss/seq after 03500 batchs: 658.4682006835938
INFO:root:Train (Epoch 75): Loss/seq after 03550 batchs: 655.250244140625
INFO:root:Train (Epoch 75): Loss/seq after 03600 batchs: 663.7879638671875
INFO:root:Train (Epoch 75): Loss/seq after 03650 batchs: 660.3999633789062
INFO:root:Train (Epoch 75): Loss/seq after 03700 batchs: 662.7258911132812
INFO:root:Train (Epoch 75): Loss/seq after 03750 batchs: 667.3523559570312
INFO:root:Train (Epoch 75): Loss/seq after 03800 batchs: 664.086669921875
INFO:root:Train (Epoch 75): Loss/seq after 03850 batchs: 663.3668823242188
INFO:root:Train (Epoch 75): Loss/seq after 03900 batchs: 666.7250366210938
INFO:root:Train (Epoch 75): Loss/seq after 03950 batchs: 669.5809326171875
INFO:root:Train (Epoch 75): Loss/seq after 04000 batchs: 665.1883544921875
INFO:root:Train (Epoch 75): Loss/seq after 04050 batchs: 660.7326049804688
INFO:root:Train (Epoch 75): Loss/seq after 04100 batchs: 658.761474609375
INFO:root:Train (Epoch 75): Loss/seq after 04150 batchs: 658.100341796875
INFO:root:Train (Epoch 75): Loss/seq after 04200 batchs: 656.3706665039062
INFO:root:Train (Epoch 75): Loss/seq after 04250 batchs: 654.4360961914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 75): Loss/seq after 00000 batches: 591.0516967773438
INFO:root:# Valid (Epoch 75): Loss/seq after 00050 batches: 785.4380493164062
INFO:root:# Valid (Epoch 75): Loss/seq after 00100 batches: 875.5333251953125
INFO:root:# Valid (Epoch 75): Loss/seq after 00150 batches: 660.9534301757812
INFO:root:# Valid (Epoch 75): Loss/seq after 00200 batches: 618.2090454101562
INFO:root:Artifacts: Make stick videos for epoch 75
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_75_on_20220422_054322.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_75_index_177_on_20220422_054322.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 76): Loss/seq after 00000 batchs: 1254.5704345703125
INFO:root:Train (Epoch 76): Loss/seq after 00050 batchs: 951.4335327148438
INFO:root:Train (Epoch 76): Loss/seq after 00100 batchs: 970.4132080078125
INFO:root:Train (Epoch 76): Loss/seq after 00150 batchs: 885.0343627929688
INFO:root:Train (Epoch 76): Loss/seq after 00200 batchs: 977.146484375
INFO:root:Train (Epoch 76): Loss/seq after 00250 batchs: 1092.12841796875
INFO:root:Train (Epoch 76): Loss/seq after 00300 batchs: 1066.3876953125
INFO:root:Train (Epoch 76): Loss/seq after 00350 batchs: 988.8500366210938
INFO:root:Train (Epoch 76): Loss/seq after 00400 batchs: 985.9913940429688
INFO:root:Train (Epoch 76): Loss/seq after 00450 batchs: 955.2766723632812
INFO:root:Train (Epoch 76): Loss/seq after 00500 batchs: 933.232666015625
INFO:root:Train (Epoch 76): Loss/seq after 00550 batchs: 900.788818359375
INFO:root:Train (Epoch 76): Loss/seq after 00600 batchs: 866.7698364257812
INFO:root:Train (Epoch 76): Loss/seq after 00650 batchs: 842.6415405273438
INFO:root:Train (Epoch 76): Loss/seq after 00700 batchs: 811.9088134765625
INFO:root:Train (Epoch 76): Loss/seq after 00750 batchs: 822.9180908203125
INFO:root:Train (Epoch 76): Loss/seq after 00800 batchs: 824.3104248046875
INFO:root:Train (Epoch 76): Loss/seq after 00850 batchs: 800.2312622070312
INFO:root:Train (Epoch 76): Loss/seq after 00900 batchs: 782.1063842773438
INFO:root:Train (Epoch 76): Loss/seq after 00950 batchs: 782.4300537109375
INFO:root:Train (Epoch 76): Loss/seq after 01000 batchs: 772.421142578125
INFO:root:Train (Epoch 76): Loss/seq after 01050 batchs: 761.7637329101562
INFO:root:Train (Epoch 76): Loss/seq after 01100 batchs: 749.1002197265625
INFO:root:Train (Epoch 76): Loss/seq after 01150 batchs: 729.1558837890625
INFO:root:Train (Epoch 76): Loss/seq after 01200 batchs: 732.0316772460938
INFO:root:Train (Epoch 76): Loss/seq after 01250 batchs: 727.4698486328125
INFO:root:Train (Epoch 76): Loss/seq after 01300 batchs: 712.4181518554688
INFO:root:Train (Epoch 76): Loss/seq after 01350 batchs: 700.61279296875
INFO:root:Train (Epoch 76): Loss/seq after 01400 batchs: 706.7803344726562
INFO:root:Train (Epoch 76): Loss/seq after 01450 batchs: 707.1610107421875
INFO:root:Train (Epoch 76): Loss/seq after 01500 batchs: 712.2921752929688
INFO:root:Train (Epoch 76): Loss/seq after 01550 batchs: 714.8292846679688
INFO:root:Train (Epoch 76): Loss/seq after 01600 batchs: 708.15771484375
INFO:root:Train (Epoch 76): Loss/seq after 01650 batchs: 705.612548828125
INFO:root:Train (Epoch 76): Loss/seq after 01700 batchs: 706.3173828125
INFO:root:Train (Epoch 76): Loss/seq after 01750 batchs: 702.79345703125
INFO:root:Train (Epoch 76): Loss/seq after 01800 batchs: 699.2686767578125
INFO:root:Train (Epoch 76): Loss/seq after 01850 batchs: 695.0603637695312
INFO:root:Train (Epoch 76): Loss/seq after 01900 batchs: 696.2013549804688
INFO:root:Train (Epoch 76): Loss/seq after 01950 batchs: 695.4862060546875
INFO:root:Train (Epoch 76): Loss/seq after 02000 batchs: 693.8289794921875
INFO:root:Train (Epoch 76): Loss/seq after 02050 batchs: 692.2025146484375
INFO:root:Train (Epoch 76): Loss/seq after 02100 batchs: 688.2877197265625
INFO:root:Train (Epoch 76): Loss/seq after 02150 batchs: 685.6109619140625
INFO:root:Train (Epoch 76): Loss/seq after 02200 batchs: 682.0425415039062
INFO:root:Train (Epoch 76): Loss/seq after 02250 batchs: 681.38232421875
INFO:root:Train (Epoch 76): Loss/seq after 02300 batchs: 678.0863647460938
INFO:root:Train (Epoch 76): Loss/seq after 02350 batchs: 672.6024780273438
INFO:root:Train (Epoch 76): Loss/seq after 02400 batchs: 672.8113403320312
INFO:root:Train (Epoch 76): Loss/seq after 02450 batchs: 666.7188110351562
INFO:root:Train (Epoch 76): Loss/seq after 02500 batchs: 656.5546875
INFO:root:Train (Epoch 76): Loss/seq after 02550 batchs: 648.9610595703125
INFO:root:Train (Epoch 76): Loss/seq after 02600 batchs: 647.0147705078125
INFO:root:Train (Epoch 76): Loss/seq after 02650 batchs: 644.1785888671875
INFO:root:Train (Epoch 76): Loss/seq after 02700 batchs: 641.709228515625
INFO:root:Train (Epoch 76): Loss/seq after 02750 batchs: 641.1337280273438
INFO:root:Train (Epoch 76): Loss/seq after 02800 batchs: 640.9205322265625
INFO:root:Train (Epoch 76): Loss/seq after 02850 batchs: 641.4962158203125
INFO:root:Train (Epoch 76): Loss/seq after 02900 batchs: 642.92919921875
INFO:root:Train (Epoch 76): Loss/seq after 02950 batchs: 641.3148803710938
INFO:root:Train (Epoch 76): Loss/seq after 03000 batchs: 645.7770385742188
INFO:root:Train (Epoch 76): Loss/seq after 03050 batchs: 648.7763671875
INFO:root:Train (Epoch 76): Loss/seq after 03100 batchs: 654.345458984375
INFO:root:Train (Epoch 76): Loss/seq after 03150 batchs: 656.9285888671875
INFO:root:Train (Epoch 76): Loss/seq after 03200 batchs: 659.5133666992188
INFO:root:Train (Epoch 76): Loss/seq after 03250 batchs: 664.22412109375
INFO:root:Train (Epoch 76): Loss/seq after 03300 batchs: 663.020751953125
INFO:root:Train (Epoch 76): Loss/seq after 03350 batchs: 662.8615112304688
INFO:root:Train (Epoch 76): Loss/seq after 03400 batchs: 657.5452270507812
INFO:root:Train (Epoch 76): Loss/seq after 03450 batchs: 655.2567749023438
INFO:root:Train (Epoch 76): Loss/seq after 03500 batchs: 655.7561645507812
INFO:root:Train (Epoch 76): Loss/seq after 03550 batchs: 652.4257202148438
INFO:root:Train (Epoch 76): Loss/seq after 03600 batchs: 660.9239501953125
INFO:root:Train (Epoch 76): Loss/seq after 03650 batchs: 657.9178466796875
INFO:root:Train (Epoch 76): Loss/seq after 03700 batchs: 660.2550048828125
INFO:root:Train (Epoch 76): Loss/seq after 03750 batchs: 664.9125366210938
INFO:root:Train (Epoch 76): Loss/seq after 03800 batchs: 661.635498046875
INFO:root:Train (Epoch 76): Loss/seq after 03850 batchs: 661.0455932617188
INFO:root:Train (Epoch 76): Loss/seq after 03900 batchs: 664.2991333007812
INFO:root:Train (Epoch 76): Loss/seq after 03950 batchs: 667.2264404296875
INFO:root:Train (Epoch 76): Loss/seq after 04000 batchs: 662.9176635742188
INFO:root:Train (Epoch 76): Loss/seq after 04050 batchs: 658.5543823242188
INFO:root:Train (Epoch 76): Loss/seq after 04100 batchs: 656.4716796875
INFO:root:Train (Epoch 76): Loss/seq after 04150 batchs: 655.83837890625
INFO:root:Train (Epoch 76): Loss/seq after 04200 batchs: 653.9826049804688
INFO:root:Train (Epoch 76): Loss/seq after 04250 batchs: 652.0841064453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 76): Loss/seq after 00000 batches: 580.2471313476562
INFO:root:# Valid (Epoch 76): Loss/seq after 00050 batches: 753.8306884765625
INFO:root:# Valid (Epoch 76): Loss/seq after 00100 batches: 829.7058715820312
INFO:root:# Valid (Epoch 76): Loss/seq after 00150 batches: 624.3675537109375
INFO:root:# Valid (Epoch 76): Loss/seq after 00200 batches: 588.8829345703125
INFO:root:Artifacts: Make stick videos for epoch 76
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_76_on_20220422_054812.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_76_index_1256_on_20220422_054812.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 77): Loss/seq after 00000 batchs: 1342.5181884765625
INFO:root:Train (Epoch 77): Loss/seq after 00050 batchs: 946.9571533203125
INFO:root:Train (Epoch 77): Loss/seq after 00100 batchs: 982.4002685546875
INFO:root:Train (Epoch 77): Loss/seq after 00150 batchs: 896.999267578125
INFO:root:Train (Epoch 77): Loss/seq after 00200 batchs: 977.7139282226562
INFO:root:Train (Epoch 77): Loss/seq after 00250 batchs: 1089.62890625
INFO:root:Train (Epoch 77): Loss/seq after 00300 batchs: 1064.350830078125
INFO:root:Train (Epoch 77): Loss/seq after 00350 batchs: 987.47900390625
INFO:root:Train (Epoch 77): Loss/seq after 00400 batchs: 985.1146850585938
INFO:root:Train (Epoch 77): Loss/seq after 00450 batchs: 954.3770751953125
INFO:root:Train (Epoch 77): Loss/seq after 00500 batchs: 930.1641845703125
INFO:root:Train (Epoch 77): Loss/seq after 00550 batchs: 896.798095703125
INFO:root:Train (Epoch 77): Loss/seq after 00600 batchs: 863.500732421875
INFO:root:Train (Epoch 77): Loss/seq after 00650 batchs: 839.1642456054688
INFO:root:Train (Epoch 77): Loss/seq after 00700 batchs: 808.8408813476562
INFO:root:Train (Epoch 77): Loss/seq after 00750 batchs: 819.1203002929688
INFO:root:Train (Epoch 77): Loss/seq after 00800 batchs: 819.8396606445312
INFO:root:Train (Epoch 77): Loss/seq after 00850 batchs: 796.207763671875
INFO:root:Train (Epoch 77): Loss/seq after 00900 batchs: 777.3473510742188
INFO:root:Train (Epoch 77): Loss/seq after 00950 batchs: 775.4329223632812
INFO:root:Train (Epoch 77): Loss/seq after 01000 batchs: 766.0305786132812
INFO:root:Train (Epoch 77): Loss/seq after 01050 batchs: 750.673828125
INFO:root:Train (Epoch 77): Loss/seq after 01100 batchs: 738.1334838867188
INFO:root:Train (Epoch 77): Loss/seq after 01150 batchs: 718.2820434570312
INFO:root:Train (Epoch 77): Loss/seq after 01200 batchs: 721.5904541015625
INFO:root:Train (Epoch 77): Loss/seq after 01250 batchs: 717.0360107421875
INFO:root:Train (Epoch 77): Loss/seq after 01300 batchs: 702.6250610351562
INFO:root:Train (Epoch 77): Loss/seq after 01350 batchs: 691.1123657226562
INFO:root:Train (Epoch 77): Loss/seq after 01400 batchs: 698.3760375976562
INFO:root:Train (Epoch 77): Loss/seq after 01450 batchs: 699.25634765625
INFO:root:Train (Epoch 77): Loss/seq after 01500 batchs: 704.5750732421875
INFO:root:Train (Epoch 77): Loss/seq after 01550 batchs: 707.0989990234375
INFO:root:Train (Epoch 77): Loss/seq after 01600 batchs: 700.7120971679688
INFO:root:Train (Epoch 77): Loss/seq after 01650 batchs: 697.5774536132812
INFO:root:Train (Epoch 77): Loss/seq after 01700 batchs: 698.098876953125
INFO:root:Train (Epoch 77): Loss/seq after 01750 batchs: 694.4794921875
INFO:root:Train (Epoch 77): Loss/seq after 01800 batchs: 690.9192504882812
INFO:root:Train (Epoch 77): Loss/seq after 01850 batchs: 686.34619140625
INFO:root:Train (Epoch 77): Loss/seq after 01900 batchs: 687.1409301757812
INFO:root:Train (Epoch 77): Loss/seq after 01950 batchs: 685.05908203125
INFO:root:Train (Epoch 77): Loss/seq after 02000 batchs: 682.9866943359375
INFO:root:Train (Epoch 77): Loss/seq after 02050 batchs: 681.4447631835938
INFO:root:Train (Epoch 77): Loss/seq after 02100 batchs: 677.9833984375
INFO:root:Train (Epoch 77): Loss/seq after 02150 batchs: 675.499755859375
INFO:root:Train (Epoch 77): Loss/seq after 02200 batchs: 672.0587158203125
INFO:root:Train (Epoch 77): Loss/seq after 02250 batchs: 671.7728881835938
INFO:root:Train (Epoch 77): Loss/seq after 02300 batchs: 669.4716186523438
INFO:root:Train (Epoch 77): Loss/seq after 02350 batchs: 664.8232421875
INFO:root:Train (Epoch 77): Loss/seq after 02400 batchs: 666.1045532226562
INFO:root:Train (Epoch 77): Loss/seq after 02450 batchs: 660.2576293945312
INFO:root:Train (Epoch 77): Loss/seq after 02500 batchs: 650.2159423828125
INFO:root:Train (Epoch 77): Loss/seq after 02550 batchs: 642.9304809570312
INFO:root:Train (Epoch 77): Loss/seq after 02600 batchs: 641.0604248046875
INFO:root:Train (Epoch 77): Loss/seq after 02650 batchs: 638.404541015625
INFO:root:Train (Epoch 77): Loss/seq after 02700 batchs: 635.9745483398438
INFO:root:Train (Epoch 77): Loss/seq after 02750 batchs: 634.868408203125
INFO:root:Train (Epoch 77): Loss/seq after 02800 batchs: 634.9224853515625
INFO:root:Train (Epoch 77): Loss/seq after 02850 batchs: 635.1819458007812
INFO:root:Train (Epoch 77): Loss/seq after 02900 batchs: 636.6444091796875
INFO:root:Train (Epoch 77): Loss/seq after 02950 batchs: 635.1560668945312
INFO:root:Train (Epoch 77): Loss/seq after 03000 batchs: 639.7720336914062
INFO:root:Train (Epoch 77): Loss/seq after 03050 batchs: 643.2933959960938
INFO:root:Train (Epoch 77): Loss/seq after 03100 batchs: 648.5914306640625
INFO:root:Train (Epoch 77): Loss/seq after 03150 batchs: 651.049072265625
INFO:root:Train (Epoch 77): Loss/seq after 03200 batchs: 654.030517578125
INFO:root:Train (Epoch 77): Loss/seq after 03250 batchs: 658.0755004882812
INFO:root:Train (Epoch 77): Loss/seq after 03300 batchs: 657.4298706054688
INFO:root:Train (Epoch 77): Loss/seq after 03350 batchs: 657.5347290039062
INFO:root:Train (Epoch 77): Loss/seq after 03400 batchs: 652.2694702148438
INFO:root:Train (Epoch 77): Loss/seq after 03450 batchs: 650.0184936523438
INFO:root:Train (Epoch 77): Loss/seq after 03500 batchs: 651.2276000976562
INFO:root:Train (Epoch 77): Loss/seq after 03550 batchs: 647.875
INFO:root:Train (Epoch 77): Loss/seq after 03600 batchs: 656.4193725585938
INFO:root:Train (Epoch 77): Loss/seq after 03650 batchs: 653.1232299804688
INFO:root:Train (Epoch 77): Loss/seq after 03700 batchs: 655.2186279296875
INFO:root:Train (Epoch 77): Loss/seq after 03750 batchs: 659.7447509765625
INFO:root:Train (Epoch 77): Loss/seq after 03800 batchs: 656.5452270507812
INFO:root:Train (Epoch 77): Loss/seq after 03850 batchs: 655.7777099609375
INFO:root:Train (Epoch 77): Loss/seq after 03900 batchs: 659.0560302734375
INFO:root:Train (Epoch 77): Loss/seq after 03950 batchs: 662.0825805664062
INFO:root:Train (Epoch 77): Loss/seq after 04000 batchs: 657.739501953125
INFO:root:Train (Epoch 77): Loss/seq after 04050 batchs: 653.354248046875
INFO:root:Train (Epoch 77): Loss/seq after 04100 batchs: 651.2462158203125
INFO:root:Train (Epoch 77): Loss/seq after 04150 batchs: 650.6874389648438
INFO:root:Train (Epoch 77): Loss/seq after 04200 batchs: 649.0567016601562
INFO:root:Train (Epoch 77): Loss/seq after 04250 batchs: 647.0836181640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 77): Loss/seq after 00000 batches: 549.7666015625
INFO:root:# Valid (Epoch 77): Loss/seq after 00050 batches: 810.0650634765625
INFO:root:# Valid (Epoch 77): Loss/seq after 00100 batches: 902.8203125
INFO:root:# Valid (Epoch 77): Loss/seq after 00150 batches: 677.4577026367188
INFO:root:# Valid (Epoch 77): Loss/seq after 00200 batches: 630.5435791015625
INFO:root:Artifacts: Make stick videos for epoch 77
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_77_on_20220422_055303.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_77_index_73_on_20220422_055303.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 78): Loss/seq after 00000 batchs: 1354.8331298828125
INFO:root:Train (Epoch 78): Loss/seq after 00050 batchs: 973.0450439453125
INFO:root:Train (Epoch 78): Loss/seq after 00100 batchs: 980.0846557617188
INFO:root:Train (Epoch 78): Loss/seq after 00150 batchs: 894.25341796875
INFO:root:Train (Epoch 78): Loss/seq after 00200 batchs: 981.2816772460938
INFO:root:Train (Epoch 78): Loss/seq after 00250 batchs: 1093.61181640625
INFO:root:Train (Epoch 78): Loss/seq after 00300 batchs: 1066.81640625
INFO:root:Train (Epoch 78): Loss/seq after 00350 batchs: 990.4452514648438
INFO:root:Train (Epoch 78): Loss/seq after 00400 batchs: 984.2405395507812
INFO:root:Train (Epoch 78): Loss/seq after 00450 batchs: 953.5001220703125
INFO:root:Train (Epoch 78): Loss/seq after 00500 batchs: 927.8997802734375
INFO:root:Train (Epoch 78): Loss/seq after 00550 batchs: 894.9996337890625
INFO:root:Train (Epoch 78): Loss/seq after 00600 batchs: 860.6298217773438
INFO:root:Train (Epoch 78): Loss/seq after 00650 batchs: 835.2102661132812
INFO:root:Train (Epoch 78): Loss/seq after 00700 batchs: 802.4009399414062
INFO:root:Train (Epoch 78): Loss/seq after 00750 batchs: 812.7073364257812
INFO:root:Train (Epoch 78): Loss/seq after 00800 batchs: 812.967041015625
INFO:root:Train (Epoch 78): Loss/seq after 00850 batchs: 789.4574584960938
INFO:root:Train (Epoch 78): Loss/seq after 00900 batchs: 770.4585571289062
INFO:root:Train (Epoch 78): Loss/seq after 00950 batchs: 768.1135864257812
INFO:root:Train (Epoch 78): Loss/seq after 01000 batchs: 756.6038208007812
INFO:root:Train (Epoch 78): Loss/seq after 01050 batchs: 741.560791015625
INFO:root:Train (Epoch 78): Loss/seq after 01100 batchs: 728.454833984375
INFO:root:Train (Epoch 78): Loss/seq after 01150 batchs: 709.419189453125
INFO:root:Train (Epoch 78): Loss/seq after 01200 batchs: 713.0213012695312
INFO:root:Train (Epoch 78): Loss/seq after 01250 batchs: 708.6923828125
INFO:root:Train (Epoch 78): Loss/seq after 01300 batchs: 694.0651245117188
INFO:root:Train (Epoch 78): Loss/seq after 01350 batchs: 682.9263916015625
INFO:root:Train (Epoch 78): Loss/seq after 01400 batchs: 689.6808471679688
INFO:root:Train (Epoch 78): Loss/seq after 01450 batchs: 690.6904907226562
INFO:root:Train (Epoch 78): Loss/seq after 01500 batchs: 696.041015625
INFO:root:Train (Epoch 78): Loss/seq after 01550 batchs: 698.603515625
INFO:root:Train (Epoch 78): Loss/seq after 01600 batchs: 692.3465576171875
INFO:root:Train (Epoch 78): Loss/seq after 01650 batchs: 689.4072875976562
INFO:root:Train (Epoch 78): Loss/seq after 01700 batchs: 690.0526733398438
INFO:root:Train (Epoch 78): Loss/seq after 01750 batchs: 686.4166259765625
INFO:root:Train (Epoch 78): Loss/seq after 01800 batchs: 683.1589965820312
INFO:root:Train (Epoch 78): Loss/seq after 01850 batchs: 679.0863037109375
INFO:root:Train (Epoch 78): Loss/seq after 01900 batchs: 680.1805419921875
INFO:root:Train (Epoch 78): Loss/seq after 01950 batchs: 679.1441040039062
INFO:root:Train (Epoch 78): Loss/seq after 02000 batchs: 677.3074951171875
INFO:root:Train (Epoch 78): Loss/seq after 02050 batchs: 675.6923217773438
INFO:root:Train (Epoch 78): Loss/seq after 02100 batchs: 672.282958984375
INFO:root:Train (Epoch 78): Loss/seq after 02150 batchs: 669.8416137695312
INFO:root:Train (Epoch 78): Loss/seq after 02200 batchs: 666.2340698242188
INFO:root:Train (Epoch 78): Loss/seq after 02250 batchs: 665.6676025390625
INFO:root:Train (Epoch 78): Loss/seq after 02300 batchs: 661.7385864257812
INFO:root:Train (Epoch 78): Loss/seq after 02350 batchs: 656.4683837890625
INFO:root:Train (Epoch 78): Loss/seq after 02400 batchs: 656.969482421875
INFO:root:Train (Epoch 78): Loss/seq after 02450 batchs: 651.1453247070312
INFO:root:Train (Epoch 78): Loss/seq after 02500 batchs: 641.2376098632812
INFO:root:Train (Epoch 78): Loss/seq after 02550 batchs: 633.9016723632812
INFO:root:Train (Epoch 78): Loss/seq after 02600 batchs: 632.1449584960938
INFO:root:Train (Epoch 78): Loss/seq after 02650 batchs: 629.3899536132812
INFO:root:Train (Epoch 78): Loss/seq after 02700 batchs: 626.9365844726562
INFO:root:Train (Epoch 78): Loss/seq after 02750 batchs: 626.0064086914062
INFO:root:Train (Epoch 78): Loss/seq after 02800 batchs: 626.6798706054688
INFO:root:Train (Epoch 78): Loss/seq after 02850 batchs: 627.3482055664062
INFO:root:Train (Epoch 78): Loss/seq after 02900 batchs: 629.1101684570312
INFO:root:Train (Epoch 78): Loss/seq after 02950 batchs: 627.6809692382812
INFO:root:Train (Epoch 78): Loss/seq after 03000 batchs: 632.2430419921875
INFO:root:Train (Epoch 78): Loss/seq after 03050 batchs: 635.8868408203125
INFO:root:Train (Epoch 78): Loss/seq after 03100 batchs: 641.8033447265625
INFO:root:Train (Epoch 78): Loss/seq after 03150 batchs: 644.1134033203125
INFO:root:Train (Epoch 78): Loss/seq after 03200 batchs: 646.9494018554688
INFO:root:Train (Epoch 78): Loss/seq after 03250 batchs: 651.3539428710938
INFO:root:Train (Epoch 78): Loss/seq after 03300 batchs: 650.877197265625
INFO:root:Train (Epoch 78): Loss/seq after 03350 batchs: 650.6793823242188
INFO:root:Train (Epoch 78): Loss/seq after 03400 batchs: 645.545654296875
INFO:root:Train (Epoch 78): Loss/seq after 03450 batchs: 643.3203125
INFO:root:Train (Epoch 78): Loss/seq after 03500 batchs: 644.0488891601562
INFO:root:Train (Epoch 78): Loss/seq after 03550 batchs: 640.7802734375
INFO:root:Train (Epoch 78): Loss/seq after 03600 batchs: 649.4119262695312
INFO:root:Train (Epoch 78): Loss/seq after 03650 batchs: 646.2257690429688
INFO:root:Train (Epoch 78): Loss/seq after 03700 batchs: 648.677490234375
INFO:root:Train (Epoch 78): Loss/seq after 03750 batchs: 653.324951171875
INFO:root:Train (Epoch 78): Loss/seq after 03800 batchs: 650.1564331054688
INFO:root:Train (Epoch 78): Loss/seq after 03850 batchs: 649.5869140625
INFO:root:Train (Epoch 78): Loss/seq after 03900 batchs: 652.79296875
INFO:root:Train (Epoch 78): Loss/seq after 03950 batchs: 655.724365234375
INFO:root:Train (Epoch 78): Loss/seq after 04000 batchs: 651.4072265625
INFO:root:Train (Epoch 78): Loss/seq after 04050 batchs: 647.1210327148438
INFO:root:Train (Epoch 78): Loss/seq after 04100 batchs: 645.0908203125
INFO:root:Train (Epoch 78): Loss/seq after 04150 batchs: 644.5118408203125
INFO:root:Train (Epoch 78): Loss/seq after 04200 batchs: 642.836181640625
INFO:root:Train (Epoch 78): Loss/seq after 04250 batchs: 640.9651489257812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 78): Loss/seq after 00000 batches: 546.804443359375
INFO:root:# Valid (Epoch 78): Loss/seq after 00050 batches: 768.2327880859375
INFO:root:# Valid (Epoch 78): Loss/seq after 00100 batches: 857.273193359375
INFO:root:# Valid (Epoch 78): Loss/seq after 00150 batches: 647.5358276367188
INFO:root:# Valid (Epoch 78): Loss/seq after 00200 batches: 606.3146362304688
INFO:root:Artifacts: Make stick videos for epoch 78
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_78_on_20220422_055813.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_78_index_596_on_20220422_055813.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 79): Loss/seq after 00000 batchs: 1252.177734375
INFO:root:Train (Epoch 79): Loss/seq after 00050 batchs: 940.7556762695312
INFO:root:Train (Epoch 79): Loss/seq after 00100 batchs: 955.8134155273438
INFO:root:Train (Epoch 79): Loss/seq after 00150 batchs: 874.517578125
INFO:root:Train (Epoch 79): Loss/seq after 00200 batchs: 953.893798828125
INFO:root:Train (Epoch 79): Loss/seq after 00250 batchs: 1070.9844970703125
INFO:root:Train (Epoch 79): Loss/seq after 00300 batchs: 1048.881591796875
INFO:root:Train (Epoch 79): Loss/seq after 00350 batchs: 975.1415405273438
INFO:root:Train (Epoch 79): Loss/seq after 00400 batchs: 966.7115478515625
INFO:root:Train (Epoch 79): Loss/seq after 00450 batchs: 937.6723022460938
INFO:root:Train (Epoch 79): Loss/seq after 00500 batchs: 916.55126953125
INFO:root:Train (Epoch 79): Loss/seq after 00550 batchs: 886.6879272460938
INFO:root:Train (Epoch 79): Loss/seq after 00600 batchs: 853.6746826171875
INFO:root:Train (Epoch 79): Loss/seq after 00650 batchs: 828.576416015625
INFO:root:Train (Epoch 79): Loss/seq after 00700 batchs: 797.1343994140625
INFO:root:Train (Epoch 79): Loss/seq after 00750 batchs: 807.7965698242188
INFO:root:Train (Epoch 79): Loss/seq after 00800 batchs: 809.883544921875
INFO:root:Train (Epoch 79): Loss/seq after 00850 batchs: 788.0109252929688
INFO:root:Train (Epoch 79): Loss/seq after 00900 batchs: 769.2164306640625
INFO:root:Train (Epoch 79): Loss/seq after 00950 batchs: 766.3196411132812
INFO:root:Train (Epoch 79): Loss/seq after 01000 batchs: 755.0036010742188
INFO:root:Train (Epoch 79): Loss/seq after 01050 batchs: 739.3263549804688
INFO:root:Train (Epoch 79): Loss/seq after 01100 batchs: 726.4390258789062
INFO:root:Train (Epoch 79): Loss/seq after 01150 batchs: 707.1052856445312
INFO:root:Train (Epoch 79): Loss/seq after 01200 batchs: 710.615966796875
INFO:root:Train (Epoch 79): Loss/seq after 01250 batchs: 706.574951171875
INFO:root:Train (Epoch 79): Loss/seq after 01300 batchs: 692.197021484375
INFO:root:Train (Epoch 79): Loss/seq after 01350 batchs: 681.296142578125
INFO:root:Train (Epoch 79): Loss/seq after 01400 batchs: 687.4186401367188
INFO:root:Train (Epoch 79): Loss/seq after 01450 batchs: 688.4033813476562
INFO:root:Train (Epoch 79): Loss/seq after 01500 batchs: 693.9188842773438
INFO:root:Train (Epoch 79): Loss/seq after 01550 batchs: 697.0855712890625
INFO:root:Train (Epoch 79): Loss/seq after 01600 batchs: 691.245361328125
INFO:root:Train (Epoch 79): Loss/seq after 01650 batchs: 689.3816528320312
INFO:root:Train (Epoch 79): Loss/seq after 01700 batchs: 690.2130126953125
INFO:root:Train (Epoch 79): Loss/seq after 01750 batchs: 687.1542358398438
INFO:root:Train (Epoch 79): Loss/seq after 01800 batchs: 683.9091186523438
INFO:root:Train (Epoch 79): Loss/seq after 01850 batchs: 679.5946044921875
INFO:root:Train (Epoch 79): Loss/seq after 01900 batchs: 680.6519165039062
INFO:root:Train (Epoch 79): Loss/seq after 01950 batchs: 679.5623779296875
INFO:root:Train (Epoch 79): Loss/seq after 02000 batchs: 677.3931884765625
INFO:root:Train (Epoch 79): Loss/seq after 02050 batchs: 675.6646728515625
INFO:root:Train (Epoch 79): Loss/seq after 02100 batchs: 672.29638671875
INFO:root:Train (Epoch 79): Loss/seq after 02150 batchs: 669.7587280273438
INFO:root:Train (Epoch 79): Loss/seq after 02200 batchs: 666.1651000976562
INFO:root:Train (Epoch 79): Loss/seq after 02250 batchs: 666.1123657226562
INFO:root:Train (Epoch 79): Loss/seq after 02300 batchs: 662.1603393554688
INFO:root:Train (Epoch 79): Loss/seq after 02350 batchs: 656.7552490234375
INFO:root:Train (Epoch 79): Loss/seq after 02400 batchs: 657.1365356445312
INFO:root:Train (Epoch 79): Loss/seq after 02450 batchs: 651.3235473632812
INFO:root:Train (Epoch 79): Loss/seq after 02500 batchs: 641.3611450195312
INFO:root:Train (Epoch 79): Loss/seq after 02550 batchs: 634.0150756835938
INFO:root:Train (Epoch 79): Loss/seq after 02600 batchs: 632.5603637695312
INFO:root:Train (Epoch 79): Loss/seq after 02650 batchs: 630.0005493164062
INFO:root:Train (Epoch 79): Loss/seq after 02700 batchs: 627.6749877929688
INFO:root:Train (Epoch 79): Loss/seq after 02750 batchs: 626.3904418945312
INFO:root:Train (Epoch 79): Loss/seq after 02800 batchs: 626.3147583007812
INFO:root:Train (Epoch 79): Loss/seq after 02850 batchs: 627.0048217773438
INFO:root:Train (Epoch 79): Loss/seq after 02900 batchs: 628.1102294921875
INFO:root:Train (Epoch 79): Loss/seq after 02950 batchs: 626.83203125
INFO:root:Train (Epoch 79): Loss/seq after 03000 batchs: 631.3729248046875
INFO:root:Train (Epoch 79): Loss/seq after 03050 batchs: 635.0318603515625
INFO:root:Train (Epoch 79): Loss/seq after 03100 batchs: 641.2025756835938
INFO:root:Train (Epoch 79): Loss/seq after 03150 batchs: 644.4575805664062
INFO:root:Train (Epoch 79): Loss/seq after 03200 batchs: 646.6301879882812
INFO:root:Train (Epoch 79): Loss/seq after 03250 batchs: 650.41455078125
INFO:root:Train (Epoch 79): Loss/seq after 03300 batchs: 649.6348876953125
INFO:root:Train (Epoch 79): Loss/seq after 03350 batchs: 649.3904418945312
INFO:root:Train (Epoch 79): Loss/seq after 03400 batchs: 644.1998901367188
INFO:root:Train (Epoch 79): Loss/seq after 03450 batchs: 642.2189331054688
INFO:root:Train (Epoch 79): Loss/seq after 03500 batchs: 643.7744750976562
INFO:root:Train (Epoch 79): Loss/seq after 03550 batchs: 640.8232421875
INFO:root:Train (Epoch 79): Loss/seq after 03600 batchs: 649.6353759765625
INFO:root:Train (Epoch 79): Loss/seq after 03650 batchs: 646.5288696289062
INFO:root:Train (Epoch 79): Loss/seq after 03700 batchs: 648.6412353515625
INFO:root:Train (Epoch 79): Loss/seq after 03750 batchs: 653.2540283203125
INFO:root:Train (Epoch 79): Loss/seq after 03800 batchs: 650.131103515625
INFO:root:Train (Epoch 79): Loss/seq after 03850 batchs: 649.394775390625
INFO:root:Train (Epoch 79): Loss/seq after 03900 batchs: 652.828857421875
INFO:root:Train (Epoch 79): Loss/seq after 03950 batchs: 655.8427734375
INFO:root:Train (Epoch 79): Loss/seq after 04000 batchs: 651.5645141601562
INFO:root:Train (Epoch 79): Loss/seq after 04050 batchs: 647.2401123046875
INFO:root:Train (Epoch 79): Loss/seq after 04100 batchs: 645.219482421875
INFO:root:Train (Epoch 79): Loss/seq after 04150 batchs: 644.6522827148438
INFO:root:Train (Epoch 79): Loss/seq after 04200 batchs: 642.8911743164062
INFO:root:Train (Epoch 79): Loss/seq after 04250 batchs: 641.0475463867188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 79): Loss/seq after 00000 batches: 513.5015258789062
INFO:root:# Valid (Epoch 79): Loss/seq after 00050 batches: 724.8118286132812
INFO:root:# Valid (Epoch 79): Loss/seq after 00100 batches: 808.293212890625
INFO:root:# Valid (Epoch 79): Loss/seq after 00150 batches: 609.4644775390625
INFO:root:# Valid (Epoch 79): Loss/seq after 00200 batches: 572.8606567382812
INFO:root:Artifacts: Make stick videos for epoch 79
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_79_on_20220422_060301.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_79_index_1502_on_20220422_060301.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 80): Loss/seq after 00000 batchs: 1250.498291015625
INFO:root:Train (Epoch 80): Loss/seq after 00050 batchs: 930.02490234375
INFO:root:Train (Epoch 80): Loss/seq after 00100 batchs: 943.068359375
INFO:root:Train (Epoch 80): Loss/seq after 00150 batchs: 863.0548706054688
INFO:root:Train (Epoch 80): Loss/seq after 00200 batchs: 938.11279296875
INFO:root:Train (Epoch 80): Loss/seq after 00250 batchs: 1058.2254638671875
INFO:root:Train (Epoch 80): Loss/seq after 00300 batchs: 1036.5399169921875
INFO:root:Train (Epoch 80): Loss/seq after 00350 batchs: 962.5665893554688
INFO:root:Train (Epoch 80): Loss/seq after 00400 batchs: 956.061767578125
INFO:root:Train (Epoch 80): Loss/seq after 00450 batchs: 928.0995483398438
INFO:root:Train (Epoch 80): Loss/seq after 00500 batchs: 902.73681640625
INFO:root:Train (Epoch 80): Loss/seq after 00550 batchs: 872.1607055664062
INFO:root:Train (Epoch 80): Loss/seq after 00600 batchs: 839.246337890625
INFO:root:Train (Epoch 80): Loss/seq after 00650 batchs: 814.2940673828125
INFO:root:Train (Epoch 80): Loss/seq after 00700 batchs: 782.5241088867188
INFO:root:Train (Epoch 80): Loss/seq after 00750 batchs: 791.9911499023438
INFO:root:Train (Epoch 80): Loss/seq after 00800 batchs: 794.696533203125
INFO:root:Train (Epoch 80): Loss/seq after 00850 batchs: 771.7771606445312
INFO:root:Train (Epoch 80): Loss/seq after 00900 batchs: 754.0853271484375
INFO:root:Train (Epoch 80): Loss/seq after 00950 batchs: 753.0809326171875
INFO:root:Train (Epoch 80): Loss/seq after 01000 batchs: 741.2217407226562
INFO:root:Train (Epoch 80): Loss/seq after 01050 batchs: 733.0010375976562
INFO:root:Train (Epoch 80): Loss/seq after 01100 batchs: 721.3665161132812
INFO:root:Train (Epoch 80): Loss/seq after 01150 batchs: 702.8656005859375
INFO:root:Train (Epoch 80): Loss/seq after 01200 batchs: 707.6985473632812
INFO:root:Train (Epoch 80): Loss/seq after 01250 batchs: 703.5850830078125
INFO:root:Train (Epoch 80): Loss/seq after 01300 batchs: 688.9896240234375
INFO:root:Train (Epoch 80): Loss/seq after 01350 batchs: 678.0540771484375
INFO:root:Train (Epoch 80): Loss/seq after 01400 batchs: 682.5194702148438
INFO:root:Train (Epoch 80): Loss/seq after 01450 batchs: 683.8978881835938
INFO:root:Train (Epoch 80): Loss/seq after 01500 batchs: 689.646240234375
INFO:root:Train (Epoch 80): Loss/seq after 01550 batchs: 692.7351684570312
INFO:root:Train (Epoch 80): Loss/seq after 01600 batchs: 686.7749633789062
INFO:root:Train (Epoch 80): Loss/seq after 01650 batchs: 684.2006225585938
INFO:root:Train (Epoch 80): Loss/seq after 01700 batchs: 684.8902587890625
INFO:root:Train (Epoch 80): Loss/seq after 01750 batchs: 681.5415649414062
INFO:root:Train (Epoch 80): Loss/seq after 01800 batchs: 678.522216796875
INFO:root:Train (Epoch 80): Loss/seq after 01850 batchs: 674.256591796875
INFO:root:Train (Epoch 80): Loss/seq after 01900 batchs: 675.36328125
INFO:root:Train (Epoch 80): Loss/seq after 01950 batchs: 673.3276977539062
INFO:root:Train (Epoch 80): Loss/seq after 02000 batchs: 671.2993774414062
INFO:root:Train (Epoch 80): Loss/seq after 02050 batchs: 669.518310546875
INFO:root:Train (Epoch 80): Loss/seq after 02100 batchs: 666.0491943359375
INFO:root:Train (Epoch 80): Loss/seq after 02150 batchs: 663.4859619140625
INFO:root:Train (Epoch 80): Loss/seq after 02200 batchs: 659.8214721679688
INFO:root:Train (Epoch 80): Loss/seq after 02250 batchs: 659.407470703125
INFO:root:Train (Epoch 80): Loss/seq after 02300 batchs: 655.3446044921875
INFO:root:Train (Epoch 80): Loss/seq after 02350 batchs: 650.6643676757812
INFO:root:Train (Epoch 80): Loss/seq after 02400 batchs: 651.316650390625
INFO:root:Train (Epoch 80): Loss/seq after 02450 batchs: 645.4281005859375
INFO:root:Train (Epoch 80): Loss/seq after 02500 batchs: 635.5869140625
INFO:root:Train (Epoch 80): Loss/seq after 02550 batchs: 628.2647705078125
INFO:root:Train (Epoch 80): Loss/seq after 02600 batchs: 626.6417236328125
INFO:root:Train (Epoch 80): Loss/seq after 02650 batchs: 624.0231323242188
INFO:root:Train (Epoch 80): Loss/seq after 02700 batchs: 621.470703125
INFO:root:Train (Epoch 80): Loss/seq after 02750 batchs: 620.1815185546875
INFO:root:Train (Epoch 80): Loss/seq after 02800 batchs: 620.2314453125
INFO:root:Train (Epoch 80): Loss/seq after 02850 batchs: 621.004638671875
INFO:root:Train (Epoch 80): Loss/seq after 02900 batchs: 622.5844116210938
INFO:root:Train (Epoch 80): Loss/seq after 02950 batchs: 621.3739624023438
INFO:root:Train (Epoch 80): Loss/seq after 03000 batchs: 626.037353515625
INFO:root:Train (Epoch 80): Loss/seq after 03050 batchs: 629.0521240234375
INFO:root:Train (Epoch 80): Loss/seq after 03100 batchs: 634.5064086914062
INFO:root:Train (Epoch 80): Loss/seq after 03150 batchs: 637.0679931640625
INFO:root:Train (Epoch 80): Loss/seq after 03200 batchs: 639.455078125
INFO:root:Train (Epoch 80): Loss/seq after 03250 batchs: 643.1701049804688
INFO:root:Train (Epoch 80): Loss/seq after 03300 batchs: 642.3670043945312
INFO:root:Train (Epoch 80): Loss/seq after 03350 batchs: 642.4135131835938
INFO:root:Train (Epoch 80): Loss/seq after 03400 batchs: 637.52490234375
INFO:root:Train (Epoch 80): Loss/seq after 03450 batchs: 635.5111694335938
INFO:root:Train (Epoch 80): Loss/seq after 03500 batchs: 637.0938720703125
INFO:root:Train (Epoch 80): Loss/seq after 03550 batchs: 633.9769897460938
INFO:root:Train (Epoch 80): Loss/seq after 03600 batchs: 642.5980224609375
INFO:root:Train (Epoch 80): Loss/seq after 03650 batchs: 639.4821166992188
INFO:root:Train (Epoch 80): Loss/seq after 03700 batchs: 641.7142333984375
INFO:root:Train (Epoch 80): Loss/seq after 03750 batchs: 646.3143310546875
INFO:root:Train (Epoch 80): Loss/seq after 03800 batchs: 643.2029418945312
INFO:root:Train (Epoch 80): Loss/seq after 03850 batchs: 642.6329956054688
INFO:root:Train (Epoch 80): Loss/seq after 03900 batchs: 646.0119018554688
INFO:root:Train (Epoch 80): Loss/seq after 03950 batchs: 648.6331176757812
INFO:root:Train (Epoch 80): Loss/seq after 04000 batchs: 644.3248901367188
INFO:root:Train (Epoch 80): Loss/seq after 04050 batchs: 640.0765380859375
INFO:root:Train (Epoch 80): Loss/seq after 04100 batchs: 638.1847534179688
INFO:root:Train (Epoch 80): Loss/seq after 04150 batchs: 637.60693359375
INFO:root:Train (Epoch 80): Loss/seq after 04200 batchs: 635.9912109375
INFO:root:Train (Epoch 80): Loss/seq after 04250 batchs: 634.2117919921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 80): Loss/seq after 00000 batches: 568.0889282226562
INFO:root:# Valid (Epoch 80): Loss/seq after 00050 batches: 724.9523315429688
INFO:root:# Valid (Epoch 80): Loss/seq after 00100 batches: 808.6156005859375
INFO:root:# Valid (Epoch 80): Loss/seq after 00150 batches: 613.3397216796875
INFO:root:# Valid (Epoch 80): Loss/seq after 00200 batches: 577.7255859375
INFO:root:Artifacts: Make stick videos for epoch 80
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_80_on_20220422_060804.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_80_index_41_on_20220422_060804.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 81): Loss/seq after 00000 batchs: 1552.60888671875
INFO:root:Train (Epoch 81): Loss/seq after 00050 batchs: 945.2487182617188
INFO:root:Train (Epoch 81): Loss/seq after 00100 batchs: 952.193359375
INFO:root:Train (Epoch 81): Loss/seq after 00150 batchs: 865.2888793945312
INFO:root:Train (Epoch 81): Loss/seq after 00200 batchs: 941.654541015625
INFO:root:Train (Epoch 81): Loss/seq after 00250 batchs: 1061.8055419921875
INFO:root:Train (Epoch 81): Loss/seq after 00300 batchs: 1040.05224609375
INFO:root:Train (Epoch 81): Loss/seq after 00350 batchs: 965.02099609375
INFO:root:Train (Epoch 81): Loss/seq after 00400 batchs: 959.7080078125
INFO:root:Train (Epoch 81): Loss/seq after 00450 batchs: 930.6233520507812
INFO:root:Train (Epoch 81): Loss/seq after 00500 batchs: 906.7476806640625
INFO:root:Train (Epoch 81): Loss/seq after 00550 batchs: 874.5040893554688
INFO:root:Train (Epoch 81): Loss/seq after 00600 batchs: 841.2352294921875
INFO:root:Train (Epoch 81): Loss/seq after 00650 batchs: 815.4442138671875
INFO:root:Train (Epoch 81): Loss/seq after 00700 batchs: 784.2677612304688
INFO:root:Train (Epoch 81): Loss/seq after 00750 batchs: 793.2196044921875
INFO:root:Train (Epoch 81): Loss/seq after 00800 batchs: 794.94482421875
INFO:root:Train (Epoch 81): Loss/seq after 00850 batchs: 770.5955810546875
INFO:root:Train (Epoch 81): Loss/seq after 00900 batchs: 751.9902954101562
INFO:root:Train (Epoch 81): Loss/seq after 00950 batchs: 748.392333984375
INFO:root:Train (Epoch 81): Loss/seq after 01000 batchs: 736.3475952148438
INFO:root:Train (Epoch 81): Loss/seq after 01050 batchs: 722.5951538085938
INFO:root:Train (Epoch 81): Loss/seq after 01100 batchs: 710.6064453125
INFO:root:Train (Epoch 81): Loss/seq after 01150 batchs: 691.9168090820312
INFO:root:Train (Epoch 81): Loss/seq after 01200 batchs: 695.165771484375
INFO:root:Train (Epoch 81): Loss/seq after 01250 batchs: 691.4263305664062
INFO:root:Train (Epoch 81): Loss/seq after 01300 batchs: 677.1287231445312
INFO:root:Train (Epoch 81): Loss/seq after 01350 batchs: 665.884521484375
INFO:root:Train (Epoch 81): Loss/seq after 01400 batchs: 672.673583984375
INFO:root:Train (Epoch 81): Loss/seq after 01450 batchs: 673.8637084960938
INFO:root:Train (Epoch 81): Loss/seq after 01500 batchs: 679.698486328125
INFO:root:Train (Epoch 81): Loss/seq after 01550 batchs: 683.15380859375
INFO:root:Train (Epoch 81): Loss/seq after 01600 batchs: 677.2493286132812
INFO:root:Train (Epoch 81): Loss/seq after 01650 batchs: 674.9865112304688
INFO:root:Train (Epoch 81): Loss/seq after 01700 batchs: 676.507080078125
INFO:root:Train (Epoch 81): Loss/seq after 01750 batchs: 673.4998168945312
INFO:root:Train (Epoch 81): Loss/seq after 01800 batchs: 670.602783203125
INFO:root:Train (Epoch 81): Loss/seq after 01850 batchs: 666.4476928710938
INFO:root:Train (Epoch 81): Loss/seq after 01900 batchs: 667.4027099609375
INFO:root:Train (Epoch 81): Loss/seq after 01950 batchs: 666.1473999023438
INFO:root:Train (Epoch 81): Loss/seq after 02000 batchs: 664.2042846679688
INFO:root:Train (Epoch 81): Loss/seq after 02050 batchs: 662.7211303710938
INFO:root:Train (Epoch 81): Loss/seq after 02100 batchs: 659.4326782226562
INFO:root:Train (Epoch 81): Loss/seq after 02150 batchs: 657.2114868164062
INFO:root:Train (Epoch 81): Loss/seq after 02200 batchs: 653.6288452148438
INFO:root:Train (Epoch 81): Loss/seq after 02250 batchs: 652.8511962890625
INFO:root:Train (Epoch 81): Loss/seq after 02300 batchs: 648.7876586914062
INFO:root:Train (Epoch 81): Loss/seq after 02350 batchs: 643.7861328125
INFO:root:Train (Epoch 81): Loss/seq after 02400 batchs: 644.4000244140625
INFO:root:Train (Epoch 81): Loss/seq after 02450 batchs: 638.6630859375
INFO:root:Train (Epoch 81): Loss/seq after 02500 batchs: 628.9821166992188
INFO:root:Train (Epoch 81): Loss/seq after 02550 batchs: 621.8196411132812
INFO:root:Train (Epoch 81): Loss/seq after 02600 batchs: 620.1185913085938
INFO:root:Train (Epoch 81): Loss/seq after 02650 batchs: 617.3336181640625
INFO:root:Train (Epoch 81): Loss/seq after 02700 batchs: 614.8578491210938
INFO:root:Train (Epoch 81): Loss/seq after 02750 batchs: 613.2692260742188
INFO:root:Train (Epoch 81): Loss/seq after 02800 batchs: 613.34423828125
INFO:root:Train (Epoch 81): Loss/seq after 02850 batchs: 614.1129150390625
INFO:root:Train (Epoch 81): Loss/seq after 02900 batchs: 616.0883178710938
INFO:root:Train (Epoch 81): Loss/seq after 02950 batchs: 615.0917358398438
INFO:root:Train (Epoch 81): Loss/seq after 03000 batchs: 619.83984375
INFO:root:Train (Epoch 81): Loss/seq after 03050 batchs: 623.3247680664062
INFO:root:Train (Epoch 81): Loss/seq after 03100 batchs: 628.8592529296875
INFO:root:Train (Epoch 81): Loss/seq after 03150 batchs: 631.8281860351562
INFO:root:Train (Epoch 81): Loss/seq after 03200 batchs: 633.6039428710938
INFO:root:Train (Epoch 81): Loss/seq after 03250 batchs: 637.4214477539062
INFO:root:Train (Epoch 81): Loss/seq after 03300 batchs: 636.5096435546875
INFO:root:Train (Epoch 81): Loss/seq after 03350 batchs: 636.6195678710938
INFO:root:Train (Epoch 81): Loss/seq after 03400 batchs: 631.6499633789062
INFO:root:Train (Epoch 81): Loss/seq after 03450 batchs: 629.6515502929688
INFO:root:Train (Epoch 81): Loss/seq after 03500 batchs: 631.1256103515625
INFO:root:Train (Epoch 81): Loss/seq after 03550 batchs: 628.0023803710938
INFO:root:Train (Epoch 81): Loss/seq after 03600 batchs: 636.5758666992188
INFO:root:Train (Epoch 81): Loss/seq after 03650 batchs: 633.424560546875
INFO:root:Train (Epoch 81): Loss/seq after 03700 batchs: 635.8027954101562
INFO:root:Train (Epoch 81): Loss/seq after 03750 batchs: 640.4957885742188
INFO:root:Train (Epoch 81): Loss/seq after 03800 batchs: 637.5177001953125
INFO:root:Train (Epoch 81): Loss/seq after 03850 batchs: 637.24560546875
INFO:root:Train (Epoch 81): Loss/seq after 03900 batchs: 640.6464233398438
INFO:root:Train (Epoch 81): Loss/seq after 03950 batchs: 643.3660888671875
INFO:root:Train (Epoch 81): Loss/seq after 04000 batchs: 639.0733642578125
INFO:root:Train (Epoch 81): Loss/seq after 04050 batchs: 634.860595703125
INFO:root:Train (Epoch 81): Loss/seq after 04100 batchs: 633.0410766601562
INFO:root:Train (Epoch 81): Loss/seq after 04150 batchs: 632.611328125
INFO:root:Train (Epoch 81): Loss/seq after 04200 batchs: 630.9772338867188
INFO:root:Train (Epoch 81): Loss/seq after 04250 batchs: 629.17822265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 81): Loss/seq after 00000 batches: 704.4385375976562
INFO:root:# Valid (Epoch 81): Loss/seq after 00050 batches: 755.4059448242188
INFO:root:# Valid (Epoch 81): Loss/seq after 00100 batches: 805.5253295898438
INFO:root:# Valid (Epoch 81): Loss/seq after 00150 batches: 608.544677734375
INFO:root:# Valid (Epoch 81): Loss/seq after 00200 batches: 569.958984375
INFO:root:Artifacts: Make stick videos for epoch 81
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_81_on_20220422_061259.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_81_index_1219_on_20220422_061259.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 82): Loss/seq after 00000 batchs: 1289.4366455078125
INFO:root:Train (Epoch 82): Loss/seq after 00050 batchs: 911.7606811523438
INFO:root:Train (Epoch 82): Loss/seq after 00100 batchs: 924.7619018554688
INFO:root:Train (Epoch 82): Loss/seq after 00150 batchs: 856.7073974609375
INFO:root:Train (Epoch 82): Loss/seq after 00200 batchs: 931.9279174804688
INFO:root:Train (Epoch 82): Loss/seq after 00250 batchs: 1053.925048828125
INFO:root:Train (Epoch 82): Loss/seq after 00300 batchs: 1032.4827880859375
INFO:root:Train (Epoch 82): Loss/seq after 00350 batchs: 961.5422973632812
INFO:root:Train (Epoch 82): Loss/seq after 00400 batchs: 954.8023071289062
INFO:root:Train (Epoch 82): Loss/seq after 00450 batchs: 926.2796020507812
INFO:root:Train (Epoch 82): Loss/seq after 00500 batchs: 898.585693359375
INFO:root:Train (Epoch 82): Loss/seq after 00550 batchs: 866.6441040039062
INFO:root:Train (Epoch 82): Loss/seq after 00600 batchs: 833.8959350585938
INFO:root:Train (Epoch 82): Loss/seq after 00650 batchs: 807.3494873046875
INFO:root:Train (Epoch 82): Loss/seq after 00700 batchs: 778.4862060546875
INFO:root:Train (Epoch 82): Loss/seq after 00750 batchs: 785.8833618164062
INFO:root:Train (Epoch 82): Loss/seq after 00800 batchs: 785.7799682617188
INFO:root:Train (Epoch 82): Loss/seq after 00850 batchs: 762.2861328125
INFO:root:Train (Epoch 82): Loss/seq after 00900 batchs: 744.060302734375
INFO:root:Train (Epoch 82): Loss/seq after 00950 batchs: 740.8124389648438
INFO:root:Train (Epoch 82): Loss/seq after 01000 batchs: 729.5178833007812
INFO:root:Train (Epoch 82): Loss/seq after 01050 batchs: 714.7000122070312
INFO:root:Train (Epoch 82): Loss/seq after 01100 batchs: 702.9554443359375
INFO:root:Train (Epoch 82): Loss/seq after 01150 batchs: 684.7390747070312
INFO:root:Train (Epoch 82): Loss/seq after 01200 batchs: 688.3507690429688
INFO:root:Train (Epoch 82): Loss/seq after 01250 batchs: 685.0841674804688
INFO:root:Train (Epoch 82): Loss/seq after 01300 batchs: 671.3768920898438
INFO:root:Train (Epoch 82): Loss/seq after 01350 batchs: 660.6052856445312
INFO:root:Train (Epoch 82): Loss/seq after 01400 batchs: 666.027099609375
INFO:root:Train (Epoch 82): Loss/seq after 01450 batchs: 667.7268676757812
INFO:root:Train (Epoch 82): Loss/seq after 01500 batchs: 673.8179931640625
INFO:root:Train (Epoch 82): Loss/seq after 01550 batchs: 677.2133178710938
INFO:root:Train (Epoch 82): Loss/seq after 01600 batchs: 671.635009765625
INFO:root:Train (Epoch 82): Loss/seq after 01650 batchs: 669.156005859375
INFO:root:Train (Epoch 82): Loss/seq after 01700 batchs: 670.2496948242188
INFO:root:Train (Epoch 82): Loss/seq after 01750 batchs: 667.0601806640625
INFO:root:Train (Epoch 82): Loss/seq after 01800 batchs: 664.151611328125
INFO:root:Train (Epoch 82): Loss/seq after 01850 batchs: 659.9931640625
INFO:root:Train (Epoch 82): Loss/seq after 01900 batchs: 661.1062622070312
INFO:root:Train (Epoch 82): Loss/seq after 01950 batchs: 659.9276733398438
INFO:root:Train (Epoch 82): Loss/seq after 02000 batchs: 657.9097900390625
INFO:root:Train (Epoch 82): Loss/seq after 02050 batchs: 656.3417358398438
INFO:root:Train (Epoch 82): Loss/seq after 02100 batchs: 653.193115234375
INFO:root:Train (Epoch 82): Loss/seq after 02150 batchs: 650.7455444335938
INFO:root:Train (Epoch 82): Loss/seq after 02200 batchs: 647.30859375
INFO:root:Train (Epoch 82): Loss/seq after 02250 batchs: 646.8021240234375
INFO:root:Train (Epoch 82): Loss/seq after 02300 batchs: 642.6187133789062
INFO:root:Train (Epoch 82): Loss/seq after 02350 batchs: 637.7496337890625
INFO:root:Train (Epoch 82): Loss/seq after 02400 batchs: 638.5396728515625
INFO:root:Train (Epoch 82): Loss/seq after 02450 batchs: 632.849609375
INFO:root:Train (Epoch 82): Loss/seq after 02500 batchs: 623.2427368164062
INFO:root:Train (Epoch 82): Loss/seq after 02550 batchs: 616.089599609375
INFO:root:Train (Epoch 82): Loss/seq after 02600 batchs: 614.5506591796875
INFO:root:Train (Epoch 82): Loss/seq after 02650 batchs: 611.7435302734375
INFO:root:Train (Epoch 82): Loss/seq after 02700 batchs: 609.3078002929688
INFO:root:Train (Epoch 82): Loss/seq after 02750 batchs: 607.74462890625
INFO:root:Train (Epoch 82): Loss/seq after 02800 batchs: 608.034912109375
INFO:root:Train (Epoch 82): Loss/seq after 02850 batchs: 608.896484375
INFO:root:Train (Epoch 82): Loss/seq after 02900 batchs: 611.1140747070312
INFO:root:Train (Epoch 82): Loss/seq after 02950 batchs: 610.086669921875
INFO:root:Train (Epoch 82): Loss/seq after 03000 batchs: 614.8790283203125
INFO:root:Train (Epoch 82): Loss/seq after 03050 batchs: 618.4765014648438
INFO:root:Train (Epoch 82): Loss/seq after 03100 batchs: 624.1526489257812
INFO:root:Train (Epoch 82): Loss/seq after 03150 batchs: 625.8948974609375
INFO:root:Train (Epoch 82): Loss/seq after 03200 batchs: 627.8435668945312
INFO:root:Train (Epoch 82): Loss/seq after 03250 batchs: 631.4972534179688
INFO:root:Train (Epoch 82): Loss/seq after 03300 batchs: 630.561767578125
INFO:root:Train (Epoch 82): Loss/seq after 03350 batchs: 630.3666381835938
INFO:root:Train (Epoch 82): Loss/seq after 03400 batchs: 625.4650268554688
INFO:root:Train (Epoch 82): Loss/seq after 03450 batchs: 623.6648559570312
INFO:root:Train (Epoch 82): Loss/seq after 03500 batchs: 624.76171875
INFO:root:Train (Epoch 82): Loss/seq after 03550 batchs: 621.6199951171875
INFO:root:Train (Epoch 82): Loss/seq after 03600 batchs: 630.4345092773438
INFO:root:Train (Epoch 82): Loss/seq after 03650 batchs: 627.4978637695312
INFO:root:Train (Epoch 82): Loss/seq after 03700 batchs: 629.8727416992188
INFO:root:Train (Epoch 82): Loss/seq after 03750 batchs: 634.56396484375
INFO:root:Train (Epoch 82): Loss/seq after 03800 batchs: 631.5891723632812
INFO:root:Train (Epoch 82): Loss/seq after 03850 batchs: 631.2308349609375
INFO:root:Train (Epoch 82): Loss/seq after 03900 batchs: 634.8721313476562
INFO:root:Train (Epoch 82): Loss/seq after 03950 batchs: 637.7582397460938
INFO:root:Train (Epoch 82): Loss/seq after 04000 batchs: 633.580810546875
INFO:root:Train (Epoch 82): Loss/seq after 04050 batchs: 629.4717407226562
INFO:root:Train (Epoch 82): Loss/seq after 04100 batchs: 627.5311279296875
INFO:root:Train (Epoch 82): Loss/seq after 04150 batchs: 627.1211547851562
INFO:root:Train (Epoch 82): Loss/seq after 04200 batchs: 625.5057373046875
INFO:root:Train (Epoch 82): Loss/seq after 04250 batchs: 623.7516479492188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 82): Loss/seq after 00000 batches: 548.63720703125
INFO:root:# Valid (Epoch 82): Loss/seq after 00050 batches: 797.2216186523438
INFO:root:# Valid (Epoch 82): Loss/seq after 00100 batches: 845.6167602539062
INFO:root:# Valid (Epoch 82): Loss/seq after 00150 batches: 637.078125
INFO:root:# Valid (Epoch 82): Loss/seq after 00200 batches: 595.0543823242188
INFO:root:Artifacts: Make stick videos for epoch 82
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_82_on_20220422_061745.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_82_index_1854_on_20220422_061745.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 83): Loss/seq after 00000 batchs: 1330.6748046875
INFO:root:Train (Epoch 83): Loss/seq after 00050 batchs: 919.2738647460938
INFO:root:Train (Epoch 83): Loss/seq after 00100 batchs: 933.8203735351562
INFO:root:Train (Epoch 83): Loss/seq after 00150 batchs: 857.0169677734375
INFO:root:Train (Epoch 83): Loss/seq after 00200 batchs: 925.8953247070312
INFO:root:Train (Epoch 83): Loss/seq after 00250 batchs: 1048.014404296875
INFO:root:Train (Epoch 83): Loss/seq after 00300 batchs: 1027.26611328125
INFO:root:Train (Epoch 83): Loss/seq after 00350 batchs: 956.2808837890625
INFO:root:Train (Epoch 83): Loss/seq after 00400 batchs: 948.6327514648438
INFO:root:Train (Epoch 83): Loss/seq after 00450 batchs: 920.8602905273438
INFO:root:Train (Epoch 83): Loss/seq after 00500 batchs: 898.8809204101562
INFO:root:Train (Epoch 83): Loss/seq after 00550 batchs: 868.08984375
INFO:root:Train (Epoch 83): Loss/seq after 00600 batchs: 838.267578125
INFO:root:Train (Epoch 83): Loss/seq after 00650 batchs: 810.1104125976562
INFO:root:Train (Epoch 83): Loss/seq after 00700 batchs: 778.2240600585938
INFO:root:Train (Epoch 83): Loss/seq after 00750 batchs: 785.3723754882812
INFO:root:Train (Epoch 83): Loss/seq after 00800 batchs: 788.3235473632812
INFO:root:Train (Epoch 83): Loss/seq after 00850 batchs: 765.9595336914062
INFO:root:Train (Epoch 83): Loss/seq after 00900 batchs: 747.48291015625
INFO:root:Train (Epoch 83): Loss/seq after 00950 batchs: 742.906494140625
INFO:root:Train (Epoch 83): Loss/seq after 01000 batchs: 732.2184448242188
INFO:root:Train (Epoch 83): Loss/seq after 01050 batchs: 718.0960083007812
INFO:root:Train (Epoch 83): Loss/seq after 01100 batchs: 706.1961669921875
INFO:root:Train (Epoch 83): Loss/seq after 01150 batchs: 688.31591796875
INFO:root:Train (Epoch 83): Loss/seq after 01200 batchs: 692.1928100585938
INFO:root:Train (Epoch 83): Loss/seq after 01250 batchs: 687.9567260742188
INFO:root:Train (Epoch 83): Loss/seq after 01300 batchs: 673.57080078125
INFO:root:Train (Epoch 83): Loss/seq after 01350 batchs: 662.1038208007812
INFO:root:Train (Epoch 83): Loss/seq after 01400 batchs: 666.696533203125
INFO:root:Train (Epoch 83): Loss/seq after 01450 batchs: 667.601318359375
INFO:root:Train (Epoch 83): Loss/seq after 01500 batchs: 673.593994140625
INFO:root:Train (Epoch 83): Loss/seq after 01550 batchs: 676.6071166992188
INFO:root:Train (Epoch 83): Loss/seq after 01600 batchs: 670.8313598632812
INFO:root:Train (Epoch 83): Loss/seq after 01650 batchs: 668.1755981445312
INFO:root:Train (Epoch 83): Loss/seq after 01700 batchs: 669.3204345703125
INFO:root:Train (Epoch 83): Loss/seq after 01750 batchs: 666.3478393554688
INFO:root:Train (Epoch 83): Loss/seq after 01800 batchs: 663.376708984375
INFO:root:Train (Epoch 83): Loss/seq after 01850 batchs: 659.3973388671875
INFO:root:Train (Epoch 83): Loss/seq after 01900 batchs: 660.3671264648438
INFO:root:Train (Epoch 83): Loss/seq after 01950 batchs: 658.3968505859375
INFO:root:Train (Epoch 83): Loss/seq after 02000 batchs: 656.4342651367188
INFO:root:Train (Epoch 83): Loss/seq after 02050 batchs: 655.0115356445312
INFO:root:Train (Epoch 83): Loss/seq after 02100 batchs: 651.83056640625
INFO:root:Train (Epoch 83): Loss/seq after 02150 batchs: 649.4352416992188
INFO:root:Train (Epoch 83): Loss/seq after 02200 batchs: 645.916259765625
INFO:root:Train (Epoch 83): Loss/seq after 02250 batchs: 645.377685546875
INFO:root:Train (Epoch 83): Loss/seq after 02300 batchs: 641.340576171875
INFO:root:Train (Epoch 83): Loss/seq after 02350 batchs: 636.7090454101562
INFO:root:Train (Epoch 83): Loss/seq after 02400 batchs: 637.4095458984375
INFO:root:Train (Epoch 83): Loss/seq after 02450 batchs: 631.8457641601562
INFO:root:Train (Epoch 83): Loss/seq after 02500 batchs: 622.288330078125
INFO:root:Train (Epoch 83): Loss/seq after 02550 batchs: 615.2139892578125
INFO:root:Train (Epoch 83): Loss/seq after 02600 batchs: 613.82763671875
INFO:root:Train (Epoch 83): Loss/seq after 02650 batchs: 611.4110717773438
INFO:root:Train (Epoch 83): Loss/seq after 02700 batchs: 608.9536743164062
INFO:root:Train (Epoch 83): Loss/seq after 02750 batchs: 606.8910522460938
INFO:root:Train (Epoch 83): Loss/seq after 02800 batchs: 607.2462768554688
INFO:root:Train (Epoch 83): Loss/seq after 02850 batchs: 607.7470092773438
INFO:root:Train (Epoch 83): Loss/seq after 02900 batchs: 609.5025024414062
INFO:root:Train (Epoch 83): Loss/seq after 02950 batchs: 608.4038696289062
INFO:root:Train (Epoch 83): Loss/seq after 03000 batchs: 613.168212890625
INFO:root:Train (Epoch 83): Loss/seq after 03050 batchs: 617.2704467773438
INFO:root:Train (Epoch 83): Loss/seq after 03100 batchs: 622.0244750976562
INFO:root:Train (Epoch 83): Loss/seq after 03150 batchs: 623.6104736328125
INFO:root:Train (Epoch 83): Loss/seq after 03200 batchs: 625.2723999023438
INFO:root:Train (Epoch 83): Loss/seq after 03250 batchs: 628.9125366210938
INFO:root:Train (Epoch 83): Loss/seq after 03300 batchs: 627.5333251953125
INFO:root:Train (Epoch 83): Loss/seq after 03350 batchs: 627.5914306640625
INFO:root:Train (Epoch 83): Loss/seq after 03400 batchs: 622.5921020507812
INFO:root:Train (Epoch 83): Loss/seq after 03450 batchs: 620.8173828125
INFO:root:Train (Epoch 83): Loss/seq after 03500 batchs: 621.7816772460938
INFO:root:Train (Epoch 83): Loss/seq after 03550 batchs: 618.8947143554688
INFO:root:Train (Epoch 83): Loss/seq after 03600 batchs: 627.6239624023438
INFO:root:Train (Epoch 83): Loss/seq after 03650 batchs: 625.357666015625
INFO:root:Train (Epoch 83): Loss/seq after 03700 batchs: 627.9498291015625
INFO:root:Train (Epoch 83): Loss/seq after 03750 batchs: 632.6826171875
INFO:root:Train (Epoch 83): Loss/seq after 03800 batchs: 629.7617797851562
INFO:root:Train (Epoch 83): Loss/seq after 03850 batchs: 629.1541137695312
INFO:root:Train (Epoch 83): Loss/seq after 03900 batchs: 632.4700927734375
INFO:root:Train (Epoch 83): Loss/seq after 03950 batchs: 635.2722778320312
INFO:root:Train (Epoch 83): Loss/seq after 04000 batchs: 631.0366821289062
INFO:root:Train (Epoch 83): Loss/seq after 04050 batchs: 626.8815307617188
INFO:root:Train (Epoch 83): Loss/seq after 04100 batchs: 624.934326171875
INFO:root:Train (Epoch 83): Loss/seq after 04150 batchs: 624.51123046875
INFO:root:Train (Epoch 83): Loss/seq after 04200 batchs: 622.8226928710938
INFO:root:Train (Epoch 83): Loss/seq after 04250 batchs: 621.0100708007812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 83): Loss/seq after 00000 batches: 509.89599609375
INFO:root:# Valid (Epoch 83): Loss/seq after 00050 batches: 778.9425659179688
INFO:root:# Valid (Epoch 83): Loss/seq after 00100 batches: 821.509521484375
INFO:root:# Valid (Epoch 83): Loss/seq after 00150 batches: 623.0182495117188
INFO:root:# Valid (Epoch 83): Loss/seq after 00200 batches: 584.4303588867188
INFO:root:Artifacts: Make stick videos for epoch 83
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_83_on_20220422_062230.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_83_index_184_on_20220422_062230.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 84): Loss/seq after 00000 batchs: 1392.1922607421875
INFO:root:Train (Epoch 84): Loss/seq after 00050 batchs: 921.5236206054688
INFO:root:Train (Epoch 84): Loss/seq after 00100 batchs: 927.5807495117188
INFO:root:Train (Epoch 84): Loss/seq after 00150 batchs: 851.3649291992188
INFO:root:Train (Epoch 84): Loss/seq after 00200 batchs: 916.3078002929688
INFO:root:Train (Epoch 84): Loss/seq after 00250 batchs: 1037.473388671875
INFO:root:Train (Epoch 84): Loss/seq after 00300 batchs: 1019.8535766601562
INFO:root:Train (Epoch 84): Loss/seq after 00350 batchs: 954.181640625
INFO:root:Train (Epoch 84): Loss/seq after 00400 batchs: 947.5814819335938
INFO:root:Train (Epoch 84): Loss/seq after 00450 batchs: 919.3851318359375
INFO:root:Train (Epoch 84): Loss/seq after 00500 batchs: 892.8603515625
INFO:root:Train (Epoch 84): Loss/seq after 00550 batchs: 861.7716064453125
INFO:root:Train (Epoch 84): Loss/seq after 00600 batchs: 829.2545166015625
INFO:root:Train (Epoch 84): Loss/seq after 00650 batchs: 800.84716796875
INFO:root:Train (Epoch 84): Loss/seq after 00700 batchs: 769.141357421875
INFO:root:Train (Epoch 84): Loss/seq after 00750 batchs: 777.0737915039062
INFO:root:Train (Epoch 84): Loss/seq after 00800 batchs: 778.9146728515625
INFO:root:Train (Epoch 84): Loss/seq after 00850 batchs: 755.6974487304688
INFO:root:Train (Epoch 84): Loss/seq after 00900 batchs: 738.0999145507812
INFO:root:Train (Epoch 84): Loss/seq after 00950 batchs: 735.9151000976562
INFO:root:Train (Epoch 84): Loss/seq after 01000 batchs: 724.0925903320312
INFO:root:Train (Epoch 84): Loss/seq after 01050 batchs: 710.620361328125
INFO:root:Train (Epoch 84): Loss/seq after 01100 batchs: 698.4912719726562
INFO:root:Train (Epoch 84): Loss/seq after 01150 batchs: 680.33056640625
INFO:root:Train (Epoch 84): Loss/seq after 01200 batchs: 684.487548828125
INFO:root:Train (Epoch 84): Loss/seq after 01250 batchs: 680.3128662109375
INFO:root:Train (Epoch 84): Loss/seq after 01300 batchs: 665.7041015625
INFO:root:Train (Epoch 84): Loss/seq after 01350 batchs: 654.6140747070312
INFO:root:Train (Epoch 84): Loss/seq after 01400 batchs: 659.397216796875
INFO:root:Train (Epoch 84): Loss/seq after 01450 batchs: 660.7971801757812
INFO:root:Train (Epoch 84): Loss/seq after 01500 batchs: 666.8530883789062
INFO:root:Train (Epoch 84): Loss/seq after 01550 batchs: 669.720947265625
INFO:root:Train (Epoch 84): Loss/seq after 01600 batchs: 663.7848510742188
INFO:root:Train (Epoch 84): Loss/seq after 01650 batchs: 661.2139282226562
INFO:root:Train (Epoch 84): Loss/seq after 01700 batchs: 662.53662109375
INFO:root:Train (Epoch 84): Loss/seq after 01750 batchs: 659.554931640625
INFO:root:Train (Epoch 84): Loss/seq after 01800 batchs: 656.6345825195312
INFO:root:Train (Epoch 84): Loss/seq after 01850 batchs: 652.7162475585938
INFO:root:Train (Epoch 84): Loss/seq after 01900 batchs: 653.74609375
INFO:root:Train (Epoch 84): Loss/seq after 01950 batchs: 652.6371459960938
INFO:root:Train (Epoch 84): Loss/seq after 02000 batchs: 650.7754516601562
INFO:root:Train (Epoch 84): Loss/seq after 02050 batchs: 649.3652954101562
INFO:root:Train (Epoch 84): Loss/seq after 02100 batchs: 646.23095703125
INFO:root:Train (Epoch 84): Loss/seq after 02150 batchs: 643.9539184570312
INFO:root:Train (Epoch 84): Loss/seq after 02200 batchs: 640.63916015625
INFO:root:Train (Epoch 84): Loss/seq after 02250 batchs: 639.71240234375
INFO:root:Train (Epoch 84): Loss/seq after 02300 batchs: 635.2781982421875
INFO:root:Train (Epoch 84): Loss/seq after 02350 batchs: 630.5379028320312
INFO:root:Train (Epoch 84): Loss/seq after 02400 batchs: 631.3488159179688
INFO:root:Train (Epoch 84): Loss/seq after 02450 batchs: 625.699951171875
INFO:root:Train (Epoch 84): Loss/seq after 02500 batchs: 616.21728515625
INFO:root:Train (Epoch 84): Loss/seq after 02550 batchs: 609.2448120117188
INFO:root:Train (Epoch 84): Loss/seq after 02600 batchs: 607.5996704101562
INFO:root:Train (Epoch 84): Loss/seq after 02650 batchs: 604.9142456054688
INFO:root:Train (Epoch 84): Loss/seq after 02700 batchs: 602.3740234375
INFO:root:Train (Epoch 84): Loss/seq after 02750 batchs: 600.0048217773438
INFO:root:Train (Epoch 84): Loss/seq after 02800 batchs: 600.360107421875
INFO:root:Train (Epoch 84): Loss/seq after 02850 batchs: 601.1487426757812
INFO:root:Train (Epoch 84): Loss/seq after 02900 batchs: 602.7596435546875
INFO:root:Train (Epoch 84): Loss/seq after 02950 batchs: 601.6647338867188
INFO:root:Train (Epoch 84): Loss/seq after 03000 batchs: 606.5797119140625
INFO:root:Train (Epoch 84): Loss/seq after 03050 batchs: 610.4205932617188
INFO:root:Train (Epoch 84): Loss/seq after 03100 batchs: 615.950439453125
INFO:root:Train (Epoch 84): Loss/seq after 03150 batchs: 618.5880737304688
INFO:root:Train (Epoch 84): Loss/seq after 03200 batchs: 619.7635498046875
INFO:root:Train (Epoch 84): Loss/seq after 03250 batchs: 622.80859375
INFO:root:Train (Epoch 84): Loss/seq after 03300 batchs: 622.4530029296875
INFO:root:Train (Epoch 84): Loss/seq after 03350 batchs: 622.9179077148438
INFO:root:Train (Epoch 84): Loss/seq after 03400 batchs: 617.9769897460938
INFO:root:Train (Epoch 84): Loss/seq after 03450 batchs: 616.2816162109375
INFO:root:Train (Epoch 84): Loss/seq after 03500 batchs: 617.7276000976562
INFO:root:Train (Epoch 84): Loss/seq after 03550 batchs: 614.9133911132812
INFO:root:Train (Epoch 84): Loss/seq after 03600 batchs: 623.691650390625
INFO:root:Train (Epoch 84): Loss/seq after 03650 batchs: 620.8451538085938
INFO:root:Train (Epoch 84): Loss/seq after 03700 batchs: 623.6113891601562
INFO:root:Train (Epoch 84): Loss/seq after 03750 batchs: 628.4427490234375
INFO:root:Train (Epoch 84): Loss/seq after 03800 batchs: 625.5532836914062
INFO:root:Train (Epoch 84): Loss/seq after 03850 batchs: 625.1124877929688
INFO:root:Train (Epoch 84): Loss/seq after 03900 batchs: 628.5010986328125
INFO:root:Train (Epoch 84): Loss/seq after 03950 batchs: 631.4202880859375
INFO:root:Train (Epoch 84): Loss/seq after 04000 batchs: 627.2241821289062
INFO:root:Train (Epoch 84): Loss/seq after 04050 batchs: 623.1337280273438
INFO:root:Train (Epoch 84): Loss/seq after 04100 batchs: 621.2850341796875
INFO:root:Train (Epoch 84): Loss/seq after 04150 batchs: 620.9298095703125
INFO:root:Train (Epoch 84): Loss/seq after 04200 batchs: 619.3026123046875
INFO:root:Train (Epoch 84): Loss/seq after 04250 batchs: 617.6207275390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 84): Loss/seq after 00000 batches: 635.9169921875
INFO:root:# Valid (Epoch 84): Loss/seq after 00050 batches: 789.2775268554688
INFO:root:# Valid (Epoch 84): Loss/seq after 00100 batches: 821.9221801757812
INFO:root:# Valid (Epoch 84): Loss/seq after 00150 batches: 616.2977294921875
INFO:root:# Valid (Epoch 84): Loss/seq after 00200 batches: 574.7688598632812
INFO:root:Artifacts: Make stick videos for epoch 84
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_84_on_20220422_062740.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_84_index_756_on_20220422_062740.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 85): Loss/seq after 00000 batchs: 1202.8114013671875
INFO:root:Train (Epoch 85): Loss/seq after 00050 batchs: 903.9664916992188
INFO:root:Train (Epoch 85): Loss/seq after 00100 batchs: 897.6117553710938
INFO:root:Train (Epoch 85): Loss/seq after 00150 batchs: 827.3585815429688
INFO:root:Train (Epoch 85): Loss/seq after 00200 batchs: 892.4351196289062
INFO:root:Train (Epoch 85): Loss/seq after 00250 batchs: 1012.4677734375
INFO:root:Train (Epoch 85): Loss/seq after 00300 batchs: 997.6312255859375
INFO:root:Train (Epoch 85): Loss/seq after 00350 batchs: 928.3688354492188
INFO:root:Train (Epoch 85): Loss/seq after 00400 batchs: 921.0674438476562
INFO:root:Train (Epoch 85): Loss/seq after 00450 batchs: 895.9154052734375
INFO:root:Train (Epoch 85): Loss/seq after 00500 batchs: 872.3764038085938
INFO:root:Train (Epoch 85): Loss/seq after 00550 batchs: 842.8256225585938
INFO:root:Train (Epoch 85): Loss/seq after 00600 batchs: 811.9353637695312
INFO:root:Train (Epoch 85): Loss/seq after 00650 batchs: 786.019775390625
INFO:root:Train (Epoch 85): Loss/seq after 00700 batchs: 757.3638916015625
INFO:root:Train (Epoch 85): Loss/seq after 00750 batchs: 764.5174560546875
INFO:root:Train (Epoch 85): Loss/seq after 00800 batchs: 767.5791015625
INFO:root:Train (Epoch 85): Loss/seq after 00850 batchs: 745.3765258789062
INFO:root:Train (Epoch 85): Loss/seq after 00900 batchs: 727.984619140625
INFO:root:Train (Epoch 85): Loss/seq after 00950 batchs: 725.775390625
INFO:root:Train (Epoch 85): Loss/seq after 01000 batchs: 713.354736328125
INFO:root:Train (Epoch 85): Loss/seq after 01050 batchs: 699.4730224609375
INFO:root:Train (Epoch 85): Loss/seq after 01100 batchs: 687.5315551757812
INFO:root:Train (Epoch 85): Loss/seq after 01150 batchs: 669.6869506835938
INFO:root:Train (Epoch 85): Loss/seq after 01200 batchs: 673.6321411132812
INFO:root:Train (Epoch 85): Loss/seq after 01250 batchs: 669.9594116210938
INFO:root:Train (Epoch 85): Loss/seq after 01300 batchs: 655.673828125
INFO:root:Train (Epoch 85): Loss/seq after 01350 batchs: 644.8500366210938
INFO:root:Train (Epoch 85): Loss/seq after 01400 batchs: 649.095703125
INFO:root:Train (Epoch 85): Loss/seq after 01450 batchs: 650.8440551757812
INFO:root:Train (Epoch 85): Loss/seq after 01500 batchs: 657.2540283203125
INFO:root:Train (Epoch 85): Loss/seq after 01550 batchs: 660.4791259765625
INFO:root:Train (Epoch 85): Loss/seq after 01600 batchs: 655.0767822265625
INFO:root:Train (Epoch 85): Loss/seq after 01650 batchs: 653.6231079101562
INFO:root:Train (Epoch 85): Loss/seq after 01700 batchs: 655.3607788085938
INFO:root:Train (Epoch 85): Loss/seq after 01750 batchs: 652.8330688476562
INFO:root:Train (Epoch 85): Loss/seq after 01800 batchs: 650.14794921875
INFO:root:Train (Epoch 85): Loss/seq after 01850 batchs: 646.4168701171875
INFO:root:Train (Epoch 85): Loss/seq after 01900 batchs: 647.8502807617188
INFO:root:Train (Epoch 85): Loss/seq after 01950 batchs: 646.4784545898438
INFO:root:Train (Epoch 85): Loss/seq after 02000 batchs: 644.7146606445312
INFO:root:Train (Epoch 85): Loss/seq after 02050 batchs: 643.2804565429688
INFO:root:Train (Epoch 85): Loss/seq after 02100 batchs: 640.0635375976562
INFO:root:Train (Epoch 85): Loss/seq after 02150 batchs: 637.8555908203125
INFO:root:Train (Epoch 85): Loss/seq after 02200 batchs: 634.5125732421875
INFO:root:Train (Epoch 85): Loss/seq after 02250 batchs: 633.8948364257812
INFO:root:Train (Epoch 85): Loss/seq after 02300 batchs: 629.65380859375
INFO:root:Train (Epoch 85): Loss/seq after 02350 batchs: 624.95068359375
INFO:root:Train (Epoch 85): Loss/seq after 02400 batchs: 626.1439819335938
INFO:root:Train (Epoch 85): Loss/seq after 02450 batchs: 620.7709350585938
INFO:root:Train (Epoch 85): Loss/seq after 02500 batchs: 611.417236328125
INFO:root:Train (Epoch 85): Loss/seq after 02550 batchs: 604.455322265625
INFO:root:Train (Epoch 85): Loss/seq after 02600 batchs: 602.8900146484375
INFO:root:Train (Epoch 85): Loss/seq after 02650 batchs: 600.3477783203125
INFO:root:Train (Epoch 85): Loss/seq after 02700 batchs: 597.8648681640625
INFO:root:Train (Epoch 85): Loss/seq after 02750 batchs: 595.0814208984375
INFO:root:Train (Epoch 85): Loss/seq after 02800 batchs: 596.6634521484375
INFO:root:Train (Epoch 85): Loss/seq after 02850 batchs: 597.2781982421875
INFO:root:Train (Epoch 85): Loss/seq after 02900 batchs: 599.1056518554688
INFO:root:Train (Epoch 85): Loss/seq after 02950 batchs: 598.1589965820312
INFO:root:Train (Epoch 85): Loss/seq after 03000 batchs: 603.0945434570312
INFO:root:Train (Epoch 85): Loss/seq after 03050 batchs: 605.95751953125
INFO:root:Train (Epoch 85): Loss/seq after 03100 batchs: 610.8821411132812
INFO:root:Train (Epoch 85): Loss/seq after 03150 batchs: 613.4739379882812
INFO:root:Train (Epoch 85): Loss/seq after 03200 batchs: 614.6660766601562
INFO:root:Train (Epoch 85): Loss/seq after 03250 batchs: 617.5014038085938
INFO:root:Train (Epoch 85): Loss/seq after 03300 batchs: 616.9111328125
INFO:root:Train (Epoch 85): Loss/seq after 03350 batchs: 617.0067138671875
INFO:root:Train (Epoch 85): Loss/seq after 03400 batchs: 612.384765625
INFO:root:Train (Epoch 85): Loss/seq after 03450 batchs: 610.7575073242188
INFO:root:Train (Epoch 85): Loss/seq after 03500 batchs: 611.7711181640625
INFO:root:Train (Epoch 85): Loss/seq after 03550 batchs: 608.8563232421875
INFO:root:Train (Epoch 85): Loss/seq after 03600 batchs: 617.609375
INFO:root:Train (Epoch 85): Loss/seq after 03650 batchs: 614.9105834960938
INFO:root:Train (Epoch 85): Loss/seq after 03700 batchs: 617.3721923828125
INFO:root:Train (Epoch 85): Loss/seq after 03750 batchs: 622.203857421875
INFO:root:Train (Epoch 85): Loss/seq after 03800 batchs: 619.3535766601562
INFO:root:Train (Epoch 85): Loss/seq after 03850 batchs: 618.9749755859375
INFO:root:Train (Epoch 85): Loss/seq after 03900 batchs: 622.4172973632812
INFO:root:Train (Epoch 85): Loss/seq after 03950 batchs: 625.1592407226562
INFO:root:Train (Epoch 85): Loss/seq after 04000 batchs: 621.1078491210938
INFO:root:Train (Epoch 85): Loss/seq after 04050 batchs: 617.0737915039062
INFO:root:Train (Epoch 85): Loss/seq after 04100 batchs: 615.2199096679688
INFO:root:Train (Epoch 85): Loss/seq after 04150 batchs: 614.8521728515625
INFO:root:Train (Epoch 85): Loss/seq after 04200 batchs: 613.3909301757812
INFO:root:Train (Epoch 85): Loss/seq after 04250 batchs: 611.76318359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 85): Loss/seq after 00000 batches: 579.8612060546875
INFO:root:# Valid (Epoch 85): Loss/seq after 00050 batches: 822.4205322265625
INFO:root:# Valid (Epoch 85): Loss/seq after 00100 batches: 871.1286010742188
INFO:root:# Valid (Epoch 85): Loss/seq after 00150 batches: 654.6754760742188
INFO:root:# Valid (Epoch 85): Loss/seq after 00200 batches: 606.27880859375
INFO:root:Artifacts: Make stick videos for epoch 85
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_85_on_20220422_063249.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_85_index_1602_on_20220422_063249.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 86): Loss/seq after 00000 batchs: 1217.5018310546875
INFO:root:Train (Epoch 86): Loss/seq after 00050 batchs: 901.4937744140625
INFO:root:Train (Epoch 86): Loss/seq after 00100 batchs: 889.3135986328125
INFO:root:Train (Epoch 86): Loss/seq after 00150 batchs: 825.0477905273438
INFO:root:Train (Epoch 86): Loss/seq after 00200 batchs: 898.4654541015625
INFO:root:Train (Epoch 86): Loss/seq after 00250 batchs: 1018.899169921875
INFO:root:Train (Epoch 86): Loss/seq after 00300 batchs: 1001.445556640625
INFO:root:Train (Epoch 86): Loss/seq after 00350 batchs: 932.3157958984375
INFO:root:Train (Epoch 86): Loss/seq after 00400 batchs: 926.3707275390625
INFO:root:Train (Epoch 86): Loss/seq after 00450 batchs: 900.8597412109375
INFO:root:Train (Epoch 86): Loss/seq after 00500 batchs: 879.809814453125
INFO:root:Train (Epoch 86): Loss/seq after 00550 batchs: 850.1244506835938
INFO:root:Train (Epoch 86): Loss/seq after 00600 batchs: 820.85693359375
INFO:root:Train (Epoch 86): Loss/seq after 00650 batchs: 794.4063720703125
INFO:root:Train (Epoch 86): Loss/seq after 00700 batchs: 763.5831298828125
INFO:root:Train (Epoch 86): Loss/seq after 00750 batchs: 769.2050170898438
INFO:root:Train (Epoch 86): Loss/seq after 00800 batchs: 774.505859375
INFO:root:Train (Epoch 86): Loss/seq after 00850 batchs: 751.1707153320312
INFO:root:Train (Epoch 86): Loss/seq after 00900 batchs: 733.1919555664062
INFO:root:Train (Epoch 86): Loss/seq after 00950 batchs: 728.5177612304688
INFO:root:Train (Epoch 86): Loss/seq after 01000 batchs: 716.9212036132812
INFO:root:Train (Epoch 86): Loss/seq after 01050 batchs: 703.3115234375
INFO:root:Train (Epoch 86): Loss/seq after 01100 batchs: 692.2483520507812
INFO:root:Train (Epoch 86): Loss/seq after 01150 batchs: 674.3916625976562
INFO:root:Train (Epoch 86): Loss/seq after 01200 batchs: 678.684326171875
INFO:root:Train (Epoch 86): Loss/seq after 01250 batchs: 675.3452758789062
INFO:root:Train (Epoch 86): Loss/seq after 01300 batchs: 660.9791259765625
INFO:root:Train (Epoch 86): Loss/seq after 01350 batchs: 649.9436645507812
INFO:root:Train (Epoch 86): Loss/seq after 01400 batchs: 654.15673828125
INFO:root:Train (Epoch 86): Loss/seq after 01450 batchs: 655.3251342773438
INFO:root:Train (Epoch 86): Loss/seq after 01500 batchs: 661.7448120117188
INFO:root:Train (Epoch 86): Loss/seq after 01550 batchs: 665.036865234375
INFO:root:Train (Epoch 86): Loss/seq after 01600 batchs: 659.79736328125
INFO:root:Train (Epoch 86): Loss/seq after 01650 batchs: 657.786865234375
INFO:root:Train (Epoch 86): Loss/seq after 01700 batchs: 659.0664672851562
INFO:root:Train (Epoch 86): Loss/seq after 01750 batchs: 655.9610595703125
INFO:root:Train (Epoch 86): Loss/seq after 01800 batchs: 653.0350952148438
INFO:root:Train (Epoch 86): Loss/seq after 01850 batchs: 649.0531616210938
INFO:root:Train (Epoch 86): Loss/seq after 01900 batchs: 649.979736328125
INFO:root:Train (Epoch 86): Loss/seq after 01950 batchs: 648.3524169921875
INFO:root:Train (Epoch 86): Loss/seq after 02000 batchs: 646.3681030273438
INFO:root:Train (Epoch 86): Loss/seq after 02050 batchs: 644.8048706054688
INFO:root:Train (Epoch 86): Loss/seq after 02100 batchs: 641.8037719726562
INFO:root:Train (Epoch 86): Loss/seq after 02150 batchs: 639.619384765625
INFO:root:Train (Epoch 86): Loss/seq after 02200 batchs: 636.256103515625
INFO:root:Train (Epoch 86): Loss/seq after 02250 batchs: 635.2694702148438
INFO:root:Train (Epoch 86): Loss/seq after 02300 batchs: 631.1974487304688
INFO:root:Train (Epoch 86): Loss/seq after 02350 batchs: 626.5994262695312
INFO:root:Train (Epoch 86): Loss/seq after 02400 batchs: 627.6455078125
INFO:root:Train (Epoch 86): Loss/seq after 02450 batchs: 622.1847534179688
INFO:root:Train (Epoch 86): Loss/seq after 02500 batchs: 612.7537231445312
INFO:root:Train (Epoch 86): Loss/seq after 02550 batchs: 605.727783203125
INFO:root:Train (Epoch 86): Loss/seq after 02600 batchs: 603.8692016601562
INFO:root:Train (Epoch 86): Loss/seq after 02650 batchs: 601.1680297851562
INFO:root:Train (Epoch 86): Loss/seq after 02700 batchs: 598.7694091796875
INFO:root:Train (Epoch 86): Loss/seq after 02750 batchs: 596.3321533203125
INFO:root:Train (Epoch 86): Loss/seq after 02800 batchs: 596.6138916015625
INFO:root:Train (Epoch 86): Loss/seq after 02850 batchs: 597.386962890625
INFO:root:Train (Epoch 86): Loss/seq after 02900 batchs: 598.6642456054688
INFO:root:Train (Epoch 86): Loss/seq after 02950 batchs: 597.6152954101562
INFO:root:Train (Epoch 86): Loss/seq after 03000 batchs: 602.56494140625
INFO:root:Train (Epoch 86): Loss/seq after 03050 batchs: 606.0357666015625
INFO:root:Train (Epoch 86): Loss/seq after 03100 batchs: 610.8577880859375
INFO:root:Train (Epoch 86): Loss/seq after 03150 batchs: 612.3362426757812
INFO:root:Train (Epoch 86): Loss/seq after 03200 batchs: 613.36767578125
INFO:root:Train (Epoch 86): Loss/seq after 03250 batchs: 616.1793823242188
INFO:root:Train (Epoch 86): Loss/seq after 03300 batchs: 615.4141235351562
INFO:root:Train (Epoch 86): Loss/seq after 03350 batchs: 614.77197265625
INFO:root:Train (Epoch 86): Loss/seq after 03400 batchs: 609.952392578125
INFO:root:Train (Epoch 86): Loss/seq after 03450 batchs: 608.3406982421875
INFO:root:Train (Epoch 86): Loss/seq after 03500 batchs: 609.499755859375
INFO:root:Train (Epoch 86): Loss/seq after 03550 batchs: 606.7606811523438
INFO:root:Train (Epoch 86): Loss/seq after 03600 batchs: 615.8295288085938
INFO:root:Train (Epoch 86): Loss/seq after 03650 batchs: 613.34716796875
INFO:root:Train (Epoch 86): Loss/seq after 03700 batchs: 616.2753295898438
INFO:root:Train (Epoch 86): Loss/seq after 03750 batchs: 621.1245727539062
INFO:root:Train (Epoch 86): Loss/seq after 03800 batchs: 618.3138427734375
INFO:root:Train (Epoch 86): Loss/seq after 03850 batchs: 617.6282348632812
INFO:root:Train (Epoch 86): Loss/seq after 03900 batchs: 621.1483154296875
INFO:root:Train (Epoch 86): Loss/seq after 03950 batchs: 624.0753784179688
INFO:root:Train (Epoch 86): Loss/seq after 04000 batchs: 620.0345458984375
INFO:root:Train (Epoch 86): Loss/seq after 04050 batchs: 616.0188598632812
INFO:root:Train (Epoch 86): Loss/seq after 04100 batchs: 614.3290405273438
INFO:root:Train (Epoch 86): Loss/seq after 04150 batchs: 613.9925537109375
INFO:root:Train (Epoch 86): Loss/seq after 04200 batchs: 612.3662719726562
INFO:root:Train (Epoch 86): Loss/seq after 04250 batchs: 610.5283203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 86): Loss/seq after 00000 batches: 528.390625
INFO:root:# Valid (Epoch 86): Loss/seq after 00050 batches: 876.5504150390625
INFO:root:# Valid (Epoch 86): Loss/seq after 00100 batches: 876.2496948242188
INFO:root:# Valid (Epoch 86): Loss/seq after 00150 batches: 652.9353637695312
INFO:root:# Valid (Epoch 86): Loss/seq after 00200 batches: 601.1477661132812
INFO:root:Artifacts: Make stick videos for epoch 86
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_86_on_20220422_063733.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_86_index_1053_on_20220422_063733.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 87): Loss/seq after 00000 batchs: 1280.2052001953125
INFO:root:Train (Epoch 87): Loss/seq after 00050 batchs: 894.8239135742188
INFO:root:Train (Epoch 87): Loss/seq after 00100 batchs: 905.6702270507812
INFO:root:Train (Epoch 87): Loss/seq after 00150 batchs: 836.0432739257812
INFO:root:Train (Epoch 87): Loss/seq after 00200 batchs: 911.3748779296875
INFO:root:Train (Epoch 87): Loss/seq after 00250 batchs: 1031.0460205078125
INFO:root:Train (Epoch 87): Loss/seq after 00300 batchs: 1012.9248046875
INFO:root:Train (Epoch 87): Loss/seq after 00350 batchs: 942.2545166015625
INFO:root:Train (Epoch 87): Loss/seq after 00400 batchs: 937.1260986328125
INFO:root:Train (Epoch 87): Loss/seq after 00450 batchs: 910.2391357421875
INFO:root:Train (Epoch 87): Loss/seq after 00500 batchs: 882.855224609375
INFO:root:Train (Epoch 87): Loss/seq after 00550 batchs: 852.1104125976562
INFO:root:Train (Epoch 87): Loss/seq after 00600 batchs: 819.853515625
INFO:root:Train (Epoch 87): Loss/seq after 00650 batchs: 791.6361083984375
INFO:root:Train (Epoch 87): Loss/seq after 00700 batchs: 761.898193359375
INFO:root:Train (Epoch 87): Loss/seq after 00750 batchs: 765.6024169921875
INFO:root:Train (Epoch 87): Loss/seq after 00800 batchs: 766.167724609375
INFO:root:Train (Epoch 87): Loss/seq after 00850 batchs: 742.6231689453125
INFO:root:Train (Epoch 87): Loss/seq after 00900 batchs: 724.4850463867188
INFO:root:Train (Epoch 87): Loss/seq after 00950 batchs: 720.2010498046875
INFO:root:Train (Epoch 87): Loss/seq after 01000 batchs: 708.1436157226562
INFO:root:Train (Epoch 87): Loss/seq after 01050 batchs: 693.9046630859375
INFO:root:Train (Epoch 87): Loss/seq after 01100 batchs: 682.5443115234375
INFO:root:Train (Epoch 87): Loss/seq after 01150 batchs: 664.750244140625
INFO:root:Train (Epoch 87): Loss/seq after 01200 batchs: 669.3590698242188
INFO:root:Train (Epoch 87): Loss/seq after 01250 batchs: 665.5795288085938
INFO:root:Train (Epoch 87): Loss/seq after 01300 batchs: 651.3076171875
INFO:root:Train (Epoch 87): Loss/seq after 01350 batchs: 640.7068481445312
INFO:root:Train (Epoch 87): Loss/seq after 01400 batchs: 644.4778442382812
INFO:root:Train (Epoch 87): Loss/seq after 01450 batchs: 646.1141967773438
INFO:root:Train (Epoch 87): Loss/seq after 01500 batchs: 652.5676879882812
INFO:root:Train (Epoch 87): Loss/seq after 01550 batchs: 655.656494140625
INFO:root:Train (Epoch 87): Loss/seq after 01600 batchs: 649.9148559570312
INFO:root:Train (Epoch 87): Loss/seq after 01650 batchs: 647.1904907226562
INFO:root:Train (Epoch 87): Loss/seq after 01700 batchs: 648.7052001953125
INFO:root:Train (Epoch 87): Loss/seq after 01750 batchs: 645.6536254882812
INFO:root:Train (Epoch 87): Loss/seq after 01800 batchs: 642.884765625
INFO:root:Train (Epoch 87): Loss/seq after 01850 batchs: 639.0438232421875
INFO:root:Train (Epoch 87): Loss/seq after 01900 batchs: 640.10107421875
INFO:root:Train (Epoch 87): Loss/seq after 01950 batchs: 639.1325073242188
INFO:root:Train (Epoch 87): Loss/seq after 02000 batchs: 637.3438720703125
INFO:root:Train (Epoch 87): Loss/seq after 02050 batchs: 636.2061157226562
INFO:root:Train (Epoch 87): Loss/seq after 02100 batchs: 633.3154907226562
INFO:root:Train (Epoch 87): Loss/seq after 02150 batchs: 631.2675170898438
INFO:root:Train (Epoch 87): Loss/seq after 02200 batchs: 628.074462890625
INFO:root:Train (Epoch 87): Loss/seq after 02250 batchs: 626.8539428710938
INFO:root:Train (Epoch 87): Loss/seq after 02300 batchs: 622.5036010742188
INFO:root:Train (Epoch 87): Loss/seq after 02350 batchs: 617.8064575195312
INFO:root:Train (Epoch 87): Loss/seq after 02400 batchs: 618.74853515625
INFO:root:Train (Epoch 87): Loss/seq after 02450 batchs: 613.3720092773438
INFO:root:Train (Epoch 87): Loss/seq after 02500 batchs: 604.0724487304688
INFO:root:Train (Epoch 87): Loss/seq after 02550 batchs: 597.021728515625
INFO:root:Train (Epoch 87): Loss/seq after 02600 batchs: 595.451904296875
INFO:root:Train (Epoch 87): Loss/seq after 02650 batchs: 592.7799682617188
INFO:root:Train (Epoch 87): Loss/seq after 02700 batchs: 590.203125
INFO:root:Train (Epoch 87): Loss/seq after 02750 batchs: 587.4034423828125
INFO:root:Train (Epoch 87): Loss/seq after 02800 batchs: 587.4442749023438
INFO:root:Train (Epoch 87): Loss/seq after 02850 batchs: 588.0176391601562
INFO:root:Train (Epoch 87): Loss/seq after 02900 batchs: 589.6900024414062
INFO:root:Train (Epoch 87): Loss/seq after 02950 batchs: 588.747314453125
INFO:root:Train (Epoch 87): Loss/seq after 03000 batchs: 593.7598266601562
INFO:root:Train (Epoch 87): Loss/seq after 03050 batchs: 597.392822265625
INFO:root:Train (Epoch 87): Loss/seq after 03100 batchs: 602.142333984375
INFO:root:Train (Epoch 87): Loss/seq after 03150 batchs: 603.56689453125
INFO:root:Train (Epoch 87): Loss/seq after 03200 batchs: 604.5198364257812
INFO:root:Train (Epoch 87): Loss/seq after 03250 batchs: 607.1895751953125
INFO:root:Train (Epoch 87): Loss/seq after 03300 batchs: 606.1048583984375
INFO:root:Train (Epoch 87): Loss/seq after 03350 batchs: 605.4752197265625
INFO:root:Train (Epoch 87): Loss/seq after 03400 batchs: 600.6815795898438
INFO:root:Train (Epoch 87): Loss/seq after 03450 batchs: 598.9365844726562
INFO:root:Train (Epoch 87): Loss/seq after 03500 batchs: 600.310791015625
INFO:root:Train (Epoch 87): Loss/seq after 03550 batchs: 597.5308837890625
INFO:root:Train (Epoch 87): Loss/seq after 03600 batchs: 606.5338745117188
INFO:root:Train (Epoch 87): Loss/seq after 03650 batchs: 604.085205078125
INFO:root:Train (Epoch 87): Loss/seq after 03700 batchs: 606.7987060546875
INFO:root:Train (Epoch 87): Loss/seq after 03750 batchs: 611.7755737304688
INFO:root:Train (Epoch 87): Loss/seq after 03800 batchs: 609.1348266601562
INFO:root:Train (Epoch 87): Loss/seq after 03850 batchs: 608.4558715820312
INFO:root:Train (Epoch 87): Loss/seq after 03900 batchs: 612.1005249023438
INFO:root:Train (Epoch 87): Loss/seq after 03950 batchs: 615.0621948242188
INFO:root:Train (Epoch 87): Loss/seq after 04000 batchs: 611.0722045898438
INFO:root:Train (Epoch 87): Loss/seq after 04050 batchs: 607.1279296875
INFO:root:Train (Epoch 87): Loss/seq after 04100 batchs: 605.4894409179688
INFO:root:Train (Epoch 87): Loss/seq after 04150 batchs: 605.2391357421875
INFO:root:Train (Epoch 87): Loss/seq after 04200 batchs: 603.6831665039062
INFO:root:Train (Epoch 87): Loss/seq after 04250 batchs: 601.9004516601562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 87): Loss/seq after 00000 batches: 503.00714111328125
INFO:root:# Valid (Epoch 87): Loss/seq after 00050 batches: 796.1781005859375
INFO:root:# Valid (Epoch 87): Loss/seq after 00100 batches: 832.50439453125
INFO:root:# Valid (Epoch 87): Loss/seq after 00150 batches: 624.8934326171875
INFO:root:# Valid (Epoch 87): Loss/seq after 00200 batches: 583.7877807617188
INFO:root:Artifacts: Make stick videos for epoch 87
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_87_on_20220422_064217.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_87_index_325_on_20220422_064217.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 88): Loss/seq after 00000 batchs: 1378.93701171875
INFO:root:Train (Epoch 88): Loss/seq after 00050 batchs: 883.0082397460938
INFO:root:Train (Epoch 88): Loss/seq after 00100 batchs: 899.0615844726562
INFO:root:Train (Epoch 88): Loss/seq after 00150 batchs: 830.2772827148438
INFO:root:Train (Epoch 88): Loss/seq after 00200 batchs: 903.0873413085938
INFO:root:Train (Epoch 88): Loss/seq after 00250 batchs: 1031.4105224609375
INFO:root:Train (Epoch 88): Loss/seq after 00300 batchs: 1012.5777587890625
INFO:root:Train (Epoch 88): Loss/seq after 00350 batchs: 942.7051391601562
INFO:root:Train (Epoch 88): Loss/seq after 00400 batchs: 938.5167846679688
INFO:root:Train (Epoch 88): Loss/seq after 00450 batchs: 912.12353515625
INFO:root:Train (Epoch 88): Loss/seq after 00500 batchs: 885.0404663085938
INFO:root:Train (Epoch 88): Loss/seq after 00550 batchs: 855.5064697265625
INFO:root:Train (Epoch 88): Loss/seq after 00600 batchs: 823.1467895507812
INFO:root:Train (Epoch 88): Loss/seq after 00650 batchs: 795.8818969726562
INFO:root:Train (Epoch 88): Loss/seq after 00700 batchs: 764.02490234375
INFO:root:Train (Epoch 88): Loss/seq after 00750 batchs: 767.3585815429688
INFO:root:Train (Epoch 88): Loss/seq after 00800 batchs: 767.6077880859375
INFO:root:Train (Epoch 88): Loss/seq after 00850 batchs: 743.885986328125
INFO:root:Train (Epoch 88): Loss/seq after 00900 batchs: 725.7389526367188
INFO:root:Train (Epoch 88): Loss/seq after 00950 batchs: 720.14208984375
INFO:root:Train (Epoch 88): Loss/seq after 01000 batchs: 707.7691650390625
INFO:root:Train (Epoch 88): Loss/seq after 01050 batchs: 693.5108642578125
INFO:root:Train (Epoch 88): Loss/seq after 01100 batchs: 681.6134033203125
INFO:root:Train (Epoch 88): Loss/seq after 01150 batchs: 663.6702270507812
INFO:root:Train (Epoch 88): Loss/seq after 01200 batchs: 667.9466552734375
INFO:root:Train (Epoch 88): Loss/seq after 01250 batchs: 663.9708251953125
INFO:root:Train (Epoch 88): Loss/seq after 01300 batchs: 650.2952880859375
INFO:root:Train (Epoch 88): Loss/seq after 01350 batchs: 638.8258056640625
INFO:root:Train (Epoch 88): Loss/seq after 01400 batchs: 642.839599609375
INFO:root:Train (Epoch 88): Loss/seq after 01450 batchs: 644.7799682617188
INFO:root:Train (Epoch 88): Loss/seq after 01500 batchs: 651.1739501953125
INFO:root:Train (Epoch 88): Loss/seq after 01550 batchs: 654.146240234375
INFO:root:Train (Epoch 88): Loss/seq after 01600 batchs: 648.8749389648438
INFO:root:Train (Epoch 88): Loss/seq after 01650 batchs: 646.4765625
INFO:root:Train (Epoch 88): Loss/seq after 01700 batchs: 648.155029296875
INFO:root:Train (Epoch 88): Loss/seq after 01750 batchs: 645.3831787109375
INFO:root:Train (Epoch 88): Loss/seq after 01800 batchs: 642.5518188476562
INFO:root:Train (Epoch 88): Loss/seq after 01850 batchs: 638.7067260742188
INFO:root:Train (Epoch 88): Loss/seq after 01900 batchs: 639.8245849609375
INFO:root:Train (Epoch 88): Loss/seq after 01950 batchs: 638.7217407226562
INFO:root:Train (Epoch 88): Loss/seq after 02000 batchs: 637.1068115234375
INFO:root:Train (Epoch 88): Loss/seq after 02050 batchs: 635.762451171875
INFO:root:Train (Epoch 88): Loss/seq after 02100 batchs: 632.880126953125
INFO:root:Train (Epoch 88): Loss/seq after 02150 batchs: 630.8956909179688
INFO:root:Train (Epoch 88): Loss/seq after 02200 batchs: 627.5758666992188
INFO:root:Train (Epoch 88): Loss/seq after 02250 batchs: 626.2249755859375
INFO:root:Train (Epoch 88): Loss/seq after 02300 batchs: 621.9793090820312
INFO:root:Train (Epoch 88): Loss/seq after 02350 batchs: 617.282470703125
INFO:root:Train (Epoch 88): Loss/seq after 02400 batchs: 618.212646484375
INFO:root:Train (Epoch 88): Loss/seq after 02450 batchs: 612.8264770507812
INFO:root:Train (Epoch 88): Loss/seq after 02500 batchs: 603.5186767578125
INFO:root:Train (Epoch 88): Loss/seq after 02550 batchs: 596.5687866210938
INFO:root:Train (Epoch 88): Loss/seq after 02600 batchs: 594.80908203125
INFO:root:Train (Epoch 88): Loss/seq after 02650 batchs: 591.8876342773438
INFO:root:Train (Epoch 88): Loss/seq after 02700 batchs: 589.4486083984375
INFO:root:Train (Epoch 88): Loss/seq after 02750 batchs: 586.0332641601562
INFO:root:Train (Epoch 88): Loss/seq after 02800 batchs: 586.4906005859375
INFO:root:Train (Epoch 88): Loss/seq after 02850 batchs: 587.3093872070312
INFO:root:Train (Epoch 88): Loss/seq after 02900 batchs: 589.5767822265625
INFO:root:Train (Epoch 88): Loss/seq after 02950 batchs: 588.6448364257812
INFO:root:Train (Epoch 88): Loss/seq after 03000 batchs: 593.6630249023438
INFO:root:Train (Epoch 88): Loss/seq after 03050 batchs: 596.3947143554688
INFO:root:Train (Epoch 88): Loss/seq after 03100 batchs: 601.6898193359375
INFO:root:Train (Epoch 88): Loss/seq after 03150 batchs: 603.0828247070312
INFO:root:Train (Epoch 88): Loss/seq after 03200 batchs: 603.6610717773438
INFO:root:Train (Epoch 88): Loss/seq after 03250 batchs: 606.58740234375
INFO:root:Train (Epoch 88): Loss/seq after 03300 batchs: 605.4442138671875
INFO:root:Train (Epoch 88): Loss/seq after 03350 batchs: 605.1431884765625
INFO:root:Train (Epoch 88): Loss/seq after 03400 batchs: 600.1954956054688
INFO:root:Train (Epoch 88): Loss/seq after 03450 batchs: 598.5150146484375
INFO:root:Train (Epoch 88): Loss/seq after 03500 batchs: 599.6743774414062
INFO:root:Train (Epoch 88): Loss/seq after 03550 batchs: 596.7218017578125
INFO:root:Train (Epoch 88): Loss/seq after 03600 batchs: 605.5208129882812
INFO:root:Train (Epoch 88): Loss/seq after 03650 batchs: 602.7207641601562
INFO:root:Train (Epoch 88): Loss/seq after 03700 batchs: 605.2882080078125
INFO:root:Train (Epoch 88): Loss/seq after 03750 batchs: 610.2102661132812
INFO:root:Train (Epoch 88): Loss/seq after 03800 batchs: 607.6307373046875
INFO:root:Train (Epoch 88): Loss/seq after 03850 batchs: 606.9957275390625
INFO:root:Train (Epoch 88): Loss/seq after 03900 batchs: 610.848876953125
INFO:root:Train (Epoch 88): Loss/seq after 03950 batchs: 613.9383544921875
INFO:root:Train (Epoch 88): Loss/seq after 04000 batchs: 609.9568481445312
INFO:root:Train (Epoch 88): Loss/seq after 04050 batchs: 605.9898071289062
INFO:root:Train (Epoch 88): Loss/seq after 04100 batchs: 604.183349609375
INFO:root:Train (Epoch 88): Loss/seq after 04150 batchs: 604.066650390625
INFO:root:Train (Epoch 88): Loss/seq after 04200 batchs: 602.5406494140625
INFO:root:Train (Epoch 88): Loss/seq after 04250 batchs: 600.9203491210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 88): Loss/seq after 00000 batches: 483.7694091796875
INFO:root:# Valid (Epoch 88): Loss/seq after 00050 batches: 776.9347534179688
INFO:root:# Valid (Epoch 88): Loss/seq after 00100 batches: 824.9280395507812
INFO:root:# Valid (Epoch 88): Loss/seq after 00150 batches: 623.852783203125
INFO:root:# Valid (Epoch 88): Loss/seq after 00200 batches: 584.0042114257812
INFO:root:Artifacts: Make stick videos for epoch 88
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_88_on_20220422_064719.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_88_index_532_on_20220422_064719.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 89): Loss/seq after 00000 batchs: 1149.1658935546875
INFO:root:Train (Epoch 89): Loss/seq after 00050 batchs: 893.8975219726562
INFO:root:Train (Epoch 89): Loss/seq after 00100 batchs: 912.7610473632812
INFO:root:Train (Epoch 89): Loss/seq after 00150 batchs: 838.8746948242188
INFO:root:Train (Epoch 89): Loss/seq after 00200 batchs: 913.3505859375
INFO:root:Train (Epoch 89): Loss/seq after 00250 batchs: 1037.98828125
INFO:root:Train (Epoch 89): Loss/seq after 00300 batchs: 1018.7133178710938
INFO:root:Train (Epoch 89): Loss/seq after 00350 batchs: 948.5316162109375
INFO:root:Train (Epoch 89): Loss/seq after 00400 batchs: 938.1597290039062
INFO:root:Train (Epoch 89): Loss/seq after 00450 batchs: 910.3072509765625
INFO:root:Train (Epoch 89): Loss/seq after 00500 batchs: 883.2999267578125
INFO:root:Train (Epoch 89): Loss/seq after 00550 batchs: 851.8419189453125
INFO:root:Train (Epoch 89): Loss/seq after 00600 batchs: 820.462158203125
INFO:root:Train (Epoch 89): Loss/seq after 00650 batchs: 792.0261840820312
INFO:root:Train (Epoch 89): Loss/seq after 00700 batchs: 760.171142578125
INFO:root:Train (Epoch 89): Loss/seq after 00750 batchs: 763.7971801757812
INFO:root:Train (Epoch 89): Loss/seq after 00800 batchs: 766.416259765625
INFO:root:Train (Epoch 89): Loss/seq after 00850 batchs: 743.3989868164062
INFO:root:Train (Epoch 89): Loss/seq after 00900 batchs: 725.5851440429688
INFO:root:Train (Epoch 89): Loss/seq after 00950 batchs: 721.1931762695312
INFO:root:Train (Epoch 89): Loss/seq after 01000 batchs: 708.1575927734375
INFO:root:Train (Epoch 89): Loss/seq after 01050 batchs: 693.8599853515625
INFO:root:Train (Epoch 89): Loss/seq after 01100 batchs: 682.36328125
INFO:root:Train (Epoch 89): Loss/seq after 01150 batchs: 664.276611328125
INFO:root:Train (Epoch 89): Loss/seq after 01200 batchs: 668.3101806640625
INFO:root:Train (Epoch 89): Loss/seq after 01250 batchs: 664.3140258789062
INFO:root:Train (Epoch 89): Loss/seq after 01300 batchs: 650.4068603515625
INFO:root:Train (Epoch 89): Loss/seq after 01350 batchs: 638.98046875
INFO:root:Train (Epoch 89): Loss/seq after 01400 batchs: 642.3035888671875
INFO:root:Train (Epoch 89): Loss/seq after 01450 batchs: 644.0148315429688
INFO:root:Train (Epoch 89): Loss/seq after 01500 batchs: 650.4739379882812
INFO:root:Train (Epoch 89): Loss/seq after 01550 batchs: 653.9176025390625
INFO:root:Train (Epoch 89): Loss/seq after 01600 batchs: 648.436767578125
INFO:root:Train (Epoch 89): Loss/seq after 01650 batchs: 646.5339965820312
INFO:root:Train (Epoch 89): Loss/seq after 01700 batchs: 648.5725708007812
INFO:root:Train (Epoch 89): Loss/seq after 01750 batchs: 645.9142456054688
INFO:root:Train (Epoch 89): Loss/seq after 01800 batchs: 643.1090698242188
INFO:root:Train (Epoch 89): Loss/seq after 01850 batchs: 639.400390625
INFO:root:Train (Epoch 89): Loss/seq after 01900 batchs: 640.5786743164062
INFO:root:Train (Epoch 89): Loss/seq after 01950 batchs: 639.6134033203125
INFO:root:Train (Epoch 89): Loss/seq after 02000 batchs: 637.6882934570312
INFO:root:Train (Epoch 89): Loss/seq after 02050 batchs: 636.3694458007812
INFO:root:Train (Epoch 89): Loss/seq after 02100 batchs: 633.3384399414062
INFO:root:Train (Epoch 89): Loss/seq after 02150 batchs: 631.2239379882812
INFO:root:Train (Epoch 89): Loss/seq after 02200 batchs: 627.9432373046875
INFO:root:Train (Epoch 89): Loss/seq after 02250 batchs: 627.6194458007812
INFO:root:Train (Epoch 89): Loss/seq after 02300 batchs: 623.4949340820312
INFO:root:Train (Epoch 89): Loss/seq after 02350 batchs: 618.5716552734375
INFO:root:Train (Epoch 89): Loss/seq after 02400 batchs: 619.4964599609375
INFO:root:Train (Epoch 89): Loss/seq after 02450 batchs: 614.1176147460938
INFO:root:Train (Epoch 89): Loss/seq after 02500 batchs: 604.8012084960938
INFO:root:Train (Epoch 89): Loss/seq after 02550 batchs: 597.668701171875
INFO:root:Train (Epoch 89): Loss/seq after 02600 batchs: 595.7349243164062
INFO:root:Train (Epoch 89): Loss/seq after 02650 batchs: 592.9241943359375
INFO:root:Train (Epoch 89): Loss/seq after 02700 batchs: 590.319580078125
INFO:root:Train (Epoch 89): Loss/seq after 02750 batchs: 586.2816772460938
INFO:root:Train (Epoch 89): Loss/seq after 02800 batchs: 586.12939453125
INFO:root:Train (Epoch 89): Loss/seq after 02850 batchs: 586.8534545898438
INFO:root:Train (Epoch 89): Loss/seq after 02900 batchs: 588.5895385742188
INFO:root:Train (Epoch 89): Loss/seq after 02950 batchs: 587.5704956054688
INFO:root:Train (Epoch 89): Loss/seq after 03000 batchs: 592.64453125
INFO:root:Train (Epoch 89): Loss/seq after 03050 batchs: 595.314453125
INFO:root:Train (Epoch 89): Loss/seq after 03100 batchs: 600.0159301757812
INFO:root:Train (Epoch 89): Loss/seq after 03150 batchs: 601.847412109375
INFO:root:Train (Epoch 89): Loss/seq after 03200 batchs: 603.008544921875
INFO:root:Train (Epoch 89): Loss/seq after 03250 batchs: 606.024658203125
INFO:root:Train (Epoch 89): Loss/seq after 03300 batchs: 606.1409301757812
INFO:root:Train (Epoch 89): Loss/seq after 03350 batchs: 606.2763671875
INFO:root:Train (Epoch 89): Loss/seq after 03400 batchs: 601.4702758789062
INFO:root:Train (Epoch 89): Loss/seq after 03450 batchs: 599.8843994140625
INFO:root:Train (Epoch 89): Loss/seq after 03500 batchs: 601.3469848632812
INFO:root:Train (Epoch 89): Loss/seq after 03550 batchs: 598.7675170898438
INFO:root:Train (Epoch 89): Loss/seq after 03600 batchs: 607.815185546875
INFO:root:Train (Epoch 89): Loss/seq after 03650 batchs: 605.248779296875
INFO:root:Train (Epoch 89): Loss/seq after 03700 batchs: 607.7482299804688
INFO:root:Train (Epoch 89): Loss/seq after 03750 batchs: 612.5908203125
INFO:root:Train (Epoch 89): Loss/seq after 03800 batchs: 609.863525390625
INFO:root:Train (Epoch 89): Loss/seq after 03850 batchs: 609.369873046875
INFO:root:Train (Epoch 89): Loss/seq after 03900 batchs: 613.024658203125
INFO:root:Train (Epoch 89): Loss/seq after 03950 batchs: 616.1505126953125
INFO:root:Train (Epoch 89): Loss/seq after 04000 batchs: 612.1412963867188
INFO:root:Train (Epoch 89): Loss/seq after 04050 batchs: 608.136474609375
INFO:root:Train (Epoch 89): Loss/seq after 04100 batchs: 606.3223266601562
INFO:root:Train (Epoch 89): Loss/seq after 04150 batchs: 606.076904296875
INFO:root:Train (Epoch 89): Loss/seq after 04200 batchs: 604.6250610351562
INFO:root:Train (Epoch 89): Loss/seq after 04250 batchs: 602.8785400390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 89): Loss/seq after 00000 batches: 553.8267211914062
INFO:root:# Valid (Epoch 89): Loss/seq after 00050 batches: 744.6571044921875
INFO:root:# Valid (Epoch 89): Loss/seq after 00100 batches: 791.5142822265625
INFO:root:# Valid (Epoch 89): Loss/seq after 00150 batches: 595.0265502929688
INFO:root:# Valid (Epoch 89): Loss/seq after 00200 batches: 558.8340454101562
INFO:root:Artifacts: Make stick videos for epoch 89
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_89_on_20220422_065212.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_89_index_1288_on_20220422_065212.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 90): Loss/seq after 00000 batchs: 1177.38916015625
INFO:root:Train (Epoch 90): Loss/seq after 00050 batchs: 875.2330322265625
INFO:root:Train (Epoch 90): Loss/seq after 00100 batchs: 886.8526611328125
INFO:root:Train (Epoch 90): Loss/seq after 00150 batchs: 816.8997802734375
INFO:root:Train (Epoch 90): Loss/seq after 00200 batchs: 882.1525268554688
INFO:root:Train (Epoch 90): Loss/seq after 00250 batchs: 1013.7482299804688
INFO:root:Train (Epoch 90): Loss/seq after 00300 batchs: 997.6355590820312
INFO:root:Train (Epoch 90): Loss/seq after 00350 batchs: 933.1199340820312
INFO:root:Train (Epoch 90): Loss/seq after 00400 batchs: 930.419921875
INFO:root:Train (Epoch 90): Loss/seq after 00450 batchs: 904.4739379882812
INFO:root:Train (Epoch 90): Loss/seq after 00500 batchs: 880.2212524414062
INFO:root:Train (Epoch 90): Loss/seq after 00550 batchs: 849.363525390625
INFO:root:Train (Epoch 90): Loss/seq after 00600 batchs: 817.8091430664062
INFO:root:Train (Epoch 90): Loss/seq after 00650 batchs: 790.8883666992188
INFO:root:Train (Epoch 90): Loss/seq after 00700 batchs: 758.9906005859375
INFO:root:Train (Epoch 90): Loss/seq after 00750 batchs: 763.255126953125
INFO:root:Train (Epoch 90): Loss/seq after 00800 batchs: 764.8854370117188
INFO:root:Train (Epoch 90): Loss/seq after 00850 batchs: 741.0280151367188
INFO:root:Train (Epoch 90): Loss/seq after 00900 batchs: 722.5744018554688
INFO:root:Train (Epoch 90): Loss/seq after 00950 batchs: 716.674072265625
INFO:root:Train (Epoch 90): Loss/seq after 01000 batchs: 703.8095092773438
INFO:root:Train (Epoch 90): Loss/seq after 01050 batchs: 689.8897705078125
INFO:root:Train (Epoch 90): Loss/seq after 01100 batchs: 678.5567016601562
INFO:root:Train (Epoch 90): Loss/seq after 01150 batchs: 660.7039794921875
INFO:root:Train (Epoch 90): Loss/seq after 01200 batchs: 664.4434204101562
INFO:root:Train (Epoch 90): Loss/seq after 01250 batchs: 661.3701782226562
INFO:root:Train (Epoch 90): Loss/seq after 01300 batchs: 647.5369873046875
INFO:root:Train (Epoch 90): Loss/seq after 01350 batchs: 636.658447265625
INFO:root:Train (Epoch 90): Loss/seq after 01400 batchs: 640.0279541015625
INFO:root:Train (Epoch 90): Loss/seq after 01450 batchs: 642.0032958984375
INFO:root:Train (Epoch 90): Loss/seq after 01500 batchs: 648.5708618164062
INFO:root:Train (Epoch 90): Loss/seq after 01550 batchs: 651.7366943359375
INFO:root:Train (Epoch 90): Loss/seq after 01600 batchs: 646.5155029296875
INFO:root:Train (Epoch 90): Loss/seq after 01650 batchs: 644.253173828125
INFO:root:Train (Epoch 90): Loss/seq after 01700 batchs: 645.9047241210938
INFO:root:Train (Epoch 90): Loss/seq after 01750 batchs: 642.975830078125
INFO:root:Train (Epoch 90): Loss/seq after 01800 batchs: 640.17431640625
INFO:root:Train (Epoch 90): Loss/seq after 01850 batchs: 636.2872924804688
INFO:root:Train (Epoch 90): Loss/seq after 01900 batchs: 637.0060424804688
INFO:root:Train (Epoch 90): Loss/seq after 01950 batchs: 635.4982299804688
INFO:root:Train (Epoch 90): Loss/seq after 02000 batchs: 633.4887084960938
INFO:root:Train (Epoch 90): Loss/seq after 02050 batchs: 632.0892944335938
INFO:root:Train (Epoch 90): Loss/seq after 02100 batchs: 629.2269287109375
INFO:root:Train (Epoch 90): Loss/seq after 02150 batchs: 627.0664672851562
INFO:root:Train (Epoch 90): Loss/seq after 02200 batchs: 623.9017944335938
INFO:root:Train (Epoch 90): Loss/seq after 02250 batchs: 622.9246826171875
INFO:root:Train (Epoch 90): Loss/seq after 02300 batchs: 618.1690063476562
INFO:root:Train (Epoch 90): Loss/seq after 02350 batchs: 613.8536987304688
INFO:root:Train (Epoch 90): Loss/seq after 02400 batchs: 614.8179321289062
INFO:root:Train (Epoch 90): Loss/seq after 02450 batchs: 609.5165405273438
INFO:root:Train (Epoch 90): Loss/seq after 02500 batchs: 600.29638671875
INFO:root:Train (Epoch 90): Loss/seq after 02550 batchs: 593.2420654296875
INFO:root:Train (Epoch 90): Loss/seq after 02600 batchs: 591.5844116210938
INFO:root:Train (Epoch 90): Loss/seq after 02650 batchs: 588.6076049804688
INFO:root:Train (Epoch 90): Loss/seq after 02700 batchs: 585.8466186523438
INFO:root:Train (Epoch 90): Loss/seq after 02750 batchs: 582.4365234375
INFO:root:Train (Epoch 90): Loss/seq after 02800 batchs: 582.2943725585938
INFO:root:Train (Epoch 90): Loss/seq after 02850 batchs: 582.8679809570312
INFO:root:Train (Epoch 90): Loss/seq after 02900 batchs: 584.3658447265625
INFO:root:Train (Epoch 90): Loss/seq after 02950 batchs: 583.3818969726562
INFO:root:Train (Epoch 90): Loss/seq after 03000 batchs: 588.3997192382812
INFO:root:Train (Epoch 90): Loss/seq after 03050 batchs: 590.6351928710938
INFO:root:Train (Epoch 90): Loss/seq after 03100 batchs: 595.4622802734375
INFO:root:Train (Epoch 90): Loss/seq after 03150 batchs: 597.4226684570312
INFO:root:Train (Epoch 90): Loss/seq after 03200 batchs: 597.7982177734375
INFO:root:Train (Epoch 90): Loss/seq after 03250 batchs: 600.0323486328125
INFO:root:Train (Epoch 90): Loss/seq after 03300 batchs: 599.2879028320312
INFO:root:Train (Epoch 90): Loss/seq after 03350 batchs: 598.6729125976562
INFO:root:Train (Epoch 90): Loss/seq after 03400 batchs: 593.8222045898438
INFO:root:Train (Epoch 90): Loss/seq after 03450 batchs: 592.3162841796875
INFO:root:Train (Epoch 90): Loss/seq after 03500 batchs: 593.3890380859375
INFO:root:Train (Epoch 90): Loss/seq after 03550 batchs: 590.5462036132812
INFO:root:Train (Epoch 90): Loss/seq after 03600 batchs: 599.2718505859375
INFO:root:Train (Epoch 90): Loss/seq after 03650 batchs: 596.8446044921875
INFO:root:Train (Epoch 90): Loss/seq after 03700 batchs: 599.6067504882812
INFO:root:Train (Epoch 90): Loss/seq after 03750 batchs: 604.584228515625
INFO:root:Train (Epoch 90): Loss/seq after 03800 batchs: 601.966552734375
INFO:root:Train (Epoch 90): Loss/seq after 03850 batchs: 601.3530883789062
INFO:root:Train (Epoch 90): Loss/seq after 03900 batchs: 605.0474243164062
INFO:root:Train (Epoch 90): Loss/seq after 03950 batchs: 607.832275390625
INFO:root:Train (Epoch 90): Loss/seq after 04000 batchs: 603.8866577148438
INFO:root:Train (Epoch 90): Loss/seq after 04050 batchs: 600.0358276367188
INFO:root:Train (Epoch 90): Loss/seq after 04100 batchs: 598.259033203125
INFO:root:Train (Epoch 90): Loss/seq after 04150 batchs: 598.1070556640625
INFO:root:Train (Epoch 90): Loss/seq after 04200 batchs: 596.6661376953125
INFO:root:Train (Epoch 90): Loss/seq after 04250 batchs: 595.0907592773438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 90): Loss/seq after 00000 batches: 540.5760498046875
INFO:root:# Valid (Epoch 90): Loss/seq after 00050 batches: 805.3382568359375
INFO:root:# Valid (Epoch 90): Loss/seq after 00100 batches: 861.814208984375
INFO:root:# Valid (Epoch 90): Loss/seq after 00150 batches: 641.1441040039062
INFO:root:# Valid (Epoch 90): Loss/seq after 00200 batches: 590.9088134765625
INFO:root:Artifacts: Make stick videos for epoch 90
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_90_on_20220422_065701.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_90_index_364_on_20220422_065701.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 91): Loss/seq after 00000 batchs: 1179.06787109375
INFO:root:Train (Epoch 91): Loss/seq after 00050 batchs: 886.2021484375
INFO:root:Train (Epoch 91): Loss/seq after 00100 batchs: 916.74609375
INFO:root:Train (Epoch 91): Loss/seq after 00150 batchs: 851.8682250976562
INFO:root:Train (Epoch 91): Loss/seq after 00200 batchs: 918.904541015625
INFO:root:Train (Epoch 91): Loss/seq after 00250 batchs: 1037.263427734375
INFO:root:Train (Epoch 91): Loss/seq after 00300 batchs: 1017.89013671875
INFO:root:Train (Epoch 91): Loss/seq after 00350 batchs: 947.871337890625
INFO:root:Train (Epoch 91): Loss/seq after 00400 batchs: 942.688232421875
INFO:root:Train (Epoch 91): Loss/seq after 00450 batchs: 914.550048828125
INFO:root:Train (Epoch 91): Loss/seq after 00500 batchs: 886.0134887695312
INFO:root:Train (Epoch 91): Loss/seq after 00550 batchs: 856.3416748046875
INFO:root:Train (Epoch 91): Loss/seq after 00600 batchs: 824.5182495117188
INFO:root:Train (Epoch 91): Loss/seq after 00650 batchs: 794.4186401367188
INFO:root:Train (Epoch 91): Loss/seq after 00700 batchs: 762.7758178710938
INFO:root:Train (Epoch 91): Loss/seq after 00750 batchs: 765.5549926757812
INFO:root:Train (Epoch 91): Loss/seq after 00800 batchs: 765.2449340820312
INFO:root:Train (Epoch 91): Loss/seq after 00850 batchs: 741.5364379882812
INFO:root:Train (Epoch 91): Loss/seq after 00900 batchs: 723.1612548828125
INFO:root:Train (Epoch 91): Loss/seq after 00950 batchs: 717.6654663085938
INFO:root:Train (Epoch 91): Loss/seq after 01000 batchs: 704.2390747070312
INFO:root:Train (Epoch 91): Loss/seq after 01050 batchs: 689.4069213867188
INFO:root:Train (Epoch 91): Loss/seq after 01100 batchs: 677.7650756835938
INFO:root:Train (Epoch 91): Loss/seq after 01150 batchs: 660.0117797851562
INFO:root:Train (Epoch 91): Loss/seq after 01200 batchs: 664.1025390625
INFO:root:Train (Epoch 91): Loss/seq after 01250 batchs: 660.3302001953125
INFO:root:Train (Epoch 91): Loss/seq after 01300 batchs: 645.6348266601562
INFO:root:Train (Epoch 91): Loss/seq after 01350 batchs: 634.9761962890625
INFO:root:Train (Epoch 91): Loss/seq after 01400 batchs: 638.2376098632812
INFO:root:Train (Epoch 91): Loss/seq after 01450 batchs: 639.7783813476562
INFO:root:Train (Epoch 91): Loss/seq after 01500 batchs: 646.45166015625
INFO:root:Train (Epoch 91): Loss/seq after 01550 batchs: 649.3619995117188
INFO:root:Train (Epoch 91): Loss/seq after 01600 batchs: 643.9097900390625
INFO:root:Train (Epoch 91): Loss/seq after 01650 batchs: 641.2554931640625
INFO:root:Train (Epoch 91): Loss/seq after 01700 batchs: 642.8413696289062
INFO:root:Train (Epoch 91): Loss/seq after 01750 batchs: 639.7802124023438
INFO:root:Train (Epoch 91): Loss/seq after 01800 batchs: 637.10693359375
INFO:root:Train (Epoch 91): Loss/seq after 01850 batchs: 633.3464965820312
INFO:root:Train (Epoch 91): Loss/seq after 01900 batchs: 633.9943237304688
INFO:root:Train (Epoch 91): Loss/seq after 01950 batchs: 631.8339233398438
INFO:root:Train (Epoch 91): Loss/seq after 02000 batchs: 630.4437866210938
INFO:root:Train (Epoch 91): Loss/seq after 02050 batchs: 629.1107177734375
INFO:root:Train (Epoch 91): Loss/seq after 02100 batchs: 626.34423828125
INFO:root:Train (Epoch 91): Loss/seq after 02150 batchs: 624.3402709960938
INFO:root:Train (Epoch 91): Loss/seq after 02200 batchs: 621.1509399414062
INFO:root:Train (Epoch 91): Loss/seq after 02250 batchs: 620.7390747070312
INFO:root:Train (Epoch 91): Loss/seq after 02300 batchs: 616.2246704101562
INFO:root:Train (Epoch 91): Loss/seq after 02350 batchs: 611.6503295898438
INFO:root:Train (Epoch 91): Loss/seq after 02400 batchs: 612.4312744140625
INFO:root:Train (Epoch 91): Loss/seq after 02450 batchs: 607.1354370117188
INFO:root:Train (Epoch 91): Loss/seq after 02500 batchs: 597.9142456054688
INFO:root:Train (Epoch 91): Loss/seq after 02550 batchs: 590.9654541015625
INFO:root:Train (Epoch 91): Loss/seq after 02600 batchs: 589.7803955078125
INFO:root:Train (Epoch 91): Loss/seq after 02650 batchs: 586.8587036132812
INFO:root:Train (Epoch 91): Loss/seq after 02700 batchs: 584.105224609375
INFO:root:Train (Epoch 91): Loss/seq after 02750 batchs: 580.279296875
INFO:root:Train (Epoch 91): Loss/seq after 02800 batchs: 580.3016967773438
INFO:root:Train (Epoch 91): Loss/seq after 02850 batchs: 580.897705078125
INFO:root:Train (Epoch 91): Loss/seq after 02900 batchs: 582.93701171875
INFO:root:Train (Epoch 91): Loss/seq after 02950 batchs: 582.0016479492188
INFO:root:Train (Epoch 91): Loss/seq after 03000 batchs: 587.109375
INFO:root:Train (Epoch 91): Loss/seq after 03050 batchs: 590.5491943359375
INFO:root:Train (Epoch 91): Loss/seq after 03100 batchs: 595.486572265625
INFO:root:Train (Epoch 91): Loss/seq after 03150 batchs: 597.559814453125
INFO:root:Train (Epoch 91): Loss/seq after 03200 batchs: 598.6845092773438
INFO:root:Train (Epoch 91): Loss/seq after 03250 batchs: 600.7059326171875
INFO:root:Train (Epoch 91): Loss/seq after 03300 batchs: 600.2703247070312
INFO:root:Train (Epoch 91): Loss/seq after 03350 batchs: 599.5964965820312
INFO:root:Train (Epoch 91): Loss/seq after 03400 batchs: 594.697265625
INFO:root:Train (Epoch 91): Loss/seq after 03450 batchs: 593.2894897460938
INFO:root:Train (Epoch 91): Loss/seq after 03500 batchs: 594.3366088867188
INFO:root:Train (Epoch 91): Loss/seq after 03550 batchs: 591.5792236328125
INFO:root:Train (Epoch 91): Loss/seq after 03600 batchs: 600.727783203125
INFO:root:Train (Epoch 91): Loss/seq after 03650 batchs: 598.7381591796875
INFO:root:Train (Epoch 91): Loss/seq after 03700 batchs: 601.4447631835938
INFO:root:Train (Epoch 91): Loss/seq after 03750 batchs: 606.2437133789062
INFO:root:Train (Epoch 91): Loss/seq after 03800 batchs: 603.6237182617188
INFO:root:Train (Epoch 91): Loss/seq after 03850 batchs: 602.6476440429688
INFO:root:Train (Epoch 91): Loss/seq after 03900 batchs: 606.1691284179688
INFO:root:Train (Epoch 91): Loss/seq after 03950 batchs: 608.8234252929688
INFO:root:Train (Epoch 91): Loss/seq after 04000 batchs: 604.8731689453125
INFO:root:Train (Epoch 91): Loss/seq after 04050 batchs: 600.9869995117188
INFO:root:Train (Epoch 91): Loss/seq after 04100 batchs: 599.2720336914062
INFO:root:Train (Epoch 91): Loss/seq after 04150 batchs: 599.0357666015625
INFO:root:Train (Epoch 91): Loss/seq after 04200 batchs: 597.5946044921875
INFO:root:Train (Epoch 91): Loss/seq after 04250 batchs: 595.8955078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 91): Loss/seq after 00000 batches: 583.240966796875
INFO:root:# Valid (Epoch 91): Loss/seq after 00050 batches: 840.0504150390625
INFO:root:# Valid (Epoch 91): Loss/seq after 00100 batches: 890.274658203125
INFO:root:# Valid (Epoch 91): Loss/seq after 00150 batches: 665.3795776367188
INFO:root:# Valid (Epoch 91): Loss/seq after 00200 batches: 612.963623046875
INFO:root:Artifacts: Make stick videos for epoch 91
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_91_on_20220422_070154.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_91_index_35_on_20220422_070154.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 92): Loss/seq after 00000 batchs: 1164.3472900390625
INFO:root:Train (Epoch 92): Loss/seq after 00050 batchs: 864.785400390625
INFO:root:Train (Epoch 92): Loss/seq after 00100 batchs: 870.4966430664062
INFO:root:Train (Epoch 92): Loss/seq after 00150 batchs: 807.5487060546875
INFO:root:Train (Epoch 92): Loss/seq after 00200 batchs: 874.3057861328125
INFO:root:Train (Epoch 92): Loss/seq after 00250 batchs: 996.9974975585938
INFO:root:Train (Epoch 92): Loss/seq after 00300 batchs: 982.5369262695312
INFO:root:Train (Epoch 92): Loss/seq after 00350 batchs: 915.6221313476562
INFO:root:Train (Epoch 92): Loss/seq after 00400 batchs: 907.0842895507812
INFO:root:Train (Epoch 92): Loss/seq after 00450 batchs: 882.8514404296875
INFO:root:Train (Epoch 92): Loss/seq after 00500 batchs: 857.2548217773438
INFO:root:Train (Epoch 92): Loss/seq after 00550 batchs: 830.4735107421875
INFO:root:Train (Epoch 92): Loss/seq after 00600 batchs: 800.322265625
INFO:root:Train (Epoch 92): Loss/seq after 00650 batchs: 772.6821899414062
INFO:root:Train (Epoch 92): Loss/seq after 00700 batchs: 740.6243286132812
INFO:root:Train (Epoch 92): Loss/seq after 00750 batchs: 742.2274169921875
INFO:root:Train (Epoch 92): Loss/seq after 00800 batchs: 747.3255004882812
INFO:root:Train (Epoch 92): Loss/seq after 00850 batchs: 724.9615478515625
INFO:root:Train (Epoch 92): Loss/seq after 00900 batchs: 708.7022094726562
INFO:root:Train (Epoch 92): Loss/seq after 00950 batchs: 703.3936157226562
INFO:root:Train (Epoch 92): Loss/seq after 01000 batchs: 692.2108764648438
INFO:root:Train (Epoch 92): Loss/seq after 01050 batchs: 677.4376831054688
INFO:root:Train (Epoch 92): Loss/seq after 01100 batchs: 665.7896728515625
INFO:root:Train (Epoch 92): Loss/seq after 01150 batchs: 649.15380859375
INFO:root:Train (Epoch 92): Loss/seq after 01200 batchs: 654.05224609375
INFO:root:Train (Epoch 92): Loss/seq after 01250 batchs: 650.91943359375
INFO:root:Train (Epoch 92): Loss/seq after 01300 batchs: 637.1892700195312
INFO:root:Train (Epoch 92): Loss/seq after 01350 batchs: 626.2760009765625
INFO:root:Train (Epoch 92): Loss/seq after 01400 batchs: 630.0274658203125
INFO:root:Train (Epoch 92): Loss/seq after 01450 batchs: 631.8760986328125
INFO:root:Train (Epoch 92): Loss/seq after 01500 batchs: 638.4710083007812
INFO:root:Train (Epoch 92): Loss/seq after 01550 batchs: 641.4107055664062
INFO:root:Train (Epoch 92): Loss/seq after 01600 batchs: 635.9573364257812
INFO:root:Train (Epoch 92): Loss/seq after 01650 batchs: 633.6815795898438
INFO:root:Train (Epoch 92): Loss/seq after 01700 batchs: 635.3392944335938
INFO:root:Train (Epoch 92): Loss/seq after 01750 batchs: 632.6753540039062
INFO:root:Train (Epoch 92): Loss/seq after 01800 batchs: 630.1380004882812
INFO:root:Train (Epoch 92): Loss/seq after 01850 batchs: 626.5759887695312
INFO:root:Train (Epoch 92): Loss/seq after 01900 batchs: 627.3179321289062
INFO:root:Train (Epoch 92): Loss/seq after 01950 batchs: 625.31298828125
INFO:root:Train (Epoch 92): Loss/seq after 02000 batchs: 623.59619140625
INFO:root:Train (Epoch 92): Loss/seq after 02050 batchs: 622.12255859375
INFO:root:Train (Epoch 92): Loss/seq after 02100 batchs: 619.3621826171875
INFO:root:Train (Epoch 92): Loss/seq after 02150 batchs: 617.4525756835938
INFO:root:Train (Epoch 92): Loss/seq after 02200 batchs: 614.423583984375
INFO:root:Train (Epoch 92): Loss/seq after 02250 batchs: 613.7598876953125
INFO:root:Train (Epoch 92): Loss/seq after 02300 batchs: 609.9485473632812
INFO:root:Train (Epoch 92): Loss/seq after 02350 batchs: 605.3510131835938
INFO:root:Train (Epoch 92): Loss/seq after 02400 batchs: 606.2937622070312
INFO:root:Train (Epoch 92): Loss/seq after 02450 batchs: 601.0492553710938
INFO:root:Train (Epoch 92): Loss/seq after 02500 batchs: 591.9623413085938
INFO:root:Train (Epoch 92): Loss/seq after 02550 batchs: 585.0609741210938
INFO:root:Train (Epoch 92): Loss/seq after 02600 batchs: 583.6693725585938
INFO:root:Train (Epoch 92): Loss/seq after 02650 batchs: 580.9786987304688
INFO:root:Train (Epoch 92): Loss/seq after 02700 batchs: 578.2260131835938
INFO:root:Train (Epoch 92): Loss/seq after 02750 batchs: 575.029052734375
INFO:root:Train (Epoch 92): Loss/seq after 02800 batchs: 575.5765380859375
INFO:root:Train (Epoch 92): Loss/seq after 02850 batchs: 576.2369995117188
INFO:root:Train (Epoch 92): Loss/seq after 02900 batchs: 577.9246826171875
INFO:root:Train (Epoch 92): Loss/seq after 02950 batchs: 576.92919921875
INFO:root:Train (Epoch 92): Loss/seq after 03000 batchs: 582.0970458984375
INFO:root:Train (Epoch 92): Loss/seq after 03050 batchs: 584.5802001953125
INFO:root:Train (Epoch 92): Loss/seq after 03100 batchs: 588.89013671875
INFO:root:Train (Epoch 92): Loss/seq after 03150 batchs: 591.1109008789062
INFO:root:Train (Epoch 92): Loss/seq after 03200 batchs: 592.0526733398438
INFO:root:Train (Epoch 92): Loss/seq after 03250 batchs: 594.864013671875
INFO:root:Train (Epoch 92): Loss/seq after 03300 batchs: 594.0520629882812
INFO:root:Train (Epoch 92): Loss/seq after 03350 batchs: 593.912841796875
INFO:root:Train (Epoch 92): Loss/seq after 03400 batchs: 589.2254028320312
INFO:root:Train (Epoch 92): Loss/seq after 03450 batchs: 588.1131591796875
INFO:root:Train (Epoch 92): Loss/seq after 03500 batchs: 589.3831787109375
INFO:root:Train (Epoch 92): Loss/seq after 03550 batchs: 586.7251586914062
INFO:root:Train (Epoch 92): Loss/seq after 03600 batchs: 595.6036987304688
INFO:root:Train (Epoch 92): Loss/seq after 03650 batchs: 592.9754028320312
INFO:root:Train (Epoch 92): Loss/seq after 03700 batchs: 595.522705078125
INFO:root:Train (Epoch 92): Loss/seq after 03750 batchs: 600.402099609375
INFO:root:Train (Epoch 92): Loss/seq after 03800 batchs: 597.8159790039062
INFO:root:Train (Epoch 92): Loss/seq after 03850 batchs: 596.9984130859375
INFO:root:Train (Epoch 92): Loss/seq after 03900 batchs: 600.3633422851562
INFO:root:Train (Epoch 92): Loss/seq after 03950 batchs: 603.0769653320312
INFO:root:Train (Epoch 92): Loss/seq after 04000 batchs: 599.24365234375
INFO:root:Train (Epoch 92): Loss/seq after 04050 batchs: 595.366455078125
INFO:root:Train (Epoch 92): Loss/seq after 04100 batchs: 593.64697265625
INFO:root:Train (Epoch 92): Loss/seq after 04150 batchs: 593.5330200195312
INFO:root:Train (Epoch 92): Loss/seq after 04200 batchs: 592.0836791992188
INFO:root:Train (Epoch 92): Loss/seq after 04250 batchs: 590.36572265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 92): Loss/seq after 00000 batches: 505.68707275390625
INFO:root:# Valid (Epoch 92): Loss/seq after 00050 batches: 740.5009155273438
INFO:root:# Valid (Epoch 92): Loss/seq after 00100 batches: 817.5901489257812
INFO:root:# Valid (Epoch 92): Loss/seq after 00150 batches: 611.5288696289062
INFO:root:# Valid (Epoch 92): Loss/seq after 00200 batches: 569.464111328125
INFO:root:Artifacts: Make stick videos for epoch 92
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_92_on_20220422_070653.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_92_index_1089_on_20220422_070653.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 93): Loss/seq after 00000 batchs: 1241.6435546875
INFO:root:Train (Epoch 93): Loss/seq after 00050 batchs: 865.61865234375
INFO:root:Train (Epoch 93): Loss/seq after 00100 batchs: 872.704345703125
INFO:root:Train (Epoch 93): Loss/seq after 00150 batchs: 803.624755859375
INFO:root:Train (Epoch 93): Loss/seq after 00200 batchs: 867.4804077148438
INFO:root:Train (Epoch 93): Loss/seq after 00250 batchs: 993.7160034179688
INFO:root:Train (Epoch 93): Loss/seq after 00300 batchs: 980.97900390625
INFO:root:Train (Epoch 93): Loss/seq after 00350 batchs: 912.5442504882812
INFO:root:Train (Epoch 93): Loss/seq after 00400 batchs: 902.71435546875
INFO:root:Train (Epoch 93): Loss/seq after 00450 batchs: 878.4208374023438
INFO:root:Train (Epoch 93): Loss/seq after 00500 batchs: 850.7017822265625
INFO:root:Train (Epoch 93): Loss/seq after 00550 batchs: 822.1489868164062
INFO:root:Train (Epoch 93): Loss/seq after 00600 batchs: 792.6025390625
INFO:root:Train (Epoch 93): Loss/seq after 00650 batchs: 764.2962036132812
INFO:root:Train (Epoch 93): Loss/seq after 00700 batchs: 733.1729125976562
INFO:root:Train (Epoch 93): Loss/seq after 00750 batchs: 736.9721069335938
INFO:root:Train (Epoch 93): Loss/seq after 00800 batchs: 738.8280029296875
INFO:root:Train (Epoch 93): Loss/seq after 00850 batchs: 716.2178955078125
INFO:root:Train (Epoch 93): Loss/seq after 00900 batchs: 699.4946899414062
INFO:root:Train (Epoch 93): Loss/seq after 00950 batchs: 696.4268188476562
INFO:root:Train (Epoch 93): Loss/seq after 01000 batchs: 684.9800415039062
INFO:root:Train (Epoch 93): Loss/seq after 01050 batchs: 672.8223266601562
INFO:root:Train (Epoch 93): Loss/seq after 01100 batchs: 663.1841430664062
INFO:root:Train (Epoch 93): Loss/seq after 01150 batchs: 646.0437622070312
INFO:root:Train (Epoch 93): Loss/seq after 01200 batchs: 650.345458984375
INFO:root:Train (Epoch 93): Loss/seq after 01250 batchs: 647.1460571289062
INFO:root:Train (Epoch 93): Loss/seq after 01300 batchs: 633.2886962890625
INFO:root:Train (Epoch 93): Loss/seq after 01350 batchs: 622.67578125
INFO:root:Train (Epoch 93): Loss/seq after 01400 batchs: 625.6873168945312
INFO:root:Train (Epoch 93): Loss/seq after 01450 batchs: 627.2295532226562
INFO:root:Train (Epoch 93): Loss/seq after 01500 batchs: 634.0709838867188
INFO:root:Train (Epoch 93): Loss/seq after 01550 batchs: 637.378173828125
INFO:root:Train (Epoch 93): Loss/seq after 01600 batchs: 631.888671875
INFO:root:Train (Epoch 93): Loss/seq after 01650 batchs: 629.5787353515625
INFO:root:Train (Epoch 93): Loss/seq after 01700 batchs: 631.5669555664062
INFO:root:Train (Epoch 93): Loss/seq after 01750 batchs: 628.81982421875
INFO:root:Train (Epoch 93): Loss/seq after 01800 batchs: 626.1649169921875
INFO:root:Train (Epoch 93): Loss/seq after 01850 batchs: 622.61572265625
INFO:root:Train (Epoch 93): Loss/seq after 01900 batchs: 623.6403198242188
INFO:root:Train (Epoch 93): Loss/seq after 01950 batchs: 621.6586303710938
INFO:root:Train (Epoch 93): Loss/seq after 02000 batchs: 619.8189086914062
INFO:root:Train (Epoch 93): Loss/seq after 02050 batchs: 618.7427978515625
INFO:root:Train (Epoch 93): Loss/seq after 02100 batchs: 616.0924072265625
INFO:root:Train (Epoch 93): Loss/seq after 02150 batchs: 614.2052612304688
INFO:root:Train (Epoch 93): Loss/seq after 02200 batchs: 611.1337890625
INFO:root:Train (Epoch 93): Loss/seq after 02250 batchs: 609.818115234375
INFO:root:Train (Epoch 93): Loss/seq after 02300 batchs: 605.2125854492188
INFO:root:Train (Epoch 93): Loss/seq after 02350 batchs: 600.9158935546875
INFO:root:Train (Epoch 93): Loss/seq after 02400 batchs: 601.8359985351562
INFO:root:Train (Epoch 93): Loss/seq after 02450 batchs: 596.7241821289062
INFO:root:Train (Epoch 93): Loss/seq after 02500 batchs: 587.707275390625
INFO:root:Train (Epoch 93): Loss/seq after 02550 batchs: 580.8438110351562
INFO:root:Train (Epoch 93): Loss/seq after 02600 batchs: 579.2774047851562
INFO:root:Train (Epoch 93): Loss/seq after 02650 batchs: 576.27880859375
INFO:root:Train (Epoch 93): Loss/seq after 02700 batchs: 573.6058349609375
INFO:root:Train (Epoch 93): Loss/seq after 02750 batchs: 569.7847900390625
INFO:root:Train (Epoch 93): Loss/seq after 02800 batchs: 569.8182373046875
INFO:root:Train (Epoch 93): Loss/seq after 02850 batchs: 570.5588989257812
INFO:root:Train (Epoch 93): Loss/seq after 02900 batchs: 572.098388671875
INFO:root:Train (Epoch 93): Loss/seq after 02950 batchs: 571.2628784179688
INFO:root:Train (Epoch 93): Loss/seq after 03000 batchs: 576.48779296875
INFO:root:Train (Epoch 93): Loss/seq after 03050 batchs: 579.11865234375
INFO:root:Train (Epoch 93): Loss/seq after 03100 batchs: 583.1322631835938
INFO:root:Train (Epoch 93): Loss/seq after 03150 batchs: 584.5494995117188
INFO:root:Train (Epoch 93): Loss/seq after 03200 batchs: 585.0596923828125
INFO:root:Train (Epoch 93): Loss/seq after 03250 batchs: 587.900390625
INFO:root:Train (Epoch 93): Loss/seq after 03300 batchs: 587.253173828125
INFO:root:Train (Epoch 93): Loss/seq after 03350 batchs: 587.2007446289062
INFO:root:Train (Epoch 93): Loss/seq after 03400 batchs: 582.5933837890625
INFO:root:Train (Epoch 93): Loss/seq after 03450 batchs: 581.1280517578125
INFO:root:Train (Epoch 93): Loss/seq after 03500 batchs: 582.6173095703125
INFO:root:Train (Epoch 93): Loss/seq after 03550 batchs: 580.3776245117188
INFO:root:Train (Epoch 93): Loss/seq after 03600 batchs: 590.0435180664062
INFO:root:Train (Epoch 93): Loss/seq after 03650 batchs: 588.2536010742188
INFO:root:Train (Epoch 93): Loss/seq after 03700 batchs: 591.898681640625
INFO:root:Train (Epoch 93): Loss/seq after 03750 batchs: 596.9285888671875
INFO:root:Train (Epoch 93): Loss/seq after 03800 batchs: 594.4082641601562
INFO:root:Train (Epoch 93): Loss/seq after 03850 batchs: 593.5663452148438
INFO:root:Train (Epoch 93): Loss/seq after 03900 batchs: 597.8614501953125
INFO:root:Train (Epoch 93): Loss/seq after 03950 batchs: 600.8506469726562
INFO:root:Train (Epoch 93): Loss/seq after 04000 batchs: 597.4011840820312
INFO:root:Train (Epoch 93): Loss/seq after 04050 batchs: 593.569091796875
INFO:root:Train (Epoch 93): Loss/seq after 04100 batchs: 591.9898071289062
INFO:root:Train (Epoch 93): Loss/seq after 04150 batchs: 591.9336547851562
INFO:root:Train (Epoch 93): Loss/seq after 04200 batchs: 590.7322998046875
INFO:root:Train (Epoch 93): Loss/seq after 04250 batchs: 589.0671997070312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 93): Loss/seq after 00000 batches: 559.1297607421875
INFO:root:# Valid (Epoch 93): Loss/seq after 00050 batches: 722.5278930664062
INFO:root:# Valid (Epoch 93): Loss/seq after 00100 batches: 766.067138671875
INFO:root:# Valid (Epoch 93): Loss/seq after 00150 batches: 578.43017578125
INFO:root:# Valid (Epoch 93): Loss/seq after 00200 batches: 543.3093872070312
INFO:root:Artifacts: Make stick videos for epoch 93
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_93_on_20220422_071138.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_93_index_703_on_20220422_071138.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 94): Loss/seq after 00000 batchs: 1390.683837890625
INFO:root:Train (Epoch 94): Loss/seq after 00050 batchs: 859.92626953125
INFO:root:Train (Epoch 94): Loss/seq after 00100 batchs: 880.2335205078125
INFO:root:Train (Epoch 94): Loss/seq after 00150 batchs: 817.1064453125
INFO:root:Train (Epoch 94): Loss/seq after 00200 batchs: 878.2256469726562
INFO:root:Train (Epoch 94): Loss/seq after 00250 batchs: 999.0557861328125
INFO:root:Train (Epoch 94): Loss/seq after 00300 batchs: 983.7672119140625
INFO:root:Train (Epoch 94): Loss/seq after 00350 batchs: 914.7389526367188
INFO:root:Train (Epoch 94): Loss/seq after 00400 batchs: 906.2974243164062
INFO:root:Train (Epoch 94): Loss/seq after 00450 batchs: 881.868408203125
INFO:root:Train (Epoch 94): Loss/seq after 00500 batchs: 852.1803588867188
INFO:root:Train (Epoch 94): Loss/seq after 00550 batchs: 823.329345703125
INFO:root:Train (Epoch 94): Loss/seq after 00600 batchs: 792.64794921875
INFO:root:Train (Epoch 94): Loss/seq after 00650 batchs: 763.0255126953125
INFO:root:Train (Epoch 94): Loss/seq after 00700 batchs: 730.9102172851562
INFO:root:Train (Epoch 94): Loss/seq after 00750 batchs: 733.7706298828125
INFO:root:Train (Epoch 94): Loss/seq after 00800 batchs: 734.2598266601562
INFO:root:Train (Epoch 94): Loss/seq after 00850 batchs: 711.256103515625
INFO:root:Train (Epoch 94): Loss/seq after 00900 batchs: 694.533447265625
INFO:root:Train (Epoch 94): Loss/seq after 00950 batchs: 688.6401977539062
INFO:root:Train (Epoch 94): Loss/seq after 01000 batchs: 676.8239135742188
INFO:root:Train (Epoch 94): Loss/seq after 01050 batchs: 662.9384155273438
INFO:root:Train (Epoch 94): Loss/seq after 01100 batchs: 652.5028686523438
INFO:root:Train (Epoch 94): Loss/seq after 01150 batchs: 635.52685546875
INFO:root:Train (Epoch 94): Loss/seq after 01200 batchs: 640.7127075195312
INFO:root:Train (Epoch 94): Loss/seq after 01250 batchs: 637.448486328125
INFO:root:Train (Epoch 94): Loss/seq after 01300 batchs: 624.0012817382812
INFO:root:Train (Epoch 94): Loss/seq after 01350 batchs: 613.0087280273438
INFO:root:Train (Epoch 94): Loss/seq after 01400 batchs: 616.6675415039062
INFO:root:Train (Epoch 94): Loss/seq after 01450 batchs: 618.5283203125
INFO:root:Train (Epoch 94): Loss/seq after 01500 batchs: 625.611572265625
INFO:root:Train (Epoch 94): Loss/seq after 01550 batchs: 628.8158569335938
INFO:root:Train (Epoch 94): Loss/seq after 01600 batchs: 623.8119506835938
INFO:root:Train (Epoch 94): Loss/seq after 01650 batchs: 621.8726196289062
INFO:root:Train (Epoch 94): Loss/seq after 01700 batchs: 623.8570556640625
INFO:root:Train (Epoch 94): Loss/seq after 01750 batchs: 621.1930541992188
INFO:root:Train (Epoch 94): Loss/seq after 01800 batchs: 618.736328125
INFO:root:Train (Epoch 94): Loss/seq after 01850 batchs: 615.2007446289062
INFO:root:Train (Epoch 94): Loss/seq after 01900 batchs: 616.1016235351562
INFO:root:Train (Epoch 94): Loss/seq after 01950 batchs: 614.5418701171875
INFO:root:Train (Epoch 94): Loss/seq after 02000 batchs: 613.3071899414062
INFO:root:Train (Epoch 94): Loss/seq after 02050 batchs: 612.2090454101562
INFO:root:Train (Epoch 94): Loss/seq after 02100 batchs: 609.7546997070312
INFO:root:Train (Epoch 94): Loss/seq after 02150 batchs: 608.035888671875
INFO:root:Train (Epoch 94): Loss/seq after 02200 batchs: 605.1979370117188
INFO:root:Train (Epoch 94): Loss/seq after 02250 batchs: 604.2969970703125
INFO:root:Train (Epoch 94): Loss/seq after 02300 batchs: 599.609619140625
INFO:root:Train (Epoch 94): Loss/seq after 02350 batchs: 595.4378662109375
INFO:root:Train (Epoch 94): Loss/seq after 02400 batchs: 596.6380004882812
INFO:root:Train (Epoch 94): Loss/seq after 02450 batchs: 591.5497436523438
INFO:root:Train (Epoch 94): Loss/seq after 02500 batchs: 582.6281127929688
INFO:root:Train (Epoch 94): Loss/seq after 02550 batchs: 575.7313842773438
INFO:root:Train (Epoch 94): Loss/seq after 02600 batchs: 573.8626098632812
INFO:root:Train (Epoch 94): Loss/seq after 02650 batchs: 571.1363525390625
INFO:root:Train (Epoch 94): Loss/seq after 02700 batchs: 568.4749755859375
INFO:root:Train (Epoch 94): Loss/seq after 02750 batchs: 564.3341674804688
INFO:root:Train (Epoch 94): Loss/seq after 02800 batchs: 564.1189575195312
INFO:root:Train (Epoch 94): Loss/seq after 02850 batchs: 564.8058471679688
INFO:root:Train (Epoch 94): Loss/seq after 02900 batchs: 566.38427734375
INFO:root:Train (Epoch 94): Loss/seq after 02950 batchs: 565.682861328125
INFO:root:Train (Epoch 94): Loss/seq after 03000 batchs: 570.9635620117188
INFO:root:Train (Epoch 94): Loss/seq after 03050 batchs: 572.9149169921875
INFO:root:Train (Epoch 94): Loss/seq after 03100 batchs: 576.7975463867188
INFO:root:Train (Epoch 94): Loss/seq after 03150 batchs: 577.802978515625
INFO:root:Train (Epoch 94): Loss/seq after 03200 batchs: 578.585693359375
INFO:root:Train (Epoch 94): Loss/seq after 03250 batchs: 581.4730224609375
INFO:root:Train (Epoch 94): Loss/seq after 03300 batchs: 580.439453125
INFO:root:Train (Epoch 94): Loss/seq after 03350 batchs: 579.934814453125
INFO:root:Train (Epoch 94): Loss/seq after 03400 batchs: 575.3763427734375
INFO:root:Train (Epoch 94): Loss/seq after 03450 batchs: 574.0982055664062
INFO:root:Train (Epoch 94): Loss/seq after 03500 batchs: 575.5728149414062
INFO:root:Train (Epoch 94): Loss/seq after 03550 batchs: 573.08740234375
INFO:root:Train (Epoch 94): Loss/seq after 03600 batchs: 581.754150390625
INFO:root:Train (Epoch 94): Loss/seq after 03650 batchs: 579.466552734375
INFO:root:Train (Epoch 94): Loss/seq after 03700 batchs: 582.1767578125
INFO:root:Train (Epoch 94): Loss/seq after 03750 batchs: 587.324951171875
INFO:root:Train (Epoch 94): Loss/seq after 03800 batchs: 584.8391723632812
INFO:root:Train (Epoch 94): Loss/seq after 03850 batchs: 584.3115234375
INFO:root:Train (Epoch 94): Loss/seq after 03900 batchs: 587.98291015625
INFO:root:Train (Epoch 94): Loss/seq after 03950 batchs: 590.8303833007812
INFO:root:Train (Epoch 94): Loss/seq after 04000 batchs: 587.107421875
INFO:root:Train (Epoch 94): Loss/seq after 04050 batchs: 583.360107421875
INFO:root:Train (Epoch 94): Loss/seq after 04100 batchs: 581.7815551757812
INFO:root:Train (Epoch 94): Loss/seq after 04150 batchs: 581.7604370117188
INFO:root:Train (Epoch 94): Loss/seq after 04200 batchs: 580.42578125
INFO:root:Train (Epoch 94): Loss/seq after 04250 batchs: 578.7376098632812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 94): Loss/seq after 00000 batches: 504.674560546875
INFO:root:# Valid (Epoch 94): Loss/seq after 00050 batches: 765.3806762695312
INFO:root:# Valid (Epoch 94): Loss/seq after 00100 batches: 801.1354370117188
INFO:root:# Valid (Epoch 94): Loss/seq after 00150 batches: 602.3143920898438
INFO:root:# Valid (Epoch 94): Loss/seq after 00200 batches: 562.35888671875
INFO:root:Artifacts: Make stick videos for epoch 94
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_94_on_20220422_071622.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_94_index_1582_on_20220422_071622.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 95): Loss/seq after 00000 batchs: 1030.8291015625
INFO:root:Train (Epoch 95): Loss/seq after 00050 batchs: 841.5963134765625
INFO:root:Train (Epoch 95): Loss/seq after 00100 batchs: 864.3814697265625
INFO:root:Train (Epoch 95): Loss/seq after 00150 batchs: 805.4156494140625
INFO:root:Train (Epoch 95): Loss/seq after 00200 batchs: 879.7169189453125
INFO:root:Train (Epoch 95): Loss/seq after 00250 batchs: 1000.1318969726562
INFO:root:Train (Epoch 95): Loss/seq after 00300 batchs: 984.7294311523438
INFO:root:Train (Epoch 95): Loss/seq after 00350 batchs: 916.0186767578125
INFO:root:Train (Epoch 95): Loss/seq after 00400 batchs: 907.2533569335938
INFO:root:Train (Epoch 95): Loss/seq after 00450 batchs: 882.5507202148438
INFO:root:Train (Epoch 95): Loss/seq after 00500 batchs: 856.2962036132812
INFO:root:Train (Epoch 95): Loss/seq after 00550 batchs: 829.1077270507812
INFO:root:Train (Epoch 95): Loss/seq after 00600 batchs: 798.9940185546875
INFO:root:Train (Epoch 95): Loss/seq after 00650 batchs: 769.8668823242188
INFO:root:Train (Epoch 95): Loss/seq after 00700 batchs: 737.9229736328125
INFO:root:Train (Epoch 95): Loss/seq after 00750 batchs: 738.8645629882812
INFO:root:Train (Epoch 95): Loss/seq after 00800 batchs: 740.0286865234375
INFO:root:Train (Epoch 95): Loss/seq after 00850 batchs: 716.6713256835938
INFO:root:Train (Epoch 95): Loss/seq after 00900 batchs: 700.4600830078125
INFO:root:Train (Epoch 95): Loss/seq after 00950 batchs: 695.2017211914062
INFO:root:Train (Epoch 95): Loss/seq after 01000 batchs: 682.9521484375
INFO:root:Train (Epoch 95): Loss/seq after 01050 batchs: 668.5543212890625
INFO:root:Train (Epoch 95): Loss/seq after 01100 batchs: 658.468994140625
INFO:root:Train (Epoch 95): Loss/seq after 01150 batchs: 640.9777221679688
INFO:root:Train (Epoch 95): Loss/seq after 01200 batchs: 645.0031127929688
INFO:root:Train (Epoch 95): Loss/seq after 01250 batchs: 641.5300903320312
INFO:root:Train (Epoch 95): Loss/seq after 01300 batchs: 627.343505859375
INFO:root:Train (Epoch 95): Loss/seq after 01350 batchs: 616.3179321289062
INFO:root:Train (Epoch 95): Loss/seq after 01400 batchs: 618.7444458007812
INFO:root:Train (Epoch 95): Loss/seq after 01450 batchs: 620.5252685546875
INFO:root:Train (Epoch 95): Loss/seq after 01500 batchs: 627.4654541015625
INFO:root:Train (Epoch 95): Loss/seq after 01550 batchs: 630.16259765625
INFO:root:Train (Epoch 95): Loss/seq after 01600 batchs: 624.9391479492188
INFO:root:Train (Epoch 95): Loss/seq after 01650 batchs: 622.7108154296875
INFO:root:Train (Epoch 95): Loss/seq after 01700 batchs: 624.58251953125
INFO:root:Train (Epoch 95): Loss/seq after 01750 batchs: 622.0209350585938
INFO:root:Train (Epoch 95): Loss/seq after 01800 batchs: 619.4473266601562
INFO:root:Train (Epoch 95): Loss/seq after 01850 batchs: 615.92333984375
INFO:root:Train (Epoch 95): Loss/seq after 01900 batchs: 616.5515747070312
INFO:root:Train (Epoch 95): Loss/seq after 01950 batchs: 614.7424926757812
INFO:root:Train (Epoch 95): Loss/seq after 02000 batchs: 613.4234008789062
INFO:root:Train (Epoch 95): Loss/seq after 02050 batchs: 612.2262573242188
INFO:root:Train (Epoch 95): Loss/seq after 02100 batchs: 609.7359008789062
INFO:root:Train (Epoch 95): Loss/seq after 02150 batchs: 607.9636840820312
INFO:root:Train (Epoch 95): Loss/seq after 02200 batchs: 605.1333618164062
INFO:root:Train (Epoch 95): Loss/seq after 02250 batchs: 603.77001953125
INFO:root:Train (Epoch 95): Loss/seq after 02300 batchs: 599.2275390625
INFO:root:Train (Epoch 95): Loss/seq after 02350 batchs: 594.6512451171875
INFO:root:Train (Epoch 95): Loss/seq after 02400 batchs: 595.4364624023438
INFO:root:Train (Epoch 95): Loss/seq after 02450 batchs: 590.3651123046875
INFO:root:Train (Epoch 95): Loss/seq after 02500 batchs: 581.357666015625
INFO:root:Train (Epoch 95): Loss/seq after 02550 batchs: 574.4642333984375
INFO:root:Train (Epoch 95): Loss/seq after 02600 batchs: 572.6217651367188
INFO:root:Train (Epoch 95): Loss/seq after 02650 batchs: 569.7660522460938
INFO:root:Train (Epoch 95): Loss/seq after 02700 batchs: 567.10302734375
INFO:root:Train (Epoch 95): Loss/seq after 02750 batchs: 563.2097778320312
INFO:root:Train (Epoch 95): Loss/seq after 02800 batchs: 563.29443359375
INFO:root:Train (Epoch 95): Loss/seq after 02850 batchs: 563.8399047851562
INFO:root:Train (Epoch 95): Loss/seq after 02900 batchs: 565.4970092773438
INFO:root:Train (Epoch 95): Loss/seq after 02950 batchs: 564.6123046875
INFO:root:Train (Epoch 95): Loss/seq after 03000 batchs: 569.8745727539062
INFO:root:Train (Epoch 95): Loss/seq after 03050 batchs: 572.086669921875
INFO:root:Train (Epoch 95): Loss/seq after 03100 batchs: 577.54052734375
INFO:root:Train (Epoch 95): Loss/seq after 03150 batchs: 579.337158203125
INFO:root:Train (Epoch 95): Loss/seq after 03200 batchs: 580.630126953125
INFO:root:Train (Epoch 95): Loss/seq after 03250 batchs: 583.3864135742188
INFO:root:Train (Epoch 95): Loss/seq after 03300 batchs: 582.367431640625
INFO:root:Train (Epoch 95): Loss/seq after 03350 batchs: 581.8798217773438
INFO:root:Train (Epoch 95): Loss/seq after 03400 batchs: 577.1857299804688
INFO:root:Train (Epoch 95): Loss/seq after 03450 batchs: 575.776123046875
INFO:root:Train (Epoch 95): Loss/seq after 03500 batchs: 576.9406127929688
INFO:root:Train (Epoch 95): Loss/seq after 03550 batchs: 574.2131958007812
INFO:root:Train (Epoch 95): Loss/seq after 03600 batchs: 582.8980712890625
INFO:root:Train (Epoch 95): Loss/seq after 03650 batchs: 580.3579711914062
INFO:root:Train (Epoch 95): Loss/seq after 03700 batchs: 582.8938598632812
INFO:root:Train (Epoch 95): Loss/seq after 03750 batchs: 587.843505859375
INFO:root:Train (Epoch 95): Loss/seq after 03800 batchs: 585.3878173828125
INFO:root:Train (Epoch 95): Loss/seq after 03850 batchs: 584.7254028320312
INFO:root:Train (Epoch 95): Loss/seq after 03900 batchs: 588.2896728515625
INFO:root:Train (Epoch 95): Loss/seq after 03950 batchs: 590.8807983398438
INFO:root:Train (Epoch 95): Loss/seq after 04000 batchs: 587.094970703125
INFO:root:Train (Epoch 95): Loss/seq after 04050 batchs: 583.287353515625
INFO:root:Train (Epoch 95): Loss/seq after 04100 batchs: 581.7213134765625
INFO:root:Train (Epoch 95): Loss/seq after 04150 batchs: 581.6952514648438
INFO:root:Train (Epoch 95): Loss/seq after 04200 batchs: 580.5108642578125
INFO:root:Train (Epoch 95): Loss/seq after 04250 batchs: 578.8692016601562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 95): Loss/seq after 00000 batches: 512.0454711914062
INFO:root:# Valid (Epoch 95): Loss/seq after 00050 batches: 772.540771484375
INFO:root:# Valid (Epoch 95): Loss/seq after 00100 batches: 816.2382202148438
INFO:root:# Valid (Epoch 95): Loss/seq after 00150 batches: 613.3655395507812
INFO:root:# Valid (Epoch 95): Loss/seq after 00200 batches: 572.0357666015625
INFO:root:Artifacts: Make stick videos for epoch 95
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_95_on_20220422_072115.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_95_index_367_on_20220422_072115.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 96): Loss/seq after 00000 batchs: 1169.5396728515625
INFO:root:Train (Epoch 96): Loss/seq after 00050 batchs: 832.9719848632812
INFO:root:Train (Epoch 96): Loss/seq after 00100 batchs: 848.6902465820312
INFO:root:Train (Epoch 96): Loss/seq after 00150 batchs: 788.4549560546875
INFO:root:Train (Epoch 96): Loss/seq after 00200 batchs: 851.327392578125
INFO:root:Train (Epoch 96): Loss/seq after 00250 batchs: 972.3579711914062
INFO:root:Train (Epoch 96): Loss/seq after 00300 batchs: 960.7408447265625
INFO:root:Train (Epoch 96): Loss/seq after 00350 batchs: 895.2979125976562
INFO:root:Train (Epoch 96): Loss/seq after 00400 batchs: 882.633056640625
INFO:root:Train (Epoch 96): Loss/seq after 00450 batchs: 860.228759765625
INFO:root:Train (Epoch 96): Loss/seq after 00500 batchs: 833.0645141601562
INFO:root:Train (Epoch 96): Loss/seq after 00550 batchs: 805.2452392578125
INFO:root:Train (Epoch 96): Loss/seq after 00600 batchs: 775.3751831054688
INFO:root:Train (Epoch 96): Loss/seq after 00650 batchs: 746.8040161132812
INFO:root:Train (Epoch 96): Loss/seq after 00700 batchs: 717.1663818359375
INFO:root:Train (Epoch 96): Loss/seq after 00750 batchs: 719.7549438476562
INFO:root:Train (Epoch 96): Loss/seq after 00800 batchs: 721.7389526367188
INFO:root:Train (Epoch 96): Loss/seq after 00850 batchs: 698.9976806640625
INFO:root:Train (Epoch 96): Loss/seq after 00900 batchs: 683.326416015625
INFO:root:Train (Epoch 96): Loss/seq after 00950 batchs: 678.6065063476562
INFO:root:Train (Epoch 96): Loss/seq after 01000 batchs: 666.75830078125
INFO:root:Train (Epoch 96): Loss/seq after 01050 batchs: 652.99365234375
INFO:root:Train (Epoch 96): Loss/seq after 01100 batchs: 642.2327270507812
INFO:root:Train (Epoch 96): Loss/seq after 01150 batchs: 625.9041748046875
INFO:root:Train (Epoch 96): Loss/seq after 01200 batchs: 630.8033447265625
INFO:root:Train (Epoch 96): Loss/seq after 01250 batchs: 628.0711669921875
INFO:root:Train (Epoch 96): Loss/seq after 01300 batchs: 614.82177734375
INFO:root:Train (Epoch 96): Loss/seq after 01350 batchs: 604.517578125
INFO:root:Train (Epoch 96): Loss/seq after 01400 batchs: 606.9033813476562
INFO:root:Train (Epoch 96): Loss/seq after 01450 batchs: 608.7908325195312
INFO:root:Train (Epoch 96): Loss/seq after 01500 batchs: 616.0098266601562
INFO:root:Train (Epoch 96): Loss/seq after 01550 batchs: 619.70361328125
INFO:root:Train (Epoch 96): Loss/seq after 01600 batchs: 614.9234619140625
INFO:root:Train (Epoch 96): Loss/seq after 01650 batchs: 613.5762939453125
INFO:root:Train (Epoch 96): Loss/seq after 01700 batchs: 615.9434814453125
INFO:root:Train (Epoch 96): Loss/seq after 01750 batchs: 613.7035522460938
INFO:root:Train (Epoch 96): Loss/seq after 01800 batchs: 611.3544311523438
INFO:root:Train (Epoch 96): Loss/seq after 01850 batchs: 608.03076171875
INFO:root:Train (Epoch 96): Loss/seq after 01900 batchs: 608.6753540039062
INFO:root:Train (Epoch 96): Loss/seq after 01950 batchs: 606.9306640625
INFO:root:Train (Epoch 96): Loss/seq after 02000 batchs: 605.2348022460938
INFO:root:Train (Epoch 96): Loss/seq after 02050 batchs: 604.1080322265625
INFO:root:Train (Epoch 96): Loss/seq after 02100 batchs: 601.6646728515625
INFO:root:Train (Epoch 96): Loss/seq after 02150 batchs: 600.0855102539062
INFO:root:Train (Epoch 96): Loss/seq after 02200 batchs: 597.2862548828125
INFO:root:Train (Epoch 96): Loss/seq after 02250 batchs: 596.3411865234375
INFO:root:Train (Epoch 96): Loss/seq after 02300 batchs: 592.0421142578125
INFO:root:Train (Epoch 96): Loss/seq after 02350 batchs: 587.631103515625
INFO:root:Train (Epoch 96): Loss/seq after 02400 batchs: 588.4374389648438
INFO:root:Train (Epoch 96): Loss/seq after 02450 batchs: 583.5668334960938
INFO:root:Train (Epoch 96): Loss/seq after 02500 batchs: 574.7752075195312
INFO:root:Train (Epoch 96): Loss/seq after 02550 batchs: 567.9342651367188
INFO:root:Train (Epoch 96): Loss/seq after 02600 batchs: 566.1559448242188
INFO:root:Train (Epoch 96): Loss/seq after 02650 batchs: 563.4362182617188
INFO:root:Train (Epoch 96): Loss/seq after 02700 batchs: 560.8809814453125
INFO:root:Train (Epoch 96): Loss/seq after 02750 batchs: 556.8683471679688
INFO:root:Train (Epoch 96): Loss/seq after 02800 batchs: 556.4928588867188
INFO:root:Train (Epoch 96): Loss/seq after 02850 batchs: 557.3860473632812
INFO:root:Train (Epoch 96): Loss/seq after 02900 batchs: 558.6817626953125
INFO:root:Train (Epoch 96): Loss/seq after 02950 batchs: 557.9011840820312
INFO:root:Train (Epoch 96): Loss/seq after 03000 batchs: 563.3521118164062
INFO:root:Train (Epoch 96): Loss/seq after 03050 batchs: 565.5390014648438
INFO:root:Train (Epoch 96): Loss/seq after 03100 batchs: 569.2119750976562
INFO:root:Train (Epoch 96): Loss/seq after 03150 batchs: 570.0928955078125
INFO:root:Train (Epoch 96): Loss/seq after 03200 batchs: 571.1791381835938
INFO:root:Train (Epoch 96): Loss/seq after 03250 batchs: 573.6497802734375
INFO:root:Train (Epoch 96): Loss/seq after 03300 batchs: 573.2080078125
INFO:root:Train (Epoch 96): Loss/seq after 03350 batchs: 572.76708984375
INFO:root:Train (Epoch 96): Loss/seq after 03400 batchs: 568.338623046875
INFO:root:Train (Epoch 96): Loss/seq after 03450 batchs: 567.0473022460938
INFO:root:Train (Epoch 96): Loss/seq after 03500 batchs: 568.4873046875
INFO:root:Train (Epoch 96): Loss/seq after 03550 batchs: 566.2546997070312
INFO:root:Train (Epoch 96): Loss/seq after 03600 batchs: 576.0521240234375
INFO:root:Train (Epoch 96): Loss/seq after 03650 batchs: 574.9198608398438
INFO:root:Train (Epoch 96): Loss/seq after 03700 batchs: 577.7860717773438
INFO:root:Train (Epoch 96): Loss/seq after 03750 batchs: 582.8909301757812
INFO:root:Train (Epoch 96): Loss/seq after 03800 batchs: 580.5054931640625
INFO:root:Train (Epoch 96): Loss/seq after 03850 batchs: 579.8290405273438
INFO:root:Train (Epoch 96): Loss/seq after 03900 batchs: 583.1898803710938
INFO:root:Train (Epoch 96): Loss/seq after 03950 batchs: 586.0018920898438
INFO:root:Train (Epoch 96): Loss/seq after 04000 batchs: 582.2803955078125
INFO:root:Train (Epoch 96): Loss/seq after 04050 batchs: 578.499267578125
INFO:root:Train (Epoch 96): Loss/seq after 04100 batchs: 577.0370483398438
INFO:root:Train (Epoch 96): Loss/seq after 04150 batchs: 577.1309204101562
INFO:root:Train (Epoch 96): Loss/seq after 04200 batchs: 575.8698120117188
INFO:root:Train (Epoch 96): Loss/seq after 04250 batchs: 574.2337646484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 96): Loss/seq after 00000 batches: 519.162841796875
INFO:root:# Valid (Epoch 96): Loss/seq after 00050 batches: 798.41845703125
INFO:root:# Valid (Epoch 96): Loss/seq after 00100 batches: 810.2583618164062
INFO:root:# Valid (Epoch 96): Loss/seq after 00150 batches: 609.6651611328125
INFO:root:# Valid (Epoch 96): Loss/seq after 00200 batches: 572.556396484375
INFO:root:Artifacts: Make stick videos for epoch 96
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_96_on_20220422_072624.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_96_index_711_on_20220422_072624.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 97): Loss/seq after 00000 batchs: 1185.613037109375
INFO:root:Train (Epoch 97): Loss/seq after 00050 batchs: 842.7137451171875
INFO:root:Train (Epoch 97): Loss/seq after 00100 batchs: 879.0203857421875
INFO:root:Train (Epoch 97): Loss/seq after 00150 batchs: 816.2810668945312
INFO:root:Train (Epoch 97): Loss/seq after 00200 batchs: 882.2177124023438
INFO:root:Train (Epoch 97): Loss/seq after 00250 batchs: 1000.2799682617188
INFO:root:Train (Epoch 97): Loss/seq after 00300 batchs: 983.9982299804688
INFO:root:Train (Epoch 97): Loss/seq after 00350 batchs: 914.6602783203125
INFO:root:Train (Epoch 97): Loss/seq after 00400 batchs: 904.2409057617188
INFO:root:Train (Epoch 97): Loss/seq after 00450 batchs: 879.7064819335938
INFO:root:Train (Epoch 97): Loss/seq after 00500 batchs: 854.31298828125
INFO:root:Train (Epoch 97): Loss/seq after 00550 batchs: 825.1060791015625
INFO:root:Train (Epoch 97): Loss/seq after 00600 batchs: 794.0540771484375
INFO:root:Train (Epoch 97): Loss/seq after 00650 batchs: 762.9996337890625
INFO:root:Train (Epoch 97): Loss/seq after 00700 batchs: 732.6107788085938
INFO:root:Train (Epoch 97): Loss/seq after 00750 batchs: 731.93212890625
INFO:root:Train (Epoch 97): Loss/seq after 00800 batchs: 732.6093139648438
INFO:root:Train (Epoch 97): Loss/seq after 00850 batchs: 709.6785888671875
INFO:root:Train (Epoch 97): Loss/seq after 00900 batchs: 693.2684936523438
INFO:root:Train (Epoch 97): Loss/seq after 00950 batchs: 687.0742797851562
INFO:root:Train (Epoch 97): Loss/seq after 01000 batchs: 674.6744384765625
INFO:root:Train (Epoch 97): Loss/seq after 01050 batchs: 660.482177734375
INFO:root:Train (Epoch 97): Loss/seq after 01100 batchs: 650.1915893554688
INFO:root:Train (Epoch 97): Loss/seq after 01150 batchs: 632.7982788085938
INFO:root:Train (Epoch 97): Loss/seq after 01200 batchs: 637.198486328125
INFO:root:Train (Epoch 97): Loss/seq after 01250 batchs: 634.6759033203125
INFO:root:Train (Epoch 97): Loss/seq after 01300 batchs: 621.3704833984375
INFO:root:Train (Epoch 97): Loss/seq after 01350 batchs: 610.9969482421875
INFO:root:Train (Epoch 97): Loss/seq after 01400 batchs: 613.5000610351562
INFO:root:Train (Epoch 97): Loss/seq after 01450 batchs: 616.0865478515625
INFO:root:Train (Epoch 97): Loss/seq after 01500 batchs: 622.8605346679688
INFO:root:Train (Epoch 97): Loss/seq after 01550 batchs: 625.7967529296875
INFO:root:Train (Epoch 97): Loss/seq after 01600 batchs: 620.5269775390625
INFO:root:Train (Epoch 97): Loss/seq after 01650 batchs: 618.322998046875
INFO:root:Train (Epoch 97): Loss/seq after 01700 batchs: 620.3189086914062
INFO:root:Train (Epoch 97): Loss/seq after 01750 batchs: 617.4329223632812
INFO:root:Train (Epoch 97): Loss/seq after 01800 batchs: 614.8590698242188
INFO:root:Train (Epoch 97): Loss/seq after 01850 batchs: 611.2952880859375
INFO:root:Train (Epoch 97): Loss/seq after 01900 batchs: 611.7806396484375
INFO:root:Train (Epoch 97): Loss/seq after 01950 batchs: 610.004150390625
INFO:root:Train (Epoch 97): Loss/seq after 02000 batchs: 608.1957397460938
INFO:root:Train (Epoch 97): Loss/seq after 02050 batchs: 606.8389282226562
INFO:root:Train (Epoch 97): Loss/seq after 02100 batchs: 604.1890869140625
INFO:root:Train (Epoch 97): Loss/seq after 02150 batchs: 602.384521484375
INFO:root:Train (Epoch 97): Loss/seq after 02200 batchs: 599.5050048828125
INFO:root:Train (Epoch 97): Loss/seq after 02250 batchs: 598.4175415039062
INFO:root:Train (Epoch 97): Loss/seq after 02300 batchs: 593.6769409179688
INFO:root:Train (Epoch 97): Loss/seq after 02350 batchs: 589.4432373046875
INFO:root:Train (Epoch 97): Loss/seq after 02400 batchs: 590.5089721679688
INFO:root:Train (Epoch 97): Loss/seq after 02450 batchs: 585.544189453125
INFO:root:Train (Epoch 97): Loss/seq after 02500 batchs: 576.6856689453125
INFO:root:Train (Epoch 97): Loss/seq after 02550 batchs: 569.9449462890625
INFO:root:Train (Epoch 97): Loss/seq after 02600 batchs: 568.3594970703125
INFO:root:Train (Epoch 97): Loss/seq after 02650 batchs: 565.3345947265625
INFO:root:Train (Epoch 97): Loss/seq after 02700 batchs: 562.7113037109375
INFO:root:Train (Epoch 97): Loss/seq after 02750 batchs: 558.71630859375
INFO:root:Train (Epoch 97): Loss/seq after 02800 batchs: 558.298828125
INFO:root:Train (Epoch 97): Loss/seq after 02850 batchs: 558.9622802734375
INFO:root:Train (Epoch 97): Loss/seq after 02900 batchs: 560.50439453125
INFO:root:Train (Epoch 97): Loss/seq after 02950 batchs: 559.7434692382812
INFO:root:Train (Epoch 97): Loss/seq after 03000 batchs: 564.9996337890625
INFO:root:Train (Epoch 97): Loss/seq after 03050 batchs: 567.6170043945312
INFO:root:Train (Epoch 97): Loss/seq after 03100 batchs: 571.2880249023438
INFO:root:Train (Epoch 97): Loss/seq after 03150 batchs: 572.4581909179688
INFO:root:Train (Epoch 97): Loss/seq after 03200 batchs: 572.9428100585938
INFO:root:Train (Epoch 97): Loss/seq after 03250 batchs: 575.1630249023438
INFO:root:Train (Epoch 97): Loss/seq after 03300 batchs: 574.08740234375
INFO:root:Train (Epoch 97): Loss/seq after 03350 batchs: 573.5148315429688
INFO:root:Train (Epoch 97): Loss/seq after 03400 batchs: 568.868408203125
INFO:root:Train (Epoch 97): Loss/seq after 03450 batchs: 567.5081176757812
INFO:root:Train (Epoch 97): Loss/seq after 03500 batchs: 568.6500854492188
INFO:root:Train (Epoch 97): Loss/seq after 03550 batchs: 565.986328125
INFO:root:Train (Epoch 97): Loss/seq after 03600 batchs: 575.05859375
INFO:root:Train (Epoch 97): Loss/seq after 03650 batchs: 573.560302734375
INFO:root:Train (Epoch 97): Loss/seq after 03700 batchs: 576.4036254882812
INFO:root:Train (Epoch 97): Loss/seq after 03750 batchs: 581.3786010742188
INFO:root:Train (Epoch 97): Loss/seq after 03800 batchs: 578.9553833007812
INFO:root:Train (Epoch 97): Loss/seq after 03850 batchs: 578.2396850585938
INFO:root:Train (Epoch 97): Loss/seq after 03900 batchs: 581.8359985351562
INFO:root:Train (Epoch 97): Loss/seq after 03950 batchs: 584.720703125
INFO:root:Train (Epoch 97): Loss/seq after 04000 batchs: 581.0895385742188
INFO:root:Train (Epoch 97): Loss/seq after 04050 batchs: 577.3565673828125
INFO:root:Train (Epoch 97): Loss/seq after 04100 batchs: 575.7672729492188
INFO:root:Train (Epoch 97): Loss/seq after 04150 batchs: 575.7125244140625
INFO:root:Train (Epoch 97): Loss/seq after 04200 batchs: 574.446533203125
INFO:root:Train (Epoch 97): Loss/seq after 04250 batchs: 572.8392333984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 97): Loss/seq after 00000 batches: 521.8763427734375
INFO:root:# Valid (Epoch 97): Loss/seq after 00050 batches: 786.6670532226562
INFO:root:# Valid (Epoch 97): Loss/seq after 00100 batches: 821.71337890625
INFO:root:# Valid (Epoch 97): Loss/seq after 00150 batches: 622.799072265625
INFO:root:# Valid (Epoch 97): Loss/seq after 00200 batches: 582.349609375
INFO:root:Artifacts: Make stick videos for epoch 97
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_97_on_20220422_073109.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_97_index_1100_on_20220422_073109.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 98): Loss/seq after 00000 batchs: 1137.2650146484375
INFO:root:Train (Epoch 98): Loss/seq after 00050 batchs: 869.6015014648438
INFO:root:Train (Epoch 98): Loss/seq after 00100 batchs: 875.3102416992188
INFO:root:Train (Epoch 98): Loss/seq after 00150 batchs: 818.6533203125
INFO:root:Train (Epoch 98): Loss/seq after 00200 batchs: 883.8486938476562
INFO:root:Train (Epoch 98): Loss/seq after 00250 batchs: 997.7306518554688
INFO:root:Train (Epoch 98): Loss/seq after 00300 batchs: 980.8781127929688
INFO:root:Train (Epoch 98): Loss/seq after 00350 batchs: 912.0689086914062
INFO:root:Train (Epoch 98): Loss/seq after 00400 batchs: 903.0340576171875
INFO:root:Train (Epoch 98): Loss/seq after 00450 batchs: 878.8955688476562
INFO:root:Train (Epoch 98): Loss/seq after 00500 batchs: 850.8219604492188
INFO:root:Train (Epoch 98): Loss/seq after 00550 batchs: 824.5751342773438
INFO:root:Train (Epoch 98): Loss/seq after 00600 batchs: 793.3395385742188
INFO:root:Train (Epoch 98): Loss/seq after 00650 batchs: 763.9260864257812
INFO:root:Train (Epoch 98): Loss/seq after 00700 batchs: 732.626953125
INFO:root:Train (Epoch 98): Loss/seq after 00750 batchs: 731.544677734375
INFO:root:Train (Epoch 98): Loss/seq after 00800 batchs: 734.5463256835938
INFO:root:Train (Epoch 98): Loss/seq after 00850 batchs: 711.6383666992188
INFO:root:Train (Epoch 98): Loss/seq after 00900 batchs: 694.6069946289062
INFO:root:Train (Epoch 98): Loss/seq after 00950 batchs: 690.4545288085938
INFO:root:Train (Epoch 98): Loss/seq after 01000 batchs: 677.488525390625
INFO:root:Train (Epoch 98): Loss/seq after 01050 batchs: 663.9052124023438
INFO:root:Train (Epoch 98): Loss/seq after 01100 batchs: 655.3614501953125
INFO:root:Train (Epoch 98): Loss/seq after 01150 batchs: 638.5579833984375
INFO:root:Train (Epoch 98): Loss/seq after 01200 batchs: 643.1806640625
INFO:root:Train (Epoch 98): Loss/seq after 01250 batchs: 639.6513061523438
INFO:root:Train (Epoch 98): Loss/seq after 01300 batchs: 626.1029663085938
INFO:root:Train (Epoch 98): Loss/seq after 01350 batchs: 615.6439208984375
INFO:root:Train (Epoch 98): Loss/seq after 01400 batchs: 617.5164794921875
INFO:root:Train (Epoch 98): Loss/seq after 01450 batchs: 619.3131103515625
INFO:root:Train (Epoch 98): Loss/seq after 01500 batchs: 625.979248046875
INFO:root:Train (Epoch 98): Loss/seq after 01550 batchs: 628.8068237304688
INFO:root:Train (Epoch 98): Loss/seq after 01600 batchs: 623.425048828125
INFO:root:Train (Epoch 98): Loss/seq after 01650 batchs: 620.8956909179688
INFO:root:Train (Epoch 98): Loss/seq after 01700 batchs: 622.9766845703125
INFO:root:Train (Epoch 98): Loss/seq after 01750 batchs: 620.1160278320312
INFO:root:Train (Epoch 98): Loss/seq after 01800 batchs: 617.3235473632812
INFO:root:Train (Epoch 98): Loss/seq after 01850 batchs: 613.5746459960938
INFO:root:Train (Epoch 98): Loss/seq after 01900 batchs: 614.06884765625
INFO:root:Train (Epoch 98): Loss/seq after 01950 batchs: 611.9976806640625
INFO:root:Train (Epoch 98): Loss/seq after 02000 batchs: 610.310302734375
INFO:root:Train (Epoch 98): Loss/seq after 02050 batchs: 609.3126831054688
INFO:root:Train (Epoch 98): Loss/seq after 02100 batchs: 606.8237915039062
INFO:root:Train (Epoch 98): Loss/seq after 02150 batchs: 604.9776611328125
INFO:root:Train (Epoch 98): Loss/seq after 02200 batchs: 602.1371459960938
INFO:root:Train (Epoch 98): Loss/seq after 02250 batchs: 601.4993896484375
INFO:root:Train (Epoch 98): Loss/seq after 02300 batchs: 596.9732055664062
INFO:root:Train (Epoch 98): Loss/seq after 02350 batchs: 592.6436157226562
INFO:root:Train (Epoch 98): Loss/seq after 02400 batchs: 593.786376953125
INFO:root:Train (Epoch 98): Loss/seq after 02450 batchs: 589.0306396484375
INFO:root:Train (Epoch 98): Loss/seq after 02500 batchs: 580.12841796875
INFO:root:Train (Epoch 98): Loss/seq after 02550 batchs: 573.1748657226562
INFO:root:Train (Epoch 98): Loss/seq after 02600 batchs: 571.3467407226562
INFO:root:Train (Epoch 98): Loss/seq after 02650 batchs: 568.2570190429688
INFO:root:Train (Epoch 98): Loss/seq after 02700 batchs: 565.3724975585938
INFO:root:Train (Epoch 98): Loss/seq after 02750 batchs: 561.4342041015625
INFO:root:Train (Epoch 98): Loss/seq after 02800 batchs: 561.3546752929688
INFO:root:Train (Epoch 98): Loss/seq after 02850 batchs: 561.8916625976562
INFO:root:Train (Epoch 98): Loss/seq after 02900 batchs: 563.3030395507812
INFO:root:Train (Epoch 98): Loss/seq after 02950 batchs: 562.2985229492188
INFO:root:Train (Epoch 98): Loss/seq after 03000 batchs: 567.4169921875
INFO:root:Train (Epoch 98): Loss/seq after 03050 batchs: 569.4857788085938
INFO:root:Train (Epoch 98): Loss/seq after 03100 batchs: 573.50146484375
INFO:root:Train (Epoch 98): Loss/seq after 03150 batchs: 574.1721801757812
INFO:root:Train (Epoch 98): Loss/seq after 03200 batchs: 574.7105102539062
INFO:root:Train (Epoch 98): Loss/seq after 03250 batchs: 576.9786376953125
INFO:root:Train (Epoch 98): Loss/seq after 03300 batchs: 575.7982788085938
INFO:root:Train (Epoch 98): Loss/seq after 03350 batchs: 574.9266967773438
INFO:root:Train (Epoch 98): Loss/seq after 03400 batchs: 570.2783813476562
INFO:root:Train (Epoch 98): Loss/seq after 03450 batchs: 568.7880859375
INFO:root:Train (Epoch 98): Loss/seq after 03500 batchs: 570.2091674804688
INFO:root:Train (Epoch 98): Loss/seq after 03550 batchs: 567.67041015625
INFO:root:Train (Epoch 98): Loss/seq after 03600 batchs: 576.2766723632812
INFO:root:Train (Epoch 98): Loss/seq after 03650 batchs: 573.83984375
INFO:root:Train (Epoch 98): Loss/seq after 03700 batchs: 576.5885009765625
INFO:root:Train (Epoch 98): Loss/seq after 03750 batchs: 581.6321411132812
INFO:root:Train (Epoch 98): Loss/seq after 03800 batchs: 579.2505493164062
INFO:root:Train (Epoch 98): Loss/seq after 03850 batchs: 578.426025390625
INFO:root:Train (Epoch 98): Loss/seq after 03900 batchs: 581.7733764648438
INFO:root:Train (Epoch 98): Loss/seq after 03950 batchs: 584.6383666992188
INFO:root:Train (Epoch 98): Loss/seq after 04000 batchs: 581.0012817382812
INFO:root:Train (Epoch 98): Loss/seq after 04050 batchs: 577.2620849609375
INFO:root:Train (Epoch 98): Loss/seq after 04100 batchs: 575.606201171875
INFO:root:Train (Epoch 98): Loss/seq after 04150 batchs: 575.5448608398438
INFO:root:Train (Epoch 98): Loss/seq after 04200 batchs: 574.3311157226562
INFO:root:Train (Epoch 98): Loss/seq after 04250 batchs: 572.6270751953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 98): Loss/seq after 00000 batches: 520.8817138671875
INFO:root:# Valid (Epoch 98): Loss/seq after 00050 batches: 770.151123046875
INFO:root:# Valid (Epoch 98): Loss/seq after 00100 batches: 816.6068725585938
INFO:root:# Valid (Epoch 98): Loss/seq after 00150 batches: 613.7796020507812
INFO:root:# Valid (Epoch 98): Loss/seq after 00200 batches: 572.1441650390625
INFO:root:Artifacts: Make stick videos for epoch 98
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_98_on_20220422_073552.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_98_index_1594_on_20220422_073552.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 99): Loss/seq after 00000 batchs: 1059.4970703125
INFO:root:Train (Epoch 99): Loss/seq after 00050 batchs: 840.71826171875
INFO:root:Train (Epoch 99): Loss/seq after 00100 batchs: 874.5833740234375
INFO:root:Train (Epoch 99): Loss/seq after 00150 batchs: 802.5465698242188
INFO:root:Train (Epoch 99): Loss/seq after 00200 batchs: 863.9241333007812
INFO:root:Train (Epoch 99): Loss/seq after 00250 batchs: 980.98779296875
INFO:root:Train (Epoch 99): Loss/seq after 00300 batchs: 966.3119506835938
INFO:root:Train (Epoch 99): Loss/seq after 00350 batchs: 898.2860717773438
INFO:root:Train (Epoch 99): Loss/seq after 00400 batchs: 885.9393920898438
INFO:root:Train (Epoch 99): Loss/seq after 00450 batchs: 863.5418701171875
INFO:root:Train (Epoch 99): Loss/seq after 00500 batchs: 835.0138549804688
INFO:root:Train (Epoch 99): Loss/seq after 00550 batchs: 806.9860229492188
INFO:root:Train (Epoch 99): Loss/seq after 00600 batchs: 777.3369750976562
INFO:root:Train (Epoch 99): Loss/seq after 00650 batchs: 747.7132568359375
INFO:root:Train (Epoch 99): Loss/seq after 00700 batchs: 716.5505981445312
INFO:root:Train (Epoch 99): Loss/seq after 00750 batchs: 717.634521484375
INFO:root:Train (Epoch 99): Loss/seq after 00800 batchs: 719.5947875976562
INFO:root:Train (Epoch 99): Loss/seq after 00850 batchs: 696.9009399414062
INFO:root:Train (Epoch 99): Loss/seq after 00900 batchs: 680.446533203125
INFO:root:Train (Epoch 99): Loss/seq after 00950 batchs: 675.8681030273438
INFO:root:Train (Epoch 99): Loss/seq after 01000 batchs: 663.0621948242188
INFO:root:Train (Epoch 99): Loss/seq after 01050 batchs: 649.2208862304688
INFO:root:Train (Epoch 99): Loss/seq after 01100 batchs: 639.0938720703125
INFO:root:Train (Epoch 99): Loss/seq after 01150 batchs: 622.4317016601562
INFO:root:Train (Epoch 99): Loss/seq after 01200 batchs: 627.2822265625
INFO:root:Train (Epoch 99): Loss/seq after 01250 batchs: 624.6529541015625
INFO:root:Train (Epoch 99): Loss/seq after 01300 batchs: 611.5316772460938
INFO:root:Train (Epoch 99): Loss/seq after 01350 batchs: 601.2150268554688
INFO:root:Train (Epoch 99): Loss/seq after 01400 batchs: 603.6288452148438
INFO:root:Train (Epoch 99): Loss/seq after 01450 batchs: 605.3822631835938
INFO:root:Train (Epoch 99): Loss/seq after 01500 batchs: 612.4444580078125
INFO:root:Train (Epoch 99): Loss/seq after 01550 batchs: 615.7442016601562
INFO:root:Train (Epoch 99): Loss/seq after 01600 batchs: 611.11865234375
INFO:root:Train (Epoch 99): Loss/seq after 01650 batchs: 609.3895263671875
INFO:root:Train (Epoch 99): Loss/seq after 01700 batchs: 611.5469970703125
INFO:root:Train (Epoch 99): Loss/seq after 01750 batchs: 608.9033203125
INFO:root:Train (Epoch 99): Loss/seq after 01800 batchs: 606.5171508789062
INFO:root:Train (Epoch 99): Loss/seq after 01850 batchs: 602.9244995117188
INFO:root:Train (Epoch 99): Loss/seq after 01900 batchs: 603.42578125
INFO:root:Train (Epoch 99): Loss/seq after 01950 batchs: 601.8321533203125
INFO:root:Train (Epoch 99): Loss/seq after 02000 batchs: 600.1517333984375
INFO:root:Train (Epoch 99): Loss/seq after 02050 batchs: 599.0904541015625
INFO:root:Train (Epoch 99): Loss/seq after 02100 batchs: 596.7328491210938
INFO:root:Train (Epoch 99): Loss/seq after 02150 batchs: 594.9788208007812
INFO:root:Train (Epoch 99): Loss/seq after 02200 batchs: 592.1439819335938
INFO:root:Train (Epoch 99): Loss/seq after 02250 batchs: 590.946044921875
INFO:root:Train (Epoch 99): Loss/seq after 02300 batchs: 586.3214721679688
INFO:root:Train (Epoch 99): Loss/seq after 02350 batchs: 581.7142944335938
INFO:root:Train (Epoch 99): Loss/seq after 02400 batchs: 582.4232788085938
INFO:root:Train (Epoch 99): Loss/seq after 02450 batchs: 577.5089111328125
INFO:root:Train (Epoch 99): Loss/seq after 02500 batchs: 568.7387084960938
INFO:root:Train (Epoch 99): Loss/seq after 02550 batchs: 561.7625122070312
INFO:root:Train (Epoch 99): Loss/seq after 02600 batchs: 559.9808959960938
INFO:root:Train (Epoch 99): Loss/seq after 02650 batchs: 556.805419921875
INFO:root:Train (Epoch 99): Loss/seq after 02700 batchs: 554.079833984375
INFO:root:Train (Epoch 99): Loss/seq after 02750 batchs: 550.0189208984375
INFO:root:Train (Epoch 99): Loss/seq after 02800 batchs: 549.6038818359375
INFO:root:Train (Epoch 99): Loss/seq after 02850 batchs: 550.0963134765625
INFO:root:Train (Epoch 99): Loss/seq after 02900 batchs: 551.10888671875
INFO:root:Train (Epoch 99): Loss/seq after 02950 batchs: 550.3058471679688
INFO:root:Train (Epoch 99): Loss/seq after 03000 batchs: 555.7540283203125
INFO:root:Train (Epoch 99): Loss/seq after 03050 batchs: 557.865234375
INFO:root:Train (Epoch 99): Loss/seq after 03100 batchs: 561.3751831054688
INFO:root:Train (Epoch 99): Loss/seq after 03150 batchs: 562.0835571289062
INFO:root:Train (Epoch 99): Loss/seq after 03200 batchs: 562.88623046875
INFO:root:Train (Epoch 99): Loss/seq after 03250 batchs: 565.474609375
INFO:root:Train (Epoch 99): Loss/seq after 03300 batchs: 565.3270874023438
INFO:root:Train (Epoch 99): Loss/seq after 03350 batchs: 564.7283325195312
INFO:root:Train (Epoch 99): Loss/seq after 03400 batchs: 560.1276245117188
INFO:root:Train (Epoch 99): Loss/seq after 03450 batchs: 558.8387451171875
INFO:root:Train (Epoch 99): Loss/seq after 03500 batchs: 560.1798095703125
INFO:root:Train (Epoch 99): Loss/seq after 03550 batchs: 557.7681274414062
INFO:root:Train (Epoch 99): Loss/seq after 03600 batchs: 566.5322875976562
INFO:root:Train (Epoch 99): Loss/seq after 03650 batchs: 564.3682861328125
INFO:root:Train (Epoch 99): Loss/seq after 03700 batchs: 566.948974609375
INFO:root:Train (Epoch 99): Loss/seq after 03750 batchs: 571.9716796875
INFO:root:Train (Epoch 99): Loss/seq after 03800 batchs: 569.6284790039062
INFO:root:Train (Epoch 99): Loss/seq after 03850 batchs: 569.091064453125
INFO:root:Train (Epoch 99): Loss/seq after 03900 batchs: 572.5326538085938
INFO:root:Train (Epoch 99): Loss/seq after 03950 batchs: 575.3745727539062
INFO:root:Train (Epoch 99): Loss/seq after 04000 batchs: 571.7134399414062
INFO:root:Train (Epoch 99): Loss/seq after 04050 batchs: 568.0261840820312
INFO:root:Train (Epoch 99): Loss/seq after 04100 batchs: 566.4722290039062
INFO:root:Train (Epoch 99): Loss/seq after 04150 batchs: 566.51806640625
INFO:root:Train (Epoch 99): Loss/seq after 04200 batchs: 565.1883544921875
INFO:root:Train (Epoch 99): Loss/seq after 04250 batchs: 563.4537353515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 99): Loss/seq after 00000 batches: 511.8016357421875
INFO:root:# Valid (Epoch 99): Loss/seq after 00050 batches: 702.8571166992188
INFO:root:# Valid (Epoch 99): Loss/seq after 00100 batches: 764.5299072265625
INFO:root:# Valid (Epoch 99): Loss/seq after 00150 batches: 576.6497192382812
INFO:root:# Valid (Epoch 99): Loss/seq after 00200 batches: 541.1843872070312
INFO:root:Artifacts: Make stick videos for epoch 99
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_99_on_20220422_074050.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_99_index_539_on_20220422_074050.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 100): Loss/seq after 00000 batchs: 1458.6168212890625
INFO:root:Train (Epoch 100): Loss/seq after 00050 batchs: 848.2008056640625
INFO:root:Train (Epoch 100): Loss/seq after 00100 batchs: 850.49853515625
INFO:root:Train (Epoch 100): Loss/seq after 00150 batchs: 784.3541259765625
INFO:root:Train (Epoch 100): Loss/seq after 00200 batchs: 847.7982788085938
INFO:root:Train (Epoch 100): Loss/seq after 00250 batchs: 967.29736328125
INFO:root:Train (Epoch 100): Loss/seq after 00300 batchs: 955.540771484375
INFO:root:Train (Epoch 100): Loss/seq after 00350 batchs: 889.2509765625
INFO:root:Train (Epoch 100): Loss/seq after 00400 batchs: 879.6144409179688
INFO:root:Train (Epoch 100): Loss/seq after 00450 batchs: 858.451904296875
INFO:root:Train (Epoch 100): Loss/seq after 00500 batchs: 831.181884765625
INFO:root:Train (Epoch 100): Loss/seq after 00550 batchs: 802.3837890625
INFO:root:Train (Epoch 100): Loss/seq after 00600 batchs: 773.8128051757812
INFO:root:Train (Epoch 100): Loss/seq after 00650 batchs: 745.778564453125
INFO:root:Train (Epoch 100): Loss/seq after 00700 batchs: 714.4951171875
INFO:root:Train (Epoch 100): Loss/seq after 00750 batchs: 713.8118286132812
INFO:root:Train (Epoch 100): Loss/seq after 00800 batchs: 717.2401733398438
INFO:root:Train (Epoch 100): Loss/seq after 00850 batchs: 694.7233276367188
INFO:root:Train (Epoch 100): Loss/seq after 00900 batchs: 679.9420166015625
INFO:root:Train (Epoch 100): Loss/seq after 00950 batchs: 673.3584594726562
INFO:root:Train (Epoch 100): Loss/seq after 01000 batchs: 660.842529296875
INFO:root:Train (Epoch 100): Loss/seq after 01050 batchs: 646.6170043945312
INFO:root:Train (Epoch 100): Loss/seq after 01100 batchs: 638.1688232421875
INFO:root:Train (Epoch 100): Loss/seq after 01150 batchs: 621.5845336914062
INFO:root:Train (Epoch 100): Loss/seq after 01200 batchs: 626.525390625
INFO:root:Train (Epoch 100): Loss/seq after 01250 batchs: 624.1170654296875
INFO:root:Train (Epoch 100): Loss/seq after 01300 batchs: 611.255615234375
INFO:root:Train (Epoch 100): Loss/seq after 01350 batchs: 600.6275024414062
INFO:root:Train (Epoch 100): Loss/seq after 01400 batchs: 602.3355712890625
INFO:root:Train (Epoch 100): Loss/seq after 01450 batchs: 604.1446533203125
INFO:root:Train (Epoch 100): Loss/seq after 01500 batchs: 611.170166015625
INFO:root:Train (Epoch 100): Loss/seq after 01550 batchs: 613.8661499023438
INFO:root:Train (Epoch 100): Loss/seq after 01600 batchs: 608.822509765625
INFO:root:Train (Epoch 100): Loss/seq after 01650 batchs: 606.6181030273438
INFO:root:Train (Epoch 100): Loss/seq after 01700 batchs: 608.7410278320312
INFO:root:Train (Epoch 100): Loss/seq after 01750 batchs: 605.927001953125
INFO:root:Train (Epoch 100): Loss/seq after 01800 batchs: 603.558837890625
INFO:root:Train (Epoch 100): Loss/seq after 01850 batchs: 600.2645263671875
INFO:root:Train (Epoch 100): Loss/seq after 01900 batchs: 600.9237670898438
INFO:root:Train (Epoch 100): Loss/seq after 01950 batchs: 599.0877685546875
INFO:root:Train (Epoch 100): Loss/seq after 02000 batchs: 597.65283203125
INFO:root:Train (Epoch 100): Loss/seq after 02050 batchs: 596.3854370117188
INFO:root:Train (Epoch 100): Loss/seq after 02100 batchs: 593.900390625
INFO:root:Train (Epoch 100): Loss/seq after 02150 batchs: 592.15771484375
INFO:root:Train (Epoch 100): Loss/seq after 02200 batchs: 589.5010375976562
INFO:root:Train (Epoch 100): Loss/seq after 02250 batchs: 589.086669921875
INFO:root:Train (Epoch 100): Loss/seq after 02300 batchs: 584.3848266601562
INFO:root:Train (Epoch 100): Loss/seq after 02350 batchs: 580.3063354492188
INFO:root:Train (Epoch 100): Loss/seq after 02400 batchs: 581.1802368164062
INFO:root:Train (Epoch 100): Loss/seq after 02450 batchs: 576.2994384765625
INFO:root:Train (Epoch 100): Loss/seq after 02500 batchs: 567.5452880859375
INFO:root:Train (Epoch 100): Loss/seq after 02550 batchs: 560.3798217773438
INFO:root:Train (Epoch 100): Loss/seq after 02600 batchs: 558.525634765625
INFO:root:Train (Epoch 100): Loss/seq after 02650 batchs: 555.4471435546875
INFO:root:Train (Epoch 100): Loss/seq after 02700 batchs: 552.66796875
INFO:root:Train (Epoch 100): Loss/seq after 02750 batchs: 548.1533813476562
INFO:root:Train (Epoch 100): Loss/seq after 02800 batchs: 547.147705078125
INFO:root:Train (Epoch 100): Loss/seq after 02850 batchs: 547.47216796875
INFO:root:Train (Epoch 100): Loss/seq after 02900 batchs: 548.9754638671875
INFO:root:Train (Epoch 100): Loss/seq after 02950 batchs: 548.2405395507812
INFO:root:Train (Epoch 100): Loss/seq after 03000 batchs: 553.5921630859375
INFO:root:Train (Epoch 100): Loss/seq after 03050 batchs: 555.8959350585938
INFO:root:Train (Epoch 100): Loss/seq after 03100 batchs: 560.2157592773438
INFO:root:Train (Epoch 100): Loss/seq after 03150 batchs: 561.3338623046875
INFO:root:Train (Epoch 100): Loss/seq after 03200 batchs: 561.7965087890625
INFO:root:Train (Epoch 100): Loss/seq after 03250 batchs: 564.0986328125
INFO:root:Train (Epoch 100): Loss/seq after 03300 batchs: 563.2637939453125
INFO:root:Train (Epoch 100): Loss/seq after 03350 batchs: 562.6593627929688
INFO:root:Train (Epoch 100): Loss/seq after 03400 batchs: 558.0884399414062
INFO:root:Train (Epoch 100): Loss/seq after 03450 batchs: 556.9567260742188
INFO:root:Train (Epoch 100): Loss/seq after 03500 batchs: 558.2030639648438
INFO:root:Train (Epoch 100): Loss/seq after 03550 batchs: 555.6756591796875
INFO:root:Train (Epoch 100): Loss/seq after 03600 batchs: 564.2299194335938
INFO:root:Train (Epoch 100): Loss/seq after 03650 batchs: 562.4229736328125
INFO:root:Train (Epoch 100): Loss/seq after 03700 batchs: 565.9149780273438
INFO:root:Train (Epoch 100): Loss/seq after 03750 batchs: 570.8955688476562
INFO:root:Train (Epoch 100): Loss/seq after 03800 batchs: 568.6572875976562
INFO:root:Train (Epoch 100): Loss/seq after 03850 batchs: 567.8877563476562
INFO:root:Train (Epoch 100): Loss/seq after 03900 batchs: 571.2626342773438
INFO:root:Train (Epoch 100): Loss/seq after 03950 batchs: 573.9786376953125
INFO:root:Train (Epoch 100): Loss/seq after 04000 batchs: 570.3036499023438
INFO:root:Train (Epoch 100): Loss/seq after 04050 batchs: 566.6223754882812
INFO:root:Train (Epoch 100): Loss/seq after 04100 batchs: 565.0478515625
INFO:root:Train (Epoch 100): Loss/seq after 04150 batchs: 565.1047973632812
INFO:root:Train (Epoch 100): Loss/seq after 04200 batchs: 563.9899291992188
INFO:root:Train (Epoch 100): Loss/seq after 04250 batchs: 562.3317260742188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 100): Loss/seq after 00000 batches: 480.7658996582031
INFO:root:# Valid (Epoch 100): Loss/seq after 00050 batches: 806.184326171875
INFO:root:# Valid (Epoch 100): Loss/seq after 00100 batches: 854.9920043945312
INFO:root:# Valid (Epoch 100): Loss/seq after 00150 batches: 638.5686645507812
INFO:root:# Valid (Epoch 100): Loss/seq after 00200 batches: 590.488037109375
INFO:root:Artifacts: Make stick videos for epoch 100
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_100_on_20220422_074546.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_100_index_111_on_20220422_074546.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 101): Loss/seq after 00000 batchs: 1058.540771484375
INFO:root:Train (Epoch 101): Loss/seq after 00050 batchs: 849.9012451171875
INFO:root:Train (Epoch 101): Loss/seq after 00100 batchs: 887.3131713867188
INFO:root:Train (Epoch 101): Loss/seq after 00150 batchs: 811.456787109375
INFO:root:Train (Epoch 101): Loss/seq after 00200 batchs: 883.7245483398438
INFO:root:Train (Epoch 101): Loss/seq after 00250 batchs: 1002.9990844726562
INFO:root:Train (Epoch 101): Loss/seq after 00300 batchs: 984.9237670898438
INFO:root:Train (Epoch 101): Loss/seq after 00350 batchs: 918.92431640625
INFO:root:Train (Epoch 101): Loss/seq after 00400 batchs: 911.0530395507812
INFO:root:Train (Epoch 101): Loss/seq after 00450 batchs: 886.7698364257812
INFO:root:Train (Epoch 101): Loss/seq after 00500 batchs: 862.5123291015625
INFO:root:Train (Epoch 101): Loss/seq after 00550 batchs: 834.1036987304688
INFO:root:Train (Epoch 101): Loss/seq after 00600 batchs: 801.3732299804688
INFO:root:Train (Epoch 101): Loss/seq after 00650 batchs: 769.6453247070312
INFO:root:Train (Epoch 101): Loss/seq after 00700 batchs: 737.06787109375
INFO:root:Train (Epoch 101): Loss/seq after 00750 batchs: 734.449462890625
INFO:root:Train (Epoch 101): Loss/seq after 00800 batchs: 734.2618408203125
INFO:root:Train (Epoch 101): Loss/seq after 00850 batchs: 711.6430053710938
INFO:root:Train (Epoch 101): Loss/seq after 00900 batchs: 694.3353271484375
INFO:root:Train (Epoch 101): Loss/seq after 00950 batchs: 689.020263671875
INFO:root:Train (Epoch 101): Loss/seq after 01000 batchs: 676.2742919921875
INFO:root:Train (Epoch 101): Loss/seq after 01050 batchs: 662.8483276367188
INFO:root:Train (Epoch 101): Loss/seq after 01100 batchs: 653.1239013671875
INFO:root:Train (Epoch 101): Loss/seq after 01150 batchs: 635.6106567382812
INFO:root:Train (Epoch 101): Loss/seq after 01200 batchs: 639.4461059570312
INFO:root:Train (Epoch 101): Loss/seq after 01250 batchs: 636.1292724609375
INFO:root:Train (Epoch 101): Loss/seq after 01300 batchs: 621.9622802734375
INFO:root:Train (Epoch 101): Loss/seq after 01350 batchs: 610.8372802734375
INFO:root:Train (Epoch 101): Loss/seq after 01400 batchs: 612.526611328125
INFO:root:Train (Epoch 101): Loss/seq after 01450 batchs: 614.1835327148438
INFO:root:Train (Epoch 101): Loss/seq after 01500 batchs: 620.7535400390625
INFO:root:Train (Epoch 101): Loss/seq after 01550 batchs: 623.136962890625
INFO:root:Train (Epoch 101): Loss/seq after 01600 batchs: 617.5732421875
INFO:root:Train (Epoch 101): Loss/seq after 01650 batchs: 615.134033203125
INFO:root:Train (Epoch 101): Loss/seq after 01700 batchs: 617.0765380859375
INFO:root:Train (Epoch 101): Loss/seq after 01750 batchs: 614.2520751953125
INFO:root:Train (Epoch 101): Loss/seq after 01800 batchs: 611.3997192382812
INFO:root:Train (Epoch 101): Loss/seq after 01850 batchs: 607.7006225585938
INFO:root:Train (Epoch 101): Loss/seq after 01900 batchs: 608.2742919921875
INFO:root:Train (Epoch 101): Loss/seq after 01950 batchs: 607.0781860351562
INFO:root:Train (Epoch 101): Loss/seq after 02000 batchs: 605.2261352539062
INFO:root:Train (Epoch 101): Loss/seq after 02050 batchs: 603.7850341796875
INFO:root:Train (Epoch 101): Loss/seq after 02100 batchs: 600.964111328125
INFO:root:Train (Epoch 101): Loss/seq after 02150 batchs: 598.7807006835938
INFO:root:Train (Epoch 101): Loss/seq after 02200 batchs: 595.8784790039062
INFO:root:Train (Epoch 101): Loss/seq after 02250 batchs: 594.8124389648438
INFO:root:Train (Epoch 101): Loss/seq after 02300 batchs: 589.5266723632812
INFO:root:Train (Epoch 101): Loss/seq after 02350 batchs: 584.9337158203125
INFO:root:Train (Epoch 101): Loss/seq after 02400 batchs: 585.5652465820312
INFO:root:Train (Epoch 101): Loss/seq after 02450 batchs: 580.6148681640625
INFO:root:Train (Epoch 101): Loss/seq after 02500 batchs: 571.7648315429688
INFO:root:Train (Epoch 101): Loss/seq after 02550 batchs: 564.693603515625
INFO:root:Train (Epoch 101): Loss/seq after 02600 batchs: 562.7149047851562
INFO:root:Train (Epoch 101): Loss/seq after 02650 batchs: 559.421142578125
INFO:root:Train (Epoch 101): Loss/seq after 02700 batchs: 556.3355712890625
INFO:root:Train (Epoch 101): Loss/seq after 02750 batchs: 551.6710205078125
INFO:root:Train (Epoch 101): Loss/seq after 02800 batchs: 550.6410522460938
INFO:root:Train (Epoch 101): Loss/seq after 02850 batchs: 550.761962890625
INFO:root:Train (Epoch 101): Loss/seq after 02900 batchs: 551.8259887695312
INFO:root:Train (Epoch 101): Loss/seq after 02950 batchs: 551.004638671875
INFO:root:Train (Epoch 101): Loss/seq after 03000 batchs: 556.2540283203125
INFO:root:Train (Epoch 101): Loss/seq after 03050 batchs: 558.1737670898438
INFO:root:Train (Epoch 101): Loss/seq after 03100 batchs: 562.2150268554688
INFO:root:Train (Epoch 101): Loss/seq after 03150 batchs: 563.1893310546875
INFO:root:Train (Epoch 101): Loss/seq after 03200 batchs: 563.1376342773438
INFO:root:Train (Epoch 101): Loss/seq after 03250 batchs: 565.0811767578125
INFO:root:Train (Epoch 101): Loss/seq after 03300 batchs: 564.4583740234375
INFO:root:Train (Epoch 101): Loss/seq after 03350 batchs: 563.8821411132812
INFO:root:Train (Epoch 101): Loss/seq after 03400 batchs: 559.2675170898438
INFO:root:Train (Epoch 101): Loss/seq after 03450 batchs: 557.9857788085938
INFO:root:Train (Epoch 101): Loss/seq after 03500 batchs: 559.4237060546875
INFO:root:Train (Epoch 101): Loss/seq after 03550 batchs: 557.005615234375
INFO:root:Train (Epoch 101): Loss/seq after 03600 batchs: 565.1491088867188
INFO:root:Train (Epoch 101): Loss/seq after 03650 batchs: 563.22607421875
INFO:root:Train (Epoch 101): Loss/seq after 03700 batchs: 565.8944702148438
INFO:root:Train (Epoch 101): Loss/seq after 03750 batchs: 570.938720703125
INFO:root:Train (Epoch 101): Loss/seq after 03800 batchs: 568.6856079101562
INFO:root:Train (Epoch 101): Loss/seq after 03850 batchs: 567.6937866210938
INFO:root:Train (Epoch 101): Loss/seq after 03900 batchs: 571.1156005859375
INFO:root:Train (Epoch 101): Loss/seq after 03950 batchs: 573.82421875
INFO:root:Train (Epoch 101): Loss/seq after 04000 batchs: 570.215087890625
INFO:root:Train (Epoch 101): Loss/seq after 04050 batchs: 566.52685546875
INFO:root:Train (Epoch 101): Loss/seq after 04100 batchs: 564.8201293945312
INFO:root:Train (Epoch 101): Loss/seq after 04150 batchs: 564.8294677734375
INFO:root:Train (Epoch 101): Loss/seq after 04200 batchs: 563.4191284179688
INFO:root:Train (Epoch 101): Loss/seq after 04250 batchs: 561.7088623046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 101): Loss/seq after 00000 batches: 482.7467041015625
INFO:root:# Valid (Epoch 101): Loss/seq after 00050 batches: 806.5950927734375
INFO:root:# Valid (Epoch 101): Loss/seq after 00100 batches: 842.4119873046875
INFO:root:# Valid (Epoch 101): Loss/seq after 00150 batches: 631.295166015625
INFO:root:# Valid (Epoch 101): Loss/seq after 00200 batches: 581.3983154296875
INFO:root:Artifacts: Make stick videos for epoch 101
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_101_on_20220422_075032.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_101_index_1660_on_20220422_075032.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 102): Loss/seq after 00000 batchs: 1027.40673828125
INFO:root:Train (Epoch 102): Loss/seq after 00050 batchs: 800.7803344726562
INFO:root:Train (Epoch 102): Loss/seq after 00100 batchs: 823.1488647460938
INFO:root:Train (Epoch 102): Loss/seq after 00150 batchs: 766.233154296875
INFO:root:Train (Epoch 102): Loss/seq after 00200 batchs: 843.5692138671875
INFO:root:Train (Epoch 102): Loss/seq after 00250 batchs: 963.75439453125
INFO:root:Train (Epoch 102): Loss/seq after 00300 batchs: 953.4144287109375
INFO:root:Train (Epoch 102): Loss/seq after 00350 batchs: 890.5916748046875
INFO:root:Train (Epoch 102): Loss/seq after 00400 batchs: 878.7985229492188
INFO:root:Train (Epoch 102): Loss/seq after 00450 batchs: 857.1962280273438
INFO:root:Train (Epoch 102): Loss/seq after 00500 batchs: 833.891845703125
INFO:root:Train (Epoch 102): Loss/seq after 00550 batchs: 806.9299926757812
INFO:root:Train (Epoch 102): Loss/seq after 00600 batchs: 779.8885498046875
INFO:root:Train (Epoch 102): Loss/seq after 00650 batchs: 754.4238891601562
INFO:root:Train (Epoch 102): Loss/seq after 00700 batchs: 723.2543334960938
INFO:root:Train (Epoch 102): Loss/seq after 00750 batchs: 724.3097534179688
INFO:root:Train (Epoch 102): Loss/seq after 00800 batchs: 725.9979858398438
INFO:root:Train (Epoch 102): Loss/seq after 00850 batchs: 702.4693603515625
INFO:root:Train (Epoch 102): Loss/seq after 00900 batchs: 685.7385864257812
INFO:root:Train (Epoch 102): Loss/seq after 00950 batchs: 680.82275390625
INFO:root:Train (Epoch 102): Loss/seq after 01000 batchs: 667.8699340820312
INFO:root:Train (Epoch 102): Loss/seq after 01050 batchs: 654.3170166015625
INFO:root:Train (Epoch 102): Loss/seq after 01100 batchs: 644.3963623046875
INFO:root:Train (Epoch 102): Loss/seq after 01150 batchs: 627.2009887695312
INFO:root:Train (Epoch 102): Loss/seq after 01200 batchs: 631.3216552734375
INFO:root:Train (Epoch 102): Loss/seq after 01250 batchs: 628.2965087890625
INFO:root:Train (Epoch 102): Loss/seq after 01300 batchs: 614.7525634765625
INFO:root:Train (Epoch 102): Loss/seq after 01350 batchs: 603.878662109375
INFO:root:Train (Epoch 102): Loss/seq after 01400 batchs: 605.448486328125
INFO:root:Train (Epoch 102): Loss/seq after 01450 batchs: 607.0496826171875
INFO:root:Train (Epoch 102): Loss/seq after 01500 batchs: 613.7916870117188
INFO:root:Train (Epoch 102): Loss/seq after 01550 batchs: 616.6566772460938
INFO:root:Train (Epoch 102): Loss/seq after 01600 batchs: 612.0988159179688
INFO:root:Train (Epoch 102): Loss/seq after 01650 batchs: 610.2199096679688
INFO:root:Train (Epoch 102): Loss/seq after 01700 batchs: 612.7587890625
INFO:root:Train (Epoch 102): Loss/seq after 01750 batchs: 609.740234375
INFO:root:Train (Epoch 102): Loss/seq after 01800 batchs: 607.09033203125
INFO:root:Train (Epoch 102): Loss/seq after 01850 batchs: 603.6300048828125
INFO:root:Train (Epoch 102): Loss/seq after 01900 batchs: 604.4036865234375
INFO:root:Train (Epoch 102): Loss/seq after 01950 batchs: 602.8845825195312
INFO:root:Train (Epoch 102): Loss/seq after 02000 batchs: 601.7688598632812
INFO:root:Train (Epoch 102): Loss/seq after 02050 batchs: 600.422119140625
INFO:root:Train (Epoch 102): Loss/seq after 02100 batchs: 597.5628662109375
INFO:root:Train (Epoch 102): Loss/seq after 02150 batchs: 595.705322265625
INFO:root:Train (Epoch 102): Loss/seq after 02200 batchs: 592.83447265625
INFO:root:Train (Epoch 102): Loss/seq after 02250 batchs: 591.8285522460938
INFO:root:Train (Epoch 102): Loss/seq after 02300 batchs: 587.1593017578125
INFO:root:Train (Epoch 102): Loss/seq after 02350 batchs: 582.3028564453125
INFO:root:Train (Epoch 102): Loss/seq after 02400 batchs: 583.1958618164062
INFO:root:Train (Epoch 102): Loss/seq after 02450 batchs: 578.1964721679688
INFO:root:Train (Epoch 102): Loss/seq after 02500 batchs: 569.4215087890625
INFO:root:Train (Epoch 102): Loss/seq after 02550 batchs: 562.1837158203125
INFO:root:Train (Epoch 102): Loss/seq after 02600 batchs: 560.0602416992188
INFO:root:Train (Epoch 102): Loss/seq after 02650 batchs: 556.636962890625
INFO:root:Train (Epoch 102): Loss/seq after 02700 batchs: 553.4576416015625
INFO:root:Train (Epoch 102): Loss/seq after 02750 batchs: 548.977783203125
INFO:root:Train (Epoch 102): Loss/seq after 02800 batchs: 548.2318115234375
INFO:root:Train (Epoch 102): Loss/seq after 02850 batchs: 548.4172973632812
INFO:root:Train (Epoch 102): Loss/seq after 02900 batchs: 549.2861328125
INFO:root:Train (Epoch 102): Loss/seq after 02950 batchs: 548.4193725585938
INFO:root:Train (Epoch 102): Loss/seq after 03000 batchs: 553.8012084960938
INFO:root:Train (Epoch 102): Loss/seq after 03050 batchs: 555.7999877929688
INFO:root:Train (Epoch 102): Loss/seq after 03100 batchs: 559.4725952148438
INFO:root:Train (Epoch 102): Loss/seq after 03150 batchs: 560.0952758789062
INFO:root:Train (Epoch 102): Loss/seq after 03200 batchs: 560.3110961914062
INFO:root:Train (Epoch 102): Loss/seq after 03250 batchs: 563.0327758789062
INFO:root:Train (Epoch 102): Loss/seq after 03300 batchs: 562.7352294921875
INFO:root:Train (Epoch 102): Loss/seq after 03350 batchs: 562.9111328125
INFO:root:Train (Epoch 102): Loss/seq after 03400 batchs: 558.4069213867188
INFO:root:Train (Epoch 102): Loss/seq after 03450 batchs: 557.0925903320312
INFO:root:Train (Epoch 102): Loss/seq after 03500 batchs: 558.3421630859375
INFO:root:Train (Epoch 102): Loss/seq after 03550 batchs: 555.8831787109375
INFO:root:Train (Epoch 102): Loss/seq after 03600 batchs: 564.2526245117188
INFO:root:Train (Epoch 102): Loss/seq after 03650 batchs: 561.990234375
INFO:root:Train (Epoch 102): Loss/seq after 03700 batchs: 564.687744140625
INFO:root:Train (Epoch 102): Loss/seq after 03750 batchs: 569.5211181640625
INFO:root:Train (Epoch 102): Loss/seq after 03800 batchs: 567.2142333984375
INFO:root:Train (Epoch 102): Loss/seq after 03850 batchs: 566.279541015625
INFO:root:Train (Epoch 102): Loss/seq after 03900 batchs: 570.1217651367188
INFO:root:Train (Epoch 102): Loss/seq after 03950 batchs: 572.9263305664062
INFO:root:Train (Epoch 102): Loss/seq after 04000 batchs: 569.2366943359375
INFO:root:Train (Epoch 102): Loss/seq after 04050 batchs: 565.5205078125
INFO:root:Train (Epoch 102): Loss/seq after 04100 batchs: 563.8767700195312
INFO:root:Train (Epoch 102): Loss/seq after 04150 batchs: 563.8563232421875
INFO:root:Train (Epoch 102): Loss/seq after 04200 batchs: 562.54052734375
INFO:root:Train (Epoch 102): Loss/seq after 04250 batchs: 560.7918701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 102): Loss/seq after 00000 batches: 500.722412109375
INFO:root:# Valid (Epoch 102): Loss/seq after 00050 batches: 745.1295166015625
INFO:root:# Valid (Epoch 102): Loss/seq after 00100 batches: 771.8574829101562
INFO:root:# Valid (Epoch 102): Loss/seq after 00150 batches: 582.0810546875
INFO:root:# Valid (Epoch 102): Loss/seq after 00200 batches: 541.5386962890625
INFO:root:Artifacts: Make stick videos for epoch 102
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_102_on_20220422_075526.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_102_index_1109_on_20220422_075526.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 103): Loss/seq after 00000 batchs: 1066.6025390625
INFO:root:Train (Epoch 103): Loss/seq after 00050 batchs: 799.9329223632812
INFO:root:Train (Epoch 103): Loss/seq after 00100 batchs: 807.5733642578125
INFO:root:Train (Epoch 103): Loss/seq after 00150 batchs: 751.3599243164062
INFO:root:Train (Epoch 103): Loss/seq after 00200 batchs: 812.3197631835938
INFO:root:Train (Epoch 103): Loss/seq after 00250 batchs: 936.3530883789062
INFO:root:Train (Epoch 103): Loss/seq after 00300 batchs: 929.132568359375
INFO:root:Train (Epoch 103): Loss/seq after 00350 batchs: 865.2925415039062
INFO:root:Train (Epoch 103): Loss/seq after 00400 batchs: 855.8165893554688
INFO:root:Train (Epoch 103): Loss/seq after 00450 batchs: 837.0933837890625
INFO:root:Train (Epoch 103): Loss/seq after 00500 batchs: 813.4339599609375
INFO:root:Train (Epoch 103): Loss/seq after 00550 batchs: 787.9271850585938
INFO:root:Train (Epoch 103): Loss/seq after 00600 batchs: 759.0697631835938
INFO:root:Train (Epoch 103): Loss/seq after 00650 batchs: 731.9960327148438
INFO:root:Train (Epoch 103): Loss/seq after 00700 batchs: 702.5284423828125
INFO:root:Train (Epoch 103): Loss/seq after 00750 batchs: 704.1221313476562
INFO:root:Train (Epoch 103): Loss/seq after 00800 batchs: 705.001220703125
INFO:root:Train (Epoch 103): Loss/seq after 00850 batchs: 682.4690551757812
INFO:root:Train (Epoch 103): Loss/seq after 00900 batchs: 665.896484375
INFO:root:Train (Epoch 103): Loss/seq after 00950 batchs: 660.8153686523438
INFO:root:Train (Epoch 103): Loss/seq after 01000 batchs: 648.781005859375
INFO:root:Train (Epoch 103): Loss/seq after 01050 batchs: 635.0399169921875
INFO:root:Train (Epoch 103): Loss/seq after 01100 batchs: 624.9100952148438
INFO:root:Train (Epoch 103): Loss/seq after 01150 batchs: 608.2464599609375
INFO:root:Train (Epoch 103): Loss/seq after 01200 batchs: 612.8628540039062
INFO:root:Train (Epoch 103): Loss/seq after 01250 batchs: 610.4517211914062
INFO:root:Train (Epoch 103): Loss/seq after 01300 batchs: 597.54052734375
INFO:root:Train (Epoch 103): Loss/seq after 01350 batchs: 587.1204223632812
INFO:root:Train (Epoch 103): Loss/seq after 01400 batchs: 589.9397583007812
INFO:root:Train (Epoch 103): Loss/seq after 01450 batchs: 592.0997314453125
INFO:root:Train (Epoch 103): Loss/seq after 01500 batchs: 599.346435546875
INFO:root:Train (Epoch 103): Loss/seq after 01550 batchs: 602.4563598632812
INFO:root:Train (Epoch 103): Loss/seq after 01600 batchs: 597.8720703125
INFO:root:Train (Epoch 103): Loss/seq after 01650 batchs: 596.451904296875
INFO:root:Train (Epoch 103): Loss/seq after 01700 batchs: 599.2384643554688
INFO:root:Train (Epoch 103): Loss/seq after 01750 batchs: 596.5261840820312
INFO:root:Train (Epoch 103): Loss/seq after 01800 batchs: 593.9259033203125
INFO:root:Train (Epoch 103): Loss/seq after 01850 batchs: 590.646728515625
INFO:root:Train (Epoch 103): Loss/seq after 01900 batchs: 591.2522583007812
INFO:root:Train (Epoch 103): Loss/seq after 01950 batchs: 589.6541748046875
INFO:root:Train (Epoch 103): Loss/seq after 02000 batchs: 588.6317749023438
INFO:root:Train (Epoch 103): Loss/seq after 02050 batchs: 587.4528198242188
INFO:root:Train (Epoch 103): Loss/seq after 02100 batchs: 585.12060546875
INFO:root:Train (Epoch 103): Loss/seq after 02150 batchs: 583.232666015625
INFO:root:Train (Epoch 103): Loss/seq after 02200 batchs: 580.5630493164062
INFO:root:Train (Epoch 103): Loss/seq after 02250 batchs: 579.7152099609375
INFO:root:Train (Epoch 103): Loss/seq after 02300 batchs: 575.3298950195312
INFO:root:Train (Epoch 103): Loss/seq after 02350 batchs: 570.8142700195312
INFO:root:Train (Epoch 103): Loss/seq after 02400 batchs: 571.96875
INFO:root:Train (Epoch 103): Loss/seq after 02450 batchs: 567.2219848632812
INFO:root:Train (Epoch 103): Loss/seq after 02500 batchs: 558.6034545898438
INFO:root:Train (Epoch 103): Loss/seq after 02550 batchs: 551.5814819335938
INFO:root:Train (Epoch 103): Loss/seq after 02600 batchs: 549.6484375
INFO:root:Train (Epoch 103): Loss/seq after 02650 batchs: 546.36474609375
INFO:root:Train (Epoch 103): Loss/seq after 02700 batchs: 543.3088989257812
INFO:root:Train (Epoch 103): Loss/seq after 02750 batchs: 540.124267578125
INFO:root:Train (Epoch 103): Loss/seq after 02800 batchs: 539.7684936523438
INFO:root:Train (Epoch 103): Loss/seq after 02850 batchs: 540.1664428710938
INFO:root:Train (Epoch 103): Loss/seq after 02900 batchs: 541.1121215820312
INFO:root:Train (Epoch 103): Loss/seq after 02950 batchs: 540.4667358398438
INFO:root:Train (Epoch 103): Loss/seq after 03000 batchs: 545.8189086914062
INFO:root:Train (Epoch 103): Loss/seq after 03050 batchs: 548.4595336914062
INFO:root:Train (Epoch 103): Loss/seq after 03100 batchs: 552.0980834960938
INFO:root:Train (Epoch 103): Loss/seq after 03150 batchs: 552.6641845703125
INFO:root:Train (Epoch 103): Loss/seq after 03200 batchs: 553.3314819335938
INFO:root:Train (Epoch 103): Loss/seq after 03250 batchs: 555.034912109375
INFO:root:Train (Epoch 103): Loss/seq after 03300 batchs: 554.4730834960938
INFO:root:Train (Epoch 103): Loss/seq after 03350 batchs: 553.9039916992188
INFO:root:Train (Epoch 103): Loss/seq after 03400 batchs: 549.3738403320312
INFO:root:Train (Epoch 103): Loss/seq after 03450 batchs: 548.2820434570312
INFO:root:Train (Epoch 103): Loss/seq after 03500 batchs: 549.3694458007812
INFO:root:Train (Epoch 103): Loss/seq after 03550 batchs: 546.8916625976562
INFO:root:Train (Epoch 103): Loss/seq after 03600 batchs: 555.0873413085938
INFO:root:Train (Epoch 103): Loss/seq after 03650 batchs: 552.7362060546875
INFO:root:Train (Epoch 103): Loss/seq after 03700 batchs: 555.453857421875
INFO:root:Train (Epoch 103): Loss/seq after 03750 batchs: 560.5328369140625
INFO:root:Train (Epoch 103): Loss/seq after 03800 batchs: 558.3261108398438
INFO:root:Train (Epoch 103): Loss/seq after 03850 batchs: 557.3878784179688
INFO:root:Train (Epoch 103): Loss/seq after 03900 batchs: 560.7505493164062
INFO:root:Train (Epoch 103): Loss/seq after 03950 batchs: 563.40380859375
INFO:root:Train (Epoch 103): Loss/seq after 04000 batchs: 559.8441162109375
INFO:root:Train (Epoch 103): Loss/seq after 04050 batchs: 556.2376708984375
INFO:root:Train (Epoch 103): Loss/seq after 04100 batchs: 554.7178955078125
INFO:root:Train (Epoch 103): Loss/seq after 04150 batchs: 554.761474609375
INFO:root:Train (Epoch 103): Loss/seq after 04200 batchs: 553.445556640625
INFO:root:Train (Epoch 103): Loss/seq after 04250 batchs: 551.7125244140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 103): Loss/seq after 00000 batches: 489.6212463378906
INFO:root:# Valid (Epoch 103): Loss/seq after 00050 batches: 741.8097534179688
INFO:root:# Valid (Epoch 103): Loss/seq after 00100 batches: 775.1218872070312
INFO:root:# Valid (Epoch 103): Loss/seq after 00150 batches: 582.2557983398438
INFO:root:# Valid (Epoch 103): Loss/seq after 00200 batches: 544.34228515625
INFO:root:Artifacts: Make stick videos for epoch 103
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_103_on_20220422_080025.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_103_index_546_on_20220422_080025.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 104): Loss/seq after 00000 batchs: 1090.3974609375
INFO:root:Train (Epoch 104): Loss/seq after 00050 batchs: 816.9871826171875
INFO:root:Train (Epoch 104): Loss/seq after 00100 batchs: 816.9600830078125
INFO:root:Train (Epoch 104): Loss/seq after 00150 batchs: 748.1113891601562
INFO:root:Train (Epoch 104): Loss/seq after 00200 batchs: 813.3045654296875
INFO:root:Train (Epoch 104): Loss/seq after 00250 batchs: 933.3670654296875
INFO:root:Train (Epoch 104): Loss/seq after 00300 batchs: 924.7008666992188
INFO:root:Train (Epoch 104): Loss/seq after 00350 batchs: 862.0469970703125
INFO:root:Train (Epoch 104): Loss/seq after 00400 batchs: 848.1056518554688
INFO:root:Train (Epoch 104): Loss/seq after 00450 batchs: 829.1205444335938
INFO:root:Train (Epoch 104): Loss/seq after 00500 batchs: 805.1552124023438
INFO:root:Train (Epoch 104): Loss/seq after 00550 batchs: 780.0892333984375
INFO:root:Train (Epoch 104): Loss/seq after 00600 batchs: 751.7677001953125
INFO:root:Train (Epoch 104): Loss/seq after 00650 batchs: 725.6421508789062
INFO:root:Train (Epoch 104): Loss/seq after 00700 batchs: 696.1318359375
INFO:root:Train (Epoch 104): Loss/seq after 00750 batchs: 701.6873779296875
INFO:root:Train (Epoch 104): Loss/seq after 00800 batchs: 704.115234375
INFO:root:Train (Epoch 104): Loss/seq after 00850 batchs: 682.0360717773438
INFO:root:Train (Epoch 104): Loss/seq after 00900 batchs: 665.6068725585938
INFO:root:Train (Epoch 104): Loss/seq after 00950 batchs: 658.928466796875
INFO:root:Train (Epoch 104): Loss/seq after 01000 batchs: 646.9701538085938
INFO:root:Train (Epoch 104): Loss/seq after 01050 batchs: 632.9578247070312
INFO:root:Train (Epoch 104): Loss/seq after 01100 batchs: 622.2610473632812
INFO:root:Train (Epoch 104): Loss/seq after 01150 batchs: 605.2957153320312
INFO:root:Train (Epoch 104): Loss/seq after 01200 batchs: 609.7137451171875
INFO:root:Train (Epoch 104): Loss/seq after 01250 batchs: 607.1976928710938
INFO:root:Train (Epoch 104): Loss/seq after 01300 batchs: 594.1295776367188
INFO:root:Train (Epoch 104): Loss/seq after 01350 batchs: 583.1898803710938
INFO:root:Train (Epoch 104): Loss/seq after 01400 batchs: 586.1148071289062
INFO:root:Train (Epoch 104): Loss/seq after 01450 batchs: 588.2200317382812
INFO:root:Train (Epoch 104): Loss/seq after 01500 batchs: 595.4676513671875
INFO:root:Train (Epoch 104): Loss/seq after 01550 batchs: 598.120361328125
INFO:root:Train (Epoch 104): Loss/seq after 01600 batchs: 593.2144165039062
INFO:root:Train (Epoch 104): Loss/seq after 01650 batchs: 591.7120971679688
INFO:root:Train (Epoch 104): Loss/seq after 01700 batchs: 594.1776123046875
INFO:root:Train (Epoch 104): Loss/seq after 01750 batchs: 591.7139282226562
INFO:root:Train (Epoch 104): Loss/seq after 01800 batchs: 589.3948364257812
INFO:root:Train (Epoch 104): Loss/seq after 01850 batchs: 586.145751953125
INFO:root:Train (Epoch 104): Loss/seq after 01900 batchs: 586.638671875
INFO:root:Train (Epoch 104): Loss/seq after 01950 batchs: 584.8736572265625
INFO:root:Train (Epoch 104): Loss/seq after 02000 batchs: 584.1560668945312
INFO:root:Train (Epoch 104): Loss/seq after 02050 batchs: 583.0857543945312
INFO:root:Train (Epoch 104): Loss/seq after 02100 batchs: 580.441650390625
INFO:root:Train (Epoch 104): Loss/seq after 02150 batchs: 578.7149658203125
INFO:root:Train (Epoch 104): Loss/seq after 02200 batchs: 576.1492309570312
INFO:root:Train (Epoch 104): Loss/seq after 02250 batchs: 575.502685546875
INFO:root:Train (Epoch 104): Loss/seq after 02300 batchs: 570.9937133789062
INFO:root:Train (Epoch 104): Loss/seq after 02350 batchs: 566.8978881835938
INFO:root:Train (Epoch 104): Loss/seq after 02400 batchs: 568.0635986328125
INFO:root:Train (Epoch 104): Loss/seq after 02450 batchs: 563.4011840820312
INFO:root:Train (Epoch 104): Loss/seq after 02500 batchs: 554.8012084960938
INFO:root:Train (Epoch 104): Loss/seq after 02550 batchs: 547.8126220703125
INFO:root:Train (Epoch 104): Loss/seq after 02600 batchs: 545.58349609375
INFO:root:Train (Epoch 104): Loss/seq after 02650 batchs: 542.3663940429688
INFO:root:Train (Epoch 104): Loss/seq after 02700 batchs: 539.4177856445312
INFO:root:Train (Epoch 104): Loss/seq after 02750 batchs: 535.1846313476562
INFO:root:Train (Epoch 104): Loss/seq after 02800 batchs: 535.06591796875
INFO:root:Train (Epoch 104): Loss/seq after 02850 batchs: 535.49755859375
INFO:root:Train (Epoch 104): Loss/seq after 02900 batchs: 537.2891235351562
INFO:root:Train (Epoch 104): Loss/seq after 02950 batchs: 536.644287109375
INFO:root:Train (Epoch 104): Loss/seq after 03000 batchs: 542.1690063476562
INFO:root:Train (Epoch 104): Loss/seq after 03050 batchs: 544.2962646484375
INFO:root:Train (Epoch 104): Loss/seq after 03100 batchs: 548.5936889648438
INFO:root:Train (Epoch 104): Loss/seq after 03150 batchs: 548.7427368164062
INFO:root:Train (Epoch 104): Loss/seq after 03200 batchs: 549.1748657226562
INFO:root:Train (Epoch 104): Loss/seq after 03250 batchs: 551.6265258789062
INFO:root:Train (Epoch 104): Loss/seq after 03300 batchs: 550.6779174804688
INFO:root:Train (Epoch 104): Loss/seq after 03350 batchs: 549.9685668945312
INFO:root:Train (Epoch 104): Loss/seq after 03400 batchs: 545.5350341796875
INFO:root:Train (Epoch 104): Loss/seq after 03450 batchs: 544.442138671875
INFO:root:Train (Epoch 104): Loss/seq after 03500 batchs: 545.6088256835938
INFO:root:Train (Epoch 104): Loss/seq after 03550 batchs: 543.17724609375
INFO:root:Train (Epoch 104): Loss/seq after 03600 batchs: 551.2508544921875
INFO:root:Train (Epoch 104): Loss/seq after 03650 batchs: 548.9876708984375
INFO:root:Train (Epoch 104): Loss/seq after 03700 batchs: 551.5534057617188
INFO:root:Train (Epoch 104): Loss/seq after 03750 batchs: 556.5174560546875
INFO:root:Train (Epoch 104): Loss/seq after 03800 batchs: 554.360107421875
INFO:root:Train (Epoch 104): Loss/seq after 03850 batchs: 553.311767578125
INFO:root:Train (Epoch 104): Loss/seq after 03900 batchs: 556.6807861328125
INFO:root:Train (Epoch 104): Loss/seq after 03950 batchs: 559.5541381835938
INFO:root:Train (Epoch 104): Loss/seq after 04000 batchs: 555.9797973632812
INFO:root:Train (Epoch 104): Loss/seq after 04050 batchs: 552.415283203125
INFO:root:Train (Epoch 104): Loss/seq after 04100 batchs: 550.8917236328125
INFO:root:Train (Epoch 104): Loss/seq after 04150 batchs: 551.0034790039062
INFO:root:Train (Epoch 104): Loss/seq after 04200 batchs: 549.597412109375
INFO:root:Train (Epoch 104): Loss/seq after 04250 batchs: 547.9725952148438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 104): Loss/seq after 00000 batches: 500.0852355957031
INFO:root:# Valid (Epoch 104): Loss/seq after 00050 batches: 695.9924926757812
INFO:root:# Valid (Epoch 104): Loss/seq after 00100 batches: 741.001220703125
INFO:root:# Valid (Epoch 104): Loss/seq after 00150 batches: 559.1043090820312
INFO:root:# Valid (Epoch 104): Loss/seq after 00200 batches: 525.1522216796875
INFO:root:Artifacts: Make stick videos for epoch 104
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_104_on_20220422_080527.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_104_index_1122_on_20220422_080527.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 105): Loss/seq after 00000 batchs: 908.94091796875
INFO:root:Train (Epoch 105): Loss/seq after 00050 batchs: 788.9635009765625
INFO:root:Train (Epoch 105): Loss/seq after 00100 batchs: 822.31591796875
INFO:root:Train (Epoch 105): Loss/seq after 00150 batchs: 760.3265991210938
INFO:root:Train (Epoch 105): Loss/seq after 00200 batchs: 818.9190673828125
INFO:root:Train (Epoch 105): Loss/seq after 00250 batchs: 931.8619384765625
INFO:root:Train (Epoch 105): Loss/seq after 00300 batchs: 923.2999267578125
INFO:root:Train (Epoch 105): Loss/seq after 00350 batchs: 861.239501953125
INFO:root:Train (Epoch 105): Loss/seq after 00400 batchs: 848.073974609375
INFO:root:Train (Epoch 105): Loss/seq after 00450 batchs: 829.3215942382812
INFO:root:Train (Epoch 105): Loss/seq after 00500 batchs: 798.7485961914062
INFO:root:Train (Epoch 105): Loss/seq after 00550 batchs: 772.7239990234375
INFO:root:Train (Epoch 105): Loss/seq after 00600 batchs: 745.5437622070312
INFO:root:Train (Epoch 105): Loss/seq after 00650 batchs: 717.4854125976562
INFO:root:Train (Epoch 105): Loss/seq after 00700 batchs: 687.6253662109375
INFO:root:Train (Epoch 105): Loss/seq after 00750 batchs: 685.8916625976562
INFO:root:Train (Epoch 105): Loss/seq after 00800 batchs: 690.037353515625
INFO:root:Train (Epoch 105): Loss/seq after 00850 batchs: 668.9285888671875
INFO:root:Train (Epoch 105): Loss/seq after 00900 batchs: 653.892822265625
INFO:root:Train (Epoch 105): Loss/seq after 00950 batchs: 649.9559326171875
INFO:root:Train (Epoch 105): Loss/seq after 01000 batchs: 638.9907836914062
INFO:root:Train (Epoch 105): Loss/seq after 01050 batchs: 630.6626586914062
INFO:root:Train (Epoch 105): Loss/seq after 01100 batchs: 621.8856811523438
INFO:root:Train (Epoch 105): Loss/seq after 01150 batchs: 605.1851806640625
INFO:root:Train (Epoch 105): Loss/seq after 01200 batchs: 609.725830078125
INFO:root:Train (Epoch 105): Loss/seq after 01250 batchs: 607.6741943359375
INFO:root:Train (Epoch 105): Loss/seq after 01300 batchs: 594.91162109375
INFO:root:Train (Epoch 105): Loss/seq after 01350 batchs: 584.3175048828125
INFO:root:Train (Epoch 105): Loss/seq after 01400 batchs: 586.5143432617188
INFO:root:Train (Epoch 105): Loss/seq after 01450 batchs: 588.8504638671875
INFO:root:Train (Epoch 105): Loss/seq after 01500 batchs: 596.08203125
INFO:root:Train (Epoch 105): Loss/seq after 01550 batchs: 599.1672973632812
INFO:root:Train (Epoch 105): Loss/seq after 01600 batchs: 594.7366943359375
INFO:root:Train (Epoch 105): Loss/seq after 01650 batchs: 593.2213134765625
INFO:root:Train (Epoch 105): Loss/seq after 01700 batchs: 595.6593627929688
INFO:root:Train (Epoch 105): Loss/seq after 01750 batchs: 592.9033813476562
INFO:root:Train (Epoch 105): Loss/seq after 01800 batchs: 590.6409301757812
INFO:root:Train (Epoch 105): Loss/seq after 01850 batchs: 587.0917358398438
INFO:root:Train (Epoch 105): Loss/seq after 01900 batchs: 587.765869140625
INFO:root:Train (Epoch 105): Loss/seq after 01950 batchs: 586.2435913085938
INFO:root:Train (Epoch 105): Loss/seq after 02000 batchs: 585.3027954101562
INFO:root:Train (Epoch 105): Loss/seq after 02050 batchs: 584.2965087890625
INFO:root:Train (Epoch 105): Loss/seq after 02100 batchs: 581.8600463867188
INFO:root:Train (Epoch 105): Loss/seq after 02150 batchs: 579.984130859375
INFO:root:Train (Epoch 105): Loss/seq after 02200 batchs: 577.172119140625
INFO:root:Train (Epoch 105): Loss/seq after 02250 batchs: 576.329345703125
INFO:root:Train (Epoch 105): Loss/seq after 02300 batchs: 571.7607421875
INFO:root:Train (Epoch 105): Loss/seq after 02350 batchs: 567.6019897460938
INFO:root:Train (Epoch 105): Loss/seq after 02400 batchs: 568.3783569335938
INFO:root:Train (Epoch 105): Loss/seq after 02450 batchs: 563.639404296875
INFO:root:Train (Epoch 105): Loss/seq after 02500 batchs: 555.0335693359375
INFO:root:Train (Epoch 105): Loss/seq after 02550 batchs: 548.0923461914062
INFO:root:Train (Epoch 105): Loss/seq after 02600 batchs: 546.0333251953125
INFO:root:Train (Epoch 105): Loss/seq after 02650 batchs: 542.6151733398438
INFO:root:Train (Epoch 105): Loss/seq after 02700 batchs: 539.6102905273438
INFO:root:Train (Epoch 105): Loss/seq after 02750 batchs: 534.8334350585938
INFO:root:Train (Epoch 105): Loss/seq after 02800 batchs: 533.9071044921875
INFO:root:Train (Epoch 105): Loss/seq after 02850 batchs: 534.2494506835938
INFO:root:Train (Epoch 105): Loss/seq after 02900 batchs: 536.2920532226562
INFO:root:Train (Epoch 105): Loss/seq after 02950 batchs: 535.6149291992188
INFO:root:Train (Epoch 105): Loss/seq after 03000 batchs: 540.9625854492188
INFO:root:Train (Epoch 105): Loss/seq after 03050 batchs: 543.1047973632812
INFO:root:Train (Epoch 105): Loss/seq after 03100 batchs: 546.6693115234375
INFO:root:Train (Epoch 105): Loss/seq after 03150 batchs: 548.2132568359375
INFO:root:Train (Epoch 105): Loss/seq after 03200 batchs: 548.7828979492188
INFO:root:Train (Epoch 105): Loss/seq after 03250 batchs: 550.0286254882812
INFO:root:Train (Epoch 105): Loss/seq after 03300 batchs: 550.7622680664062
INFO:root:Train (Epoch 105): Loss/seq after 03350 batchs: 550.7918701171875
INFO:root:Train (Epoch 105): Loss/seq after 03400 batchs: 546.3858032226562
INFO:root:Train (Epoch 105): Loss/seq after 03450 batchs: 545.123046875
INFO:root:Train (Epoch 105): Loss/seq after 03500 batchs: 547.029052734375
INFO:root:Train (Epoch 105): Loss/seq after 03550 batchs: 545.3591918945312
INFO:root:Train (Epoch 105): Loss/seq after 03600 batchs: 553.860595703125
INFO:root:Train (Epoch 105): Loss/seq after 03650 batchs: 551.5360717773438
INFO:root:Train (Epoch 105): Loss/seq after 03700 batchs: 554.2091064453125
INFO:root:Train (Epoch 105): Loss/seq after 03750 batchs: 559.1414184570312
INFO:root:Train (Epoch 105): Loss/seq after 03800 batchs: 556.9603271484375
INFO:root:Train (Epoch 105): Loss/seq after 03850 batchs: 556.0101318359375
INFO:root:Train (Epoch 105): Loss/seq after 03900 batchs: 559.3193359375
INFO:root:Train (Epoch 105): Loss/seq after 03950 batchs: 561.8129272460938
INFO:root:Train (Epoch 105): Loss/seq after 04000 batchs: 558.228271484375
INFO:root:Train (Epoch 105): Loss/seq after 04050 batchs: 554.671142578125
INFO:root:Train (Epoch 105): Loss/seq after 04100 batchs: 553.0670776367188
INFO:root:Train (Epoch 105): Loss/seq after 04150 batchs: 553.1867065429688
INFO:root:Train (Epoch 105): Loss/seq after 04200 batchs: 551.8707275390625
INFO:root:Train (Epoch 105): Loss/seq after 04250 batchs: 550.2264404296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 105): Loss/seq after 00000 batches: 502.0831298828125
INFO:root:# Valid (Epoch 105): Loss/seq after 00050 batches: 795.1809692382812
INFO:root:# Valid (Epoch 105): Loss/seq after 00100 batches: 832.8009033203125
INFO:root:# Valid (Epoch 105): Loss/seq after 00150 batches: 631.4646606445312
INFO:root:# Valid (Epoch 105): Loss/seq after 00200 batches: 586.09423828125
INFO:root:Artifacts: Make stick videos for epoch 105
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_105_on_20220422_081014.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_105_index_322_on_20220422_081014.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 106): Loss/seq after 00000 batchs: 1096.862060546875
INFO:root:Train (Epoch 106): Loss/seq after 00050 batchs: 787.3514404296875
INFO:root:Train (Epoch 106): Loss/seq after 00100 batchs: 808.8960571289062
INFO:root:Train (Epoch 106): Loss/seq after 00150 batchs: 740.0450439453125
INFO:root:Train (Epoch 106): Loss/seq after 00200 batchs: 809.3145141601562
INFO:root:Train (Epoch 106): Loss/seq after 00250 batchs: 930.7015991210938
INFO:root:Train (Epoch 106): Loss/seq after 00300 batchs: 922.9888916015625
INFO:root:Train (Epoch 106): Loss/seq after 00350 batchs: 862.4739379882812
INFO:root:Train (Epoch 106): Loss/seq after 00400 batchs: 849.59375
INFO:root:Train (Epoch 106): Loss/seq after 00450 batchs: 831.314697265625
INFO:root:Train (Epoch 106): Loss/seq after 00500 batchs: 810.1238403320312
INFO:root:Train (Epoch 106): Loss/seq after 00550 batchs: 783.8927612304688
INFO:root:Train (Epoch 106): Loss/seq after 00600 batchs: 756.0753173828125
INFO:root:Train (Epoch 106): Loss/seq after 00650 batchs: 730.2328491210938
INFO:root:Train (Epoch 106): Loss/seq after 00700 batchs: 700.134521484375
INFO:root:Train (Epoch 106): Loss/seq after 00750 batchs: 702.5878295898438
INFO:root:Train (Epoch 106): Loss/seq after 00800 batchs: 707.5631713867188
INFO:root:Train (Epoch 106): Loss/seq after 00850 batchs: 684.8245239257812
INFO:root:Train (Epoch 106): Loss/seq after 00900 batchs: 668.5245361328125
INFO:root:Train (Epoch 106): Loss/seq after 00950 batchs: 662.9300537109375
INFO:root:Train (Epoch 106): Loss/seq after 01000 batchs: 649.7882690429688
INFO:root:Train (Epoch 106): Loss/seq after 01050 batchs: 635.4556884765625
INFO:root:Train (Epoch 106): Loss/seq after 01100 batchs: 625.378662109375
INFO:root:Train (Epoch 106): Loss/seq after 01150 batchs: 608.6801147460938
INFO:root:Train (Epoch 106): Loss/seq after 01200 batchs: 612.8411254882812
INFO:root:Train (Epoch 106): Loss/seq after 01250 batchs: 609.9725341796875
INFO:root:Train (Epoch 106): Loss/seq after 01300 batchs: 596.289794921875
INFO:root:Train (Epoch 106): Loss/seq after 01350 batchs: 586.046142578125
INFO:root:Train (Epoch 106): Loss/seq after 01400 batchs: 588.7864990234375
INFO:root:Train (Epoch 106): Loss/seq after 01450 batchs: 590.9366455078125
INFO:root:Train (Epoch 106): Loss/seq after 01500 batchs: 598.4262084960938
INFO:root:Train (Epoch 106): Loss/seq after 01550 batchs: 601.071533203125
INFO:root:Train (Epoch 106): Loss/seq after 01600 batchs: 596.1085815429688
INFO:root:Train (Epoch 106): Loss/seq after 01650 batchs: 594.3070068359375
INFO:root:Train (Epoch 106): Loss/seq after 01700 batchs: 596.8275146484375
INFO:root:Train (Epoch 106): Loss/seq after 01750 batchs: 594.06298828125
INFO:root:Train (Epoch 106): Loss/seq after 01800 batchs: 591.5369262695312
INFO:root:Train (Epoch 106): Loss/seq after 01850 batchs: 587.9716796875
INFO:root:Train (Epoch 106): Loss/seq after 01900 batchs: 588.5252075195312
INFO:root:Train (Epoch 106): Loss/seq after 01950 batchs: 586.7132568359375
INFO:root:Train (Epoch 106): Loss/seq after 02000 batchs: 585.3340454101562
INFO:root:Train (Epoch 106): Loss/seq after 02050 batchs: 584.0185546875
INFO:root:Train (Epoch 106): Loss/seq after 02100 batchs: 581.48388671875
INFO:root:Train (Epoch 106): Loss/seq after 02150 batchs: 579.965087890625
INFO:root:Train (Epoch 106): Loss/seq after 02200 batchs: 577.3279418945312
INFO:root:Train (Epoch 106): Loss/seq after 02250 batchs: 576.5164794921875
INFO:root:Train (Epoch 106): Loss/seq after 02300 batchs: 572.0414428710938
INFO:root:Train (Epoch 106): Loss/seq after 02350 batchs: 567.5452270507812
INFO:root:Train (Epoch 106): Loss/seq after 02400 batchs: 568.4014282226562
INFO:root:Train (Epoch 106): Loss/seq after 02450 batchs: 563.6178588867188
INFO:root:Train (Epoch 106): Loss/seq after 02500 batchs: 555.001220703125
INFO:root:Train (Epoch 106): Loss/seq after 02550 batchs: 548.0081176757812
INFO:root:Train (Epoch 106): Loss/seq after 02600 batchs: 546.0739135742188
INFO:root:Train (Epoch 106): Loss/seq after 02650 batchs: 542.5503540039062
INFO:root:Train (Epoch 106): Loss/seq after 02700 batchs: 539.3933715820312
INFO:root:Train (Epoch 106): Loss/seq after 02750 batchs: 535.158203125
INFO:root:Train (Epoch 106): Loss/seq after 02800 batchs: 534.64111328125
INFO:root:Train (Epoch 106): Loss/seq after 02850 batchs: 534.86279296875
INFO:root:Train (Epoch 106): Loss/seq after 02900 batchs: 536.4173583984375
INFO:root:Train (Epoch 106): Loss/seq after 02950 batchs: 535.6207275390625
INFO:root:Train (Epoch 106): Loss/seq after 03000 batchs: 541.0258178710938
INFO:root:Train (Epoch 106): Loss/seq after 03050 batchs: 543.458251953125
INFO:root:Train (Epoch 106): Loss/seq after 03100 batchs: 547.02880859375
INFO:root:Train (Epoch 106): Loss/seq after 03150 batchs: 547.391845703125
INFO:root:Train (Epoch 106): Loss/seq after 03200 batchs: 547.4198608398438
INFO:root:Train (Epoch 106): Loss/seq after 03250 batchs: 548.8822021484375
INFO:root:Train (Epoch 106): Loss/seq after 03300 batchs: 548.0303344726562
INFO:root:Train (Epoch 106): Loss/seq after 03350 batchs: 547.4346923828125
INFO:root:Train (Epoch 106): Loss/seq after 03400 batchs: 543.0818481445312
INFO:root:Train (Epoch 106): Loss/seq after 03450 batchs: 541.634521484375
INFO:root:Train (Epoch 106): Loss/seq after 03500 batchs: 542.5944213867188
INFO:root:Train (Epoch 106): Loss/seq after 03550 batchs: 540.1061401367188
INFO:root:Train (Epoch 106): Loss/seq after 03600 batchs: 548.0050048828125
INFO:root:Train (Epoch 106): Loss/seq after 03650 batchs: 545.8816528320312
INFO:root:Train (Epoch 106): Loss/seq after 03700 batchs: 548.494384765625
INFO:root:Train (Epoch 106): Loss/seq after 03750 batchs: 553.5416870117188
INFO:root:Train (Epoch 106): Loss/seq after 03800 batchs: 551.3969116210938
INFO:root:Train (Epoch 106): Loss/seq after 03850 batchs: 550.30517578125
INFO:root:Train (Epoch 106): Loss/seq after 03900 batchs: 553.39404296875
INFO:root:Train (Epoch 106): Loss/seq after 03950 batchs: 555.9179077148438
INFO:root:Train (Epoch 106): Loss/seq after 04000 batchs: 552.3359375
INFO:root:Train (Epoch 106): Loss/seq after 04050 batchs: 548.756103515625
INFO:root:Train (Epoch 106): Loss/seq after 04100 batchs: 547.2149047851562
INFO:root:Train (Epoch 106): Loss/seq after 04150 batchs: 547.3345947265625
INFO:root:Train (Epoch 106): Loss/seq after 04200 batchs: 546.06005859375
INFO:root:Train (Epoch 106): Loss/seq after 04250 batchs: 544.4600830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 106): Loss/seq after 00000 batches: 528.2919311523438
INFO:root:# Valid (Epoch 106): Loss/seq after 00050 batches: 699.1993408203125
INFO:root:# Valid (Epoch 106): Loss/seq after 00100 batches: 751.6934204101562
INFO:root:# Valid (Epoch 106): Loss/seq after 00150 batches: 567.5806274414062
INFO:root:# Valid (Epoch 106): Loss/seq after 00200 batches: 533.5419311523438
INFO:root:Artifacts: Make stick videos for epoch 106
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_106_on_20220422_081459.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_106_index_92_on_20220422_081459.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 107): Loss/seq after 00000 batchs: 1062.2052001953125
INFO:root:Train (Epoch 107): Loss/seq after 00050 batchs: 782.57080078125
INFO:root:Train (Epoch 107): Loss/seq after 00100 batchs: 789.9008178710938
INFO:root:Train (Epoch 107): Loss/seq after 00150 batchs: 728.8153686523438
INFO:root:Train (Epoch 107): Loss/seq after 00200 batchs: 799.3294067382812
INFO:root:Train (Epoch 107): Loss/seq after 00250 batchs: 914.8114013671875
INFO:root:Train (Epoch 107): Loss/seq after 00300 batchs: 910.5052490234375
INFO:root:Train (Epoch 107): Loss/seq after 00350 batchs: 850.1065673828125
INFO:root:Train (Epoch 107): Loss/seq after 00400 batchs: 845.8790283203125
INFO:root:Train (Epoch 107): Loss/seq after 00450 batchs: 828.3359375
INFO:root:Train (Epoch 107): Loss/seq after 00500 batchs: 804.2838745117188
INFO:root:Train (Epoch 107): Loss/seq after 00550 batchs: 782.2906494140625
INFO:root:Train (Epoch 107): Loss/seq after 00600 batchs: 754.2840576171875
INFO:root:Train (Epoch 107): Loss/seq after 00650 batchs: 725.952880859375
INFO:root:Train (Epoch 107): Loss/seq after 00700 batchs: 696.5601806640625
INFO:root:Train (Epoch 107): Loss/seq after 00750 batchs: 694.4302978515625
INFO:root:Train (Epoch 107): Loss/seq after 00800 batchs: 696.6618041992188
INFO:root:Train (Epoch 107): Loss/seq after 00850 batchs: 673.8711547851562
INFO:root:Train (Epoch 107): Loss/seq after 00900 batchs: 657.3958740234375
INFO:root:Train (Epoch 107): Loss/seq after 00950 batchs: 652.8775634765625
INFO:root:Train (Epoch 107): Loss/seq after 01000 batchs: 640.33349609375
INFO:root:Train (Epoch 107): Loss/seq after 01050 batchs: 627.383544921875
INFO:root:Train (Epoch 107): Loss/seq after 01100 batchs: 617.4412231445312
INFO:root:Train (Epoch 107): Loss/seq after 01150 batchs: 600.2101440429688
INFO:root:Train (Epoch 107): Loss/seq after 01200 batchs: 604.651123046875
INFO:root:Train (Epoch 107): Loss/seq after 01250 batchs: 602.1141357421875
INFO:root:Train (Epoch 107): Loss/seq after 01300 batchs: 588.8978881835938
INFO:root:Train (Epoch 107): Loss/seq after 01350 batchs: 578.404052734375
INFO:root:Train (Epoch 107): Loss/seq after 01400 batchs: 579.669189453125
INFO:root:Train (Epoch 107): Loss/seq after 01450 batchs: 581.7696533203125
INFO:root:Train (Epoch 107): Loss/seq after 01500 batchs: 589.1376953125
INFO:root:Train (Epoch 107): Loss/seq after 01550 batchs: 591.8528442382812
INFO:root:Train (Epoch 107): Loss/seq after 01600 batchs: 587.123046875
INFO:root:Train (Epoch 107): Loss/seq after 01650 batchs: 585.3567504882812
INFO:root:Train (Epoch 107): Loss/seq after 01700 batchs: 587.8526611328125
INFO:root:Train (Epoch 107): Loss/seq after 01750 batchs: 585.1983032226562
INFO:root:Train (Epoch 107): Loss/seq after 01800 batchs: 582.9548950195312
INFO:root:Train (Epoch 107): Loss/seq after 01850 batchs: 579.7115478515625
INFO:root:Train (Epoch 107): Loss/seq after 01900 batchs: 580.5422973632812
INFO:root:Train (Epoch 107): Loss/seq after 01950 batchs: 579.3722534179688
INFO:root:Train (Epoch 107): Loss/seq after 02000 batchs: 578.5700073242188
INFO:root:Train (Epoch 107): Loss/seq after 02050 batchs: 577.58203125
INFO:root:Train (Epoch 107): Loss/seq after 02100 batchs: 575.0805053710938
INFO:root:Train (Epoch 107): Loss/seq after 02150 batchs: 573.2591552734375
INFO:root:Train (Epoch 107): Loss/seq after 02200 batchs: 570.6763305664062
INFO:root:Train (Epoch 107): Loss/seq after 02250 batchs: 570.0445556640625
INFO:root:Train (Epoch 107): Loss/seq after 02300 batchs: 565.40625
INFO:root:Train (Epoch 107): Loss/seq after 02350 batchs: 561.298828125
INFO:root:Train (Epoch 107): Loss/seq after 02400 batchs: 562.2760009765625
INFO:root:Train (Epoch 107): Loss/seq after 02450 batchs: 557.6437377929688
INFO:root:Train (Epoch 107): Loss/seq after 02500 batchs: 549.1016845703125
INFO:root:Train (Epoch 107): Loss/seq after 02550 batchs: 542.1702880859375
INFO:root:Train (Epoch 107): Loss/seq after 02600 batchs: 540.251220703125
INFO:root:Train (Epoch 107): Loss/seq after 02650 batchs: 536.8385620117188
INFO:root:Train (Epoch 107): Loss/seq after 02700 batchs: 533.7586059570312
INFO:root:Train (Epoch 107): Loss/seq after 02750 batchs: 528.8923950195312
INFO:root:Train (Epoch 107): Loss/seq after 02800 batchs: 528.0460205078125
INFO:root:Train (Epoch 107): Loss/seq after 02850 batchs: 528.31689453125
INFO:root:Train (Epoch 107): Loss/seq after 02900 batchs: 529.9765625
INFO:root:Train (Epoch 107): Loss/seq after 02950 batchs: 529.3365478515625
INFO:root:Train (Epoch 107): Loss/seq after 03000 batchs: 534.896484375
INFO:root:Train (Epoch 107): Loss/seq after 03050 batchs: 536.9683227539062
INFO:root:Train (Epoch 107): Loss/seq after 03100 batchs: 540.463623046875
INFO:root:Train (Epoch 107): Loss/seq after 03150 batchs: 540.7305908203125
INFO:root:Train (Epoch 107): Loss/seq after 03200 batchs: 541.0208740234375
INFO:root:Train (Epoch 107): Loss/seq after 03250 batchs: 543.3361206054688
INFO:root:Train (Epoch 107): Loss/seq after 03300 batchs: 542.6694946289062
INFO:root:Train (Epoch 107): Loss/seq after 03350 batchs: 541.8295288085938
INFO:root:Train (Epoch 107): Loss/seq after 03400 batchs: 537.5018920898438
INFO:root:Train (Epoch 107): Loss/seq after 03450 batchs: 536.15771484375
INFO:root:Train (Epoch 107): Loss/seq after 03500 batchs: 537.7574462890625
INFO:root:Train (Epoch 107): Loss/seq after 03550 batchs: 536.0442504882812
INFO:root:Train (Epoch 107): Loss/seq after 03600 batchs: 544.1268310546875
INFO:root:Train (Epoch 107): Loss/seq after 03650 batchs: 541.8212890625
INFO:root:Train (Epoch 107): Loss/seq after 03700 batchs: 544.443603515625
INFO:root:Train (Epoch 107): Loss/seq after 03750 batchs: 549.507080078125
INFO:root:Train (Epoch 107): Loss/seq after 03800 batchs: 547.37158203125
INFO:root:Train (Epoch 107): Loss/seq after 03850 batchs: 546.4476318359375
INFO:root:Train (Epoch 107): Loss/seq after 03900 batchs: 549.6522216796875
INFO:root:Train (Epoch 107): Loss/seq after 03950 batchs: 552.2108764648438
INFO:root:Train (Epoch 107): Loss/seq after 04000 batchs: 548.7232055664062
INFO:root:Train (Epoch 107): Loss/seq after 04050 batchs: 545.2021484375
INFO:root:Train (Epoch 107): Loss/seq after 04100 batchs: 543.6746826171875
INFO:root:Train (Epoch 107): Loss/seq after 04150 batchs: 543.7621459960938
INFO:root:Train (Epoch 107): Loss/seq after 04200 batchs: 542.576171875
INFO:root:Train (Epoch 107): Loss/seq after 04250 batchs: 540.9698486328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 107): Loss/seq after 00000 batches: 473.1943359375
INFO:root:# Valid (Epoch 107): Loss/seq after 00050 batches: 711.140869140625
INFO:root:# Valid (Epoch 107): Loss/seq after 00100 batches: 777.4357299804688
INFO:root:# Valid (Epoch 107): Loss/seq after 00150 batches: 586.51806640625
INFO:root:# Valid (Epoch 107): Loss/seq after 00200 batches: 546.9050903320312
INFO:root:Artifacts: Make stick videos for epoch 107
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_107_on_20220422_081944.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_107_index_730_on_20220422_081944.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 108): Loss/seq after 00000 batchs: 1046.4642333984375
INFO:root:Train (Epoch 108): Loss/seq after 00050 batchs: 783.7947387695312
INFO:root:Train (Epoch 108): Loss/seq after 00100 batchs: 804.773681640625
INFO:root:Train (Epoch 108): Loss/seq after 00150 batchs: 730.2626342773438
INFO:root:Train (Epoch 108): Loss/seq after 00200 batchs: 795.2593994140625
INFO:root:Train (Epoch 108): Loss/seq after 00250 batchs: 917.3397827148438
INFO:root:Train (Epoch 108): Loss/seq after 00300 batchs: 911.2734375
INFO:root:Train (Epoch 108): Loss/seq after 00350 batchs: 849.985107421875
INFO:root:Train (Epoch 108): Loss/seq after 00400 batchs: 837.355712890625
INFO:root:Train (Epoch 108): Loss/seq after 00450 batchs: 819.730224609375
INFO:root:Train (Epoch 108): Loss/seq after 00500 batchs: 796.2907104492188
INFO:root:Train (Epoch 108): Loss/seq after 00550 batchs: 772.62451171875
INFO:root:Train (Epoch 108): Loss/seq after 00600 batchs: 745.1975708007812
INFO:root:Train (Epoch 108): Loss/seq after 00650 batchs: 717.8907470703125
INFO:root:Train (Epoch 108): Loss/seq after 00700 batchs: 688.6163940429688
INFO:root:Train (Epoch 108): Loss/seq after 00750 batchs: 687.4921875
INFO:root:Train (Epoch 108): Loss/seq after 00800 batchs: 689.5098876953125
INFO:root:Train (Epoch 108): Loss/seq after 00850 batchs: 667.3115844726562
INFO:root:Train (Epoch 108): Loss/seq after 00900 batchs: 650.701171875
INFO:root:Train (Epoch 108): Loss/seq after 00950 batchs: 647.5947265625
INFO:root:Train (Epoch 108): Loss/seq after 01000 batchs: 635.3801879882812
INFO:root:Train (Epoch 108): Loss/seq after 01050 batchs: 622.8043823242188
INFO:root:Train (Epoch 108): Loss/seq after 01100 batchs: 613.9885864257812
INFO:root:Train (Epoch 108): Loss/seq after 01150 batchs: 597.3265991210938
INFO:root:Train (Epoch 108): Loss/seq after 01200 batchs: 601.5794677734375
INFO:root:Train (Epoch 108): Loss/seq after 01250 batchs: 598.9781494140625
INFO:root:Train (Epoch 108): Loss/seq after 01300 batchs: 586.028564453125
INFO:root:Train (Epoch 108): Loss/seq after 01350 batchs: 575.6177368164062
INFO:root:Train (Epoch 108): Loss/seq after 01400 batchs: 577.234130859375
INFO:root:Train (Epoch 108): Loss/seq after 01450 batchs: 579.1813354492188
INFO:root:Train (Epoch 108): Loss/seq after 01500 batchs: 586.54833984375
INFO:root:Train (Epoch 108): Loss/seq after 01550 batchs: 589.014404296875
INFO:root:Train (Epoch 108): Loss/seq after 01600 batchs: 584.0325927734375
INFO:root:Train (Epoch 108): Loss/seq after 01650 batchs: 582.4140014648438
INFO:root:Train (Epoch 108): Loss/seq after 01700 batchs: 585.2111206054688
INFO:root:Train (Epoch 108): Loss/seq after 01750 batchs: 582.67138671875
INFO:root:Train (Epoch 108): Loss/seq after 01800 batchs: 580.22705078125
INFO:root:Train (Epoch 108): Loss/seq after 01850 batchs: 577.0330200195312
INFO:root:Train (Epoch 108): Loss/seq after 01900 batchs: 577.6798706054688
INFO:root:Train (Epoch 108): Loss/seq after 01950 batchs: 576.5562133789062
INFO:root:Train (Epoch 108): Loss/seq after 02000 batchs: 575.7252807617188
INFO:root:Train (Epoch 108): Loss/seq after 02050 batchs: 574.6133422851562
INFO:root:Train (Epoch 108): Loss/seq after 02100 batchs: 572.2056884765625
INFO:root:Train (Epoch 108): Loss/seq after 02150 batchs: 570.4766845703125
INFO:root:Train (Epoch 108): Loss/seq after 02200 batchs: 567.9136352539062
INFO:root:Train (Epoch 108): Loss/seq after 02250 batchs: 567.0440063476562
INFO:root:Train (Epoch 108): Loss/seq after 02300 batchs: 562.3904418945312
INFO:root:Train (Epoch 108): Loss/seq after 02350 batchs: 558.4353637695312
INFO:root:Train (Epoch 108): Loss/seq after 02400 batchs: 559.5996704101562
INFO:root:Train (Epoch 108): Loss/seq after 02450 batchs: 555.0077514648438
INFO:root:Train (Epoch 108): Loss/seq after 02500 batchs: 546.4821166992188
INFO:root:Train (Epoch 108): Loss/seq after 02550 batchs: 539.6345825195312
INFO:root:Train (Epoch 108): Loss/seq after 02600 batchs: 537.7435302734375
INFO:root:Train (Epoch 108): Loss/seq after 02650 batchs: 534.4086303710938
INFO:root:Train (Epoch 108): Loss/seq after 02700 batchs: 531.128173828125
INFO:root:Train (Epoch 108): Loss/seq after 02750 batchs: 526.349853515625
INFO:root:Train (Epoch 108): Loss/seq after 02800 batchs: 525.9736328125
INFO:root:Train (Epoch 108): Loss/seq after 02850 batchs: 526.3292846679688
INFO:root:Train (Epoch 108): Loss/seq after 02900 batchs: 527.2119140625
INFO:root:Train (Epoch 108): Loss/seq after 02950 batchs: 526.5989990234375
INFO:root:Train (Epoch 108): Loss/seq after 03000 batchs: 532.1943359375
INFO:root:Train (Epoch 108): Loss/seq after 03050 batchs: 534.1264038085938
INFO:root:Train (Epoch 108): Loss/seq after 03100 batchs: 537.1361694335938
INFO:root:Train (Epoch 108): Loss/seq after 03150 batchs: 538.0089721679688
INFO:root:Train (Epoch 108): Loss/seq after 03200 batchs: 538.4722290039062
INFO:root:Train (Epoch 108): Loss/seq after 03250 batchs: 540.0665893554688
INFO:root:Train (Epoch 108): Loss/seq after 03300 batchs: 539.436767578125
INFO:root:Train (Epoch 108): Loss/seq after 03350 batchs: 538.6685791015625
INFO:root:Train (Epoch 108): Loss/seq after 03400 batchs: 534.308837890625
INFO:root:Train (Epoch 108): Loss/seq after 03450 batchs: 533.22509765625
INFO:root:Train (Epoch 108): Loss/seq after 03500 batchs: 534.5094604492188
INFO:root:Train (Epoch 108): Loss/seq after 03550 batchs: 532.3251342773438
INFO:root:Train (Epoch 108): Loss/seq after 03600 batchs: 540.338623046875
INFO:root:Train (Epoch 108): Loss/seq after 03650 batchs: 538.6001586914062
INFO:root:Train (Epoch 108): Loss/seq after 03700 batchs: 541.6316528320312
INFO:root:Train (Epoch 108): Loss/seq after 03750 batchs: 546.6114501953125
INFO:root:Train (Epoch 108): Loss/seq after 03800 batchs: 544.6005249023438
INFO:root:Train (Epoch 108): Loss/seq after 03850 batchs: 543.8488159179688
INFO:root:Train (Epoch 108): Loss/seq after 03900 batchs: 546.9911499023438
INFO:root:Train (Epoch 108): Loss/seq after 03950 batchs: 549.5525512695312
INFO:root:Train (Epoch 108): Loss/seq after 04000 batchs: 546.1613159179688
INFO:root:Train (Epoch 108): Loss/seq after 04050 batchs: 542.6061401367188
INFO:root:Train (Epoch 108): Loss/seq after 04100 batchs: 541.1539916992188
INFO:root:Train (Epoch 108): Loss/seq after 04150 batchs: 541.2604370117188
INFO:root:Train (Epoch 108): Loss/seq after 04200 batchs: 539.8331909179688
INFO:root:Train (Epoch 108): Loss/seq after 04250 batchs: 538.2634887695312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 108): Loss/seq after 00000 batches: 500.3731384277344
INFO:root:# Valid (Epoch 108): Loss/seq after 00050 batches: 708.8382568359375
INFO:root:# Valid (Epoch 108): Loss/seq after 00100 batches: 774.2090454101562
INFO:root:# Valid (Epoch 108): Loss/seq after 00150 batches: 582.0166015625
INFO:root:# Valid (Epoch 108): Loss/seq after 00200 batches: 541.9754638671875
INFO:root:Artifacts: Make stick videos for epoch 108
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_108_on_20220422_082428.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_108_index_619_on_20220422_082428.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 109): Loss/seq after 00000 batchs: 1110.9951171875
INFO:root:Train (Epoch 109): Loss/seq after 00050 batchs: 791.4036865234375
INFO:root:Train (Epoch 109): Loss/seq after 00100 batchs: 799.6500244140625
INFO:root:Train (Epoch 109): Loss/seq after 00150 batchs: 725.7987670898438
INFO:root:Train (Epoch 109): Loss/seq after 00200 batchs: 783.6319580078125
INFO:root:Train (Epoch 109): Loss/seq after 00250 batchs: 897.9454345703125
INFO:root:Train (Epoch 109): Loss/seq after 00300 batchs: 894.1427612304688
INFO:root:Train (Epoch 109): Loss/seq after 00350 batchs: 834.3336181640625
INFO:root:Train (Epoch 109): Loss/seq after 00400 batchs: 825.9287109375
INFO:root:Train (Epoch 109): Loss/seq after 00450 batchs: 809.7372436523438
INFO:root:Train (Epoch 109): Loss/seq after 00500 batchs: 784.9353637695312
INFO:root:Train (Epoch 109): Loss/seq after 00550 batchs: 760.5595703125
INFO:root:Train (Epoch 109): Loss/seq after 00600 batchs: 733.25
INFO:root:Train (Epoch 109): Loss/seq after 00650 batchs: 705.9663696289062
INFO:root:Train (Epoch 109): Loss/seq after 00700 batchs: 677.5567016601562
INFO:root:Train (Epoch 109): Loss/seq after 00750 batchs: 675.7820434570312
INFO:root:Train (Epoch 109): Loss/seq after 00800 batchs: 678.5841064453125
INFO:root:Train (Epoch 109): Loss/seq after 00850 batchs: 656.9053344726562
INFO:root:Train (Epoch 109): Loss/seq after 00900 batchs: 640.119873046875
INFO:root:Train (Epoch 109): Loss/seq after 00950 batchs: 634.3524780273438
INFO:root:Train (Epoch 109): Loss/seq after 01000 batchs: 622.5338134765625
INFO:root:Train (Epoch 109): Loss/seq after 01050 batchs: 611.91455078125
INFO:root:Train (Epoch 109): Loss/seq after 01100 batchs: 603.7012329101562
INFO:root:Train (Epoch 109): Loss/seq after 01150 batchs: 589.2608642578125
INFO:root:Train (Epoch 109): Loss/seq after 01200 batchs: 596.2283935546875
INFO:root:Train (Epoch 109): Loss/seq after 01250 batchs: 594.74951171875
INFO:root:Train (Epoch 109): Loss/seq after 01300 batchs: 582.0355224609375
INFO:root:Train (Epoch 109): Loss/seq after 01350 batchs: 571.9371337890625
INFO:root:Train (Epoch 109): Loss/seq after 01400 batchs: 574.1013793945312
INFO:root:Train (Epoch 109): Loss/seq after 01450 batchs: 576.752197265625
INFO:root:Train (Epoch 109): Loss/seq after 01500 batchs: 584.1851196289062
INFO:root:Train (Epoch 109): Loss/seq after 01550 batchs: 587.5137329101562
INFO:root:Train (Epoch 109): Loss/seq after 01600 batchs: 583.3697509765625
INFO:root:Train (Epoch 109): Loss/seq after 01650 batchs: 582.0545043945312
INFO:root:Train (Epoch 109): Loss/seq after 01700 batchs: 584.5548095703125
INFO:root:Train (Epoch 109): Loss/seq after 01750 batchs: 581.794189453125
INFO:root:Train (Epoch 109): Loss/seq after 01800 batchs: 579.5703125
INFO:root:Train (Epoch 109): Loss/seq after 01850 batchs: 576.1395874023438
INFO:root:Train (Epoch 109): Loss/seq after 01900 batchs: 576.9695434570312
INFO:root:Train (Epoch 109): Loss/seq after 01950 batchs: 575.66455078125
INFO:root:Train (Epoch 109): Loss/seq after 02000 batchs: 574.6011352539062
INFO:root:Train (Epoch 109): Loss/seq after 02050 batchs: 573.467041015625
INFO:root:Train (Epoch 109): Loss/seq after 02100 batchs: 571.1339111328125
INFO:root:Train (Epoch 109): Loss/seq after 02150 batchs: 569.3843383789062
INFO:root:Train (Epoch 109): Loss/seq after 02200 batchs: 566.7688598632812
INFO:root:Train (Epoch 109): Loss/seq after 02250 batchs: 566.2242431640625
INFO:root:Train (Epoch 109): Loss/seq after 02300 batchs: 561.8699340820312
INFO:root:Train (Epoch 109): Loss/seq after 02350 batchs: 557.6123657226562
INFO:root:Train (Epoch 109): Loss/seq after 02400 batchs: 558.5494384765625
INFO:root:Train (Epoch 109): Loss/seq after 02450 batchs: 553.8873291015625
INFO:root:Train (Epoch 109): Loss/seq after 02500 batchs: 545.3936157226562
INFO:root:Train (Epoch 109): Loss/seq after 02550 batchs: 538.4988403320312
INFO:root:Train (Epoch 109): Loss/seq after 02600 batchs: 536.5818481445312
INFO:root:Train (Epoch 109): Loss/seq after 02650 batchs: 533.0133056640625
INFO:root:Train (Epoch 109): Loss/seq after 02700 batchs: 529.8724365234375
INFO:root:Train (Epoch 109): Loss/seq after 02750 batchs: 525.3981323242188
INFO:root:Train (Epoch 109): Loss/seq after 02800 batchs: 524.8455810546875
INFO:root:Train (Epoch 109): Loss/seq after 02850 batchs: 525.0882568359375
INFO:root:Train (Epoch 109): Loss/seq after 02900 batchs: 525.8306274414062
INFO:root:Train (Epoch 109): Loss/seq after 02950 batchs: 525.1204833984375
INFO:root:Train (Epoch 109): Loss/seq after 03000 batchs: 530.6497802734375
INFO:root:Train (Epoch 109): Loss/seq after 03050 batchs: 532.5473022460938
INFO:root:Train (Epoch 109): Loss/seq after 03100 batchs: 536.1539306640625
INFO:root:Train (Epoch 109): Loss/seq after 03150 batchs: 536.9212646484375
INFO:root:Train (Epoch 109): Loss/seq after 03200 batchs: 537.1201782226562
INFO:root:Train (Epoch 109): Loss/seq after 03250 batchs: 538.771728515625
INFO:root:Train (Epoch 109): Loss/seq after 03300 batchs: 537.6480102539062
INFO:root:Train (Epoch 109): Loss/seq after 03350 batchs: 536.901611328125
INFO:root:Train (Epoch 109): Loss/seq after 03400 batchs: 532.589111328125
INFO:root:Train (Epoch 109): Loss/seq after 03450 batchs: 531.2520751953125
INFO:root:Train (Epoch 109): Loss/seq after 03500 batchs: 532.3495483398438
INFO:root:Train (Epoch 109): Loss/seq after 03550 batchs: 530.0838623046875
INFO:root:Train (Epoch 109): Loss/seq after 03600 batchs: 537.9072875976562
INFO:root:Train (Epoch 109): Loss/seq after 03650 batchs: 535.7402954101562
INFO:root:Train (Epoch 109): Loss/seq after 03700 batchs: 538.3876342773438
INFO:root:Train (Epoch 109): Loss/seq after 03750 batchs: 543.3287353515625
INFO:root:Train (Epoch 109): Loss/seq after 03800 batchs: 541.2750854492188
INFO:root:Train (Epoch 109): Loss/seq after 03850 batchs: 540.18017578125
INFO:root:Train (Epoch 109): Loss/seq after 03900 batchs: 543.4248046875
INFO:root:Train (Epoch 109): Loss/seq after 03950 batchs: 546.1528930664062
INFO:root:Train (Epoch 109): Loss/seq after 04000 batchs: 542.7080688476562
INFO:root:Train (Epoch 109): Loss/seq after 04050 batchs: 539.1687622070312
INFO:root:Train (Epoch 109): Loss/seq after 04100 batchs: 537.8677978515625
INFO:root:Train (Epoch 109): Loss/seq after 04150 batchs: 538.044677734375
INFO:root:Train (Epoch 109): Loss/seq after 04200 batchs: 536.8269653320312
INFO:root:Train (Epoch 109): Loss/seq after 04250 batchs: 535.1554565429688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 109): Loss/seq after 00000 batches: 423.1193542480469
INFO:root:# Valid (Epoch 109): Loss/seq after 00050 batches: 667.6317749023438
INFO:root:# Valid (Epoch 109): Loss/seq after 00100 batches: 761.7301025390625
INFO:root:# Valid (Epoch 109): Loss/seq after 00150 batches: 576.3411865234375
INFO:root:# Valid (Epoch 109): Loss/seq after 00200 batches: 537.0294799804688
INFO:root:Artifacts: Make stick videos for epoch 109
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_109_on_20220422_082926.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_109_index_1863_on_20220422_082926.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 110): Loss/seq after 00000 batchs: 975.576171875
INFO:root:Train (Epoch 110): Loss/seq after 00050 batchs: 759.8785400390625
INFO:root:Train (Epoch 110): Loss/seq after 00100 batchs: 774.5078125
INFO:root:Train (Epoch 110): Loss/seq after 00150 batchs: 707.2178955078125
INFO:root:Train (Epoch 110): Loss/seq after 00200 batchs: 776.6994018554688
INFO:root:Train (Epoch 110): Loss/seq after 00250 batchs: 887.967041015625
INFO:root:Train (Epoch 110): Loss/seq after 00300 batchs: 886.165771484375
INFO:root:Train (Epoch 110): Loss/seq after 00350 batchs: 828.8377075195312
INFO:root:Train (Epoch 110): Loss/seq after 00400 batchs: 818.2215576171875
INFO:root:Train (Epoch 110): Loss/seq after 00450 batchs: 803.2470092773438
INFO:root:Train (Epoch 110): Loss/seq after 00500 batchs: 780.6639404296875
INFO:root:Train (Epoch 110): Loss/seq after 00550 batchs: 756.8222045898438
INFO:root:Train (Epoch 110): Loss/seq after 00600 batchs: 730.4495239257812
INFO:root:Train (Epoch 110): Loss/seq after 00650 batchs: 703.3633422851562
INFO:root:Train (Epoch 110): Loss/seq after 00700 batchs: 674.2763061523438
INFO:root:Train (Epoch 110): Loss/seq after 00750 batchs: 670.8641357421875
INFO:root:Train (Epoch 110): Loss/seq after 00800 batchs: 673.8291015625
INFO:root:Train (Epoch 110): Loss/seq after 00850 batchs: 651.9109497070312
INFO:root:Train (Epoch 110): Loss/seq after 00900 batchs: 636.3916625976562
INFO:root:Train (Epoch 110): Loss/seq after 00950 batchs: 630.7249755859375
INFO:root:Train (Epoch 110): Loss/seq after 01000 batchs: 619.4778442382812
INFO:root:Train (Epoch 110): Loss/seq after 01050 batchs: 606.6483154296875
INFO:root:Train (Epoch 110): Loss/seq after 01100 batchs: 597.5413818359375
INFO:root:Train (Epoch 110): Loss/seq after 01150 batchs: 581.46240234375
INFO:root:Train (Epoch 110): Loss/seq after 01200 batchs: 586.775390625
INFO:root:Train (Epoch 110): Loss/seq after 01250 batchs: 585.08056640625
INFO:root:Train (Epoch 110): Loss/seq after 01300 batchs: 572.4881591796875
INFO:root:Train (Epoch 110): Loss/seq after 01350 batchs: 562.4136352539062
INFO:root:Train (Epoch 110): Loss/seq after 01400 batchs: 563.9803466796875
INFO:root:Train (Epoch 110): Loss/seq after 01450 batchs: 566.6085205078125
INFO:root:Train (Epoch 110): Loss/seq after 01500 batchs: 574.4127197265625
INFO:root:Train (Epoch 110): Loss/seq after 01550 batchs: 577.56201171875
INFO:root:Train (Epoch 110): Loss/seq after 01600 batchs: 573.684814453125
INFO:root:Train (Epoch 110): Loss/seq after 01650 batchs: 572.3584594726562
INFO:root:Train (Epoch 110): Loss/seq after 01700 batchs: 575.5599975585938
INFO:root:Train (Epoch 110): Loss/seq after 01750 batchs: 573.1329345703125
INFO:root:Train (Epoch 110): Loss/seq after 01800 batchs: 570.9506225585938
INFO:root:Train (Epoch 110): Loss/seq after 01850 batchs: 567.6644287109375
INFO:root:Train (Epoch 110): Loss/seq after 01900 batchs: 568.293701171875
INFO:root:Train (Epoch 110): Loss/seq after 01950 batchs: 566.77294921875
INFO:root:Train (Epoch 110): Loss/seq after 02000 batchs: 565.9783935546875
INFO:root:Train (Epoch 110): Loss/seq after 02050 batchs: 564.9329223632812
INFO:root:Train (Epoch 110): Loss/seq after 02100 batchs: 562.5863647460938
INFO:root:Train (Epoch 110): Loss/seq after 02150 batchs: 560.8876953125
INFO:root:Train (Epoch 110): Loss/seq after 02200 batchs: 558.4658203125
INFO:root:Train (Epoch 110): Loss/seq after 02250 batchs: 557.519775390625
INFO:root:Train (Epoch 110): Loss/seq after 02300 batchs: 553.3786010742188
INFO:root:Train (Epoch 110): Loss/seq after 02350 batchs: 549.3239135742188
INFO:root:Train (Epoch 110): Loss/seq after 02400 batchs: 550.101318359375
INFO:root:Train (Epoch 110): Loss/seq after 02450 batchs: 545.5900268554688
INFO:root:Train (Epoch 110): Loss/seq after 02500 batchs: 537.2227783203125
INFO:root:Train (Epoch 110): Loss/seq after 02550 batchs: 530.419189453125
INFO:root:Train (Epoch 110): Loss/seq after 02600 batchs: 528.3339233398438
INFO:root:Train (Epoch 110): Loss/seq after 02650 batchs: 524.7538452148438
INFO:root:Train (Epoch 110): Loss/seq after 02700 batchs: 521.75390625
INFO:root:Train (Epoch 110): Loss/seq after 02750 batchs: 517.2958374023438
INFO:root:Train (Epoch 110): Loss/seq after 02800 batchs: 516.6306762695312
INFO:root:Train (Epoch 110): Loss/seq after 02850 batchs: 517.0222778320312
INFO:root:Train (Epoch 110): Loss/seq after 02900 batchs: 518.2662963867188
INFO:root:Train (Epoch 110): Loss/seq after 02950 batchs: 517.6654663085938
INFO:root:Train (Epoch 110): Loss/seq after 03000 batchs: 523.3394775390625
INFO:root:Train (Epoch 110): Loss/seq after 03050 batchs: 525.5875244140625
INFO:root:Train (Epoch 110): Loss/seq after 03100 batchs: 529.1242065429688
INFO:root:Train (Epoch 110): Loss/seq after 03150 batchs: 529.7478637695312
INFO:root:Train (Epoch 110): Loss/seq after 03200 batchs: 529.8694458007812
INFO:root:Train (Epoch 110): Loss/seq after 03250 batchs: 531.7185668945312
INFO:root:Train (Epoch 110): Loss/seq after 03300 batchs: 531.6779174804688
INFO:root:Train (Epoch 110): Loss/seq after 03350 batchs: 531.29345703125
INFO:root:Train (Epoch 110): Loss/seq after 03400 batchs: 527.0904541015625
INFO:root:Train (Epoch 110): Loss/seq after 03450 batchs: 525.9983520507812
INFO:root:Train (Epoch 110): Loss/seq after 03500 batchs: 527.2684326171875
INFO:root:Train (Epoch 110): Loss/seq after 03550 batchs: 525.2007446289062
INFO:root:Train (Epoch 110): Loss/seq after 03600 batchs: 533.2940673828125
INFO:root:Train (Epoch 110): Loss/seq after 03650 batchs: 531.0465087890625
INFO:root:Train (Epoch 110): Loss/seq after 03700 batchs: 533.6939697265625
INFO:root:Train (Epoch 110): Loss/seq after 03750 batchs: 538.6449584960938
INFO:root:Train (Epoch 110): Loss/seq after 03800 batchs: 536.6678466796875
INFO:root:Train (Epoch 110): Loss/seq after 03850 batchs: 535.6610717773438
INFO:root:Train (Epoch 110): Loss/seq after 03900 batchs: 539.1259765625
INFO:root:Train (Epoch 110): Loss/seq after 03950 batchs: 542.1630249023438
INFO:root:Train (Epoch 110): Loss/seq after 04000 batchs: 538.8150024414062
INFO:root:Train (Epoch 110): Loss/seq after 04050 batchs: 535.37060546875
INFO:root:Train (Epoch 110): Loss/seq after 04100 batchs: 534.001953125
INFO:root:Train (Epoch 110): Loss/seq after 04150 batchs: 534.23583984375
INFO:root:Train (Epoch 110): Loss/seq after 04200 batchs: 533.0173950195312
INFO:root:Train (Epoch 110): Loss/seq after 04250 batchs: 531.5003051757812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 110): Loss/seq after 00000 batches: 406.35662841796875
INFO:root:# Valid (Epoch 110): Loss/seq after 00050 batches: 677.1768798828125
INFO:root:# Valid (Epoch 110): Loss/seq after 00100 batches: 757.923095703125
INFO:root:# Valid (Epoch 110): Loss/seq after 00150 batches: 569.4683837890625
INFO:root:# Valid (Epoch 110): Loss/seq after 00200 batches: 531.2022705078125
INFO:root:Artifacts: Make stick videos for epoch 110
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_110_on_20220422_083414.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_110_index_1902_on_20220422_083414.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 111): Loss/seq after 00000 batchs: 1033.7781982421875
INFO:root:Train (Epoch 111): Loss/seq after 00050 batchs: 779.7747802734375
INFO:root:Train (Epoch 111): Loss/seq after 00100 batchs: 784.2952880859375
INFO:root:Train (Epoch 111): Loss/seq after 00150 batchs: 714.045654296875
INFO:root:Train (Epoch 111): Loss/seq after 00200 batchs: 772.6098022460938
INFO:root:Train (Epoch 111): Loss/seq after 00250 batchs: 883.1172485351562
INFO:root:Train (Epoch 111): Loss/seq after 00300 batchs: 881.3389282226562
INFO:root:Train (Epoch 111): Loss/seq after 00350 batchs: 823.2615966796875
INFO:root:Train (Epoch 111): Loss/seq after 00400 batchs: 809.3731689453125
INFO:root:Train (Epoch 111): Loss/seq after 00450 batchs: 794.6101684570312
INFO:root:Train (Epoch 111): Loss/seq after 00500 batchs: 767.9454956054688
INFO:root:Train (Epoch 111): Loss/seq after 00550 batchs: 746.8389282226562
INFO:root:Train (Epoch 111): Loss/seq after 00600 batchs: 719.8031005859375
INFO:root:Train (Epoch 111): Loss/seq after 00650 batchs: 694.9920654296875
INFO:root:Train (Epoch 111): Loss/seq after 00700 batchs: 667.084716796875
INFO:root:Train (Epoch 111): Loss/seq after 00750 batchs: 665.728271484375
INFO:root:Train (Epoch 111): Loss/seq after 00800 batchs: 669.3319702148438
INFO:root:Train (Epoch 111): Loss/seq after 00850 batchs: 647.9649658203125
INFO:root:Train (Epoch 111): Loss/seq after 00900 batchs: 632.7937622070312
INFO:root:Train (Epoch 111): Loss/seq after 00950 batchs: 629.0609130859375
INFO:root:Train (Epoch 111): Loss/seq after 01000 batchs: 617.7294311523438
INFO:root:Train (Epoch 111): Loss/seq after 01050 batchs: 607.8450927734375
INFO:root:Train (Epoch 111): Loss/seq after 01100 batchs: 599.0343017578125
INFO:root:Train (Epoch 111): Loss/seq after 01150 batchs: 583.2728881835938
INFO:root:Train (Epoch 111): Loss/seq after 01200 batchs: 588.9542236328125
INFO:root:Train (Epoch 111): Loss/seq after 01250 batchs: 587.1159057617188
INFO:root:Train (Epoch 111): Loss/seq after 01300 batchs: 574.931884765625
INFO:root:Train (Epoch 111): Loss/seq after 01350 batchs: 564.7884521484375
INFO:root:Train (Epoch 111): Loss/seq after 01400 batchs: 566.2745971679688
INFO:root:Train (Epoch 111): Loss/seq after 01450 batchs: 567.9995727539062
INFO:root:Train (Epoch 111): Loss/seq after 01500 batchs: 575.6488647460938
INFO:root:Train (Epoch 111): Loss/seq after 01550 batchs: 577.845703125
INFO:root:Train (Epoch 111): Loss/seq after 01600 batchs: 573.041015625
INFO:root:Train (Epoch 111): Loss/seq after 01650 batchs: 571.49365234375
INFO:root:Train (Epoch 111): Loss/seq after 01700 batchs: 574.4505004882812
INFO:root:Train (Epoch 111): Loss/seq after 01750 batchs: 572.2630615234375
INFO:root:Train (Epoch 111): Loss/seq after 01800 batchs: 570.0175170898438
INFO:root:Train (Epoch 111): Loss/seq after 01850 batchs: 566.7645263671875
INFO:root:Train (Epoch 111): Loss/seq after 01900 batchs: 567.4783325195312
INFO:root:Train (Epoch 111): Loss/seq after 01950 batchs: 566.186279296875
INFO:root:Train (Epoch 111): Loss/seq after 02000 batchs: 565.0875244140625
INFO:root:Train (Epoch 111): Loss/seq after 02050 batchs: 564.107177734375
INFO:root:Train (Epoch 111): Loss/seq after 02100 batchs: 561.72314453125
INFO:root:Train (Epoch 111): Loss/seq after 02150 batchs: 560.0725708007812
INFO:root:Train (Epoch 111): Loss/seq after 02200 batchs: 557.5883178710938
INFO:root:Train (Epoch 111): Loss/seq after 02250 batchs: 556.7236938476562
INFO:root:Train (Epoch 111): Loss/seq after 02300 batchs: 552.3162231445312
INFO:root:Train (Epoch 111): Loss/seq after 02350 batchs: 548.3013305664062
INFO:root:Train (Epoch 111): Loss/seq after 02400 batchs: 549.2354125976562
INFO:root:Train (Epoch 111): Loss/seq after 02450 batchs: 544.7532348632812
INFO:root:Train (Epoch 111): Loss/seq after 02500 batchs: 536.4275512695312
INFO:root:Train (Epoch 111): Loss/seq after 02550 batchs: 529.4320068359375
INFO:root:Train (Epoch 111): Loss/seq after 02600 batchs: 527.2203369140625
INFO:root:Train (Epoch 111): Loss/seq after 02650 batchs: 523.6859130859375
INFO:root:Train (Epoch 111): Loss/seq after 02700 batchs: 520.4735107421875
INFO:root:Train (Epoch 111): Loss/seq after 02750 batchs: 516.6959228515625
INFO:root:Train (Epoch 111): Loss/seq after 02800 batchs: 516.39013671875
INFO:root:Train (Epoch 111): Loss/seq after 02850 batchs: 516.8637084960938
INFO:root:Train (Epoch 111): Loss/seq after 02900 batchs: 517.864013671875
INFO:root:Train (Epoch 111): Loss/seq after 02950 batchs: 517.1638793945312
INFO:root:Train (Epoch 111): Loss/seq after 03000 batchs: 522.7950439453125
INFO:root:Train (Epoch 111): Loss/seq after 03050 batchs: 525.0740966796875
INFO:root:Train (Epoch 111): Loss/seq after 03100 batchs: 528.3823852539062
INFO:root:Train (Epoch 111): Loss/seq after 03150 batchs: 528.6258544921875
INFO:root:Train (Epoch 111): Loss/seq after 03200 batchs: 528.4173583984375
INFO:root:Train (Epoch 111): Loss/seq after 03250 batchs: 529.9572143554688
INFO:root:Train (Epoch 111): Loss/seq after 03300 batchs: 529.0302734375
INFO:root:Train (Epoch 111): Loss/seq after 03350 batchs: 528.2931518554688
INFO:root:Train (Epoch 111): Loss/seq after 03400 batchs: 524.07275390625
INFO:root:Train (Epoch 111): Loss/seq after 03450 batchs: 522.76220703125
INFO:root:Train (Epoch 111): Loss/seq after 03500 batchs: 523.9616088867188
INFO:root:Train (Epoch 111): Loss/seq after 03550 batchs: 522.1690063476562
INFO:root:Train (Epoch 111): Loss/seq after 03600 batchs: 530.7360229492188
INFO:root:Train (Epoch 111): Loss/seq after 03650 batchs: 528.9750366210938
INFO:root:Train (Epoch 111): Loss/seq after 03700 batchs: 532.1543579101562
INFO:root:Train (Epoch 111): Loss/seq after 03750 batchs: 537.1079711914062
INFO:root:Train (Epoch 111): Loss/seq after 03800 batchs: 535.1914672851562
INFO:root:Train (Epoch 111): Loss/seq after 03850 batchs: 534.2534790039062
INFO:root:Train (Epoch 111): Loss/seq after 03900 batchs: 537.2977294921875
INFO:root:Train (Epoch 111): Loss/seq after 03950 batchs: 540.1017456054688
INFO:root:Train (Epoch 111): Loss/seq after 04000 batchs: 536.5973510742188
INFO:root:Train (Epoch 111): Loss/seq after 04050 batchs: 533.1646118164062
INFO:root:Train (Epoch 111): Loss/seq after 04100 batchs: 531.8869018554688
INFO:root:Train (Epoch 111): Loss/seq after 04150 batchs: 531.9615478515625
INFO:root:Train (Epoch 111): Loss/seq after 04200 batchs: 530.7958374023438
INFO:root:Train (Epoch 111): Loss/seq after 04250 batchs: 529.2643432617188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 111): Loss/seq after 00000 batches: 494.7373046875
INFO:root:# Valid (Epoch 111): Loss/seq after 00050 batches: 686.9249877929688
INFO:root:# Valid (Epoch 111): Loss/seq after 00100 batches: 748.1527709960938
INFO:root:# Valid (Epoch 111): Loss/seq after 00150 batches: 563.903564453125
INFO:root:# Valid (Epoch 111): Loss/seq after 00200 batches: 526.6192016601562
INFO:root:Artifacts: Make stick videos for epoch 111
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_111_on_20220422_083924.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_111_index_547_on_20220422_083924.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 112): Loss/seq after 00000 batchs: 900.255615234375
INFO:root:Train (Epoch 112): Loss/seq after 00050 batchs: 759.6810302734375
INFO:root:Train (Epoch 112): Loss/seq after 00100 batchs: 788.9690551757812
INFO:root:Train (Epoch 112): Loss/seq after 00150 batchs: 720.4039306640625
INFO:root:Train (Epoch 112): Loss/seq after 00200 batchs: 781.47998046875
INFO:root:Train (Epoch 112): Loss/seq after 00250 batchs: 885.5283203125
INFO:root:Train (Epoch 112): Loss/seq after 00300 batchs: 881.992919921875
INFO:root:Train (Epoch 112): Loss/seq after 00350 batchs: 824.8262939453125
INFO:root:Train (Epoch 112): Loss/seq after 00400 batchs: 808.53564453125
INFO:root:Train (Epoch 112): Loss/seq after 00450 batchs: 793.4542846679688
INFO:root:Train (Epoch 112): Loss/seq after 00500 batchs: 764.1392211914062
INFO:root:Train (Epoch 112): Loss/seq after 00550 batchs: 740.7347412109375
INFO:root:Train (Epoch 112): Loss/seq after 00600 batchs: 713.7050170898438
INFO:root:Train (Epoch 112): Loss/seq after 00650 batchs: 686.548095703125
INFO:root:Train (Epoch 112): Loss/seq after 00700 batchs: 658.631103515625
INFO:root:Train (Epoch 112): Loss/seq after 00750 batchs: 656.4613647460938
INFO:root:Train (Epoch 112): Loss/seq after 00800 batchs: 660.9608154296875
INFO:root:Train (Epoch 112): Loss/seq after 00850 batchs: 639.69189453125
INFO:root:Train (Epoch 112): Loss/seq after 00900 batchs: 625.041015625
INFO:root:Train (Epoch 112): Loss/seq after 00950 batchs: 619.4627075195312
INFO:root:Train (Epoch 112): Loss/seq after 01000 batchs: 608.1663818359375
INFO:root:Train (Epoch 112): Loss/seq after 01050 batchs: 595.1202392578125
INFO:root:Train (Epoch 112): Loss/seq after 01100 batchs: 585.6802978515625
INFO:root:Train (Epoch 112): Loss/seq after 01150 batchs: 569.4823608398438
INFO:root:Train (Epoch 112): Loss/seq after 01200 batchs: 574.4207153320312
INFO:root:Train (Epoch 112): Loss/seq after 01250 batchs: 572.3492431640625
INFO:root:Train (Epoch 112): Loss/seq after 01300 batchs: 560.6329956054688
INFO:root:Train (Epoch 112): Loss/seq after 01350 batchs: 550.6324462890625
INFO:root:Train (Epoch 112): Loss/seq after 01400 batchs: 552.0132446289062
INFO:root:Train (Epoch 112): Loss/seq after 01450 batchs: 554.6677856445312
INFO:root:Train (Epoch 112): Loss/seq after 01500 batchs: 562.669189453125
INFO:root:Train (Epoch 112): Loss/seq after 01550 batchs: 565.7651977539062
INFO:root:Train (Epoch 112): Loss/seq after 01600 batchs: 561.62841796875
INFO:root:Train (Epoch 112): Loss/seq after 01650 batchs: 560.1246948242188
INFO:root:Train (Epoch 112): Loss/seq after 01700 batchs: 563.2103881835938
INFO:root:Train (Epoch 112): Loss/seq after 01750 batchs: 560.864013671875
INFO:root:Train (Epoch 112): Loss/seq after 01800 batchs: 558.8948974609375
INFO:root:Train (Epoch 112): Loss/seq after 01850 batchs: 555.7869873046875
INFO:root:Train (Epoch 112): Loss/seq after 01900 batchs: 556.7688598632812
INFO:root:Train (Epoch 112): Loss/seq after 01950 batchs: 555.5853271484375
INFO:root:Train (Epoch 112): Loss/seq after 02000 batchs: 554.9697265625
INFO:root:Train (Epoch 112): Loss/seq after 02050 batchs: 554.1178588867188
INFO:root:Train (Epoch 112): Loss/seq after 02100 batchs: 552.0731201171875
INFO:root:Train (Epoch 112): Loss/seq after 02150 batchs: 550.5552978515625
INFO:root:Train (Epoch 112): Loss/seq after 02200 batchs: 548.3077392578125
INFO:root:Train (Epoch 112): Loss/seq after 02250 batchs: 546.9860229492188
INFO:root:Train (Epoch 112): Loss/seq after 02300 batchs: 542.7930908203125
INFO:root:Train (Epoch 112): Loss/seq after 02350 batchs: 538.8917846679688
INFO:root:Train (Epoch 112): Loss/seq after 02400 batchs: 539.8208618164062
INFO:root:Train (Epoch 112): Loss/seq after 02450 batchs: 535.4740600585938
INFO:root:Train (Epoch 112): Loss/seq after 02500 batchs: 527.2826538085938
INFO:root:Train (Epoch 112): Loss/seq after 02550 batchs: 520.5003662109375
INFO:root:Train (Epoch 112): Loss/seq after 02600 batchs: 518.5675048828125
INFO:root:Train (Epoch 112): Loss/seq after 02650 batchs: 514.9246215820312
INFO:root:Train (Epoch 112): Loss/seq after 02700 batchs: 512.1685180664062
INFO:root:Train (Epoch 112): Loss/seq after 02750 batchs: 507.8802795410156
INFO:root:Train (Epoch 112): Loss/seq after 02800 batchs: 507.8987731933594
INFO:root:Train (Epoch 112): Loss/seq after 02850 batchs: 508.2261047363281
INFO:root:Train (Epoch 112): Loss/seq after 02900 batchs: 510.2756042480469
INFO:root:Train (Epoch 112): Loss/seq after 02950 batchs: 509.8682556152344
INFO:root:Train (Epoch 112): Loss/seq after 03000 batchs: 515.6630249023438
INFO:root:Train (Epoch 112): Loss/seq after 03050 batchs: 517.9901123046875
INFO:root:Train (Epoch 112): Loss/seq after 03100 batchs: 521.6441040039062
INFO:root:Train (Epoch 112): Loss/seq after 03150 batchs: 522.7875366210938
INFO:root:Train (Epoch 112): Loss/seq after 03200 batchs: 523.4488525390625
INFO:root:Train (Epoch 112): Loss/seq after 03250 batchs: 524.9132690429688
INFO:root:Train (Epoch 112): Loss/seq after 03300 batchs: 525.074462890625
INFO:root:Train (Epoch 112): Loss/seq after 03350 batchs: 524.8189697265625
INFO:root:Train (Epoch 112): Loss/seq after 03400 batchs: 520.5638427734375
INFO:root:Train (Epoch 112): Loss/seq after 03450 batchs: 519.4554443359375
INFO:root:Train (Epoch 112): Loss/seq after 03500 batchs: 521.3079223632812
INFO:root:Train (Epoch 112): Loss/seq after 03550 batchs: 519.18603515625
INFO:root:Train (Epoch 112): Loss/seq after 03600 batchs: 526.9503173828125
INFO:root:Train (Epoch 112): Loss/seq after 03650 batchs: 524.7112426757812
INFO:root:Train (Epoch 112): Loss/seq after 03700 batchs: 527.37939453125
INFO:root:Train (Epoch 112): Loss/seq after 03750 batchs: 532.1063232421875
INFO:root:Train (Epoch 112): Loss/seq after 03800 batchs: 530.2730102539062
INFO:root:Train (Epoch 112): Loss/seq after 03850 batchs: 529.3182373046875
INFO:root:Train (Epoch 112): Loss/seq after 03900 batchs: 532.7919921875
INFO:root:Train (Epoch 112): Loss/seq after 03950 batchs: 535.4638061523438
INFO:root:Train (Epoch 112): Loss/seq after 04000 batchs: 531.9729614257812
INFO:root:Train (Epoch 112): Loss/seq after 04050 batchs: 528.585693359375
INFO:root:Train (Epoch 112): Loss/seq after 04100 batchs: 527.1455688476562
INFO:root:Train (Epoch 112): Loss/seq after 04150 batchs: 527.3401489257812
INFO:root:Train (Epoch 112): Loss/seq after 04200 batchs: 525.9571533203125
INFO:root:Train (Epoch 112): Loss/seq after 04250 batchs: 524.3698120117188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 112): Loss/seq after 00000 batches: 501.5665588378906
INFO:root:# Valid (Epoch 112): Loss/seq after 00050 batches: 671.3953857421875
INFO:root:# Valid (Epoch 112): Loss/seq after 00100 batches: 721.7223510742188
INFO:root:# Valid (Epoch 112): Loss/seq after 00150 batches: 548.0478515625
INFO:root:# Valid (Epoch 112): Loss/seq after 00200 batches: 519.7538452148438
INFO:root:Artifacts: Make stick videos for epoch 112
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_112_on_20220422_084431.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_112_index_1802_on_20220422_084431.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 113): Loss/seq after 00000 batchs: 1195.304931640625
INFO:root:Train (Epoch 113): Loss/seq after 00050 batchs: 749.6426391601562
INFO:root:Train (Epoch 113): Loss/seq after 00100 batchs: 778.5736083984375
INFO:root:Train (Epoch 113): Loss/seq after 00150 batchs: 708.1798706054688
INFO:root:Train (Epoch 113): Loss/seq after 00200 batchs: 767.966552734375
INFO:root:Train (Epoch 113): Loss/seq after 00250 batchs: 884.10791015625
INFO:root:Train (Epoch 113): Loss/seq after 00300 batchs: 879.6226806640625
INFO:root:Train (Epoch 113): Loss/seq after 00350 batchs: 822.8235473632812
INFO:root:Train (Epoch 113): Loss/seq after 00400 batchs: 810.8655395507812
INFO:root:Train (Epoch 113): Loss/seq after 00450 batchs: 795.8985595703125
INFO:root:Train (Epoch 113): Loss/seq after 00500 batchs: 775.9267578125
INFO:root:Train (Epoch 113): Loss/seq after 00550 batchs: 753.4028930664062
INFO:root:Train (Epoch 113): Loss/seq after 00600 batchs: 726.7728271484375
INFO:root:Train (Epoch 113): Loss/seq after 00650 batchs: 699.8768920898438
INFO:root:Train (Epoch 113): Loss/seq after 00700 batchs: 671.3761596679688
INFO:root:Train (Epoch 113): Loss/seq after 00750 batchs: 670.778076171875
INFO:root:Train (Epoch 113): Loss/seq after 00800 batchs: 674.6998291015625
INFO:root:Train (Epoch 113): Loss/seq after 00850 batchs: 653.0301513671875
INFO:root:Train (Epoch 113): Loss/seq after 00900 batchs: 637.40283203125
INFO:root:Train (Epoch 113): Loss/seq after 00950 batchs: 633.7669677734375
INFO:root:Train (Epoch 113): Loss/seq after 01000 batchs: 622.882080078125
INFO:root:Train (Epoch 113): Loss/seq after 01050 batchs: 609.6851196289062
INFO:root:Train (Epoch 113): Loss/seq after 01100 batchs: 599.8320922851562
INFO:root:Train (Epoch 113): Loss/seq after 01150 batchs: 583.771240234375
INFO:root:Train (Epoch 113): Loss/seq after 01200 batchs: 588.4592895507812
INFO:root:Train (Epoch 113): Loss/seq after 01250 batchs: 586.3538818359375
INFO:root:Train (Epoch 113): Loss/seq after 01300 batchs: 574.5813598632812
INFO:root:Train (Epoch 113): Loss/seq after 01350 batchs: 563.951171875
INFO:root:Train (Epoch 113): Loss/seq after 01400 batchs: 564.9498291015625
INFO:root:Train (Epoch 113): Loss/seq after 01450 batchs: 566.9879760742188
INFO:root:Train (Epoch 113): Loss/seq after 01500 batchs: 574.382568359375
INFO:root:Train (Epoch 113): Loss/seq after 01550 batchs: 576.6005859375
INFO:root:Train (Epoch 113): Loss/seq after 01600 batchs: 572.1039428710938
INFO:root:Train (Epoch 113): Loss/seq after 01650 batchs: 570.0592041015625
INFO:root:Train (Epoch 113): Loss/seq after 01700 batchs: 572.9054565429688
INFO:root:Train (Epoch 113): Loss/seq after 01750 batchs: 569.9971313476562
INFO:root:Train (Epoch 113): Loss/seq after 01800 batchs: 567.6136474609375
INFO:root:Train (Epoch 113): Loss/seq after 01850 batchs: 564.3385009765625
INFO:root:Train (Epoch 113): Loss/seq after 01900 batchs: 564.8890991210938
INFO:root:Train (Epoch 113): Loss/seq after 01950 batchs: 563.2459106445312
INFO:root:Train (Epoch 113): Loss/seq after 02000 batchs: 562.2633056640625
INFO:root:Train (Epoch 113): Loss/seq after 02050 batchs: 561.105224609375
INFO:root:Train (Epoch 113): Loss/seq after 02100 batchs: 558.8838500976562
INFO:root:Train (Epoch 113): Loss/seq after 02150 batchs: 557.4127197265625
INFO:root:Train (Epoch 113): Loss/seq after 02200 batchs: 554.9802856445312
INFO:root:Train (Epoch 113): Loss/seq after 02250 batchs: 553.8292236328125
INFO:root:Train (Epoch 113): Loss/seq after 02300 batchs: 549.341796875
INFO:root:Train (Epoch 113): Loss/seq after 02350 batchs: 545.567626953125
INFO:root:Train (Epoch 113): Loss/seq after 02400 batchs: 546.391845703125
INFO:root:Train (Epoch 113): Loss/seq after 02450 batchs: 541.9654541015625
INFO:root:Train (Epoch 113): Loss/seq after 02500 batchs: 533.6371459960938
INFO:root:Train (Epoch 113): Loss/seq after 02550 batchs: 526.7572631835938
INFO:root:Train (Epoch 113): Loss/seq after 02600 batchs: 524.3298950195312
INFO:root:Train (Epoch 113): Loss/seq after 02650 batchs: 520.3966674804688
INFO:root:Train (Epoch 113): Loss/seq after 02700 batchs: 517.2245483398438
INFO:root:Train (Epoch 113): Loss/seq after 02750 batchs: 512.9828491210938
INFO:root:Train (Epoch 113): Loss/seq after 02800 batchs: 512.2846069335938
INFO:root:Train (Epoch 113): Loss/seq after 02850 batchs: 512.5401000976562
INFO:root:Train (Epoch 113): Loss/seq after 02900 batchs: 513.4817504882812
INFO:root:Train (Epoch 113): Loss/seq after 02950 batchs: 512.8462524414062
INFO:root:Train (Epoch 113): Loss/seq after 03000 batchs: 518.4656372070312
INFO:root:Train (Epoch 113): Loss/seq after 03050 batchs: 520.7813720703125
INFO:root:Train (Epoch 113): Loss/seq after 03100 batchs: 523.6102905273438
INFO:root:Train (Epoch 113): Loss/seq after 03150 batchs: 524.3306884765625
INFO:root:Train (Epoch 113): Loss/seq after 03200 batchs: 524.5540771484375
INFO:root:Train (Epoch 113): Loss/seq after 03250 batchs: 526.0208740234375
INFO:root:Train (Epoch 113): Loss/seq after 03300 batchs: 525.4918823242188
INFO:root:Train (Epoch 113): Loss/seq after 03350 batchs: 524.98486328125
INFO:root:Train (Epoch 113): Loss/seq after 03400 batchs: 520.6779174804688
INFO:root:Train (Epoch 113): Loss/seq after 03450 batchs: 519.84130859375
INFO:root:Train (Epoch 113): Loss/seq after 03500 batchs: 521.0191650390625
INFO:root:Train (Epoch 113): Loss/seq after 03550 batchs: 518.82666015625
INFO:root:Train (Epoch 113): Loss/seq after 03600 batchs: 526.4526977539062
INFO:root:Train (Epoch 113): Loss/seq after 03650 batchs: 524.1458740234375
INFO:root:Train (Epoch 113): Loss/seq after 03700 batchs: 526.8233642578125
INFO:root:Train (Epoch 113): Loss/seq after 03750 batchs: 531.7715454101562
INFO:root:Train (Epoch 113): Loss/seq after 03800 batchs: 529.870361328125
INFO:root:Train (Epoch 113): Loss/seq after 03850 batchs: 528.7781372070312
INFO:root:Train (Epoch 113): Loss/seq after 03900 batchs: 531.9014892578125
INFO:root:Train (Epoch 113): Loss/seq after 03950 batchs: 534.5198364257812
INFO:root:Train (Epoch 113): Loss/seq after 04000 batchs: 531.1111450195312
INFO:root:Train (Epoch 113): Loss/seq after 04050 batchs: 527.7049560546875
INFO:root:Train (Epoch 113): Loss/seq after 04100 batchs: 526.2932739257812
INFO:root:Train (Epoch 113): Loss/seq after 04150 batchs: 526.42919921875
INFO:root:Train (Epoch 113): Loss/seq after 04200 batchs: 525.0418090820312
INFO:root:Train (Epoch 113): Loss/seq after 04250 batchs: 523.4602661132812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 113): Loss/seq after 00000 batches: 482.9541931152344
INFO:root:# Valid (Epoch 113): Loss/seq after 00050 batches: 697.2063598632812
INFO:root:# Valid (Epoch 113): Loss/seq after 00100 batches: 721.3558349609375
INFO:root:# Valid (Epoch 113): Loss/seq after 00150 batches: 546.6521606445312
INFO:root:# Valid (Epoch 113): Loss/seq after 00200 batches: 512.2977905273438
INFO:root:Artifacts: Make stick videos for epoch 113
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_113_on_20220422_084935.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_113_index_394_on_20220422_084935.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 114): Loss/seq after 00000 batchs: 883.7091064453125
INFO:root:Train (Epoch 114): Loss/seq after 00050 batchs: 734.8317260742188
INFO:root:Train (Epoch 114): Loss/seq after 00100 batchs: 755.4561767578125
INFO:root:Train (Epoch 114): Loss/seq after 00150 batchs: 695.3998413085938
INFO:root:Train (Epoch 114): Loss/seq after 00200 batchs: 764.6454467773438
INFO:root:Train (Epoch 114): Loss/seq after 00250 batchs: 881.5531616210938
INFO:root:Train (Epoch 114): Loss/seq after 00300 batchs: 877.0953979492188
INFO:root:Train (Epoch 114): Loss/seq after 00350 batchs: 820.6691284179688
INFO:root:Train (Epoch 114): Loss/seq after 00400 batchs: 802.2298583984375
INFO:root:Train (Epoch 114): Loss/seq after 00450 batchs: 787.4544067382812
INFO:root:Train (Epoch 114): Loss/seq after 00500 batchs: 760.0587768554688
INFO:root:Train (Epoch 114): Loss/seq after 00550 batchs: 736.85009765625
INFO:root:Train (Epoch 114): Loss/seq after 00600 batchs: 710.9835815429688
INFO:root:Train (Epoch 114): Loss/seq after 00650 batchs: 684.4356079101562
INFO:root:Train (Epoch 114): Loss/seq after 00700 batchs: 656.1689453125
INFO:root:Train (Epoch 114): Loss/seq after 00750 batchs: 652.8927612304688
INFO:root:Train (Epoch 114): Loss/seq after 00800 batchs: 657.7732543945312
INFO:root:Train (Epoch 114): Loss/seq after 00850 batchs: 636.4367065429688
INFO:root:Train (Epoch 114): Loss/seq after 00900 batchs: 622.4874877929688
INFO:root:Train (Epoch 114): Loss/seq after 00950 batchs: 616.2770385742188
INFO:root:Train (Epoch 114): Loss/seq after 01000 batchs: 604.8482666015625
INFO:root:Train (Epoch 114): Loss/seq after 01050 batchs: 592.376953125
INFO:root:Train (Epoch 114): Loss/seq after 01100 batchs: 583.0817260742188
INFO:root:Train (Epoch 114): Loss/seq after 01150 batchs: 567.0048828125
INFO:root:Train (Epoch 114): Loss/seq after 01200 batchs: 571.7890014648438
INFO:root:Train (Epoch 114): Loss/seq after 01250 batchs: 569.9627075195312
INFO:root:Train (Epoch 114): Loss/seq after 01300 batchs: 557.8883056640625
INFO:root:Train (Epoch 114): Loss/seq after 01350 batchs: 547.8125
INFO:root:Train (Epoch 114): Loss/seq after 01400 batchs: 549.4531860351562
INFO:root:Train (Epoch 114): Loss/seq after 01450 batchs: 551.6890258789062
INFO:root:Train (Epoch 114): Loss/seq after 01500 batchs: 559.8281860351562
INFO:root:Train (Epoch 114): Loss/seq after 01550 batchs: 562.1309204101562
INFO:root:Train (Epoch 114): Loss/seq after 01600 batchs: 557.8495483398438
INFO:root:Train (Epoch 114): Loss/seq after 01650 batchs: 556.31689453125
INFO:root:Train (Epoch 114): Loss/seq after 01700 batchs: 559.29443359375
INFO:root:Train (Epoch 114): Loss/seq after 01750 batchs: 556.78466796875
INFO:root:Train (Epoch 114): Loss/seq after 01800 batchs: 554.7031860351562
INFO:root:Train (Epoch 114): Loss/seq after 01850 batchs: 551.4965209960938
INFO:root:Train (Epoch 114): Loss/seq after 01900 batchs: 552.41552734375
INFO:root:Train (Epoch 114): Loss/seq after 01950 batchs: 551.1913452148438
INFO:root:Train (Epoch 114): Loss/seq after 02000 batchs: 550.8765869140625
INFO:root:Train (Epoch 114): Loss/seq after 02050 batchs: 550.0337524414062
INFO:root:Train (Epoch 114): Loss/seq after 02100 batchs: 547.914306640625
INFO:root:Train (Epoch 114): Loss/seq after 02150 batchs: 546.4730834960938
INFO:root:Train (Epoch 114): Loss/seq after 02200 batchs: 544.1792602539062
INFO:root:Train (Epoch 114): Loss/seq after 02250 batchs: 543.3877563476562
INFO:root:Train (Epoch 114): Loss/seq after 02300 batchs: 539.17333984375
INFO:root:Train (Epoch 114): Loss/seq after 02350 batchs: 535.236083984375
INFO:root:Train (Epoch 114): Loss/seq after 02400 batchs: 536.2362060546875
INFO:root:Train (Epoch 114): Loss/seq after 02450 batchs: 532.0703125
INFO:root:Train (Epoch 114): Loss/seq after 02500 batchs: 523.9074096679688
INFO:root:Train (Epoch 114): Loss/seq after 02550 batchs: 516.9986572265625
INFO:root:Train (Epoch 114): Loss/seq after 02600 batchs: 514.5487670898438
INFO:root:Train (Epoch 114): Loss/seq after 02650 batchs: 510.86590576171875
INFO:root:Train (Epoch 114): Loss/seq after 02700 batchs: 507.94378662109375
INFO:root:Train (Epoch 114): Loss/seq after 02750 batchs: 503.5063781738281
INFO:root:Train (Epoch 114): Loss/seq after 02800 batchs: 503.05389404296875
INFO:root:Train (Epoch 114): Loss/seq after 02850 batchs: 503.23602294921875
INFO:root:Train (Epoch 114): Loss/seq after 02900 batchs: 504.4088134765625
INFO:root:Train (Epoch 114): Loss/seq after 02950 batchs: 504.00653076171875
INFO:root:Train (Epoch 114): Loss/seq after 03000 batchs: 509.79534912109375
INFO:root:Train (Epoch 114): Loss/seq after 03050 batchs: 511.8721008300781
INFO:root:Train (Epoch 114): Loss/seq after 03100 batchs: 515.2444458007812
INFO:root:Train (Epoch 114): Loss/seq after 03150 batchs: 516.7727661132812
INFO:root:Train (Epoch 114): Loss/seq after 03200 batchs: 516.5087280273438
INFO:root:Train (Epoch 114): Loss/seq after 03250 batchs: 517.7352294921875
INFO:root:Train (Epoch 114): Loss/seq after 03300 batchs: 516.9229736328125
INFO:root:Train (Epoch 114): Loss/seq after 03350 batchs: 516.09130859375
INFO:root:Train (Epoch 114): Loss/seq after 03400 batchs: 512.0136108398438
INFO:root:Train (Epoch 114): Loss/seq after 03450 batchs: 510.94195556640625
INFO:root:Train (Epoch 114): Loss/seq after 03500 batchs: 512.6044921875
INFO:root:Train (Epoch 114): Loss/seq after 03550 batchs: 510.7861022949219
INFO:root:Train (Epoch 114): Loss/seq after 03600 batchs: 518.5240478515625
INFO:root:Train (Epoch 114): Loss/seq after 03650 batchs: 516.3572998046875
INFO:root:Train (Epoch 114): Loss/seq after 03700 batchs: 519.1099853515625
INFO:root:Train (Epoch 114): Loss/seq after 03750 batchs: 524.0214233398438
INFO:root:Train (Epoch 114): Loss/seq after 03800 batchs: 522.2149658203125
INFO:root:Train (Epoch 114): Loss/seq after 03850 batchs: 521.2293701171875
INFO:root:Train (Epoch 114): Loss/seq after 03900 batchs: 524.5094604492188
INFO:root:Train (Epoch 114): Loss/seq after 03950 batchs: 527.2743530273438
INFO:root:Train (Epoch 114): Loss/seq after 04000 batchs: 523.9305419921875
INFO:root:Train (Epoch 114): Loss/seq after 04050 batchs: 520.4899291992188
INFO:root:Train (Epoch 114): Loss/seq after 04100 batchs: 519.1846313476562
INFO:root:Train (Epoch 114): Loss/seq after 04150 batchs: 519.4164428710938
INFO:root:Train (Epoch 114): Loss/seq after 04200 batchs: 518.1471557617188
INFO:root:Train (Epoch 114): Loss/seq after 04250 batchs: 516.5802001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 114): Loss/seq after 00000 batches: 438.0943908691406
INFO:root:# Valid (Epoch 114): Loss/seq after 00050 batches: 692.0088500976562
INFO:root:# Valid (Epoch 114): Loss/seq after 00100 batches: 730.0338745117188
INFO:root:# Valid (Epoch 114): Loss/seq after 00150 batches: 551.6961669921875
INFO:root:# Valid (Epoch 114): Loss/seq after 00200 batches: 521.1102294921875
INFO:root:Artifacts: Make stick videos for epoch 114
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_114_on_20220422_085426.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_114_index_151_on_20220422_085426.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 115): Loss/seq after 00000 batchs: 1069.545166015625
INFO:root:Train (Epoch 115): Loss/seq after 00050 batchs: 742.3766479492188
INFO:root:Train (Epoch 115): Loss/seq after 00100 batchs: 777.79150390625
INFO:root:Train (Epoch 115): Loss/seq after 00150 batchs: 717.5787353515625
INFO:root:Train (Epoch 115): Loss/seq after 00200 batchs: 776.844482421875
INFO:root:Train (Epoch 115): Loss/seq after 00250 batchs: 884.8338012695312
INFO:root:Train (Epoch 115): Loss/seq after 00300 batchs: 881.636474609375
INFO:root:Train (Epoch 115): Loss/seq after 00350 batchs: 824.0023193359375
INFO:root:Train (Epoch 115): Loss/seq after 00400 batchs: 809.7136840820312
INFO:root:Train (Epoch 115): Loss/seq after 00450 batchs: 795.1773071289062
INFO:root:Train (Epoch 115): Loss/seq after 00500 batchs: 767.6807861328125
INFO:root:Train (Epoch 115): Loss/seq after 00550 batchs: 744.2185668945312
INFO:root:Train (Epoch 115): Loss/seq after 00600 batchs: 717.6046142578125
INFO:root:Train (Epoch 115): Loss/seq after 00650 batchs: 690.687255859375
INFO:root:Train (Epoch 115): Loss/seq after 00700 batchs: 660.2101440429688
INFO:root:Train (Epoch 115): Loss/seq after 00750 batchs: 654.7109985351562
INFO:root:Train (Epoch 115): Loss/seq after 00800 batchs: 658.2429809570312
INFO:root:Train (Epoch 115): Loss/seq after 00850 batchs: 636.1785888671875
INFO:root:Train (Epoch 115): Loss/seq after 00900 batchs: 620.8734130859375
INFO:root:Train (Epoch 115): Loss/seq after 00950 batchs: 615.1843872070312
INFO:root:Train (Epoch 115): Loss/seq after 01000 batchs: 603.5415649414062
INFO:root:Train (Epoch 115): Loss/seq after 01050 batchs: 590.3255004882812
INFO:root:Train (Epoch 115): Loss/seq after 01100 batchs: 581.8876342773438
INFO:root:Train (Epoch 115): Loss/seq after 01150 batchs: 565.8900756835938
INFO:root:Train (Epoch 115): Loss/seq after 01200 batchs: 570.6976928710938
INFO:root:Train (Epoch 115): Loss/seq after 01250 batchs: 569.0049438476562
INFO:root:Train (Epoch 115): Loss/seq after 01300 batchs: 556.7431640625
INFO:root:Train (Epoch 115): Loss/seq after 01350 batchs: 547.0162963867188
INFO:root:Train (Epoch 115): Loss/seq after 01400 batchs: 548.34912109375
INFO:root:Train (Epoch 115): Loss/seq after 01450 batchs: 550.599853515625
INFO:root:Train (Epoch 115): Loss/seq after 01500 batchs: 558.43017578125
INFO:root:Train (Epoch 115): Loss/seq after 01550 batchs: 560.8390502929688
INFO:root:Train (Epoch 115): Loss/seq after 01600 batchs: 557.0078735351562
INFO:root:Train (Epoch 115): Loss/seq after 01650 batchs: 555.517333984375
INFO:root:Train (Epoch 115): Loss/seq after 01700 batchs: 558.4417724609375
INFO:root:Train (Epoch 115): Loss/seq after 01750 batchs: 555.9017944335938
INFO:root:Train (Epoch 115): Loss/seq after 01800 batchs: 553.8323364257812
INFO:root:Train (Epoch 115): Loss/seq after 01850 batchs: 550.5589599609375
INFO:root:Train (Epoch 115): Loss/seq after 01900 batchs: 551.3041381835938
INFO:root:Train (Epoch 115): Loss/seq after 01950 batchs: 550.2162475585938
INFO:root:Train (Epoch 115): Loss/seq after 02000 batchs: 549.7439575195312
INFO:root:Train (Epoch 115): Loss/seq after 02050 batchs: 548.7985229492188
INFO:root:Train (Epoch 115): Loss/seq after 02100 batchs: 546.7695922851562
INFO:root:Train (Epoch 115): Loss/seq after 02150 batchs: 545.1759643554688
INFO:root:Train (Epoch 115): Loss/seq after 02200 batchs: 542.9337768554688
INFO:root:Train (Epoch 115): Loss/seq after 02250 batchs: 542.3370361328125
INFO:root:Train (Epoch 115): Loss/seq after 02300 batchs: 538.1129760742188
INFO:root:Train (Epoch 115): Loss/seq after 02350 batchs: 534.2792358398438
INFO:root:Train (Epoch 115): Loss/seq after 02400 batchs: 535.2194213867188
INFO:root:Train (Epoch 115): Loss/seq after 02450 batchs: 531.009765625
INFO:root:Train (Epoch 115): Loss/seq after 02500 batchs: 522.8514404296875
INFO:root:Train (Epoch 115): Loss/seq after 02550 batchs: 516.0819091796875
INFO:root:Train (Epoch 115): Loss/seq after 02600 batchs: 513.8460693359375
INFO:root:Train (Epoch 115): Loss/seq after 02650 batchs: 509.9200134277344
INFO:root:Train (Epoch 115): Loss/seq after 02700 batchs: 506.828369140625
INFO:root:Train (Epoch 115): Loss/seq after 02750 batchs: 502.3985900878906
INFO:root:Train (Epoch 115): Loss/seq after 02800 batchs: 501.6200866699219
INFO:root:Train (Epoch 115): Loss/seq after 02850 batchs: 502.09234619140625
INFO:root:Train (Epoch 115): Loss/seq after 02900 batchs: 502.84051513671875
INFO:root:Train (Epoch 115): Loss/seq after 02950 batchs: 502.36431884765625
INFO:root:Train (Epoch 115): Loss/seq after 03000 batchs: 508.17803955078125
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 115): Loss/seq after 03050 batchs: 510.3133544921875
INFO:root:Train (Epoch 115): Loss/seq after 03100 batchs: 513.7192993164062
INFO:root:Train (Epoch 115): Loss/seq after 03150 batchs: 514.1360473632812
INFO:root:Train (Epoch 115): Loss/seq after 03200 batchs: 514.3387451171875
INFO:root:Train (Epoch 115): Loss/seq after 03250 batchs: 515.7147827148438
INFO:root:Train (Epoch 115): Loss/seq after 03300 batchs: 514.6896362304688
INFO:root:Train (Epoch 115): Loss/seq after 03350 batchs: 514.0151977539062
INFO:root:Train (Epoch 115): Loss/seq after 03400 batchs: 509.9566650390625
INFO:root:Train (Epoch 115): Loss/seq after 03450 batchs: 508.691162109375
INFO:root:Train (Epoch 115): Loss/seq after 03500 batchs: 509.9244079589844
INFO:root:Train (Epoch 115): Loss/seq after 03550 batchs: 508.2407531738281
INFO:root:Train (Epoch 115): Loss/seq after 03600 batchs: 516.3951416015625
INFO:root:Train (Epoch 115): Loss/seq after 03650 batchs: 514.5611572265625
INFO:root:Train (Epoch 115): Loss/seq after 03700 batchs: 517.6401977539062
INFO:root:Train (Epoch 115): Loss/seq after 03750 batchs: 522.6234741210938
INFO:root:Train (Epoch 115): Loss/seq after 03800 batchs: 520.877197265625
INFO:root:Train (Epoch 115): Loss/seq after 03850 batchs: 519.7122192382812
INFO:root:Train (Epoch 115): Loss/seq after 03900 batchs: 522.853271484375
INFO:root:Train (Epoch 115): Loss/seq after 03950 batchs: 525.49169921875
INFO:root:Train (Epoch 115): Loss/seq after 04000 batchs: 522.0654296875
INFO:root:Train (Epoch 115): Loss/seq after 04050 batchs: 518.7330322265625
INFO:root:Train (Epoch 115): Loss/seq after 04100 batchs: 517.552001953125
INFO:root:Train (Epoch 115): Loss/seq after 04150 batchs: 517.808837890625
INFO:root:Train (Epoch 115): Loss/seq after 04200 batchs: 516.50927734375
INFO:root:Train (Epoch 115): Loss/seq after 04250 batchs: 514.9407958984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 115): Loss/seq after 00000 batches: 414.6784362792969
INFO:root:# Valid (Epoch 115): Loss/seq after 00050 batches: 673.6032104492188
INFO:root:# Valid (Epoch 115): Loss/seq after 00100 batches: 720.5087280273438
INFO:root:# Valid (Epoch 115): Loss/seq after 00150 batches: 544.6624145507812
INFO:root:# Valid (Epoch 115): Loss/seq after 00200 batches: 512.6568603515625
INFO:root:Artifacts: Make stick videos for epoch 115
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_115_on_20220422_085917.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_115_index_985_on_20220422_085917.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 116): Loss/seq after 00000 batchs: 909.551025390625
INFO:root:Train (Epoch 116): Loss/seq after 00050 batchs: 739.087646484375
INFO:root:Train (Epoch 116): Loss/seq after 00100 batchs: 767.5105590820312
INFO:root:Train (Epoch 116): Loss/seq after 00150 batchs: 700.8541259765625
INFO:root:Train (Epoch 116): Loss/seq after 00200 batchs: 759.046875
INFO:root:Train (Epoch 116): Loss/seq after 00250 batchs: 870.1387939453125
INFO:root:Train (Epoch 116): Loss/seq after 00300 batchs: 866.6746826171875
INFO:root:Train (Epoch 116): Loss/seq after 00350 batchs: 809.9447021484375
INFO:root:Train (Epoch 116): Loss/seq after 00400 batchs: 793.4893798828125
INFO:root:Train (Epoch 116): Loss/seq after 00450 batchs: 780.5067138671875
INFO:root:Train (Epoch 116): Loss/seq after 00500 batchs: 754.6716918945312
INFO:root:Train (Epoch 116): Loss/seq after 00550 batchs: 732.4443969726562
INFO:root:Train (Epoch 116): Loss/seq after 00600 batchs: 706.7303466796875
INFO:root:Train (Epoch 116): Loss/seq after 00650 batchs: 680.3140258789062
INFO:root:Train (Epoch 116): Loss/seq after 00700 batchs: 653.1437377929688
INFO:root:Train (Epoch 116): Loss/seq after 00750 batchs: 649.4121704101562
INFO:root:Train (Epoch 116): Loss/seq after 00800 batchs: 653.4356689453125
INFO:root:Train (Epoch 116): Loss/seq after 00850 batchs: 631.627685546875
INFO:root:Train (Epoch 116): Loss/seq after 00900 batchs: 616.5543212890625
INFO:root:Train (Epoch 116): Loss/seq after 00950 batchs: 612.099853515625
INFO:root:Train (Epoch 116): Loss/seq after 01000 batchs: 600.681884765625
INFO:root:Train (Epoch 116): Loss/seq after 01050 batchs: 588.3329467773438
INFO:root:Train (Epoch 116): Loss/seq after 01100 batchs: 579.9285278320312
INFO:root:Train (Epoch 116): Loss/seq after 01150 batchs: 564.3482055664062
INFO:root:Train (Epoch 116): Loss/seq after 01200 batchs: 569.5579833984375
INFO:root:Train (Epoch 116): Loss/seq after 01250 batchs: 567.6478881835938
INFO:root:Train (Epoch 116): Loss/seq after 01300 batchs: 555.5776977539062
INFO:root:Train (Epoch 116): Loss/seq after 01350 batchs: 545.4343872070312
INFO:root:Train (Epoch 116): Loss/seq after 01400 batchs: 546.7974853515625
INFO:root:Train (Epoch 116): Loss/seq after 01450 batchs: 548.646728515625
INFO:root:Train (Epoch 116): Loss/seq after 01500 batchs: 556.3306274414062
INFO:root:Train (Epoch 116): Loss/seq after 01550 batchs: 558.96142578125
INFO:root:Train (Epoch 116): Loss/seq after 01600 batchs: 555.046142578125
INFO:root:Train (Epoch 116): Loss/seq after 01650 batchs: 553.8238525390625
INFO:root:Train (Epoch 116): Loss/seq after 01700 batchs: 556.8001098632812
INFO:root:Train (Epoch 116): Loss/seq after 01750 batchs: 554.2129516601562
INFO:root:Train (Epoch 116): Loss/seq after 01800 batchs: 552.1878662109375
INFO:root:Train (Epoch 116): Loss/seq after 01850 batchs: 549.1558227539062
INFO:root:Train (Epoch 116): Loss/seq after 01900 batchs: 549.9913330078125
INFO:root:Train (Epoch 116): Loss/seq after 01950 batchs: 548.6118774414062
INFO:root:Train (Epoch 116): Loss/seq after 02000 batchs: 547.92578125
INFO:root:Train (Epoch 116): Loss/seq after 02050 batchs: 546.9208984375
INFO:root:Train (Epoch 116): Loss/seq after 02100 batchs: 544.87158203125
INFO:root:Train (Epoch 116): Loss/seq after 02150 batchs: 543.3375854492188
INFO:root:Train (Epoch 116): Loss/seq after 02200 batchs: 541.154296875
INFO:root:Train (Epoch 116): Loss/seq after 02250 batchs: 540.05517578125
INFO:root:Train (Epoch 116): Loss/seq after 02300 batchs: 535.3789672851562
INFO:root:Train (Epoch 116): Loss/seq after 02350 batchs: 531.3380126953125
INFO:root:Train (Epoch 116): Loss/seq after 02400 batchs: 532.0369262695312
INFO:root:Train (Epoch 116): Loss/seq after 02450 batchs: 527.7355346679688
INFO:root:Train (Epoch 116): Loss/seq after 02500 batchs: 519.6905517578125
INFO:root:Train (Epoch 116): Loss/seq after 02550 batchs: 512.8964233398438
INFO:root:Train (Epoch 116): Loss/seq after 02600 batchs: 510.5078430175781
INFO:root:Train (Epoch 116): Loss/seq after 02650 batchs: 506.6937561035156
INFO:root:Train (Epoch 116): Loss/seq after 02700 batchs: 503.6684875488281
INFO:root:Train (Epoch 116): Loss/seq after 02750 batchs: 499.22149658203125
INFO:root:Train (Epoch 116): Loss/seq after 02800 batchs: 498.9722900390625
INFO:root:Train (Epoch 116): Loss/seq after 02850 batchs: 499.248779296875
INFO:root:Train (Epoch 116): Loss/seq after 02900 batchs: 500.2381591796875
INFO:root:Train (Epoch 116): Loss/seq after 02950 batchs: 499.8076171875
INFO:root:Train (Epoch 116): Loss/seq after 03000 batchs: 505.6336364746094
INFO:root:Train (Epoch 116): Loss/seq after 03050 batchs: 507.8401184082031
INFO:root:Train (Epoch 116): Loss/seq after 03100 batchs: 510.23663330078125
INFO:root:Train (Epoch 116): Loss/seq after 03150 batchs: 510.5787048339844
INFO:root:Train (Epoch 116): Loss/seq after 03200 batchs: 510.2880859375
INFO:root:Train (Epoch 116): Loss/seq after 03250 batchs: 511.14410400390625
INFO:root:Train (Epoch 116): Loss/seq after 03300 batchs: 510.41143798828125
INFO:root:Train (Epoch 116): Loss/seq after 03350 batchs: 509.6089172363281
INFO:root:Train (Epoch 116): Loss/seq after 03400 batchs: 505.4872131347656
INFO:root:Train (Epoch 116): Loss/seq after 03450 batchs: 504.5035095214844
INFO:root:Train (Epoch 116): Loss/seq after 03500 batchs: 505.8072204589844
INFO:root:Train (Epoch 116): Loss/seq after 03550 batchs: 503.76507568359375
INFO:root:Train (Epoch 116): Loss/seq after 03600 batchs: 511.77117919921875
INFO:root:Train (Epoch 116): Loss/seq after 03650 batchs: 509.61285400390625
INFO:root:Train (Epoch 116): Loss/seq after 03700 batchs: 512.3604125976562
INFO:root:Train (Epoch 116): Loss/seq after 03750 batchs: 517.2701416015625
INFO:root:Train (Epoch 116): Loss/seq after 03800 batchs: 515.5142822265625
INFO:root:Train (Epoch 116): Loss/seq after 03850 batchs: 514.4014892578125
INFO:root:Train (Epoch 116): Loss/seq after 03900 batchs: 517.5288696289062
INFO:root:Train (Epoch 116): Loss/seq after 03950 batchs: 520.2550048828125
INFO:root:Train (Epoch 116): Loss/seq after 04000 batchs: 516.9664916992188
INFO:root:Train (Epoch 116): Loss/seq after 04050 batchs: 513.6181640625
INFO:root:Train (Epoch 116): Loss/seq after 04100 batchs: 512.3383178710938
INFO:root:Train (Epoch 116): Loss/seq after 04150 batchs: 512.5784912109375
INFO:root:Train (Epoch 116): Loss/seq after 04200 batchs: 511.2381896972656
INFO:root:Train (Epoch 116): Loss/seq after 04250 batchs: 509.71600341796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 116): Loss/seq after 00000 batches: 485.9059753417969
INFO:root:# Valid (Epoch 116): Loss/seq after 00050 batches: 660.7223510742188
INFO:root:# Valid (Epoch 116): Loss/seq after 00100 batches: 726.2011108398438
INFO:root:# Valid (Epoch 116): Loss/seq after 00150 batches: 549.1495971679688
INFO:root:# Valid (Epoch 116): Loss/seq after 00200 batches: 513.4090576171875
INFO:root:Artifacts: Make stick videos for epoch 116
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_116_on_20220422_090407.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_116_index_189_on_20220422_090407.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 117): Loss/seq after 00000 batchs: 974.9590454101562
INFO:root:Train (Epoch 117): Loss/seq after 00050 batchs: 723.9215698242188
INFO:root:Train (Epoch 117): Loss/seq after 00100 batchs: 741.6875
INFO:root:Train (Epoch 117): Loss/seq after 00150 batchs: 686.4456787109375
INFO:root:Train (Epoch 117): Loss/seq after 00200 batchs: 751.0977783203125
INFO:root:Train (Epoch 117): Loss/seq after 00250 batchs: 850.8636474609375
INFO:root:Train (Epoch 117): Loss/seq after 00300 batchs: 849.6661987304688
INFO:root:Train (Epoch 117): Loss/seq after 00350 batchs: 799.238037109375
INFO:root:Train (Epoch 117): Loss/seq after 00400 batchs: 787.2643432617188
INFO:root:Train (Epoch 117): Loss/seq after 00450 batchs: 774.4628295898438
INFO:root:Train (Epoch 117): Loss/seq after 00500 batchs: 751.1480102539062
INFO:root:Train (Epoch 117): Loss/seq after 00550 batchs: 730.9098510742188
INFO:root:Train (Epoch 117): Loss/seq after 00600 batchs: 708.8221435546875
INFO:root:Train (Epoch 117): Loss/seq after 00650 batchs: 682.9318237304688
INFO:root:Train (Epoch 117): Loss/seq after 00700 batchs: 654.4916381835938
INFO:root:Train (Epoch 117): Loss/seq after 00750 batchs: 650.8021850585938
INFO:root:Train (Epoch 117): Loss/seq after 00800 batchs: 655.5606079101562
INFO:root:Train (Epoch 117): Loss/seq after 00850 batchs: 634.3064575195312
INFO:root:Train (Epoch 117): Loss/seq after 00900 batchs: 618.81884765625
INFO:root:Train (Epoch 117): Loss/seq after 00950 batchs: 614.7536010742188
INFO:root:Train (Epoch 117): Loss/seq after 01000 batchs: 603.6993408203125
INFO:root:Train (Epoch 117): Loss/seq after 01050 batchs: 595.1989135742188
INFO:root:Train (Epoch 117): Loss/seq after 01100 batchs: 586.4470825195312
INFO:root:Train (Epoch 117): Loss/seq after 01150 batchs: 570.0582885742188
INFO:root:Train (Epoch 117): Loss/seq after 01200 batchs: 574.9049072265625
INFO:root:Train (Epoch 117): Loss/seq after 01250 batchs: 573.0320434570312
INFO:root:Train (Epoch 117): Loss/seq after 01300 batchs: 560.3177490234375
INFO:root:Train (Epoch 117): Loss/seq after 01350 batchs: 549.7354736328125
INFO:root:Train (Epoch 117): Loss/seq after 01400 batchs: 549.9545288085938
INFO:root:Train (Epoch 117): Loss/seq after 01450 batchs: 551.9393920898438
INFO:root:Train (Epoch 117): Loss/seq after 01500 batchs: 559.4275512695312
INFO:root:Train (Epoch 117): Loss/seq after 01550 batchs: 561.6048583984375
INFO:root:Train (Epoch 117): Loss/seq after 01600 batchs: 557.0487670898438
INFO:root:Train (Epoch 117): Loss/seq after 01650 batchs: 555.71728515625
INFO:root:Train (Epoch 117): Loss/seq after 01700 batchs: 558.6803588867188
INFO:root:Train (Epoch 117): Loss/seq after 01750 batchs: 555.9723510742188
INFO:root:Train (Epoch 117): Loss/seq after 01800 batchs: 553.8836669921875
INFO:root:Train (Epoch 117): Loss/seq after 01850 batchs: 550.7351684570312
INFO:root:Train (Epoch 117): Loss/seq after 01900 batchs: 551.229248046875
INFO:root:Train (Epoch 117): Loss/seq after 01950 batchs: 550.0078125
INFO:root:Train (Epoch 117): Loss/seq after 02000 batchs: 549.5152587890625
INFO:root:Train (Epoch 117): Loss/seq after 02050 batchs: 548.464599609375
INFO:root:Train (Epoch 117): Loss/seq after 02100 batchs: 546.1555786132812
INFO:root:Train (Epoch 117): Loss/seq after 02150 batchs: 544.4839477539062
INFO:root:Train (Epoch 117): Loss/seq after 02200 batchs: 542.20751953125
INFO:root:Train (Epoch 117): Loss/seq after 02250 batchs: 541.0643920898438
INFO:root:Train (Epoch 117): Loss/seq after 02300 batchs: 536.48681640625
INFO:root:Train (Epoch 117): Loss/seq after 02350 batchs: 532.35791015625
INFO:root:Train (Epoch 117): Loss/seq after 02400 batchs: 533.15966796875
INFO:root:Train (Epoch 117): Loss/seq after 02450 batchs: 528.8251953125
INFO:root:Train (Epoch 117): Loss/seq after 02500 batchs: 520.733154296875
INFO:root:Train (Epoch 117): Loss/seq after 02550 batchs: 513.7698364257812
INFO:root:Train (Epoch 117): Loss/seq after 02600 batchs: 511.259765625
INFO:root:Train (Epoch 117): Loss/seq after 02650 batchs: 507.2115783691406
INFO:root:Train (Epoch 117): Loss/seq after 02700 batchs: 504.2232666015625
INFO:root:Train (Epoch 117): Loss/seq after 02750 batchs: 499.7010498046875
INFO:root:Train (Epoch 117): Loss/seq after 02800 batchs: 498.7421875
INFO:root:Train (Epoch 117): Loss/seq after 02850 batchs: 498.804931640625
INFO:root:Train (Epoch 117): Loss/seq after 02900 batchs: 499.82647705078125
INFO:root:Train (Epoch 117): Loss/seq after 02950 batchs: 499.41070556640625
INFO:root:Train (Epoch 117): Loss/seq after 03000 batchs: 505.2724304199219
INFO:root:Train (Epoch 117): Loss/seq after 03050 batchs: 507.26605224609375
INFO:root:Train (Epoch 117): Loss/seq after 03100 batchs: 510.113525390625
INFO:root:Train (Epoch 117): Loss/seq after 03150 batchs: 510.5843811035156
INFO:root:Train (Epoch 117): Loss/seq after 03200 batchs: 510.67974853515625
INFO:root:Train (Epoch 117): Loss/seq after 03250 batchs: 511.7870178222656
INFO:root:Train (Epoch 117): Loss/seq after 03300 batchs: 511.29083251953125
INFO:root:Train (Epoch 117): Loss/seq after 03350 batchs: 510.3992614746094
INFO:root:Train (Epoch 117): Loss/seq after 03400 batchs: 506.24993896484375
INFO:root:Train (Epoch 117): Loss/seq after 03450 batchs: 505.1664123535156
INFO:root:Train (Epoch 117): Loss/seq after 03500 batchs: 506.3158874511719
INFO:root:Train (Epoch 117): Loss/seq after 03550 batchs: 504.0672302246094
INFO:root:Train (Epoch 117): Loss/seq after 03600 batchs: 511.6205139160156
INFO:root:Train (Epoch 117): Loss/seq after 03650 batchs: 509.6521301269531
INFO:root:Train (Epoch 117): Loss/seq after 03700 batchs: 512.739990234375
INFO:root:Train (Epoch 117): Loss/seq after 03750 batchs: 517.76953125
INFO:root:Train (Epoch 117): Loss/seq after 03800 batchs: 516.0421142578125
INFO:root:Train (Epoch 117): Loss/seq after 03850 batchs: 515.2510375976562
INFO:root:Train (Epoch 117): Loss/seq after 03900 batchs: 518.3674926757812
INFO:root:Train (Epoch 117): Loss/seq after 03950 batchs: 521.1602783203125
INFO:root:Train (Epoch 117): Loss/seq after 04000 batchs: 517.9237060546875
INFO:root:Train (Epoch 117): Loss/seq after 04050 batchs: 514.600830078125
INFO:root:Train (Epoch 117): Loss/seq after 04100 batchs: 513.3744506835938
INFO:root:Train (Epoch 117): Loss/seq after 04150 batchs: 513.57763671875
INFO:root:Train (Epoch 117): Loss/seq after 04200 batchs: 512.4285278320312
INFO:root:Train (Epoch 117): Loss/seq after 04250 batchs: 510.8243408203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 117): Loss/seq after 00000 batches: 435.2136535644531
INFO:root:# Valid (Epoch 117): Loss/seq after 00050 batches: 634.9140014648438
INFO:root:# Valid (Epoch 117): Loss/seq after 00100 batches: 675.4976806640625
INFO:root:# Valid (Epoch 117): Loss/seq after 00150 batches: 517.1669311523438
INFO:root:# Valid (Epoch 117): Loss/seq after 00200 batches: 490.4138488769531
INFO:root:Artifacts: Make stick videos for epoch 117
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_117_on_20220422_090853.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_117_index_1307_on_20220422_090853.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 118): Loss/seq after 00000 batchs: 852.7138061523438
INFO:root:Train (Epoch 118): Loss/seq after 00050 batchs: 722.260986328125
INFO:root:Train (Epoch 118): Loss/seq after 00100 batchs: 761.5474853515625
INFO:root:Train (Epoch 118): Loss/seq after 00150 batchs: 696.985107421875
INFO:root:Train (Epoch 118): Loss/seq after 00200 batchs: 762.5634155273438
INFO:root:Train (Epoch 118): Loss/seq after 00250 batchs: 849.3668823242188
INFO:root:Train (Epoch 118): Loss/seq after 00300 batchs: 848.8896484375
INFO:root:Train (Epoch 118): Loss/seq after 00350 batchs: 794.900390625
INFO:root:Train (Epoch 118): Loss/seq after 00400 batchs: 782.4620971679688
INFO:root:Train (Epoch 118): Loss/seq after 00450 batchs: 770.0142211914062
INFO:root:Train (Epoch 118): Loss/seq after 00500 batchs: 748.177734375
INFO:root:Train (Epoch 118): Loss/seq after 00550 batchs: 726.3128051757812
INFO:root:Train (Epoch 118): Loss/seq after 00600 batchs: 701.9027099609375
INFO:root:Train (Epoch 118): Loss/seq after 00650 batchs: 674.5001831054688
INFO:root:Train (Epoch 118): Loss/seq after 00700 batchs: 646.088134765625
INFO:root:Train (Epoch 118): Loss/seq after 00750 batchs: 642.6616821289062
INFO:root:Train (Epoch 118): Loss/seq after 00800 batchs: 645.839599609375
INFO:root:Train (Epoch 118): Loss/seq after 00850 batchs: 624.8090209960938
INFO:root:Train (Epoch 118): Loss/seq after 00900 batchs: 610.0264892578125
INFO:root:Train (Epoch 118): Loss/seq after 00950 batchs: 605.2623901367188
INFO:root:Train (Epoch 118): Loss/seq after 01000 batchs: 594.0531616210938
INFO:root:Train (Epoch 118): Loss/seq after 01050 batchs: 581.1140747070312
INFO:root:Train (Epoch 118): Loss/seq after 01100 batchs: 572.0280151367188
INFO:root:Train (Epoch 118): Loss/seq after 01150 batchs: 556.2223510742188
INFO:root:Train (Epoch 118): Loss/seq after 01200 batchs: 561.3026123046875
INFO:root:Train (Epoch 118): Loss/seq after 01250 batchs: 559.2052001953125
INFO:root:Train (Epoch 118): Loss/seq after 01300 batchs: 547.2940673828125
INFO:root:Train (Epoch 118): Loss/seq after 01350 batchs: 537.5009765625
INFO:root:Train (Epoch 118): Loss/seq after 01400 batchs: 538.4172973632812
INFO:root:Train (Epoch 118): Loss/seq after 01450 batchs: 540.6810913085938
INFO:root:Train (Epoch 118): Loss/seq after 01500 batchs: 548.313720703125
INFO:root:Train (Epoch 118): Loss/seq after 01550 batchs: 550.4439086914062
INFO:root:Train (Epoch 118): Loss/seq after 01600 batchs: 546.2794799804688
INFO:root:Train (Epoch 118): Loss/seq after 01650 batchs: 544.751953125
INFO:root:Train (Epoch 118): Loss/seq after 01700 batchs: 547.7880249023438
INFO:root:Train (Epoch 118): Loss/seq after 01750 batchs: 545.5186767578125
INFO:root:Train (Epoch 118): Loss/seq after 01800 batchs: 543.563720703125
INFO:root:Train (Epoch 118): Loss/seq after 01850 batchs: 540.6341552734375
INFO:root:Train (Epoch 118): Loss/seq after 01900 batchs: 541.6400146484375
INFO:root:Train (Epoch 118): Loss/seq after 01950 batchs: 540.4682006835938
INFO:root:Train (Epoch 118): Loss/seq after 02000 batchs: 539.8550415039062
INFO:root:Train (Epoch 118): Loss/seq after 02050 batchs: 539.1845703125
INFO:root:Train (Epoch 118): Loss/seq after 02100 batchs: 536.9374389648438
INFO:root:Train (Epoch 118): Loss/seq after 02150 batchs: 535.4165649414062
INFO:root:Train (Epoch 118): Loss/seq after 02200 batchs: 533.3314819335938
INFO:root:Train (Epoch 118): Loss/seq after 02250 batchs: 532.44580078125
INFO:root:Train (Epoch 118): Loss/seq after 02300 batchs: 527.948974609375
INFO:root:Train (Epoch 118): Loss/seq after 02350 batchs: 523.9515380859375
INFO:root:Train (Epoch 118): Loss/seq after 02400 batchs: 524.8831787109375
INFO:root:Train (Epoch 118): Loss/seq after 02450 batchs: 520.7139282226562
INFO:root:Train (Epoch 118): Loss/seq after 02500 batchs: 512.7500610351562
INFO:root:Train (Epoch 118): Loss/seq after 02550 batchs: 505.8829345703125
INFO:root:Train (Epoch 118): Loss/seq after 02600 batchs: 503.3361511230469
INFO:root:Train (Epoch 118): Loss/seq after 02650 batchs: 499.3593444824219
INFO:root:Train (Epoch 118): Loss/seq after 02700 batchs: 496.3593444824219
INFO:root:Train (Epoch 118): Loss/seq after 02750 batchs: 491.80413818359375
INFO:root:Train (Epoch 118): Loss/seq after 02800 batchs: 490.9186096191406
INFO:root:Train (Epoch 118): Loss/seq after 02850 batchs: 491.0247497558594
INFO:root:Train (Epoch 118): Loss/seq after 02900 batchs: 492.1230773925781
INFO:root:Train (Epoch 118): Loss/seq after 02950 batchs: 491.86328125
INFO:root:Train (Epoch 118): Loss/seq after 03000 batchs: 497.7107849121094
INFO:root:Train (Epoch 118): Loss/seq after 03050 batchs: 499.82379150390625
INFO:root:Train (Epoch 118): Loss/seq after 03100 batchs: 502.715087890625
INFO:root:Train (Epoch 118): Loss/seq after 03150 batchs: 502.8583068847656
INFO:root:Train (Epoch 118): Loss/seq after 03200 batchs: 503.0615234375
INFO:root:Train (Epoch 118): Loss/seq after 03250 batchs: 503.7314453125
INFO:root:Train (Epoch 118): Loss/seq after 03300 batchs: 502.7708435058594
INFO:root:Train (Epoch 118): Loss/seq after 03350 batchs: 501.8085632324219
INFO:root:Train (Epoch 118): Loss/seq after 03400 batchs: 497.9886474609375
INFO:root:Train (Epoch 118): Loss/seq after 03450 batchs: 496.8788757324219
INFO:root:Train (Epoch 118): Loss/seq after 03500 batchs: 498.1076354980469
INFO:root:Train (Epoch 118): Loss/seq after 03550 batchs: 495.98529052734375
INFO:root:Train (Epoch 118): Loss/seq after 03600 batchs: 503.51849365234375
INFO:root:Train (Epoch 118): Loss/seq after 03650 batchs: 501.716064453125
INFO:root:Train (Epoch 118): Loss/seq after 03700 batchs: 504.7530822753906
INFO:root:Train (Epoch 118): Loss/seq after 03750 batchs: 509.68365478515625
INFO:root:Train (Epoch 118): Loss/seq after 03800 batchs: 508.0525817871094
INFO:root:Train (Epoch 118): Loss/seq after 03850 batchs: 507.0879821777344
INFO:root:Train (Epoch 118): Loss/seq after 03900 batchs: 509.90380859375
INFO:root:Train (Epoch 118): Loss/seq after 03950 batchs: 512.3896484375
INFO:root:Train (Epoch 118): Loss/seq after 04000 batchs: 509.070068359375
INFO:root:Train (Epoch 118): Loss/seq after 04050 batchs: 505.8175964355469
INFO:root:Train (Epoch 118): Loss/seq after 04100 batchs: 504.5925598144531
INFO:root:Train (Epoch 118): Loss/seq after 04150 batchs: 504.8330993652344
INFO:root:Train (Epoch 118): Loss/seq after 04200 batchs: 503.6011657714844
INFO:root:Train (Epoch 118): Loss/seq after 04250 batchs: 502.2522888183594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 118): Loss/seq after 00000 batches: 434.3929748535156
INFO:root:# Valid (Epoch 118): Loss/seq after 00050 batches: 664.812744140625
INFO:root:# Valid (Epoch 118): Loss/seq after 00100 batches: 692.6015625
INFO:root:# Valid (Epoch 118): Loss/seq after 00150 batches: 524.8258056640625
INFO:root:# Valid (Epoch 118): Loss/seq after 00200 batches: 494.27288818359375
INFO:root:Artifacts: Make stick videos for epoch 118
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_118_on_20220422_091338.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_118_index_1851_on_20220422_091338.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 119): Loss/seq after 00000 batchs: 792.0846557617188
INFO:root:Train (Epoch 119): Loss/seq after 00050 batchs: 692.0579223632812
INFO:root:Train (Epoch 119): Loss/seq after 00100 batchs: 729.2387084960938
INFO:root:Train (Epoch 119): Loss/seq after 00150 batchs: 674.3265991210938
INFO:root:Train (Epoch 119): Loss/seq after 00200 batchs: 736.9703369140625
INFO:root:Train (Epoch 119): Loss/seq after 00250 batchs: 852.759765625
INFO:root:Train (Epoch 119): Loss/seq after 00300 batchs: 851.080078125
INFO:root:Train (Epoch 119): Loss/seq after 00350 batchs: 796.5604248046875
INFO:root:Train (Epoch 119): Loss/seq after 00400 batchs: 779.2866821289062
INFO:root:Train (Epoch 119): Loss/seq after 00450 batchs: 766.795166015625
INFO:root:Train (Epoch 119): Loss/seq after 00500 batchs: 740.57666015625
INFO:root:Train (Epoch 119): Loss/seq after 00550 batchs: 718.2987060546875
INFO:root:Train (Epoch 119): Loss/seq after 00600 batchs: 693.1087646484375
INFO:root:Train (Epoch 119): Loss/seq after 00650 batchs: 666.209716796875
INFO:root:Train (Epoch 119): Loss/seq after 00700 batchs: 637.4266967773438
INFO:root:Train (Epoch 119): Loss/seq after 00750 batchs: 633.38720703125
INFO:root:Train (Epoch 119): Loss/seq after 00800 batchs: 636.6136474609375
INFO:root:Train (Epoch 119): Loss/seq after 00850 batchs: 615.4979248046875
INFO:root:Train (Epoch 119): Loss/seq after 00900 batchs: 600.13818359375
INFO:root:Train (Epoch 119): Loss/seq after 00950 batchs: 596.848876953125
INFO:root:Train (Epoch 119): Loss/seq after 01000 batchs: 585.6489868164062
INFO:root:Train (Epoch 119): Loss/seq after 01050 batchs: 575.6707153320312
INFO:root:Train (Epoch 119): Loss/seq after 01100 batchs: 566.840087890625
INFO:root:Train (Epoch 119): Loss/seq after 01150 batchs: 551.4374389648438
INFO:root:Train (Epoch 119): Loss/seq after 01200 batchs: 556.7179565429688
INFO:root:Train (Epoch 119): Loss/seq after 01250 batchs: 554.8239135742188
INFO:root:Train (Epoch 119): Loss/seq after 01300 batchs: 543.3939208984375
INFO:root:Train (Epoch 119): Loss/seq after 01350 batchs: 533.3240356445312
INFO:root:Train (Epoch 119): Loss/seq after 01400 batchs: 534.4219970703125
INFO:root:Train (Epoch 119): Loss/seq after 01450 batchs: 536.8092041015625
INFO:root:Train (Epoch 119): Loss/seq after 01500 batchs: 544.831298828125
INFO:root:Train (Epoch 119): Loss/seq after 01550 batchs: 546.81640625
INFO:root:Train (Epoch 119): Loss/seq after 01600 batchs: 543.1199340820312
INFO:root:Train (Epoch 119): Loss/seq after 01650 batchs: 541.6420288085938
INFO:root:Train (Epoch 119): Loss/seq after 01700 batchs: 544.7435302734375
INFO:root:Train (Epoch 119): Loss/seq after 01750 batchs: 542.2676391601562
INFO:root:Train (Epoch 119): Loss/seq after 01800 batchs: 540.041015625
INFO:root:Train (Epoch 119): Loss/seq after 01850 batchs: 537.0771484375
INFO:root:Train (Epoch 119): Loss/seq after 01900 batchs: 537.7703247070312
INFO:root:Train (Epoch 119): Loss/seq after 01950 batchs: 536.306640625
INFO:root:Train (Epoch 119): Loss/seq after 02000 batchs: 535.7977905273438
INFO:root:Train (Epoch 119): Loss/seq after 02050 batchs: 534.942138671875
INFO:root:Train (Epoch 119): Loss/seq after 02100 batchs: 532.7844848632812
INFO:root:Train (Epoch 119): Loss/seq after 02150 batchs: 531.4751586914062
INFO:root:Train (Epoch 119): Loss/seq after 02200 batchs: 529.388916015625
INFO:root:Train (Epoch 119): Loss/seq after 02250 batchs: 528.395263671875
INFO:root:Train (Epoch 119): Loss/seq after 02300 batchs: 523.9092407226562
INFO:root:Train (Epoch 119): Loss/seq after 02350 batchs: 519.9974975585938
INFO:root:Train (Epoch 119): Loss/seq after 02400 batchs: 520.7879028320312
INFO:root:Train (Epoch 119): Loss/seq after 02450 batchs: 516.6503295898438
INFO:root:Train (Epoch 119): Loss/seq after 02500 batchs: 508.7470397949219
INFO:root:Train (Epoch 119): Loss/seq after 02550 batchs: 501.8561706542969
INFO:root:Train (Epoch 119): Loss/seq after 02600 batchs: 499.3551940917969
INFO:root:Train (Epoch 119): Loss/seq after 02650 batchs: 495.520263671875
INFO:root:Train (Epoch 119): Loss/seq after 02700 batchs: 492.56512451171875
INFO:root:Train (Epoch 119): Loss/seq after 02750 batchs: 488.6579284667969
INFO:root:Train (Epoch 119): Loss/seq after 02800 batchs: 488.10308837890625
INFO:root:Train (Epoch 119): Loss/seq after 02850 batchs: 488.2732849121094
INFO:root:Train (Epoch 119): Loss/seq after 02900 batchs: 489.4064636230469
INFO:root:Train (Epoch 119): Loss/seq after 02950 batchs: 489.0999755859375
INFO:root:Train (Epoch 119): Loss/seq after 03000 batchs: 494.9350280761719
INFO:root:Train (Epoch 119): Loss/seq after 03050 batchs: 497.3265075683594
INFO:root:Train (Epoch 119): Loss/seq after 03100 batchs: 500.1171569824219
INFO:root:Train (Epoch 119): Loss/seq after 03150 batchs: 500.3516845703125
INFO:root:Train (Epoch 119): Loss/seq after 03200 batchs: 500.35931396484375
INFO:root:Train (Epoch 119): Loss/seq after 03250 batchs: 501.37744140625
INFO:root:Train (Epoch 119): Loss/seq after 03300 batchs: 501.0828552246094
INFO:root:Train (Epoch 119): Loss/seq after 03350 batchs: 500.148681640625
INFO:root:Train (Epoch 119): Loss/seq after 03400 batchs: 496.12115478515625
INFO:root:Train (Epoch 119): Loss/seq after 03450 batchs: 495.0601501464844
INFO:root:Train (Epoch 119): Loss/seq after 03500 batchs: 496.2281188964844
INFO:root:Train (Epoch 119): Loss/seq after 03550 batchs: 494.0520324707031
INFO:root:Train (Epoch 119): Loss/seq after 03600 batchs: 501.54754638671875
INFO:root:Train (Epoch 119): Loss/seq after 03650 batchs: 499.5945129394531
INFO:root:Train (Epoch 119): Loss/seq after 03700 batchs: 502.429443359375
INFO:root:Train (Epoch 119): Loss/seq after 03750 batchs: 507.4790954589844
INFO:root:Train (Epoch 119): Loss/seq after 03800 batchs: 505.82366943359375
INFO:root:Train (Epoch 119): Loss/seq after 03850 batchs: 504.76544189453125
INFO:root:Train (Epoch 119): Loss/seq after 03900 batchs: 507.5989685058594
INFO:root:Train (Epoch 119): Loss/seq after 03950 batchs: 510.0676574707031
INFO:root:Train (Epoch 119): Loss/seq after 04000 batchs: 506.78717041015625
INFO:root:Train (Epoch 119): Loss/seq after 04050 batchs: 503.5165710449219
INFO:root:Train (Epoch 119): Loss/seq after 04100 batchs: 502.3003845214844
INFO:root:Train (Epoch 119): Loss/seq after 04150 batchs: 502.4678955078125
INFO:root:Train (Epoch 119): Loss/seq after 04200 batchs: 501.21319580078125
INFO:root:Train (Epoch 119): Loss/seq after 04250 batchs: 499.6834716796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 119): Loss/seq after 00000 batches: 355.8533935546875
INFO:root:# Valid (Epoch 119): Loss/seq after 00050 batches: 625.3206787109375
INFO:root:# Valid (Epoch 119): Loss/seq after 00100 batches: 671.49560546875
INFO:root:# Valid (Epoch 119): Loss/seq after 00150 batches: 510.9992370605469
INFO:root:# Valid (Epoch 119): Loss/seq after 00200 batches: 482.9629211425781
INFO:root:Artifacts: Make stick videos for epoch 119
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_119_on_20220422_091823.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_119_index_1664_on_20220422_091823.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 120): Loss/seq after 00000 batchs: 832.50537109375
INFO:root:Train (Epoch 120): Loss/seq after 00050 batchs: 705.751220703125
INFO:root:Train (Epoch 120): Loss/seq after 00100 batchs: 742.6063232421875
INFO:root:Train (Epoch 120): Loss/seq after 00150 batchs: 675.0669555664062
INFO:root:Train (Epoch 120): Loss/seq after 00200 batchs: 739.1431884765625
INFO:root:Train (Epoch 120): Loss/seq after 00250 batchs: 831.3502197265625
INFO:root:Train (Epoch 120): Loss/seq after 00300 batchs: 834.2576293945312
INFO:root:Train (Epoch 120): Loss/seq after 00350 batchs: 780.85107421875
INFO:root:Train (Epoch 120): Loss/seq after 00400 batchs: 762.7213745117188
INFO:root:Train (Epoch 120): Loss/seq after 00450 batchs: 751.7102661132812
INFO:root:Train (Epoch 120): Loss/seq after 00500 batchs: 729.9898071289062
INFO:root:Train (Epoch 120): Loss/seq after 00550 batchs: 708.8147583007812
INFO:root:Train (Epoch 120): Loss/seq after 00600 batchs: 684.1842041015625
INFO:root:Train (Epoch 120): Loss/seq after 00650 batchs: 658.8942260742188
INFO:root:Train (Epoch 120): Loss/seq after 00700 batchs: 631.6742553710938
INFO:root:Train (Epoch 120): Loss/seq after 00750 batchs: 628.2507934570312
INFO:root:Train (Epoch 120): Loss/seq after 00800 batchs: 632.302001953125
INFO:root:Train (Epoch 120): Loss/seq after 00850 batchs: 611.8756103515625
INFO:root:Train (Epoch 120): Loss/seq after 00900 batchs: 599.22021484375
INFO:root:Train (Epoch 120): Loss/seq after 00950 batchs: 593.7892456054688
INFO:root:Train (Epoch 120): Loss/seq after 01000 batchs: 583.4815673828125
INFO:root:Train (Epoch 120): Loss/seq after 01050 batchs: 572.9835815429688
INFO:root:Train (Epoch 120): Loss/seq after 01100 batchs: 565.8619384765625
INFO:root:Train (Epoch 120): Loss/seq after 01150 batchs: 551.2210693359375
INFO:root:Train (Epoch 120): Loss/seq after 01200 batchs: 557.411865234375
INFO:root:Train (Epoch 120): Loss/seq after 01250 batchs: 555.6119384765625
INFO:root:Train (Epoch 120): Loss/seq after 01300 batchs: 543.5093994140625
INFO:root:Train (Epoch 120): Loss/seq after 01350 batchs: 533.3151245117188
INFO:root:Train (Epoch 120): Loss/seq after 01400 batchs: 534.4729614257812
INFO:root:Train (Epoch 120): Loss/seq after 01450 batchs: 537.0872802734375
INFO:root:Train (Epoch 120): Loss/seq after 01500 batchs: 544.9223022460938
INFO:root:Train (Epoch 120): Loss/seq after 01550 batchs: 547.513671875
INFO:root:Train (Epoch 120): Loss/seq after 01600 batchs: 543.9397583007812
INFO:root:Train (Epoch 120): Loss/seq after 01650 batchs: 542.7874755859375
INFO:root:Train (Epoch 120): Loss/seq after 01700 batchs: 546.2637329101562
INFO:root:Train (Epoch 120): Loss/seq after 01750 batchs: 543.9599609375
INFO:root:Train (Epoch 120): Loss/seq after 01800 batchs: 541.7767944335938
INFO:root:Train (Epoch 120): Loss/seq after 01850 batchs: 538.6315307617188
INFO:root:Train (Epoch 120): Loss/seq after 01900 batchs: 539.2759399414062
INFO:root:Train (Epoch 120): Loss/seq after 01950 batchs: 538.03515625
INFO:root:Train (Epoch 120): Loss/seq after 02000 batchs: 537.7078857421875
INFO:root:Train (Epoch 120): Loss/seq after 02050 batchs: 537.1090087890625
INFO:root:Train (Epoch 120): Loss/seq after 02100 batchs: 535.227783203125
INFO:root:Train (Epoch 120): Loss/seq after 02150 batchs: 533.7130126953125
INFO:root:Train (Epoch 120): Loss/seq after 02200 batchs: 531.424560546875
INFO:root:Train (Epoch 120): Loss/seq after 02250 batchs: 530.6771240234375
INFO:root:Train (Epoch 120): Loss/seq after 02300 batchs: 526.3838500976562
INFO:root:Train (Epoch 120): Loss/seq after 02350 batchs: 522.7225952148438
INFO:root:Train (Epoch 120): Loss/seq after 02400 batchs: 523.4212036132812
INFO:root:Train (Epoch 120): Loss/seq after 02450 batchs: 519.2514038085938
INFO:root:Train (Epoch 120): Loss/seq after 02500 batchs: 511.2995910644531
INFO:root:Train (Epoch 120): Loss/seq after 02550 batchs: 504.4868469238281
INFO:root:Train (Epoch 120): Loss/seq after 02600 batchs: 501.92266845703125
INFO:root:Train (Epoch 120): Loss/seq after 02650 batchs: 497.9129943847656
INFO:root:Train (Epoch 120): Loss/seq after 02700 batchs: 494.99688720703125
INFO:root:Train (Epoch 120): Loss/seq after 02750 batchs: 490.5945739746094
INFO:root:Train (Epoch 120): Loss/seq after 02800 batchs: 489.8893737792969
INFO:root:Train (Epoch 120): Loss/seq after 02850 batchs: 490.09307861328125
INFO:root:Train (Epoch 120): Loss/seq after 02900 batchs: 490.8319396972656
INFO:root:Train (Epoch 120): Loss/seq after 02950 batchs: 490.4103698730469
INFO:root:Train (Epoch 120): Loss/seq after 03000 batchs: 496.3115234375
INFO:root:Train (Epoch 120): Loss/seq after 03050 batchs: 498.2710266113281
INFO:root:Train (Epoch 120): Loss/seq after 03100 batchs: 500.7877197265625
INFO:root:Train (Epoch 120): Loss/seq after 03150 batchs: 500.9023742675781
INFO:root:Train (Epoch 120): Loss/seq after 03200 batchs: 500.9364013671875
INFO:root:Train (Epoch 120): Loss/seq after 03250 batchs: 502.3236999511719
INFO:root:Train (Epoch 120): Loss/seq after 03300 batchs: 501.21832275390625
INFO:root:Train (Epoch 120): Loss/seq after 03350 batchs: 500.2669677734375
INFO:root:Train (Epoch 120): Loss/seq after 03400 batchs: 496.2887878417969
INFO:root:Train (Epoch 120): Loss/seq after 03450 batchs: 495.0617370605469
INFO:root:Train (Epoch 120): Loss/seq after 03500 batchs: 496.1096496582031
INFO:root:Train (Epoch 120): Loss/seq after 03550 batchs: 493.8651428222656
INFO:root:Train (Epoch 120): Loss/seq after 03600 batchs: 501.2725830078125
INFO:root:Train (Epoch 120): Loss/seq after 03650 batchs: 499.4859619140625
INFO:root:Train (Epoch 120): Loss/seq after 03700 batchs: 502.4608459472656
INFO:root:Train (Epoch 120): Loss/seq after 03750 batchs: 507.34307861328125
INFO:root:Train (Epoch 120): Loss/seq after 03800 batchs: 505.6668701171875
INFO:root:Train (Epoch 120): Loss/seq after 03850 batchs: 504.6447448730469
INFO:root:Train (Epoch 120): Loss/seq after 03900 batchs: 507.5676574707031
INFO:root:Train (Epoch 120): Loss/seq after 03950 batchs: 510.1976013183594
INFO:root:Train (Epoch 120): Loss/seq after 04000 batchs: 506.8211669921875
INFO:root:Train (Epoch 120): Loss/seq after 04050 batchs: 503.6228332519531
INFO:root:Train (Epoch 120): Loss/seq after 04100 batchs: 502.4371032714844
INFO:root:Train (Epoch 120): Loss/seq after 04150 batchs: 502.6112060546875
INFO:root:Train (Epoch 120): Loss/seq after 04200 batchs: 501.2655334472656
INFO:root:Train (Epoch 120): Loss/seq after 04250 batchs: 499.77569580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 120): Loss/seq after 00000 batches: 491.67779541015625
INFO:root:# Valid (Epoch 120): Loss/seq after 00050 batches: 661.0587768554688
INFO:root:# Valid (Epoch 120): Loss/seq after 00100 batches: 694.1053466796875
INFO:root:# Valid (Epoch 120): Loss/seq after 00150 batches: 525.6094360351562
INFO:root:# Valid (Epoch 120): Loss/seq after 00200 batches: 494.6422424316406
INFO:root:Artifacts: Make stick videos for epoch 120
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_120_on_20220422_092310.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_120_index_1634_on_20220422_092310.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 121): Loss/seq after 00000 batchs: 1003.8739624023438
INFO:root:Train (Epoch 121): Loss/seq after 00050 batchs: 709.8212280273438
INFO:root:Train (Epoch 121): Loss/seq after 00100 batchs: 733.695556640625
INFO:root:Train (Epoch 121): Loss/seq after 00150 batchs: 670.0265502929688
INFO:root:Train (Epoch 121): Loss/seq after 00200 batchs: 728.2998657226562
INFO:root:Train (Epoch 121): Loss/seq after 00250 batchs: 828.7132568359375
INFO:root:Train (Epoch 121): Loss/seq after 00300 batchs: 830.560791015625
INFO:root:Train (Epoch 121): Loss/seq after 00350 batchs: 777.1475219726562
INFO:root:Train (Epoch 121): Loss/seq after 00400 batchs: 760.8157348632812
INFO:root:Train (Epoch 121): Loss/seq after 00450 batchs: 750.5065307617188
INFO:root:Train (Epoch 121): Loss/seq after 00500 batchs: 728.2034912109375
INFO:root:Train (Epoch 121): Loss/seq after 00550 batchs: 707.51953125
INFO:root:Train (Epoch 121): Loss/seq after 00600 batchs: 681.987060546875
INFO:root:Train (Epoch 121): Loss/seq after 00650 batchs: 657.339599609375
INFO:root:Train (Epoch 121): Loss/seq after 00700 batchs: 630.1583862304688
INFO:root:Train (Epoch 121): Loss/seq after 00750 batchs: 626.5551147460938
INFO:root:Train (Epoch 121): Loss/seq after 00800 batchs: 630.9464721679688
INFO:root:Train (Epoch 121): Loss/seq after 00850 batchs: 610.083984375
INFO:root:Train (Epoch 121): Loss/seq after 00900 batchs: 596.2686767578125
INFO:root:Train (Epoch 121): Loss/seq after 00950 batchs: 590.8380737304688
INFO:root:Train (Epoch 121): Loss/seq after 01000 batchs: 581.0609741210938
INFO:root:Train (Epoch 121): Loss/seq after 01050 batchs: 568.576904296875
INFO:root:Train (Epoch 121): Loss/seq after 01100 batchs: 560.3169555664062
INFO:root:Train (Epoch 121): Loss/seq after 01150 batchs: 545.0119018554688
INFO:root:Train (Epoch 121): Loss/seq after 01200 batchs: 550.1644287109375
INFO:root:Train (Epoch 121): Loss/seq after 01250 batchs: 549.040283203125
INFO:root:Train (Epoch 121): Loss/seq after 01300 batchs: 537.0477294921875
INFO:root:Train (Epoch 121): Loss/seq after 01350 batchs: 527.113525390625
INFO:root:Train (Epoch 121): Loss/seq after 01400 batchs: 529.7208862304688
INFO:root:Train (Epoch 121): Loss/seq after 01450 batchs: 532.2991943359375
INFO:root:Train (Epoch 121): Loss/seq after 01500 batchs: 540.21484375
INFO:root:Train (Epoch 121): Loss/seq after 01550 batchs: 542.446044921875
INFO:root:Train (Epoch 121): Loss/seq after 01600 batchs: 538.24853515625
INFO:root:Train (Epoch 121): Loss/seq after 01650 batchs: 536.83740234375
INFO:root:Train (Epoch 121): Loss/seq after 01700 batchs: 540.1237182617188
INFO:root:Train (Epoch 121): Loss/seq after 01750 batchs: 537.7540283203125
INFO:root:Train (Epoch 121): Loss/seq after 01800 batchs: 535.595947265625
INFO:root:Train (Epoch 121): Loss/seq after 01850 batchs: 532.6048583984375
INFO:root:Train (Epoch 121): Loss/seq after 01900 batchs: 533.0054321289062
INFO:root:Train (Epoch 121): Loss/seq after 01950 batchs: 532.0107421875
INFO:root:Train (Epoch 121): Loss/seq after 02000 batchs: 531.600341796875
INFO:root:Train (Epoch 121): Loss/seq after 02050 batchs: 530.89794921875
INFO:root:Train (Epoch 121): Loss/seq after 02100 batchs: 528.8156127929688
INFO:root:Train (Epoch 121): Loss/seq after 02150 batchs: 527.2481079101562
INFO:root:Train (Epoch 121): Loss/seq after 02200 batchs: 525.2396850585938
INFO:root:Train (Epoch 121): Loss/seq after 02250 batchs: 524.017822265625
INFO:root:Train (Epoch 121): Loss/seq after 02300 batchs: 519.70458984375
INFO:root:Train (Epoch 121): Loss/seq after 02350 batchs: 515.8768310546875
INFO:root:Train (Epoch 121): Loss/seq after 02400 batchs: 516.6697998046875
INFO:root:Train (Epoch 121): Loss/seq after 02450 batchs: 512.6254272460938
INFO:root:Train (Epoch 121): Loss/seq after 02500 batchs: 504.7452392578125
INFO:root:Train (Epoch 121): Loss/seq after 02550 batchs: 497.9558410644531
INFO:root:Train (Epoch 121): Loss/seq after 02600 batchs: 495.728515625
INFO:root:Train (Epoch 121): Loss/seq after 02650 batchs: 491.84075927734375
INFO:root:Train (Epoch 121): Loss/seq after 02700 batchs: 488.908203125
INFO:root:Train (Epoch 121): Loss/seq after 02750 batchs: 484.8749694824219
INFO:root:Train (Epoch 121): Loss/seq after 02800 batchs: 484.0722961425781
INFO:root:Train (Epoch 121): Loss/seq after 02850 batchs: 484.1377258300781
INFO:root:Train (Epoch 121): Loss/seq after 02900 batchs: 484.82208251953125
INFO:root:Train (Epoch 121): Loss/seq after 02950 batchs: 484.52044677734375
INFO:root:Train (Epoch 121): Loss/seq after 03000 batchs: 490.5129699707031
INFO:root:Train (Epoch 121): Loss/seq after 03050 batchs: 492.7085266113281
INFO:root:Train (Epoch 121): Loss/seq after 03100 batchs: 495.8334655761719
INFO:root:Train (Epoch 121): Loss/seq after 03150 batchs: 496.00634765625
INFO:root:Train (Epoch 121): Loss/seq after 03200 batchs: 496.038330078125
INFO:root:Train (Epoch 121): Loss/seq after 03250 batchs: 497.189697265625
INFO:root:Train (Epoch 121): Loss/seq after 03300 batchs: 496.61724853515625
INFO:root:Train (Epoch 121): Loss/seq after 03350 batchs: 495.62957763671875
INFO:root:Train (Epoch 121): Loss/seq after 03400 batchs: 491.7485656738281
INFO:root:Train (Epoch 121): Loss/seq after 03450 batchs: 490.6852111816406
INFO:root:Train (Epoch 121): Loss/seq after 03500 batchs: 491.8186950683594
INFO:root:Train (Epoch 121): Loss/seq after 03550 batchs: 489.9784851074219
INFO:root:Train (Epoch 121): Loss/seq after 03600 batchs: 497.54510498046875
INFO:root:Train (Epoch 121): Loss/seq after 03650 batchs: 495.6256408691406
INFO:root:Train (Epoch 121): Loss/seq after 03700 batchs: 498.4526062011719
INFO:root:Train (Epoch 121): Loss/seq after 03750 batchs: 503.2853698730469
INFO:root:Train (Epoch 121): Loss/seq after 03800 batchs: 501.622802734375
INFO:root:Train (Epoch 121): Loss/seq after 03850 batchs: 500.4908142089844
INFO:root:Train (Epoch 121): Loss/seq after 03900 batchs: 503.1412353515625
INFO:root:Train (Epoch 121): Loss/seq after 03950 batchs: 505.6898498535156
INFO:root:Train (Epoch 121): Loss/seq after 04000 batchs: 502.3829345703125
INFO:root:Train (Epoch 121): Loss/seq after 04050 batchs: 499.119873046875
INFO:root:Train (Epoch 121): Loss/seq after 04100 batchs: 497.8580322265625
INFO:root:Train (Epoch 121): Loss/seq after 04150 batchs: 498.0484313964844
INFO:root:Train (Epoch 121): Loss/seq after 04200 batchs: 496.9012451171875
INFO:root:Train (Epoch 121): Loss/seq after 04250 batchs: 495.4877014160156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 121): Loss/seq after 00000 batches: 404.0846862792969
INFO:root:# Valid (Epoch 121): Loss/seq after 00050 batches: 647.6983032226562
INFO:root:# Valid (Epoch 121): Loss/seq after 00100 batches: 745.6331787109375
INFO:root:# Valid (Epoch 121): Loss/seq after 00150 batches: 566.4251098632812
INFO:root:# Valid (Epoch 121): Loss/seq after 00200 batches: 536.4024047851562
INFO:root:Artifacts: Make stick videos for epoch 121
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_121_on_20220422_092804.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_121_index_1391_on_20220422_092804.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 122): Loss/seq after 00000 batchs: 766.133544921875
INFO:root:Train (Epoch 122): Loss/seq after 00050 batchs: 703.620361328125
INFO:root:Train (Epoch 122): Loss/seq after 00100 batchs: 733.5471801757812
INFO:root:Train (Epoch 122): Loss/seq after 00150 batchs: 679.2742309570312
INFO:root:Train (Epoch 122): Loss/seq after 00200 batchs: 746.3046264648438
INFO:root:Train (Epoch 122): Loss/seq after 00250 batchs: 834.7330932617188
INFO:root:Train (Epoch 122): Loss/seq after 00300 batchs: 834.7176513671875
INFO:root:Train (Epoch 122): Loss/seq after 00350 batchs: 782.8942260742188
INFO:root:Train (Epoch 122): Loss/seq after 00400 batchs: 767.6527099609375
INFO:root:Train (Epoch 122): Loss/seq after 00450 batchs: 757.8302612304688
INFO:root:Train (Epoch 122): Loss/seq after 00500 batchs: 738.0029907226562
INFO:root:Train (Epoch 122): Loss/seq after 00550 batchs: 721.1337890625
INFO:root:Train (Epoch 122): Loss/seq after 00600 batchs: 695.8197021484375
INFO:root:Train (Epoch 122): Loss/seq after 00650 batchs: 667.3983764648438
INFO:root:Train (Epoch 122): Loss/seq after 00700 batchs: 639.1397094726562
INFO:root:Train (Epoch 122): Loss/seq after 00750 batchs: 633.3192749023438
INFO:root:Train (Epoch 122): Loss/seq after 00800 batchs: 640.8236694335938
INFO:root:Train (Epoch 122): Loss/seq after 00850 batchs: 622.6146240234375
INFO:root:Train (Epoch 122): Loss/seq after 00900 batchs: 608.2138671875
INFO:root:Train (Epoch 122): Loss/seq after 00950 batchs: 602.98828125
INFO:root:Train (Epoch 122): Loss/seq after 01000 batchs: 591.5291137695312
INFO:root:Train (Epoch 122): Loss/seq after 01050 batchs: 580.3314819335938
INFO:root:Train (Epoch 122): Loss/seq after 01100 batchs: 570.560302734375
INFO:root:Train (Epoch 122): Loss/seq after 01150 batchs: 554.83984375
INFO:root:Train (Epoch 122): Loss/seq after 01200 batchs: 559.7951049804688
INFO:root:Train (Epoch 122): Loss/seq after 01250 batchs: 557.843994140625
INFO:root:Train (Epoch 122): Loss/seq after 01300 batchs: 545.4159545898438
INFO:root:Train (Epoch 122): Loss/seq after 01350 batchs: 534.9074096679688
INFO:root:Train (Epoch 122): Loss/seq after 01400 batchs: 536.9808349609375
INFO:root:Train (Epoch 122): Loss/seq after 01450 batchs: 539.3583984375
INFO:root:Train (Epoch 122): Loss/seq after 01500 batchs: 547.0330200195312
INFO:root:Train (Epoch 122): Loss/seq after 01550 batchs: 548.9735717773438
INFO:root:Train (Epoch 122): Loss/seq after 01600 batchs: 544.6668701171875
INFO:root:Train (Epoch 122): Loss/seq after 01650 batchs: 543.4702758789062
INFO:root:Train (Epoch 122): Loss/seq after 01700 batchs: 546.2948608398438
INFO:root:Train (Epoch 122): Loss/seq after 01750 batchs: 543.7095947265625
INFO:root:Train (Epoch 122): Loss/seq after 01800 batchs: 541.2998046875
INFO:root:Train (Epoch 122): Loss/seq after 01850 batchs: 538.1156005859375
INFO:root:Train (Epoch 122): Loss/seq after 01900 batchs: 538.372802734375
INFO:root:Train (Epoch 122): Loss/seq after 01950 batchs: 536.5803833007812
INFO:root:Train (Epoch 122): Loss/seq after 02000 batchs: 536.045166015625
INFO:root:Train (Epoch 122): Loss/seq after 02050 batchs: 535.1880493164062
INFO:root:Train (Epoch 122): Loss/seq after 02100 batchs: 532.9591064453125
INFO:root:Train (Epoch 122): Loss/seq after 02150 batchs: 531.2230834960938
INFO:root:Train (Epoch 122): Loss/seq after 02200 batchs: 529.0103149414062
INFO:root:Train (Epoch 122): Loss/seq after 02250 batchs: 527.6489868164062
INFO:root:Train (Epoch 122): Loss/seq after 02300 batchs: 523.4258422851562
INFO:root:Train (Epoch 122): Loss/seq after 02350 batchs: 519.5980834960938
INFO:root:Train (Epoch 122): Loss/seq after 02400 batchs: 520.1558227539062
INFO:root:Train (Epoch 122): Loss/seq after 02450 batchs: 515.9566650390625
INFO:root:Train (Epoch 122): Loss/seq after 02500 batchs: 508.0047607421875
INFO:root:Train (Epoch 122): Loss/seq after 02550 batchs: 501.085205078125
INFO:root:Train (Epoch 122): Loss/seq after 02600 batchs: 498.32232666015625
INFO:root:Train (Epoch 122): Loss/seq after 02650 batchs: 494.2821960449219
INFO:root:Train (Epoch 122): Loss/seq after 02700 batchs: 491.2416076660156
INFO:root:Train (Epoch 122): Loss/seq after 02750 batchs: 486.6569519042969
INFO:root:Train (Epoch 122): Loss/seq after 02800 batchs: 485.39642333984375
INFO:root:Train (Epoch 122): Loss/seq after 02850 batchs: 485.3797302246094
INFO:root:Train (Epoch 122): Loss/seq after 02900 batchs: 486.27130126953125
INFO:root:Train (Epoch 122): Loss/seq after 02950 batchs: 485.7670593261719
INFO:root:Train (Epoch 122): Loss/seq after 03000 batchs: 491.6121520996094
INFO:root:Train (Epoch 122): Loss/seq after 03050 batchs: 493.6540222167969
INFO:root:Train (Epoch 122): Loss/seq after 03100 batchs: 496.2427978515625
INFO:root:Train (Epoch 122): Loss/seq after 03150 batchs: 496.1625671386719
INFO:root:Train (Epoch 122): Loss/seq after 03200 batchs: 495.9789123535156
INFO:root:Train (Epoch 122): Loss/seq after 03250 batchs: 496.48748779296875
INFO:root:Train (Epoch 122): Loss/seq after 03300 batchs: 496.0386047363281
INFO:root:Train (Epoch 122): Loss/seq after 03350 batchs: 494.9180603027344
INFO:root:Train (Epoch 122): Loss/seq after 03400 batchs: 490.9699401855469
INFO:root:Train (Epoch 122): Loss/seq after 03450 batchs: 489.901611328125
INFO:root:Train (Epoch 122): Loss/seq after 03500 batchs: 491.08123779296875
INFO:root:Train (Epoch 122): Loss/seq after 03550 batchs: 488.89849853515625
INFO:root:Train (Epoch 122): Loss/seq after 03600 batchs: 496.1976318359375
INFO:root:Train (Epoch 122): Loss/seq after 03650 batchs: 494.1031494140625
INFO:root:Train (Epoch 122): Loss/seq after 03700 batchs: 496.88372802734375
INFO:root:Train (Epoch 122): Loss/seq after 03750 batchs: 501.75079345703125
INFO:root:Train (Epoch 122): Loss/seq after 03800 batchs: 500.1683349609375
INFO:root:Train (Epoch 122): Loss/seq after 03850 batchs: 499.0709533691406
INFO:root:Train (Epoch 122): Loss/seq after 03900 batchs: 502.11444091796875
INFO:root:Train (Epoch 122): Loss/seq after 03950 batchs: 504.4029235839844
INFO:root:Train (Epoch 122): Loss/seq after 04000 batchs: 501.094970703125
INFO:root:Train (Epoch 122): Loss/seq after 04050 batchs: 497.7979736328125
INFO:root:Train (Epoch 122): Loss/seq after 04100 batchs: 496.58685302734375
INFO:root:Train (Epoch 122): Loss/seq after 04150 batchs: 496.7962341308594
INFO:root:Train (Epoch 122): Loss/seq after 04200 batchs: 495.3829650878906
INFO:root:Train (Epoch 122): Loss/seq after 04250 batchs: 493.8943786621094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 122): Loss/seq after 00000 batches: 412.9761657714844
INFO:root:# Valid (Epoch 122): Loss/seq after 00050 batches: 632.4047241210938
INFO:root:# Valid (Epoch 122): Loss/seq after 00100 batches: 677.3298950195312
INFO:root:# Valid (Epoch 122): Loss/seq after 00150 batches: 512.0988159179688
INFO:root:# Valid (Epoch 122): Loss/seq after 00200 batches: 484.8448181152344
INFO:root:Artifacts: Make stick videos for epoch 122
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_122_on_20220422_093303.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_122_index_301_on_20220422_093303.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 123): Loss/seq after 00000 batchs: 988.4983520507812
INFO:root:Train (Epoch 123): Loss/seq after 00050 batchs: 697.8101806640625
INFO:root:Train (Epoch 123): Loss/seq after 00100 batchs: 730.9234008789062
INFO:root:Train (Epoch 123): Loss/seq after 00150 batchs: 670.0184936523438
INFO:root:Train (Epoch 123): Loss/seq after 00200 batchs: 741.8046264648438
INFO:root:Train (Epoch 123): Loss/seq after 00250 batchs: 832.42236328125
INFO:root:Train (Epoch 123): Loss/seq after 00300 batchs: 831.4318237304688
INFO:root:Train (Epoch 123): Loss/seq after 00350 batchs: 778.2619018554688
INFO:root:Train (Epoch 123): Loss/seq after 00400 batchs: 759.96728515625
INFO:root:Train (Epoch 123): Loss/seq after 00450 batchs: 749.5401611328125
INFO:root:Train (Epoch 123): Loss/seq after 00500 batchs: 723.117919921875
INFO:root:Train (Epoch 123): Loss/seq after 00550 batchs: 702.5223999023438
INFO:root:Train (Epoch 123): Loss/seq after 00600 batchs: 678.4793090820312
INFO:root:Train (Epoch 123): Loss/seq after 00650 batchs: 651.2737426757812
INFO:root:Train (Epoch 123): Loss/seq after 00700 batchs: 623.080810546875
INFO:root:Train (Epoch 123): Loss/seq after 00750 batchs: 618.6261596679688
INFO:root:Train (Epoch 123): Loss/seq after 00800 batchs: 622.501220703125
INFO:root:Train (Epoch 123): Loss/seq after 00850 batchs: 601.7151489257812
INFO:root:Train (Epoch 123): Loss/seq after 00900 batchs: 586.9129028320312
INFO:root:Train (Epoch 123): Loss/seq after 00950 batchs: 582.1280517578125
INFO:root:Train (Epoch 123): Loss/seq after 01000 batchs: 570.6741943359375
INFO:root:Train (Epoch 123): Loss/seq after 01050 batchs: 557.9853515625
INFO:root:Train (Epoch 123): Loss/seq after 01100 batchs: 548.5338134765625
INFO:root:Train (Epoch 123): Loss/seq after 01150 batchs: 533.2923583984375
INFO:root:Train (Epoch 123): Loss/seq after 01200 batchs: 538.4501342773438
INFO:root:Train (Epoch 123): Loss/seq after 01250 batchs: 536.8424072265625
INFO:root:Train (Epoch 123): Loss/seq after 01300 batchs: 524.9561767578125
INFO:root:Train (Epoch 123): Loss/seq after 01350 batchs: 515.0729370117188
INFO:root:Train (Epoch 123): Loss/seq after 01400 batchs: 516.1857299804688
INFO:root:Train (Epoch 123): Loss/seq after 01450 batchs: 519.1188354492188
INFO:root:Train (Epoch 123): Loss/seq after 01500 batchs: 527.4656372070312
INFO:root:Train (Epoch 123): Loss/seq after 01550 batchs: 529.7152099609375
INFO:root:Train (Epoch 123): Loss/seq after 01600 batchs: 525.8212890625
INFO:root:Train (Epoch 123): Loss/seq after 01650 batchs: 524.551513671875
INFO:root:Train (Epoch 123): Loss/seq after 01700 batchs: 528.0576782226562
INFO:root:Train (Epoch 123): Loss/seq after 01750 batchs: 525.5462646484375
INFO:root:Train (Epoch 123): Loss/seq after 01800 batchs: 523.757568359375
INFO:root:Train (Epoch 123): Loss/seq after 01850 batchs: 521.0076904296875
INFO:root:Train (Epoch 123): Loss/seq after 01900 batchs: 521.476318359375
INFO:root:Train (Epoch 123): Loss/seq after 01950 batchs: 519.9015502929688
INFO:root:Train (Epoch 123): Loss/seq after 02000 batchs: 519.68115234375
INFO:root:Train (Epoch 123): Loss/seq after 02050 batchs: 519.2476196289062
INFO:root:Train (Epoch 123): Loss/seq after 02100 batchs: 517.6254272460938
INFO:root:Train (Epoch 123): Loss/seq after 02150 batchs: 516.2942504882812
INFO:root:Train (Epoch 123): Loss/seq after 02200 batchs: 514.5011596679688
INFO:root:Train (Epoch 123): Loss/seq after 02250 batchs: 513.9296875
INFO:root:Train (Epoch 123): Loss/seq after 02300 batchs: 509.34686279296875
INFO:root:Train (Epoch 123): Loss/seq after 02350 batchs: 506.07550048828125
INFO:root:Train (Epoch 123): Loss/seq after 02400 batchs: 507.334228515625
INFO:root:Train (Epoch 123): Loss/seq after 02450 batchs: 503.5096435546875
INFO:root:Train (Epoch 123): Loss/seq after 02500 batchs: 495.828369140625
INFO:root:Train (Epoch 123): Loss/seq after 02550 batchs: 489.071044921875
INFO:root:Train (Epoch 123): Loss/seq after 02600 batchs: 486.7879638671875
INFO:root:Train (Epoch 123): Loss/seq after 02650 batchs: 482.8626403808594
INFO:root:Train (Epoch 123): Loss/seq after 02700 batchs: 480.1739501953125
INFO:root:Train (Epoch 123): Loss/seq after 02750 batchs: 475.92578125
INFO:root:Train (Epoch 123): Loss/seq after 02800 batchs: 475.20965576171875
INFO:root:Train (Epoch 123): Loss/seq after 02850 batchs: 475.3758850097656
INFO:root:Train (Epoch 123): Loss/seq after 02900 batchs: 476.64520263671875
INFO:root:Train (Epoch 123): Loss/seq after 02950 batchs: 476.5756530761719
INFO:root:Train (Epoch 123): Loss/seq after 03000 batchs: 482.65997314453125
INFO:root:Train (Epoch 123): Loss/seq after 03050 batchs: 484.9819641113281
INFO:root:Train (Epoch 123): Loss/seq after 03100 batchs: 487.81591796875
INFO:root:Train (Epoch 123): Loss/seq after 03150 batchs: 487.9205017089844
INFO:root:Train (Epoch 123): Loss/seq after 03200 batchs: 487.673828125
INFO:root:Train (Epoch 123): Loss/seq after 03250 batchs: 488.2401428222656
INFO:root:Train (Epoch 123): Loss/seq after 03300 batchs: 487.6103515625
INFO:root:Train (Epoch 123): Loss/seq after 03350 batchs: 486.65740966796875
INFO:root:Train (Epoch 123): Loss/seq after 03400 batchs: 482.75360107421875
INFO:root:Train (Epoch 123): Loss/seq after 03450 batchs: 481.5774230957031
INFO:root:Train (Epoch 123): Loss/seq after 03500 batchs: 482.49139404296875
INFO:root:Train (Epoch 123): Loss/seq after 03550 batchs: 480.3437194824219
INFO:root:Train (Epoch 123): Loss/seq after 03600 batchs: 487.62457275390625
INFO:root:Train (Epoch 123): Loss/seq after 03650 batchs: 486.46630859375
INFO:root:Train (Epoch 123): Loss/seq after 03700 batchs: 489.8795166015625
INFO:root:Train (Epoch 123): Loss/seq after 03750 batchs: 494.78265380859375
INFO:root:Train (Epoch 123): Loss/seq after 03800 batchs: 493.2766418457031
INFO:root:Train (Epoch 123): Loss/seq after 03850 batchs: 492.2732238769531
INFO:root:Train (Epoch 123): Loss/seq after 03900 batchs: 495.34710693359375
INFO:root:Train (Epoch 123): Loss/seq after 03950 batchs: 498.0303649902344
INFO:root:Train (Epoch 123): Loss/seq after 04000 batchs: 494.8094177246094
INFO:root:Train (Epoch 123): Loss/seq after 04050 batchs: 491.7143249511719
INFO:root:Train (Epoch 123): Loss/seq after 04100 batchs: 490.56927490234375
INFO:root:Train (Epoch 123): Loss/seq after 04150 batchs: 490.80877685546875
INFO:root:Train (Epoch 123): Loss/seq after 04200 batchs: 489.5755310058594
INFO:root:Train (Epoch 123): Loss/seq after 04250 batchs: 488.18121337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 123): Loss/seq after 00000 batches: 426.7653503417969
INFO:root:# Valid (Epoch 123): Loss/seq after 00050 batches: 660.9707641601562
INFO:root:# Valid (Epoch 123): Loss/seq after 00100 batches: 689.5369873046875
INFO:root:# Valid (Epoch 123): Loss/seq after 00150 batches: 526.220703125
INFO:root:# Valid (Epoch 123): Loss/seq after 00200 batches: 498.1473388671875
INFO:root:Artifacts: Make stick videos for epoch 123
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_123_on_20220422_093750.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_123_index_1008_on_20220422_093750.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 124): Loss/seq after 00000 batchs: 738.4822998046875
INFO:root:Train (Epoch 124): Loss/seq after 00050 batchs: 694.2687377929688
INFO:root:Train (Epoch 124): Loss/seq after 00100 batchs: 722.6788330078125
INFO:root:Train (Epoch 124): Loss/seq after 00150 batchs: 657.177490234375
INFO:root:Train (Epoch 124): Loss/seq after 00200 batchs: 725.99853515625
INFO:root:Train (Epoch 124): Loss/seq after 00250 batchs: 819.029541015625
INFO:root:Train (Epoch 124): Loss/seq after 00300 batchs: 819.8462524414062
INFO:root:Train (Epoch 124): Loss/seq after 00350 batchs: 768.738037109375
INFO:root:Train (Epoch 124): Loss/seq after 00400 batchs: 750.7352294921875
INFO:root:Train (Epoch 124): Loss/seq after 00450 batchs: 741.803955078125
INFO:root:Train (Epoch 124): Loss/seq after 00500 batchs: 714.9529418945312
INFO:root:Train (Epoch 124): Loss/seq after 00550 batchs: 694.0722045898438
INFO:root:Train (Epoch 124): Loss/seq after 00600 batchs: 669.5813598632812
INFO:root:Train (Epoch 124): Loss/seq after 00650 batchs: 643.0767822265625
INFO:root:Train (Epoch 124): Loss/seq after 00700 batchs: 616.322265625
INFO:root:Train (Epoch 124): Loss/seq after 00750 batchs: 610.9849853515625
INFO:root:Train (Epoch 124): Loss/seq after 00800 batchs: 616.87939453125
INFO:root:Train (Epoch 124): Loss/seq after 00850 batchs: 597.4097290039062
INFO:root:Train (Epoch 124): Loss/seq after 00900 batchs: 584.0791625976562
INFO:root:Train (Epoch 124): Loss/seq after 00950 batchs: 579.7613525390625
INFO:root:Train (Epoch 124): Loss/seq after 01000 batchs: 568.6036376953125
INFO:root:Train (Epoch 124): Loss/seq after 01050 batchs: 556.50146484375
INFO:root:Train (Epoch 124): Loss/seq after 01100 batchs: 548.7020263671875
INFO:root:Train (Epoch 124): Loss/seq after 01150 batchs: 533.8849487304688
INFO:root:Train (Epoch 124): Loss/seq after 01200 batchs: 539.2523193359375
INFO:root:Train (Epoch 124): Loss/seq after 01250 batchs: 538.3325805664062
INFO:root:Train (Epoch 124): Loss/seq after 01300 batchs: 526.5276489257812
INFO:root:Train (Epoch 124): Loss/seq after 01350 batchs: 516.9692993164062
INFO:root:Train (Epoch 124): Loss/seq after 01400 batchs: 519.0271606445312
INFO:root:Train (Epoch 124): Loss/seq after 01450 batchs: 522.0823974609375
INFO:root:Train (Epoch 124): Loss/seq after 01500 batchs: 530.3221435546875
INFO:root:Train (Epoch 124): Loss/seq after 01550 batchs: 532.0597534179688
INFO:root:Train (Epoch 124): Loss/seq after 01600 batchs: 528.0677490234375
INFO:root:Train (Epoch 124): Loss/seq after 01650 batchs: 526.86181640625
INFO:root:Train (Epoch 124): Loss/seq after 01700 batchs: 530.4859008789062
INFO:root:Train (Epoch 124): Loss/seq after 01750 batchs: 527.9739379882812
INFO:root:Train (Epoch 124): Loss/seq after 01800 batchs: 525.8169555664062
INFO:root:Train (Epoch 124): Loss/seq after 01850 batchs: 523.1434326171875
INFO:root:Train (Epoch 124): Loss/seq after 01900 batchs: 523.4452514648438
INFO:root:Train (Epoch 124): Loss/seq after 01950 batchs: 521.8176879882812
INFO:root:Train (Epoch 124): Loss/seq after 02000 batchs: 521.5016479492188
INFO:root:Train (Epoch 124): Loss/seq after 02050 batchs: 520.8014526367188
INFO:root:Train (Epoch 124): Loss/seq after 02100 batchs: 519.0218505859375
INFO:root:Train (Epoch 124): Loss/seq after 02150 batchs: 517.58056640625
INFO:root:Train (Epoch 124): Loss/seq after 02200 batchs: 515.6084594726562
INFO:root:Train (Epoch 124): Loss/seq after 02250 batchs: 514.7423095703125
INFO:root:Train (Epoch 124): Loss/seq after 02300 batchs: 510.44659423828125
INFO:root:Train (Epoch 124): Loss/seq after 02350 batchs: 506.93023681640625
INFO:root:Train (Epoch 124): Loss/seq after 02400 batchs: 507.927490234375
INFO:root:Train (Epoch 124): Loss/seq after 02450 batchs: 504.0075378417969
INFO:root:Train (Epoch 124): Loss/seq after 02500 batchs: 496.3059387207031
INFO:root:Train (Epoch 124): Loss/seq after 02550 batchs: 489.52911376953125
INFO:root:Train (Epoch 124): Loss/seq after 02600 batchs: 487.18670654296875
INFO:root:Train (Epoch 124): Loss/seq after 02650 batchs: 483.3699645996094
INFO:root:Train (Epoch 124): Loss/seq after 02700 batchs: 480.4643249511719
INFO:root:Train (Epoch 124): Loss/seq after 02750 batchs: 476.33148193359375
INFO:root:Train (Epoch 124): Loss/seq after 02800 batchs: 475.5784606933594
INFO:root:Train (Epoch 124): Loss/seq after 02850 batchs: 475.5542297363281
INFO:root:Train (Epoch 124): Loss/seq after 02900 batchs: 476.66278076171875
INFO:root:Train (Epoch 124): Loss/seq after 02950 batchs: 476.5036315917969
INFO:root:Train (Epoch 124): Loss/seq after 03000 batchs: 482.3768615722656
INFO:root:Train (Epoch 124): Loss/seq after 03050 batchs: 484.6491394042969
INFO:root:Train (Epoch 124): Loss/seq after 03100 batchs: 488.594482421875
INFO:root:Train (Epoch 124): Loss/seq after 03150 batchs: 488.62481689453125
INFO:root:Train (Epoch 124): Loss/seq after 03200 batchs: 488.5675964355469
INFO:root:Train (Epoch 124): Loss/seq after 03250 batchs: 489.34381103515625
INFO:root:Train (Epoch 124): Loss/seq after 03300 batchs: 488.6513977050781
INFO:root:Train (Epoch 124): Loss/seq after 03350 batchs: 487.458740234375
INFO:root:Train (Epoch 124): Loss/seq after 03400 batchs: 483.5206298828125
INFO:root:Train (Epoch 124): Loss/seq after 03450 batchs: 482.2320556640625
INFO:root:Train (Epoch 124): Loss/seq after 03500 batchs: 483.7037658691406
INFO:root:Train (Epoch 124): Loss/seq after 03550 batchs: 482.0758361816406
INFO:root:Train (Epoch 124): Loss/seq after 03600 batchs: 489.4949951171875
INFO:root:Train (Epoch 124): Loss/seq after 03650 batchs: 487.63458251953125
INFO:root:Train (Epoch 124): Loss/seq after 03700 batchs: 490.5302429199219
INFO:root:Train (Epoch 124): Loss/seq after 03750 batchs: 495.4640808105469
INFO:root:Train (Epoch 124): Loss/seq after 03800 batchs: 493.93743896484375
INFO:root:Train (Epoch 124): Loss/seq after 03850 batchs: 492.7856140136719
INFO:root:Train (Epoch 124): Loss/seq after 03900 batchs: 495.5714416503906
INFO:root:Train (Epoch 124): Loss/seq after 03950 batchs: 498.1261901855469
INFO:root:Train (Epoch 124): Loss/seq after 04000 batchs: 494.8783874511719
INFO:root:Train (Epoch 124): Loss/seq after 04050 batchs: 491.6872253417969
INFO:root:Train (Epoch 124): Loss/seq after 04100 batchs: 490.5442810058594
INFO:root:Train (Epoch 124): Loss/seq after 04150 batchs: 490.8803405761719
INFO:root:Train (Epoch 124): Loss/seq after 04200 batchs: 489.47491455078125
INFO:root:Train (Epoch 124): Loss/seq after 04250 batchs: 488.0180358886719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 124): Loss/seq after 00000 batches: 443.48974609375
INFO:root:# Valid (Epoch 124): Loss/seq after 00050 batches: 686.603271484375
INFO:root:# Valid (Epoch 124): Loss/seq after 00100 batches: 722.9722900390625
INFO:root:# Valid (Epoch 124): Loss/seq after 00150 batches: 543.9102172851562
INFO:root:# Valid (Epoch 124): Loss/seq after 00200 batches: 505.7433166503906
INFO:root:Artifacts: Make stick videos for epoch 124
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_124_on_20220422_094239.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_124_index_1421_on_20220422_094239.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 125): Loss/seq after 00000 batchs: 879.39453125
INFO:root:Train (Epoch 125): Loss/seq after 00050 batchs: 711.2337646484375
INFO:root:Train (Epoch 125): Loss/seq after 00100 batchs: 718.7311401367188
INFO:root:Train (Epoch 125): Loss/seq after 00150 batchs: 663.2254638671875
INFO:root:Train (Epoch 125): Loss/seq after 00200 batchs: 722.8670043945312
INFO:root:Train (Epoch 125): Loss/seq after 00250 batchs: 817.1708374023438
INFO:root:Train (Epoch 125): Loss/seq after 00300 batchs: 816.8134765625
INFO:root:Train (Epoch 125): Loss/seq after 00350 batchs: 764.3712768554688
INFO:root:Train (Epoch 125): Loss/seq after 00400 batchs: 748.4241943359375
INFO:root:Train (Epoch 125): Loss/seq after 00450 batchs: 739.3423461914062
INFO:root:Train (Epoch 125): Loss/seq after 00500 batchs: 715.3421020507812
INFO:root:Train (Epoch 125): Loss/seq after 00550 batchs: 695.375732421875
INFO:root:Train (Epoch 125): Loss/seq after 00600 batchs: 670.2871704101562
INFO:root:Train (Epoch 125): Loss/seq after 00650 batchs: 643.7286987304688
INFO:root:Train (Epoch 125): Loss/seq after 00700 batchs: 618.6327514648438
INFO:root:Train (Epoch 125): Loss/seq after 00750 batchs: 612.6036987304688
INFO:root:Train (Epoch 125): Loss/seq after 00800 batchs: 617.5886840820312
INFO:root:Train (Epoch 125): Loss/seq after 00850 batchs: 596.7763061523438
INFO:root:Train (Epoch 125): Loss/seq after 00900 batchs: 582.2410278320312
INFO:root:Train (Epoch 125): Loss/seq after 00950 batchs: 577.1829223632812
INFO:root:Train (Epoch 125): Loss/seq after 01000 batchs: 567.01806640625
INFO:root:Train (Epoch 125): Loss/seq after 01050 batchs: 555.6250610351562
INFO:root:Train (Epoch 125): Loss/seq after 01100 batchs: 545.8722534179688
INFO:root:Train (Epoch 125): Loss/seq after 01150 batchs: 530.7181396484375
INFO:root:Train (Epoch 125): Loss/seq after 01200 batchs: 535.6795043945312
INFO:root:Train (Epoch 125): Loss/seq after 01250 batchs: 534.6211547851562
INFO:root:Train (Epoch 125): Loss/seq after 01300 batchs: 522.931884765625
INFO:root:Train (Epoch 125): Loss/seq after 01350 batchs: 513.0299072265625
INFO:root:Train (Epoch 125): Loss/seq after 01400 batchs: 513.6819458007812
INFO:root:Train (Epoch 125): Loss/seq after 01450 batchs: 516.2516479492188
INFO:root:Train (Epoch 125): Loss/seq after 01500 batchs: 524.5040283203125
INFO:root:Train (Epoch 125): Loss/seq after 01550 batchs: 525.930419921875
INFO:root:Train (Epoch 125): Loss/seq after 01600 batchs: 521.905029296875
INFO:root:Train (Epoch 125): Loss/seq after 01650 batchs: 520.5474243164062
INFO:root:Train (Epoch 125): Loss/seq after 01700 batchs: 523.98974609375
INFO:root:Train (Epoch 125): Loss/seq after 01750 batchs: 521.7002563476562
INFO:root:Train (Epoch 125): Loss/seq after 01800 batchs: 519.7891845703125
INFO:root:Train (Epoch 125): Loss/seq after 01850 batchs: 517.0986938476562
INFO:root:Train (Epoch 125): Loss/seq after 01900 batchs: 517.597412109375
INFO:root:Train (Epoch 125): Loss/seq after 01950 batchs: 516.0846557617188
INFO:root:Train (Epoch 125): Loss/seq after 02000 batchs: 516.0109252929688
INFO:root:Train (Epoch 125): Loss/seq after 02050 batchs: 515.357666015625
INFO:root:Train (Epoch 125): Loss/seq after 02100 batchs: 513.4855346679688
INFO:root:Train (Epoch 125): Loss/seq after 02150 batchs: 512.3112182617188
INFO:root:Train (Epoch 125): Loss/seq after 02200 batchs: 510.4580993652344
INFO:root:Train (Epoch 125): Loss/seq after 02250 batchs: 509.3390808105469
INFO:root:Train (Epoch 125): Loss/seq after 02300 batchs: 504.8603210449219
INFO:root:Train (Epoch 125): Loss/seq after 02350 batchs: 501.19268798828125
INFO:root:Train (Epoch 125): Loss/seq after 02400 batchs: 501.9994812011719
INFO:root:Train (Epoch 125): Loss/seq after 02450 batchs: 498.06573486328125
INFO:root:Train (Epoch 125): Loss/seq after 02500 batchs: 490.3870849609375
INFO:root:Train (Epoch 125): Loss/seq after 02550 batchs: 483.6565856933594
INFO:root:Train (Epoch 125): Loss/seq after 02600 batchs: 480.76922607421875
INFO:root:Train (Epoch 125): Loss/seq after 02650 batchs: 476.7608947753906
INFO:root:Train (Epoch 125): Loss/seq after 02700 batchs: 473.8985290527344
INFO:root:Train (Epoch 125): Loss/seq after 02750 batchs: 469.2433776855469
INFO:root:Train (Epoch 125): Loss/seq after 02800 batchs: 467.6764221191406
INFO:root:Train (Epoch 125): Loss/seq after 02850 batchs: 467.8101501464844
INFO:root:Train (Epoch 125): Loss/seq after 02900 batchs: 468.6728210449219
INFO:root:Train (Epoch 125): Loss/seq after 02950 batchs: 468.5377502441406
INFO:root:Train (Epoch 125): Loss/seq after 03000 batchs: 474.658447265625
INFO:root:Train (Epoch 125): Loss/seq after 03050 batchs: 476.8907165527344
INFO:root:Train (Epoch 125): Loss/seq after 03100 batchs: 479.4033508300781
INFO:root:Train (Epoch 125): Loss/seq after 03150 batchs: 479.59326171875
INFO:root:Train (Epoch 125): Loss/seq after 03200 batchs: 479.8669128417969
INFO:root:Train (Epoch 125): Loss/seq after 03250 batchs: 480.4236755371094
INFO:root:Train (Epoch 125): Loss/seq after 03300 batchs: 479.9709777832031
INFO:root:Train (Epoch 125): Loss/seq after 03350 batchs: 478.9609375
INFO:root:Train (Epoch 125): Loss/seq after 03400 batchs: 475.1134338378906
INFO:root:Train (Epoch 125): Loss/seq after 03450 batchs: 473.99859619140625
INFO:root:Train (Epoch 125): Loss/seq after 03500 batchs: 475.0971374511719
INFO:root:Train (Epoch 125): Loss/seq after 03550 batchs: 473.1930847167969
INFO:root:Train (Epoch 125): Loss/seq after 03600 batchs: 480.75091552734375
INFO:root:Train (Epoch 125): Loss/seq after 03650 batchs: 478.9280090332031
INFO:root:Train (Epoch 125): Loss/seq after 03700 batchs: 481.7762756347656
INFO:root:Train (Epoch 125): Loss/seq after 03750 batchs: 486.5203552246094
INFO:root:Train (Epoch 125): Loss/seq after 03800 batchs: 485.1061096191406
INFO:root:Train (Epoch 125): Loss/seq after 03850 batchs: 484.07275390625
INFO:root:Train (Epoch 125): Loss/seq after 03900 batchs: 486.5037536621094
INFO:root:Train (Epoch 125): Loss/seq after 03950 batchs: 488.729248046875
INFO:root:Train (Epoch 125): Loss/seq after 04000 batchs: 485.5223388671875
INFO:root:Train (Epoch 125): Loss/seq after 04050 batchs: 482.3988952636719
INFO:root:Train (Epoch 125): Loss/seq after 04100 batchs: 481.22998046875
INFO:root:Train (Epoch 125): Loss/seq after 04150 batchs: 481.623779296875
INFO:root:Train (Epoch 125): Loss/seq after 04200 batchs: 480.5055847167969
INFO:root:Train (Epoch 125): Loss/seq after 04250 batchs: 479.22216796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 125): Loss/seq after 00000 batches: 368.0914611816406
INFO:root:# Valid (Epoch 125): Loss/seq after 00050 batches: 632.1503295898438
INFO:root:# Valid (Epoch 125): Loss/seq after 00100 batches: 676.503173828125
INFO:root:# Valid (Epoch 125): Loss/seq after 00150 batches: 510.1938171386719
INFO:root:# Valid (Epoch 125): Loss/seq after 00200 batches: 477.7820129394531
INFO:root:Artifacts: Make stick videos for epoch 125
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_125_on_20220422_094722.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_125_index_1247_on_20220422_094722.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 126): Loss/seq after 00000 batchs: 719.7989501953125
INFO:root:Train (Epoch 126): Loss/seq after 00050 batchs: 676.044189453125
INFO:root:Train (Epoch 126): Loss/seq after 00100 batchs: 714.7680053710938
INFO:root:Train (Epoch 126): Loss/seq after 00150 batchs: 653.7908325195312
INFO:root:Train (Epoch 126): Loss/seq after 00200 batchs: 712.1693115234375
INFO:root:Train (Epoch 126): Loss/seq after 00250 batchs: 800.8275146484375
INFO:root:Train (Epoch 126): Loss/seq after 00300 batchs: 802.8500366210938
INFO:root:Train (Epoch 126): Loss/seq after 00350 batchs: 753.3336791992188
INFO:root:Train (Epoch 126): Loss/seq after 00400 batchs: 738.8980102539062
INFO:root:Train (Epoch 126): Loss/seq after 00450 batchs: 730.4694213867188
INFO:root:Train (Epoch 126): Loss/seq after 00500 batchs: 709.1288452148438
INFO:root:Train (Epoch 126): Loss/seq after 00550 batchs: 690.6295166015625
INFO:root:Train (Epoch 126): Loss/seq after 00600 batchs: 666.75830078125
INFO:root:Train (Epoch 126): Loss/seq after 00650 batchs: 640.0632934570312
INFO:root:Train (Epoch 126): Loss/seq after 00700 batchs: 614.3400268554688
INFO:root:Train (Epoch 126): Loss/seq after 00750 batchs: 610.534912109375
INFO:root:Train (Epoch 126): Loss/seq after 00800 batchs: 615.6080932617188
INFO:root:Train (Epoch 126): Loss/seq after 00850 batchs: 595.4027709960938
INFO:root:Train (Epoch 126): Loss/seq after 00900 batchs: 580.7303466796875
INFO:root:Train (Epoch 126): Loss/seq after 00950 batchs: 577.3225708007812
INFO:root:Train (Epoch 126): Loss/seq after 01000 batchs: 566.1490478515625
INFO:root:Train (Epoch 126): Loss/seq after 01050 batchs: 553.9931030273438
INFO:root:Train (Epoch 126): Loss/seq after 01100 batchs: 544.3261108398438
INFO:root:Train (Epoch 126): Loss/seq after 01150 batchs: 528.87646484375
INFO:root:Train (Epoch 126): Loss/seq after 01200 batchs: 534.2620239257812
INFO:root:Train (Epoch 126): Loss/seq after 01250 batchs: 533.3118286132812
INFO:root:Train (Epoch 126): Loss/seq after 01300 batchs: 521.7338256835938
INFO:root:Train (Epoch 126): Loss/seq after 01350 batchs: 512.1190185546875
INFO:root:Train (Epoch 126): Loss/seq after 01400 batchs: 513.484619140625
INFO:root:Train (Epoch 126): Loss/seq after 01450 batchs: 516.1717529296875
INFO:root:Train (Epoch 126): Loss/seq after 01500 batchs: 524.0888671875
INFO:root:Train (Epoch 126): Loss/seq after 01550 batchs: 525.3241577148438
INFO:root:Train (Epoch 126): Loss/seq after 01600 batchs: 521.1405029296875
INFO:root:Train (Epoch 126): Loss/seq after 01650 batchs: 519.6461791992188
INFO:root:Train (Epoch 126): Loss/seq after 01700 batchs: 523.0521240234375
INFO:root:Train (Epoch 126): Loss/seq after 01750 batchs: 520.650146484375
INFO:root:Train (Epoch 126): Loss/seq after 01800 batchs: 518.5171508789062
INFO:root:Train (Epoch 126): Loss/seq after 01850 batchs: 515.7098388671875
INFO:root:Train (Epoch 126): Loss/seq after 01900 batchs: 516.1596069335938
INFO:root:Train (Epoch 126): Loss/seq after 01950 batchs: 514.5421142578125
INFO:root:Train (Epoch 126): Loss/seq after 02000 batchs: 514.4108276367188
INFO:root:Train (Epoch 126): Loss/seq after 02050 batchs: 513.6925659179688
INFO:root:Train (Epoch 126): Loss/seq after 02100 batchs: 511.77178955078125
INFO:root:Train (Epoch 126): Loss/seq after 02150 batchs: 510.4039306640625
INFO:root:Train (Epoch 126): Loss/seq after 02200 batchs: 508.4794921875
INFO:root:Train (Epoch 126): Loss/seq after 02250 batchs: 507.4203186035156
INFO:root:Train (Epoch 126): Loss/seq after 02300 batchs: 502.92388916015625
INFO:root:Train (Epoch 126): Loss/seq after 02350 batchs: 499.209228515625
INFO:root:Train (Epoch 126): Loss/seq after 02400 batchs: 499.7795104980469
INFO:root:Train (Epoch 126): Loss/seq after 02450 batchs: 495.88800048828125
INFO:root:Train (Epoch 126): Loss/seq after 02500 batchs: 488.2893371582031
INFO:root:Train (Epoch 126): Loss/seq after 02550 batchs: 481.5627136230469
INFO:root:Train (Epoch 126): Loss/seq after 02600 batchs: 478.5645751953125
INFO:root:Train (Epoch 126): Loss/seq after 02650 batchs: 474.5389404296875
INFO:root:Train (Epoch 126): Loss/seq after 02700 batchs: 471.7646484375
INFO:root:Train (Epoch 126): Loss/seq after 02750 batchs: 467.3090515136719
INFO:root:Train (Epoch 126): Loss/seq after 02800 batchs: 466.43023681640625
INFO:root:Train (Epoch 126): Loss/seq after 02850 batchs: 466.5592346191406
INFO:root:Train (Epoch 126): Loss/seq after 02900 batchs: 467.4881286621094
INFO:root:Train (Epoch 126): Loss/seq after 02950 batchs: 467.1683044433594
INFO:root:Train (Epoch 126): Loss/seq after 03000 batchs: 473.230224609375
INFO:root:Train (Epoch 126): Loss/seq after 03050 batchs: 475.3708801269531
INFO:root:Train (Epoch 126): Loss/seq after 03100 batchs: 478.69403076171875
INFO:root:Train (Epoch 126): Loss/seq after 03150 batchs: 478.82135009765625
INFO:root:Train (Epoch 126): Loss/seq after 03200 batchs: 478.5592956542969
INFO:root:Train (Epoch 126): Loss/seq after 03250 batchs: 479.0024108886719
INFO:root:Train (Epoch 126): Loss/seq after 03300 batchs: 478.46893310546875
INFO:root:Train (Epoch 126): Loss/seq after 03350 batchs: 477.0460510253906
INFO:root:Train (Epoch 126): Loss/seq after 03400 batchs: 473.228759765625
INFO:root:Train (Epoch 126): Loss/seq after 03450 batchs: 472.0874328613281
INFO:root:Train (Epoch 126): Loss/seq after 03500 batchs: 473.4839172363281
INFO:root:Train (Epoch 126): Loss/seq after 03550 batchs: 471.5986328125
INFO:root:Train (Epoch 126): Loss/seq after 03600 batchs: 479.1547546386719
INFO:root:Train (Epoch 126): Loss/seq after 03650 batchs: 477.3531494140625
INFO:root:Train (Epoch 126): Loss/seq after 03700 batchs: 480.3627014160156
INFO:root:Train (Epoch 126): Loss/seq after 03750 batchs: 485.0949401855469
INFO:root:Train (Epoch 126): Loss/seq after 03800 batchs: 483.651123046875
INFO:root:Train (Epoch 126): Loss/seq after 03850 batchs: 482.63067626953125
INFO:root:Train (Epoch 126): Loss/seq after 03900 batchs: 485.1243896484375
INFO:root:Train (Epoch 126): Loss/seq after 03950 batchs: 487.5692443847656
INFO:root:Train (Epoch 126): Loss/seq after 04000 batchs: 484.3754577636719
INFO:root:Train (Epoch 126): Loss/seq after 04050 batchs: 481.2626037597656
INFO:root:Train (Epoch 126): Loss/seq after 04100 batchs: 480.2301940917969
INFO:root:Train (Epoch 126): Loss/seq after 04150 batchs: 480.56646728515625
INFO:root:Train (Epoch 126): Loss/seq after 04200 batchs: 479.2132568359375
INFO:root:Train (Epoch 126): Loss/seq after 04250 batchs: 477.814453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 126): Loss/seq after 00000 batches: 330.6982727050781
INFO:root:# Valid (Epoch 126): Loss/seq after 00050 batches: 644.2576293945312
INFO:root:# Valid (Epoch 126): Loss/seq after 00100 batches: 682.9152221679688
INFO:root:# Valid (Epoch 126): Loss/seq after 00150 batches: 513.9371337890625
INFO:root:# Valid (Epoch 126): Loss/seq after 00200 batches: 481.3084411621094
INFO:root:Artifacts: Make stick videos for epoch 126
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_126_on_20220422_095218.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_126_index_847_on_20220422_095218.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 127): Loss/seq after 00000 batchs: 707.0862426757812
INFO:root:Train (Epoch 127): Loss/seq after 00050 batchs: 680.7820434570312
INFO:root:Train (Epoch 127): Loss/seq after 00100 batchs: 715.8078002929688
INFO:root:Train (Epoch 127): Loss/seq after 00150 batchs: 648.9758911132812
INFO:root:Train (Epoch 127): Loss/seq after 00200 batchs: 710.3834838867188
INFO:root:Train (Epoch 127): Loss/seq after 00250 batchs: 811.9230346679688
INFO:root:Train (Epoch 127): Loss/seq after 00300 batchs: 812.2351684570312
INFO:root:Train (Epoch 127): Loss/seq after 00350 batchs: 760.2395629882812
INFO:root:Train (Epoch 127): Loss/seq after 00400 batchs: 740.767822265625
INFO:root:Train (Epoch 127): Loss/seq after 00450 batchs: 731.9124755859375
INFO:root:Train (Epoch 127): Loss/seq after 00500 batchs: 706.93603515625
INFO:root:Train (Epoch 127): Loss/seq after 00550 batchs: 686.5172729492188
INFO:root:Train (Epoch 127): Loss/seq after 00600 batchs: 664.494873046875
INFO:root:Train (Epoch 127): Loss/seq after 00650 batchs: 638.0205078125
INFO:root:Train (Epoch 127): Loss/seq after 00700 batchs: 611.2579345703125
INFO:root:Train (Epoch 127): Loss/seq after 00750 batchs: 605.4970092773438
INFO:root:Train (Epoch 127): Loss/seq after 00800 batchs: 611.5571899414062
INFO:root:Train (Epoch 127): Loss/seq after 00850 batchs: 591.5679931640625
INFO:root:Train (Epoch 127): Loss/seq after 00900 batchs: 577.2705078125
INFO:root:Train (Epoch 127): Loss/seq after 00950 batchs: 571.4791870117188
INFO:root:Train (Epoch 127): Loss/seq after 01000 batchs: 561.44970703125
INFO:root:Train (Epoch 127): Loss/seq after 01050 batchs: 549.9674682617188
INFO:root:Train (Epoch 127): Loss/seq after 01100 batchs: 541.2742919921875
INFO:root:Train (Epoch 127): Loss/seq after 01150 batchs: 526.3516235351562
INFO:root:Train (Epoch 127): Loss/seq after 01200 batchs: 531.6559448242188
INFO:root:Train (Epoch 127): Loss/seq after 01250 batchs: 530.8970947265625
INFO:root:Train (Epoch 127): Loss/seq after 01300 batchs: 519.2736206054688
INFO:root:Train (Epoch 127): Loss/seq after 01350 batchs: 509.20391845703125
INFO:root:Train (Epoch 127): Loss/seq after 01400 batchs: 510.765869140625
INFO:root:Train (Epoch 127): Loss/seq after 01450 batchs: 513.1025390625
INFO:root:Train (Epoch 127): Loss/seq after 01500 batchs: 520.9895629882812
INFO:root:Train (Epoch 127): Loss/seq after 01550 batchs: 522.7188110351562
INFO:root:Train (Epoch 127): Loss/seq after 01600 batchs: 518.8401489257812
INFO:root:Train (Epoch 127): Loss/seq after 01650 batchs: 517.79833984375
INFO:root:Train (Epoch 127): Loss/seq after 01700 batchs: 521.0993041992188
INFO:root:Train (Epoch 127): Loss/seq after 01750 batchs: 518.7133178710938
INFO:root:Train (Epoch 127): Loss/seq after 01800 batchs: 516.719482421875
INFO:root:Train (Epoch 127): Loss/seq after 01850 batchs: 513.9400024414062
INFO:root:Train (Epoch 127): Loss/seq after 01900 batchs: 514.0498657226562
INFO:root:Train (Epoch 127): Loss/seq after 01950 batchs: 512.3327026367188
INFO:root:Train (Epoch 127): Loss/seq after 02000 batchs: 512.1095581054688
INFO:root:Train (Epoch 127): Loss/seq after 02050 batchs: 511.6502380371094
INFO:root:Train (Epoch 127): Loss/seq after 02100 batchs: 509.9235534667969
INFO:root:Train (Epoch 127): Loss/seq after 02150 batchs: 508.3208312988281
INFO:root:Train (Epoch 127): Loss/seq after 02200 batchs: 506.5318603515625
INFO:root:Train (Epoch 127): Loss/seq after 02250 batchs: 505.64910888671875
INFO:root:Train (Epoch 127): Loss/seq after 02300 batchs: 501.84588623046875
INFO:root:Train (Epoch 127): Loss/seq after 02350 batchs: 498.44146728515625
INFO:root:Train (Epoch 127): Loss/seq after 02400 batchs: 499.3713684082031
INFO:root:Train (Epoch 127): Loss/seq after 02450 batchs: 495.52935791015625
INFO:root:Train (Epoch 127): Loss/seq after 02500 batchs: 487.9287414550781
INFO:root:Train (Epoch 127): Loss/seq after 02550 batchs: 481.1663513183594
INFO:root:Train (Epoch 127): Loss/seq after 02600 batchs: 478.2844543457031
INFO:root:Train (Epoch 127): Loss/seq after 02650 batchs: 474.1692810058594
INFO:root:Train (Epoch 127): Loss/seq after 02700 batchs: 471.255615234375
INFO:root:Train (Epoch 127): Loss/seq after 02750 batchs: 466.98565673828125
INFO:root:Train (Epoch 127): Loss/seq after 02800 batchs: 466.214111328125
INFO:root:Train (Epoch 127): Loss/seq after 02850 batchs: 466.2843017578125
INFO:root:Train (Epoch 127): Loss/seq after 02900 batchs: 466.84295654296875
INFO:root:Train (Epoch 127): Loss/seq after 02950 batchs: 466.5249938964844
INFO:root:Train (Epoch 127): Loss/seq after 03000 batchs: 472.4749450683594
INFO:root:Train (Epoch 127): Loss/seq after 03050 batchs: 474.4488525390625
INFO:root:Train (Epoch 127): Loss/seq after 03100 batchs: 477.8903503417969
INFO:root:Train (Epoch 127): Loss/seq after 03150 batchs: 478.0173034667969
INFO:root:Train (Epoch 127): Loss/seq after 03200 batchs: 478.5668640136719
INFO:root:Train (Epoch 127): Loss/seq after 03250 batchs: 479.1998596191406
INFO:root:Train (Epoch 127): Loss/seq after 03300 batchs: 479.1285400390625
INFO:root:Train (Epoch 127): Loss/seq after 03350 batchs: 478.2085876464844
INFO:root:Train (Epoch 127): Loss/seq after 03400 batchs: 474.3813171386719
INFO:root:Train (Epoch 127): Loss/seq after 03450 batchs: 473.4130554199219
INFO:root:Train (Epoch 127): Loss/seq after 03500 batchs: 474.5338134765625
INFO:root:Train (Epoch 127): Loss/seq after 03550 batchs: 472.5359802246094
INFO:root:Train (Epoch 127): Loss/seq after 03600 batchs: 479.7450256347656
INFO:root:Train (Epoch 127): Loss/seq after 03650 batchs: 478.02142333984375
INFO:root:Train (Epoch 127): Loss/seq after 03700 batchs: 480.9654235839844
INFO:root:Train (Epoch 127): Loss/seq after 03750 batchs: 485.64935302734375
INFO:root:Train (Epoch 127): Loss/seq after 03800 batchs: 484.1670227050781
INFO:root:Train (Epoch 127): Loss/seq after 03850 batchs: 483.1220703125
INFO:root:Train (Epoch 127): Loss/seq after 03900 batchs: 485.73529052734375
INFO:root:Train (Epoch 127): Loss/seq after 03950 batchs: 488.4234313964844
INFO:root:Train (Epoch 127): Loss/seq after 04000 batchs: 485.150390625
INFO:root:Train (Epoch 127): Loss/seq after 04050 batchs: 481.9436950683594
INFO:root:Train (Epoch 127): Loss/seq after 04100 batchs: 480.85003662109375
INFO:root:Train (Epoch 127): Loss/seq after 04150 batchs: 481.0768127441406
INFO:root:Train (Epoch 127): Loss/seq after 04200 batchs: 479.73779296875
INFO:root:Train (Epoch 127): Loss/seq after 04250 batchs: 478.33642578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 127): Loss/seq after 00000 batches: 351.30108642578125
INFO:root:# Valid (Epoch 127): Loss/seq after 00050 batches: 669.8751831054688
INFO:root:# Valid (Epoch 127): Loss/seq after 00100 batches: 676.0122680664062
INFO:root:# Valid (Epoch 127): Loss/seq after 00150 batches: 510.94708251953125
INFO:root:# Valid (Epoch 127): Loss/seq after 00200 batches: 480.912841796875
INFO:root:Artifacts: Make stick videos for epoch 127
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_127_on_20220422_095710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_127_index_434_on_20220422_095710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 128): Loss/seq after 00000 batchs: 769.9158935546875
INFO:root:Train (Epoch 128): Loss/seq after 00050 batchs: 665.9133911132812
INFO:root:Train (Epoch 128): Loss/seq after 00100 batchs: 692.2120971679688
INFO:root:Train (Epoch 128): Loss/seq after 00150 batchs: 636.5555419921875
INFO:root:Train (Epoch 128): Loss/seq after 00200 batchs: 700.3726806640625
INFO:root:Train (Epoch 128): Loss/seq after 00250 batchs: 790.8304443359375
INFO:root:Train (Epoch 128): Loss/seq after 00300 batchs: 793.6510009765625
INFO:root:Train (Epoch 128): Loss/seq after 00350 batchs: 743.1914672851562
INFO:root:Train (Epoch 128): Loss/seq after 00400 batchs: 726.6434936523438
INFO:root:Train (Epoch 128): Loss/seq after 00450 batchs: 719.6838989257812
INFO:root:Train (Epoch 128): Loss/seq after 00500 batchs: 697.6024169921875
INFO:root:Train (Epoch 128): Loss/seq after 00550 batchs: 679.8429565429688
INFO:root:Train (Epoch 128): Loss/seq after 00600 batchs: 656.00048828125
INFO:root:Train (Epoch 128): Loss/seq after 00650 batchs: 631.1732177734375
INFO:root:Train (Epoch 128): Loss/seq after 00700 batchs: 606.0704956054688
INFO:root:Train (Epoch 128): Loss/seq after 00750 batchs: 604.3021240234375
INFO:root:Train (Epoch 128): Loss/seq after 00800 batchs: 608.7279663085938
INFO:root:Train (Epoch 128): Loss/seq after 00850 batchs: 589.041015625
INFO:root:Train (Epoch 128): Loss/seq after 00900 batchs: 574.7852172851562
INFO:root:Train (Epoch 128): Loss/seq after 00950 batchs: 571.1058349609375
INFO:root:Train (Epoch 128): Loss/seq after 01000 batchs: 560.0935668945312
INFO:root:Train (Epoch 128): Loss/seq after 01050 batchs: 548.8278198242188
INFO:root:Train (Epoch 128): Loss/seq after 01100 batchs: 539.2360229492188
INFO:root:Train (Epoch 128): Loss/seq after 01150 batchs: 524.4977416992188
INFO:root:Train (Epoch 128): Loss/seq after 01200 batchs: 529.8759155273438
INFO:root:Train (Epoch 128): Loss/seq after 01250 batchs: 528.7080078125
INFO:root:Train (Epoch 128): Loss/seq after 01300 batchs: 516.8309326171875
INFO:root:Train (Epoch 128): Loss/seq after 01350 batchs: 506.7968444824219
INFO:root:Train (Epoch 128): Loss/seq after 01400 batchs: 508.37451171875
INFO:root:Train (Epoch 128): Loss/seq after 01450 batchs: 510.8168029785156
INFO:root:Train (Epoch 128): Loss/seq after 01500 batchs: 518.6676025390625
INFO:root:Train (Epoch 128): Loss/seq after 01550 batchs: 519.796142578125
INFO:root:Train (Epoch 128): Loss/seq after 01600 batchs: 515.5939331054688
INFO:root:Train (Epoch 128): Loss/seq after 01650 batchs: 514.172607421875
INFO:root:Train (Epoch 128): Loss/seq after 01700 batchs: 517.7009887695312
INFO:root:Train (Epoch 128): Loss/seq after 01750 batchs: 515.1953735351562
INFO:root:Train (Epoch 128): Loss/seq after 01800 batchs: 513.116455078125
INFO:root:Train (Epoch 128): Loss/seq after 01850 batchs: 510.3283996582031
INFO:root:Train (Epoch 128): Loss/seq after 01900 batchs: 510.51531982421875
INFO:root:Train (Epoch 128): Loss/seq after 01950 batchs: 508.6778259277344
INFO:root:Train (Epoch 128): Loss/seq after 02000 batchs: 508.7426452636719
INFO:root:Train (Epoch 128): Loss/seq after 02050 batchs: 508.1509094238281
INFO:root:Train (Epoch 128): Loss/seq after 02100 batchs: 506.2306213378906
INFO:root:Train (Epoch 128): Loss/seq after 02150 batchs: 504.7152404785156
INFO:root:Train (Epoch 128): Loss/seq after 02200 batchs: 502.8074035644531
INFO:root:Train (Epoch 128): Loss/seq after 02250 batchs: 501.8186950683594
INFO:root:Train (Epoch 128): Loss/seq after 02300 batchs: 497.52215576171875
INFO:root:Train (Epoch 128): Loss/seq after 02350 batchs: 494.030517578125
INFO:root:Train (Epoch 128): Loss/seq after 02400 batchs: 494.9892272949219
INFO:root:Train (Epoch 128): Loss/seq after 02450 batchs: 491.2544860839844
INFO:root:Train (Epoch 128): Loss/seq after 02500 batchs: 483.6854248046875
INFO:root:Train (Epoch 128): Loss/seq after 02550 batchs: 476.9941711425781
INFO:root:Train (Epoch 128): Loss/seq after 02600 batchs: 474.0321960449219
INFO:root:Train (Epoch 128): Loss/seq after 02650 batchs: 469.9633483886719
INFO:root:Train (Epoch 128): Loss/seq after 02700 batchs: 466.9330139160156
INFO:root:Train (Epoch 128): Loss/seq after 02750 batchs: 462.73602294921875
INFO:root:Train (Epoch 128): Loss/seq after 02800 batchs: 461.2734680175781
INFO:root:Train (Epoch 128): Loss/seq after 02850 batchs: 461.2639465332031
INFO:root:Train (Epoch 128): Loss/seq after 02900 batchs: 462.2704772949219
INFO:root:Train (Epoch 128): Loss/seq after 02950 batchs: 462.1374206542969
INFO:root:Train (Epoch 128): Loss/seq after 03000 batchs: 468.0699157714844
INFO:root:Train (Epoch 128): Loss/seq after 03050 batchs: 469.9444580078125
INFO:root:Train (Epoch 128): Loss/seq after 03100 batchs: 472.79364013671875
INFO:root:Train (Epoch 128): Loss/seq after 03150 batchs: 473.06768798828125
INFO:root:Train (Epoch 128): Loss/seq after 03200 batchs: 473.16522216796875
INFO:root:Train (Epoch 128): Loss/seq after 03250 batchs: 473.4207458496094
INFO:root:Train (Epoch 128): Loss/seq after 03300 batchs: 472.9406433105469
INFO:root:Train (Epoch 128): Loss/seq after 03350 batchs: 471.7333984375
INFO:root:Train (Epoch 128): Loss/seq after 03400 batchs: 468.000244140625
INFO:root:Train (Epoch 128): Loss/seq after 03450 batchs: 466.8468322753906
INFO:root:Train (Epoch 128): Loss/seq after 03500 batchs: 467.9949951171875
INFO:root:Train (Epoch 128): Loss/seq after 03550 batchs: 466.0899658203125
INFO:root:Train (Epoch 128): Loss/seq after 03600 batchs: 473.0217590332031
INFO:root:Train (Epoch 128): Loss/seq after 03650 batchs: 471.156005859375
INFO:root:Train (Epoch 128): Loss/seq after 03700 batchs: 474.01727294921875
INFO:root:Train (Epoch 128): Loss/seq after 03750 batchs: 478.87481689453125
INFO:root:Train (Epoch 128): Loss/seq after 03800 batchs: 477.4911804199219
INFO:root:Train (Epoch 128): Loss/seq after 03850 batchs: 476.4622497558594
INFO:root:Train (Epoch 128): Loss/seq after 03900 batchs: 479.29632568359375
INFO:root:Train (Epoch 128): Loss/seq after 03950 batchs: 481.79754638671875
INFO:root:Train (Epoch 128): Loss/seq after 04000 batchs: 478.6287536621094
INFO:root:Train (Epoch 128): Loss/seq after 04050 batchs: 475.5279541015625
INFO:root:Train (Epoch 128): Loss/seq after 04100 batchs: 474.4466552734375
INFO:root:Train (Epoch 128): Loss/seq after 04150 batchs: 474.6343078613281
INFO:root:Train (Epoch 128): Loss/seq after 04200 batchs: 473.3483581542969
INFO:root:Train (Epoch 128): Loss/seq after 04250 batchs: 471.9776916503906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 128): Loss/seq after 00000 batches: 335.1428527832031
INFO:root:# Valid (Epoch 128): Loss/seq after 00050 batches: 627.9612426757812
INFO:root:# Valid (Epoch 128): Loss/seq after 00100 batches: 642.8582153320312
INFO:root:# Valid (Epoch 128): Loss/seq after 00150 batches: 487.57818603515625
INFO:root:# Valid (Epoch 128): Loss/seq after 00200 batches: 461.6016540527344
INFO:root:Artifacts: Make stick videos for epoch 128
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_128_on_20220422_100210.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_128_index_1436_on_20220422_100210.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 129): Loss/seq after 00000 batchs: 810.2391967773438
INFO:root:Train (Epoch 129): Loss/seq after 00050 batchs: 667.9940795898438
INFO:root:Train (Epoch 129): Loss/seq after 00100 batchs: 692.4237060546875
INFO:root:Train (Epoch 129): Loss/seq after 00150 batchs: 637.5157470703125
INFO:root:Train (Epoch 129): Loss/seq after 00200 batchs: 692.7272338867188
INFO:root:Train (Epoch 129): Loss/seq after 00250 batchs: 791.1412353515625
INFO:root:Train (Epoch 129): Loss/seq after 00300 batchs: 794.1069946289062
INFO:root:Train (Epoch 129): Loss/seq after 00350 batchs: 744.8366088867188
INFO:root:Train (Epoch 129): Loss/seq after 00400 batchs: 733.1229248046875
INFO:root:Train (Epoch 129): Loss/seq after 00450 batchs: 725.1663208007812
INFO:root:Train (Epoch 129): Loss/seq after 00500 batchs: 700.4606323242188
INFO:root:Train (Epoch 129): Loss/seq after 00550 batchs: 681.056396484375
INFO:root:Train (Epoch 129): Loss/seq after 00600 batchs: 658.074951171875
INFO:root:Train (Epoch 129): Loss/seq after 00650 batchs: 635.1409301757812
INFO:root:Train (Epoch 129): Loss/seq after 00700 batchs: 608.9290771484375
INFO:root:Train (Epoch 129): Loss/seq after 00750 batchs: 603.4166870117188
INFO:root:Train (Epoch 129): Loss/seq after 00800 batchs: 607.86865234375
INFO:root:Train (Epoch 129): Loss/seq after 00850 batchs: 587.6768188476562
INFO:root:Train (Epoch 129): Loss/seq after 00900 batchs: 574.1099243164062
INFO:root:Train (Epoch 129): Loss/seq after 00950 batchs: 568.9667358398438
INFO:root:Train (Epoch 129): Loss/seq after 01000 batchs: 558.35400390625
INFO:root:Train (Epoch 129): Loss/seq after 01050 batchs: 546.6177978515625
INFO:root:Train (Epoch 129): Loss/seq after 01100 batchs: 536.8209838867188
INFO:root:Train (Epoch 129): Loss/seq after 01150 batchs: 521.53369140625
INFO:root:Train (Epoch 129): Loss/seq after 01200 batchs: 526.3701171875
INFO:root:Train (Epoch 129): Loss/seq after 01250 batchs: 524.982666015625
INFO:root:Train (Epoch 129): Loss/seq after 01300 batchs: 513.1578369140625
INFO:root:Train (Epoch 129): Loss/seq after 01350 batchs: 503.39862060546875
INFO:root:Train (Epoch 129): Loss/seq after 01400 batchs: 504.2148742675781
INFO:root:Train (Epoch 129): Loss/seq after 01450 batchs: 506.6252136230469
INFO:root:Train (Epoch 129): Loss/seq after 01500 batchs: 514.8761596679688
INFO:root:Train (Epoch 129): Loss/seq after 01550 batchs: 516.1950073242188
INFO:root:Train (Epoch 129): Loss/seq after 01600 batchs: 512.2529296875
INFO:root:Train (Epoch 129): Loss/seq after 01650 batchs: 511.12841796875
INFO:root:Train (Epoch 129): Loss/seq after 01700 batchs: 514.8771362304688
INFO:root:Train (Epoch 129): Loss/seq after 01750 batchs: 512.5828247070312
INFO:root:Train (Epoch 129): Loss/seq after 01800 batchs: 510.49530029296875
INFO:root:Train (Epoch 129): Loss/seq after 01850 batchs: 507.782958984375
INFO:root:Train (Epoch 129): Loss/seq after 01900 batchs: 507.8941345214844
INFO:root:Train (Epoch 129): Loss/seq after 01950 batchs: 506.3243713378906
INFO:root:Train (Epoch 129): Loss/seq after 02000 batchs: 506.2765197753906
INFO:root:Train (Epoch 129): Loss/seq after 02050 batchs: 505.804931640625
INFO:root:Train (Epoch 129): Loss/seq after 02100 batchs: 503.797607421875
INFO:root:Train (Epoch 129): Loss/seq after 02150 batchs: 502.1144104003906
INFO:root:Train (Epoch 129): Loss/seq after 02200 batchs: 500.349853515625
INFO:root:Train (Epoch 129): Loss/seq after 02250 batchs: 499.1463317871094
INFO:root:Train (Epoch 129): Loss/seq after 02300 batchs: 494.6208190917969
INFO:root:Train (Epoch 129): Loss/seq after 02350 batchs: 491.01318359375
INFO:root:Train (Epoch 129): Loss/seq after 02400 batchs: 491.64447021484375
INFO:root:Train (Epoch 129): Loss/seq after 02450 batchs: 487.9190979003906
INFO:root:Train (Epoch 129): Loss/seq after 02500 batchs: 480.40460205078125
INFO:root:Train (Epoch 129): Loss/seq after 02550 batchs: 473.7195129394531
INFO:root:Train (Epoch 129): Loss/seq after 02600 batchs: 470.7427978515625
INFO:root:Train (Epoch 129): Loss/seq after 02650 batchs: 466.700439453125
INFO:root:Train (Epoch 129): Loss/seq after 02700 batchs: 463.912841796875
INFO:root:Train (Epoch 129): Loss/seq after 02750 batchs: 459.2283935546875
INFO:root:Train (Epoch 129): Loss/seq after 02800 batchs: 458.0152282714844
INFO:root:Train (Epoch 129): Loss/seq after 02850 batchs: 458.04656982421875
INFO:root:Train (Epoch 129): Loss/seq after 02900 batchs: 459.05120849609375
INFO:root:Train (Epoch 129): Loss/seq after 02950 batchs: 458.9662780761719
INFO:root:Train (Epoch 129): Loss/seq after 03000 batchs: 465.1403503417969
INFO:root:Train (Epoch 129): Loss/seq after 03050 batchs: 467.17401123046875
INFO:root:Train (Epoch 129): Loss/seq after 03100 batchs: 469.56610107421875
INFO:root:Train (Epoch 129): Loss/seq after 03150 batchs: 469.1946716308594
INFO:root:Train (Epoch 129): Loss/seq after 03200 batchs: 469.26983642578125
INFO:root:Train (Epoch 129): Loss/seq after 03250 batchs: 469.1492004394531
INFO:root:Train (Epoch 129): Loss/seq after 03300 batchs: 468.8113708496094
INFO:root:Train (Epoch 129): Loss/seq after 03350 batchs: 467.646240234375
INFO:root:Train (Epoch 129): Loss/seq after 03400 batchs: 463.9545593261719
INFO:root:Train (Epoch 129): Loss/seq after 03450 batchs: 462.8033447265625
INFO:root:Train (Epoch 129): Loss/seq after 03500 batchs: 464.3616943359375
INFO:root:Train (Epoch 129): Loss/seq after 03550 batchs: 462.7869567871094
INFO:root:Train (Epoch 129): Loss/seq after 03600 batchs: 470.0885314941406
INFO:root:Train (Epoch 129): Loss/seq after 03650 batchs: 468.351318359375
INFO:root:Train (Epoch 129): Loss/seq after 03700 batchs: 471.43243408203125
INFO:root:Train (Epoch 129): Loss/seq after 03750 batchs: 476.1923828125
INFO:root:Train (Epoch 129): Loss/seq after 03800 batchs: 474.85467529296875
INFO:root:Train (Epoch 129): Loss/seq after 03850 batchs: 473.9039001464844
INFO:root:Train (Epoch 129): Loss/seq after 03900 batchs: 477.01654052734375
INFO:root:Train (Epoch 129): Loss/seq after 03950 batchs: 480.08721923828125
INFO:root:Train (Epoch 129): Loss/seq after 04000 batchs: 477.019775390625
INFO:root:Train (Epoch 129): Loss/seq after 04050 batchs: 473.9428405761719
INFO:root:Train (Epoch 129): Loss/seq after 04100 batchs: 472.9126892089844
INFO:root:Train (Epoch 129): Loss/seq after 04150 batchs: 473.1474609375
INFO:root:Train (Epoch 129): Loss/seq after 04200 batchs: 471.9146728515625
INFO:root:Train (Epoch 129): Loss/seq after 04250 batchs: 470.50848388671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 129): Loss/seq after 00000 batches: 407.0865783691406
INFO:root:# Valid (Epoch 129): Loss/seq after 00050 batches: 641.0270385742188
INFO:root:# Valid (Epoch 129): Loss/seq after 00100 batches: 677.8779907226562
INFO:root:# Valid (Epoch 129): Loss/seq after 00150 batches: 514.0138549804688
INFO:root:# Valid (Epoch 129): Loss/seq after 00200 batches: 480.8037414550781
INFO:root:Artifacts: Make stick videos for epoch 129
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_129_on_20220422_100654.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_129_index_1623_on_20220422_100654.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 130): Loss/seq after 00000 batchs: 799.2940063476562
INFO:root:Train (Epoch 130): Loss/seq after 00050 batchs: 679.7412109375
INFO:root:Train (Epoch 130): Loss/seq after 00100 batchs: 704.2484130859375
INFO:root:Train (Epoch 130): Loss/seq after 00150 batchs: 642.8067626953125
INFO:root:Train (Epoch 130): Loss/seq after 00200 batchs: 700.60546875
INFO:root:Train (Epoch 130): Loss/seq after 00250 batchs: 789.1367797851562
INFO:root:Train (Epoch 130): Loss/seq after 00300 batchs: 790.2077026367188
INFO:root:Train (Epoch 130): Loss/seq after 00350 batchs: 744.6666259765625
INFO:root:Train (Epoch 130): Loss/seq after 00400 batchs: 734.2451171875
INFO:root:Train (Epoch 130): Loss/seq after 00450 batchs: 726.68994140625
INFO:root:Train (Epoch 130): Loss/seq after 00500 batchs: 706.7202758789062
INFO:root:Train (Epoch 130): Loss/seq after 00550 batchs: 689.3634033203125
INFO:root:Train (Epoch 130): Loss/seq after 00600 batchs: 669.0774536132812
INFO:root:Train (Epoch 130): Loss/seq after 00650 batchs: 642.3207397460938
INFO:root:Train (Epoch 130): Loss/seq after 00700 batchs: 614.6978149414062
INFO:root:Train (Epoch 130): Loss/seq after 00750 batchs: 608.1068725585938
INFO:root:Train (Epoch 130): Loss/seq after 00800 batchs: 614.7803955078125
INFO:root:Train (Epoch 130): Loss/seq after 00850 batchs: 594.7006225585938
INFO:root:Train (Epoch 130): Loss/seq after 00900 batchs: 579.9987182617188
INFO:root:Train (Epoch 130): Loss/seq after 00950 batchs: 574.8956909179688
INFO:root:Train (Epoch 130): Loss/seq after 01000 batchs: 563.6615600585938
INFO:root:Train (Epoch 130): Loss/seq after 01050 batchs: 552.3475341796875
INFO:root:Train (Epoch 130): Loss/seq after 01100 batchs: 543.3560180664062
INFO:root:Train (Epoch 130): Loss/seq after 01150 batchs: 528.1109619140625
INFO:root:Train (Epoch 130): Loss/seq after 01200 batchs: 533.0896606445312
INFO:root:Train (Epoch 130): Loss/seq after 01250 batchs: 531.7066650390625
INFO:root:Train (Epoch 130): Loss/seq after 01300 batchs: 519.9398193359375
INFO:root:Train (Epoch 130): Loss/seq after 01350 batchs: 509.6764831542969
INFO:root:Train (Epoch 130): Loss/seq after 01400 batchs: 510.01080322265625
INFO:root:Train (Epoch 130): Loss/seq after 01450 batchs: 512.2551879882812
INFO:root:Train (Epoch 130): Loss/seq after 01500 batchs: 520.1578369140625
INFO:root:Train (Epoch 130): Loss/seq after 01550 batchs: 521.2185668945312
INFO:root:Train (Epoch 130): Loss/seq after 01600 batchs: 517.0450439453125
INFO:root:Train (Epoch 130): Loss/seq after 01650 batchs: 515.3684692382812
INFO:root:Train (Epoch 130): Loss/seq after 01700 batchs: 518.7777709960938
INFO:root:Train (Epoch 130): Loss/seq after 01750 batchs: 516.1466064453125
INFO:root:Train (Epoch 130): Loss/seq after 01800 batchs: 514.0319213867188
INFO:root:Train (Epoch 130): Loss/seq after 01850 batchs: 511.2122802734375
INFO:root:Train (Epoch 130): Loss/seq after 01900 batchs: 511.03515625
INFO:root:Train (Epoch 130): Loss/seq after 01950 batchs: 509.8443603515625
INFO:root:Train (Epoch 130): Loss/seq after 02000 batchs: 509.6419677734375
INFO:root:Train (Epoch 130): Loss/seq after 02050 batchs: 509.09649658203125
INFO:root:Train (Epoch 130): Loss/seq after 02100 batchs: 507.4777526855469
INFO:root:Train (Epoch 130): Loss/seq after 02150 batchs: 505.8731384277344
INFO:root:Train (Epoch 130): Loss/seq after 02200 batchs: 503.89129638671875
INFO:root:Train (Epoch 130): Loss/seq after 02250 batchs: 504.19976806640625
INFO:root:Train (Epoch 130): Loss/seq after 02300 batchs: 500.26959228515625
INFO:root:Train (Epoch 130): Loss/seq after 02350 batchs: 497.6506652832031
INFO:root:Train (Epoch 130): Loss/seq after 02400 batchs: 498.527587890625
INFO:root:Train (Epoch 130): Loss/seq after 02450 batchs: 494.64801025390625
INFO:root:Train (Epoch 130): Loss/seq after 02500 batchs: 487.00555419921875
INFO:root:Train (Epoch 130): Loss/seq after 02550 batchs: 480.2115173339844
INFO:root:Train (Epoch 130): Loss/seq after 02600 batchs: 477.1630554199219
INFO:root:Train (Epoch 130): Loss/seq after 02650 batchs: 472.9836730957031
INFO:root:Train (Epoch 130): Loss/seq after 02700 batchs: 470.0985107421875
INFO:root:Train (Epoch 130): Loss/seq after 02750 batchs: 465.2388916015625
INFO:root:Train (Epoch 130): Loss/seq after 02800 batchs: 463.2621765136719
INFO:root:Train (Epoch 130): Loss/seq after 02850 batchs: 463.15008544921875
INFO:root:Train (Epoch 130): Loss/seq after 02900 batchs: 463.67376708984375
INFO:root:Train (Epoch 130): Loss/seq after 02950 batchs: 463.4158020019531
INFO:root:Train (Epoch 130): Loss/seq after 03000 batchs: 469.3578186035156
INFO:root:Train (Epoch 130): Loss/seq after 03050 batchs: 471.20916748046875
INFO:root:Train (Epoch 130): Loss/seq after 03100 batchs: 473.57366943359375
INFO:root:Train (Epoch 130): Loss/seq after 03150 batchs: 473.9805603027344
INFO:root:Train (Epoch 130): Loss/seq after 03200 batchs: 474.1875
INFO:root:Train (Epoch 130): Loss/seq after 03250 batchs: 474.2787170410156
INFO:root:Train (Epoch 130): Loss/seq after 03300 batchs: 473.518310546875
INFO:root:Train (Epoch 130): Loss/seq after 03350 batchs: 472.1893310546875
INFO:root:Train (Epoch 130): Loss/seq after 03400 batchs: 468.5489807128906
INFO:root:Train (Epoch 130): Loss/seq after 03450 batchs: 467.51556396484375
INFO:root:Train (Epoch 130): Loss/seq after 03500 batchs: 469.8088684082031
INFO:root:Train (Epoch 130): Loss/seq after 03550 batchs: 468.15643310546875
INFO:root:Train (Epoch 130): Loss/seq after 03600 batchs: 475.474365234375
INFO:root:Train (Epoch 130): Loss/seq after 03650 batchs: 473.87567138671875
INFO:root:Train (Epoch 130): Loss/seq after 03700 batchs: 477.0680847167969
INFO:root:Train (Epoch 130): Loss/seq after 03750 batchs: 481.8858947753906
INFO:root:Train (Epoch 130): Loss/seq after 03800 batchs: 480.50115966796875
INFO:root:Train (Epoch 130): Loss/seq after 03850 batchs: 479.478759765625
INFO:root:Train (Epoch 130): Loss/seq after 03900 batchs: 482.18023681640625
INFO:root:Train (Epoch 130): Loss/seq after 03950 batchs: 484.68878173828125
INFO:root:Train (Epoch 130): Loss/seq after 04000 batchs: 481.4867858886719
INFO:root:Train (Epoch 130): Loss/seq after 04050 batchs: 478.3216857910156
INFO:root:Train (Epoch 130): Loss/seq after 04100 batchs: 477.2352600097656
INFO:root:Train (Epoch 130): Loss/seq after 04150 batchs: 477.456298828125
INFO:root:Train (Epoch 130): Loss/seq after 04200 batchs: 476.16229248046875
INFO:root:Train (Epoch 130): Loss/seq after 04250 batchs: 474.6989440917969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 130): Loss/seq after 00000 batches: 396.2732238769531
INFO:root:# Valid (Epoch 130): Loss/seq after 00050 batches: 634.3310546875
INFO:root:# Valid (Epoch 130): Loss/seq after 00100 batches: 683.305419921875
INFO:root:# Valid (Epoch 130): Loss/seq after 00150 batches: 517.166259765625
INFO:root:# Valid (Epoch 130): Loss/seq after 00200 batches: 493.36627197265625
INFO:root:Artifacts: Make stick videos for epoch 130
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_130_on_20220422_101152.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_130_index_1588_on_20220422_101152.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 131): Loss/seq after 00000 batchs: 882.6486206054688
INFO:root:Train (Epoch 131): Loss/seq after 00050 batchs: 664.1304321289062
INFO:root:Train (Epoch 131): Loss/seq after 00100 batchs: 697.9170532226562
INFO:root:Train (Epoch 131): Loss/seq after 00150 batchs: 633.78271484375
INFO:root:Train (Epoch 131): Loss/seq after 00200 batchs: 690.3395385742188
INFO:root:Train (Epoch 131): Loss/seq after 00250 batchs: 769.9822998046875
INFO:root:Train (Epoch 131): Loss/seq after 00300 batchs: 773.3521118164062
INFO:root:Train (Epoch 131): Loss/seq after 00350 batchs: 725.4656982421875
INFO:root:Train (Epoch 131): Loss/seq after 00400 batchs: 710.1350708007812
INFO:root:Train (Epoch 131): Loss/seq after 00450 batchs: 704.3807983398438
INFO:root:Train (Epoch 131): Loss/seq after 00500 batchs: 680.4805908203125
INFO:root:Train (Epoch 131): Loss/seq after 00550 batchs: 663.214111328125
INFO:root:Train (Epoch 131): Loss/seq after 00600 batchs: 640.451416015625
INFO:root:Train (Epoch 131): Loss/seq after 00650 batchs: 615.0219116210938
INFO:root:Train (Epoch 131): Loss/seq after 00700 batchs: 588.4725952148438
INFO:root:Train (Epoch 131): Loss/seq after 00750 batchs: 582.2094116210938
INFO:root:Train (Epoch 131): Loss/seq after 00800 batchs: 587.405029296875
INFO:root:Train (Epoch 131): Loss/seq after 00850 batchs: 568.2780151367188
INFO:root:Train (Epoch 131): Loss/seq after 00900 batchs: 554.7002563476562
INFO:root:Train (Epoch 131): Loss/seq after 00950 batchs: 549.8851318359375
INFO:root:Train (Epoch 131): Loss/seq after 01000 batchs: 539.9873657226562
INFO:root:Train (Epoch 131): Loss/seq after 01050 batchs: 529.7896118164062
INFO:root:Train (Epoch 131): Loss/seq after 01100 batchs: 520.6301879882812
INFO:root:Train (Epoch 131): Loss/seq after 01150 batchs: 506.38555908203125
INFO:root:Train (Epoch 131): Loss/seq after 01200 batchs: 512.4955444335938
INFO:root:Train (Epoch 131): Loss/seq after 01250 batchs: 511.768798828125
INFO:root:Train (Epoch 131): Loss/seq after 01300 batchs: 500.4648742675781
INFO:root:Train (Epoch 131): Loss/seq after 01350 batchs: 491.0248107910156
INFO:root:Train (Epoch 131): Loss/seq after 01400 batchs: 492.7956848144531
INFO:root:Train (Epoch 131): Loss/seq after 01450 batchs: 495.5081787109375
INFO:root:Train (Epoch 131): Loss/seq after 01500 batchs: 503.97882080078125
INFO:root:Train (Epoch 131): Loss/seq after 01550 batchs: 505.9101257324219
INFO:root:Train (Epoch 131): Loss/seq after 01600 batchs: 502.3320007324219
INFO:root:Train (Epoch 131): Loss/seq after 01650 batchs: 501.3524475097656
INFO:root:Train (Epoch 131): Loss/seq after 01700 batchs: 505.1968688964844
INFO:root:Train (Epoch 131): Loss/seq after 01750 batchs: 503.0262145996094
INFO:root:Train (Epoch 131): Loss/seq after 01800 batchs: 500.9799499511719
INFO:root:Train (Epoch 131): Loss/seq after 01850 batchs: 498.4759216308594
INFO:root:Train (Epoch 131): Loss/seq after 01900 batchs: 498.8306884765625
INFO:root:Train (Epoch 131): Loss/seq after 01950 batchs: 497.344482421875
INFO:root:Train (Epoch 131): Loss/seq after 02000 batchs: 497.37371826171875
INFO:root:Train (Epoch 131): Loss/seq after 02050 batchs: 496.9822082519531
INFO:root:Train (Epoch 131): Loss/seq after 02100 batchs: 495.07843017578125
INFO:root:Train (Epoch 131): Loss/seq after 02150 batchs: 493.67584228515625
INFO:root:Train (Epoch 131): Loss/seq after 02200 batchs: 491.9597473144531
INFO:root:Train (Epoch 131): Loss/seq after 02250 batchs: 490.979736328125
INFO:root:Train (Epoch 131): Loss/seq after 02300 batchs: 486.9864501953125
INFO:root:Train (Epoch 131): Loss/seq after 02350 batchs: 483.55206298828125
INFO:root:Train (Epoch 131): Loss/seq after 02400 batchs: 484.2580261230469
INFO:root:Train (Epoch 131): Loss/seq after 02450 batchs: 480.5900573730469
INFO:root:Train (Epoch 131): Loss/seq after 02500 batchs: 473.198974609375
INFO:root:Train (Epoch 131): Loss/seq after 02550 batchs: 466.5823059082031
INFO:root:Train (Epoch 131): Loss/seq after 02600 batchs: 463.86407470703125
INFO:root:Train (Epoch 131): Loss/seq after 02650 batchs: 459.7689514160156
INFO:root:Train (Epoch 131): Loss/seq after 02700 batchs: 456.9139404296875
INFO:root:Train (Epoch 131): Loss/seq after 02750 batchs: 452.5157775878906
INFO:root:Train (Epoch 131): Loss/seq after 02800 batchs: 450.873291015625
INFO:root:Train (Epoch 131): Loss/seq after 02850 batchs: 450.7798156738281
INFO:root:Train (Epoch 131): Loss/seq after 02900 batchs: 451.5932312011719
INFO:root:Train (Epoch 131): Loss/seq after 02950 batchs: 451.4197692871094
INFO:root:Train (Epoch 131): Loss/seq after 03000 batchs: 457.61688232421875
INFO:root:Train (Epoch 131): Loss/seq after 03050 batchs: 459.64166259765625
INFO:root:Train (Epoch 131): Loss/seq after 03100 batchs: 461.6270751953125
INFO:root:Train (Epoch 131): Loss/seq after 03150 batchs: 461.7665100097656
INFO:root:Train (Epoch 131): Loss/seq after 03200 batchs: 462.008056640625
INFO:root:Train (Epoch 131): Loss/seq after 03250 batchs: 462.3656921386719
INFO:root:Train (Epoch 131): Loss/seq after 03300 batchs: 461.8726501464844
INFO:root:Train (Epoch 131): Loss/seq after 03350 batchs: 460.776123046875
INFO:root:Train (Epoch 131): Loss/seq after 03400 batchs: 457.19012451171875
INFO:root:Train (Epoch 131): Loss/seq after 03450 batchs: 455.8944091796875
INFO:root:Train (Epoch 131): Loss/seq after 03500 batchs: 457.6239318847656
INFO:root:Train (Epoch 131): Loss/seq after 03550 batchs: 456.3900451660156
INFO:root:Train (Epoch 131): Loss/seq after 03600 batchs: 463.9120788574219
INFO:root:Train (Epoch 131): Loss/seq after 03650 batchs: 462.4648132324219
INFO:root:Train (Epoch 131): Loss/seq after 03700 batchs: 465.39495849609375
INFO:root:Train (Epoch 131): Loss/seq after 03750 batchs: 470.1618347167969
INFO:root:Train (Epoch 131): Loss/seq after 03800 batchs: 468.8463134765625
INFO:root:Train (Epoch 131): Loss/seq after 03850 batchs: 467.9571838378906
INFO:root:Train (Epoch 131): Loss/seq after 03900 batchs: 470.5310974121094
INFO:root:Train (Epoch 131): Loss/seq after 03950 batchs: 473.4194030761719
INFO:root:Train (Epoch 131): Loss/seq after 04000 batchs: 470.3490905761719
INFO:root:Train (Epoch 131): Loss/seq after 04050 batchs: 467.32733154296875
INFO:root:Train (Epoch 131): Loss/seq after 04100 batchs: 466.3792419433594
INFO:root:Train (Epoch 131): Loss/seq after 04150 batchs: 466.6392517089844
INFO:root:Train (Epoch 131): Loss/seq after 04200 batchs: 465.4072265625
INFO:root:Train (Epoch 131): Loss/seq after 04250 batchs: 463.9422912597656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 131): Loss/seq after 00000 batches: 346.25323486328125
INFO:root:# Valid (Epoch 131): Loss/seq after 00050 batches: 629.8799438476562
INFO:root:# Valid (Epoch 131): Loss/seq after 00100 batches: 687.6569213867188
INFO:root:# Valid (Epoch 131): Loss/seq after 00150 batches: 519.6475219726562
INFO:root:# Valid (Epoch 131): Loss/seq after 00200 batches: 486.93682861328125
INFO:root:Artifacts: Make stick videos for epoch 131
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_131_on_20220422_101638.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_131_index_453_on_20220422_101638.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 132): Loss/seq after 00000 batchs: 880.2642211914062
INFO:root:Train (Epoch 132): Loss/seq after 00050 batchs: 665.6972045898438
INFO:root:Train (Epoch 132): Loss/seq after 00100 batchs: 689.673828125
INFO:root:Train (Epoch 132): Loss/seq after 00150 batchs: 630.6763305664062
INFO:root:Train (Epoch 132): Loss/seq after 00200 batchs: 690.9829711914062
INFO:root:Train (Epoch 132): Loss/seq after 00250 batchs: 776.2001342773438
INFO:root:Train (Epoch 132): Loss/seq after 00300 batchs: 780.576904296875
INFO:root:Train (Epoch 132): Loss/seq after 00350 batchs: 734.6373291015625
INFO:root:Train (Epoch 132): Loss/seq after 00400 batchs: 717.5077514648438
INFO:root:Train (Epoch 132): Loss/seq after 00450 batchs: 711.0487670898438
INFO:root:Train (Epoch 132): Loss/seq after 00500 batchs: 686.6397094726562
INFO:root:Train (Epoch 132): Loss/seq after 00550 batchs: 667.8758544921875
INFO:root:Train (Epoch 132): Loss/seq after 00600 batchs: 644.6463012695312
INFO:root:Train (Epoch 132): Loss/seq after 00650 batchs: 619.8984985351562
INFO:root:Train (Epoch 132): Loss/seq after 00700 batchs: 593.3865356445312
INFO:root:Train (Epoch 132): Loss/seq after 00750 batchs: 585.907470703125
INFO:root:Train (Epoch 132): Loss/seq after 00800 batchs: 590.3234252929688
INFO:root:Train (Epoch 132): Loss/seq after 00850 batchs: 570.6842041015625
INFO:root:Train (Epoch 132): Loss/seq after 00900 batchs: 556.9649658203125
INFO:root:Train (Epoch 132): Loss/seq after 00950 batchs: 552.4182739257812
INFO:root:Train (Epoch 132): Loss/seq after 01000 batchs: 542.01171875
INFO:root:Train (Epoch 132): Loss/seq after 01050 batchs: 531.3334350585938
INFO:root:Train (Epoch 132): Loss/seq after 01100 batchs: 522.5645141601562
INFO:root:Train (Epoch 132): Loss/seq after 01150 batchs: 508.0313415527344
INFO:root:Train (Epoch 132): Loss/seq after 01200 batchs: 513.2074584960938
INFO:root:Train (Epoch 132): Loss/seq after 01250 batchs: 512.0963745117188
INFO:root:Train (Epoch 132): Loss/seq after 01300 batchs: 500.45751953125
INFO:root:Train (Epoch 132): Loss/seq after 01350 batchs: 491.0178527832031
INFO:root:Train (Epoch 132): Loss/seq after 01400 batchs: 492.1590270996094
INFO:root:Train (Epoch 132): Loss/seq after 01450 batchs: 494.99993896484375
INFO:root:Train (Epoch 132): Loss/seq after 01500 batchs: 503.3783874511719
INFO:root:Train (Epoch 132): Loss/seq after 01550 batchs: 504.5957336425781
INFO:root:Train (Epoch 132): Loss/seq after 01600 batchs: 501.0760803222656
INFO:root:Train (Epoch 132): Loss/seq after 01650 batchs: 500.0195007324219
INFO:root:Train (Epoch 132): Loss/seq after 01700 batchs: 504.15643310546875
INFO:root:Train (Epoch 132): Loss/seq after 01750 batchs: 501.9094543457031
INFO:root:Train (Epoch 132): Loss/seq after 01800 batchs: 499.9953918457031
INFO:root:Train (Epoch 132): Loss/seq after 01850 batchs: 497.42376708984375
INFO:root:Train (Epoch 132): Loss/seq after 01900 batchs: 497.7846374511719
INFO:root:Train (Epoch 132): Loss/seq after 01950 batchs: 496.17901611328125
INFO:root:Train (Epoch 132): Loss/seq after 02000 batchs: 496.333984375
INFO:root:Train (Epoch 132): Loss/seq after 02050 batchs: 495.92864990234375
INFO:root:Train (Epoch 132): Loss/seq after 02100 batchs: 494.10601806640625
INFO:root:Train (Epoch 132): Loss/seq after 02150 batchs: 492.64813232421875
INFO:root:Train (Epoch 132): Loss/seq after 02200 batchs: 490.9022521972656
INFO:root:Train (Epoch 132): Loss/seq after 02250 batchs: 489.96624755859375
INFO:root:Train (Epoch 132): Loss/seq after 02300 batchs: 485.5762634277344
INFO:root:Train (Epoch 132): Loss/seq after 02350 batchs: 482.0893859863281
INFO:root:Train (Epoch 132): Loss/seq after 02400 batchs: 482.86761474609375
INFO:root:Train (Epoch 132): Loss/seq after 02450 batchs: 479.2884521484375
INFO:root:Train (Epoch 132): Loss/seq after 02500 batchs: 471.9290771484375
INFO:root:Train (Epoch 132): Loss/seq after 02550 batchs: 465.3390197753906
INFO:root:Train (Epoch 132): Loss/seq after 02600 batchs: 462.3179931640625
INFO:root:Train (Epoch 132): Loss/seq after 02650 batchs: 458.2261047363281
INFO:root:Train (Epoch 132): Loss/seq after 02700 batchs: 455.43829345703125
INFO:root:Train (Epoch 132): Loss/seq after 02750 batchs: 451.0168151855469
INFO:root:Train (Epoch 132): Loss/seq after 02800 batchs: 450.19873046875
INFO:root:Train (Epoch 132): Loss/seq after 02850 batchs: 450.1962890625
INFO:root:Train (Epoch 132): Loss/seq after 02900 batchs: 451.5481262207031
INFO:root:Train (Epoch 132): Loss/seq after 02950 batchs: 451.39788818359375
INFO:root:Train (Epoch 132): Loss/seq after 03000 batchs: 457.49029541015625
INFO:root:Train (Epoch 132): Loss/seq after 03050 batchs: 459.7796325683594
INFO:root:Train (Epoch 132): Loss/seq after 03100 batchs: 463.95654296875
INFO:root:Train (Epoch 132): Loss/seq after 03150 batchs: 464.7728576660156
INFO:root:Train (Epoch 132): Loss/seq after 03200 batchs: 464.7879638671875
INFO:root:Train (Epoch 132): Loss/seq after 03250 batchs: 465.255615234375
INFO:root:Train (Epoch 132): Loss/seq after 03300 batchs: 465.29156494140625
INFO:root:Train (Epoch 132): Loss/seq after 03350 batchs: 464.16937255859375
INFO:root:Train (Epoch 132): Loss/seq after 03400 batchs: 460.5230712890625
INFO:root:Train (Epoch 132): Loss/seq after 03450 batchs: 459.2302551269531
INFO:root:Train (Epoch 132): Loss/seq after 03500 batchs: 461.1578369140625
INFO:root:Train (Epoch 132): Loss/seq after 03550 batchs: 459.8474426269531
INFO:root:Train (Epoch 132): Loss/seq after 03600 batchs: 467.49505615234375
INFO:root:Train (Epoch 132): Loss/seq after 03650 batchs: 466.2470397949219
INFO:root:Train (Epoch 132): Loss/seq after 03700 batchs: 469.7280578613281
INFO:root:Train (Epoch 132): Loss/seq after 03750 batchs: 474.31494140625
INFO:root:Train (Epoch 132): Loss/seq after 03800 batchs: 472.9911193847656
INFO:root:Train (Epoch 132): Loss/seq after 03850 batchs: 472.2347412109375
INFO:root:Train (Epoch 132): Loss/seq after 03900 batchs: 475.12176513671875
INFO:root:Train (Epoch 132): Loss/seq after 03950 batchs: 478.08740234375
INFO:root:Train (Epoch 132): Loss/seq after 04000 batchs: 474.9877624511719
INFO:root:Train (Epoch 132): Loss/seq after 04050 batchs: 471.9909362792969
INFO:root:Train (Epoch 132): Loss/seq after 04100 batchs: 470.9308166503906
INFO:root:Train (Epoch 132): Loss/seq after 04150 batchs: 471.255859375
INFO:root:Train (Epoch 132): Loss/seq after 04200 batchs: 470.18060302734375
INFO:root:Train (Epoch 132): Loss/seq after 04250 batchs: 468.82635498046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 132): Loss/seq after 00000 batches: 383.7323913574219
INFO:root:# Valid (Epoch 132): Loss/seq after 00050 batches: 656.455810546875
INFO:root:# Valid (Epoch 132): Loss/seq after 00100 batches: 698.1360473632812
INFO:root:# Valid (Epoch 132): Loss/seq after 00150 batches: 528.8278198242188
INFO:root:# Valid (Epoch 132): Loss/seq after 00200 batches: 492.6417541503906
INFO:root:Artifacts: Make stick videos for epoch 132
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_132_on_20220422_102146.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_132_index_1152_on_20220422_102146.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 133): Loss/seq after 00000 batchs: 717.8361206054688
INFO:root:Train (Epoch 133): Loss/seq after 00050 batchs: 676.9495239257812
INFO:root:Train (Epoch 133): Loss/seq after 00100 batchs: 694.301025390625
INFO:root:Train (Epoch 133): Loss/seq after 00150 batchs: 636.73974609375
INFO:root:Train (Epoch 133): Loss/seq after 00200 batchs: 686.258056640625
INFO:root:Train (Epoch 133): Loss/seq after 00250 batchs: 766.62109375
INFO:root:Train (Epoch 133): Loss/seq after 00300 batchs: 769.563720703125
INFO:root:Train (Epoch 133): Loss/seq after 00350 batchs: 722.7982788085938
INFO:root:Train (Epoch 133): Loss/seq after 00400 batchs: 707.2806396484375
INFO:root:Train (Epoch 133): Loss/seq after 00450 batchs: 702.4597778320312
INFO:root:Train (Epoch 133): Loss/seq after 00500 batchs: 679.5084838867188
INFO:root:Train (Epoch 133): Loss/seq after 00550 batchs: 662.47607421875
INFO:root:Train (Epoch 133): Loss/seq after 00600 batchs: 640.445556640625
INFO:root:Train (Epoch 133): Loss/seq after 00650 batchs: 615.935791015625
INFO:root:Train (Epoch 133): Loss/seq after 00700 batchs: 590.4335327148438
INFO:root:Train (Epoch 133): Loss/seq after 00750 batchs: 582.4824829101562
INFO:root:Train (Epoch 133): Loss/seq after 00800 batchs: 588.2767944335938
INFO:root:Train (Epoch 133): Loss/seq after 00850 batchs: 569.2564086914062
INFO:root:Train (Epoch 133): Loss/seq after 00900 batchs: 555.1572875976562
INFO:root:Train (Epoch 133): Loss/seq after 00950 batchs: 550.5287475585938
INFO:root:Train (Epoch 133): Loss/seq after 01000 batchs: 540.3585815429688
INFO:root:Train (Epoch 133): Loss/seq after 01050 batchs: 529.9173583984375
INFO:root:Train (Epoch 133): Loss/seq after 01100 batchs: 521.123046875
INFO:root:Train (Epoch 133): Loss/seq after 01150 batchs: 506.7264404296875
INFO:root:Train (Epoch 133): Loss/seq after 01200 batchs: 511.61199951171875
INFO:root:Train (Epoch 133): Loss/seq after 01250 batchs: 510.6969299316406
INFO:root:Train (Epoch 133): Loss/seq after 01300 batchs: 499.6234436035156
INFO:root:Train (Epoch 133): Loss/seq after 01350 batchs: 489.88214111328125
INFO:root:Train (Epoch 133): Loss/seq after 01400 batchs: 491.4073486328125
INFO:root:Train (Epoch 133): Loss/seq after 01450 batchs: 494.35064697265625
INFO:root:Train (Epoch 133): Loss/seq after 01500 batchs: 502.9530944824219
INFO:root:Train (Epoch 133): Loss/seq after 01550 batchs: 504.29132080078125
INFO:root:Train (Epoch 133): Loss/seq after 01600 batchs: 500.24041748046875
INFO:root:Train (Epoch 133): Loss/seq after 01650 batchs: 499.06231689453125
INFO:root:Train (Epoch 133): Loss/seq after 01700 batchs: 502.7501220703125
INFO:root:Train (Epoch 133): Loss/seq after 01750 batchs: 500.32318115234375
INFO:root:Train (Epoch 133): Loss/seq after 01800 batchs: 498.5808410644531
INFO:root:Train (Epoch 133): Loss/seq after 01850 batchs: 495.9768371582031
INFO:root:Train (Epoch 133): Loss/seq after 01900 batchs: 495.9254150390625
INFO:root:Train (Epoch 133): Loss/seq after 01950 batchs: 494.4248962402344
INFO:root:Train (Epoch 133): Loss/seq after 02000 batchs: 494.5475158691406
INFO:root:Train (Epoch 133): Loss/seq after 02050 batchs: 494.0087585449219
INFO:root:Train (Epoch 133): Loss/seq after 02100 batchs: 492.2725524902344
INFO:root:Train (Epoch 133): Loss/seq after 02150 batchs: 490.994140625
INFO:root:Train (Epoch 133): Loss/seq after 02200 batchs: 489.2036437988281
INFO:root:Train (Epoch 133): Loss/seq after 02250 batchs: 488.0953674316406
INFO:root:Train (Epoch 133): Loss/seq after 02300 batchs: 484.2318420410156
INFO:root:Train (Epoch 133): Loss/seq after 02350 batchs: 481.0641174316406
INFO:root:Train (Epoch 133): Loss/seq after 02400 batchs: 482.0246276855469
INFO:root:Train (Epoch 133): Loss/seq after 02450 batchs: 478.3931884765625
INFO:root:Train (Epoch 133): Loss/seq after 02500 batchs: 471.025634765625
INFO:root:Train (Epoch 133): Loss/seq after 02550 batchs: 464.43603515625
INFO:root:Train (Epoch 133): Loss/seq after 02600 batchs: 461.8362731933594
INFO:root:Train (Epoch 133): Loss/seq after 02650 batchs: 457.89508056640625
INFO:root:Train (Epoch 133): Loss/seq after 02700 batchs: 455.1004943847656
INFO:root:Train (Epoch 133): Loss/seq after 02750 batchs: 450.59429931640625
INFO:root:Train (Epoch 133): Loss/seq after 02800 batchs: 450.0753173828125
INFO:root:Train (Epoch 133): Loss/seq after 02850 batchs: 449.8599548339844
INFO:root:Train (Epoch 133): Loss/seq after 02900 batchs: 450.7558288574219
INFO:root:Train (Epoch 133): Loss/seq after 02950 batchs: 450.52313232421875
INFO:root:Train (Epoch 133): Loss/seq after 03000 batchs: 456.7483825683594
INFO:root:Train (Epoch 133): Loss/seq after 03050 batchs: 458.89727783203125
INFO:root:Train (Epoch 133): Loss/seq after 03100 batchs: 461.89013671875
INFO:root:Train (Epoch 133): Loss/seq after 03150 batchs: 461.91094970703125
INFO:root:Train (Epoch 133): Loss/seq after 03200 batchs: 461.6861267089844
INFO:root:Train (Epoch 133): Loss/seq after 03250 batchs: 462.19769287109375
INFO:root:Train (Epoch 133): Loss/seq after 03300 batchs: 462.5815734863281
INFO:root:Train (Epoch 133): Loss/seq after 03350 batchs: 461.2305603027344
INFO:root:Train (Epoch 133): Loss/seq after 03400 batchs: 457.58306884765625
INFO:root:Train (Epoch 133): Loss/seq after 03450 batchs: 456.1737365722656
INFO:root:Train (Epoch 133): Loss/seq after 03500 batchs: 457.49615478515625
INFO:root:Train (Epoch 133): Loss/seq after 03550 batchs: 455.5502624511719
INFO:root:Train (Epoch 133): Loss/seq after 03600 batchs: 462.8406677246094
INFO:root:Train (Epoch 133): Loss/seq after 03650 batchs: 461.0428771972656
INFO:root:Train (Epoch 133): Loss/seq after 03700 batchs: 463.9913024902344
INFO:root:Train (Epoch 133): Loss/seq after 03750 batchs: 468.61505126953125
INFO:root:Train (Epoch 133): Loss/seq after 03800 batchs: 467.3489074707031
INFO:root:Train (Epoch 133): Loss/seq after 03850 batchs: 466.33056640625
INFO:root:Train (Epoch 133): Loss/seq after 03900 batchs: 469.2917175292969
INFO:root:Train (Epoch 133): Loss/seq after 03950 batchs: 471.7608642578125
INFO:root:Train (Epoch 133): Loss/seq after 04000 batchs: 468.65203857421875
INFO:root:Train (Epoch 133): Loss/seq after 04050 batchs: 465.6476745605469
INFO:root:Train (Epoch 133): Loss/seq after 04100 batchs: 464.60003662109375
INFO:root:Train (Epoch 133): Loss/seq after 04150 batchs: 464.9087219238281
INFO:root:Train (Epoch 133): Loss/seq after 04200 batchs: 463.7062683105469
INFO:root:Train (Epoch 133): Loss/seq after 04250 batchs: 462.478271484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 133): Loss/seq after 00000 batches: 360.6279602050781
INFO:root:# Valid (Epoch 133): Loss/seq after 00050 batches: 632.7608032226562
INFO:root:# Valid (Epoch 133): Loss/seq after 00100 batches: 655.3717651367188
INFO:root:# Valid (Epoch 133): Loss/seq after 00150 batches: 499.0766906738281
INFO:root:# Valid (Epoch 133): Loss/seq after 00200 batches: 470.0771179199219
INFO:root:Artifacts: Make stick videos for epoch 133
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_133_on_20220422_102631.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_133_index_1902_on_20220422_102631.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 134): Loss/seq after 00000 batchs: 646.0205688476562
INFO:root:Train (Epoch 134): Loss/seq after 00050 batchs: 639.2411499023438
INFO:root:Train (Epoch 134): Loss/seq after 00100 batchs: 668.1829833984375
INFO:root:Train (Epoch 134): Loss/seq after 00150 batchs: 612.5877685546875
INFO:root:Train (Epoch 134): Loss/seq after 00200 batchs: 669.3184814453125
INFO:root:Train (Epoch 134): Loss/seq after 00250 batchs: 758.3682250976562
INFO:root:Train (Epoch 134): Loss/seq after 00300 batchs: 764.50048828125
INFO:root:Train (Epoch 134): Loss/seq after 00350 batchs: 717.7943725585938
INFO:root:Train (Epoch 134): Loss/seq after 00400 batchs: 701.0905151367188
INFO:root:Train (Epoch 134): Loss/seq after 00450 batchs: 696.2459106445312
INFO:root:Train (Epoch 134): Loss/seq after 00500 batchs: 673.8087158203125
INFO:root:Train (Epoch 134): Loss/seq after 00550 batchs: 655.4677124023438
INFO:root:Train (Epoch 134): Loss/seq after 00600 batchs: 634.0750732421875
INFO:root:Train (Epoch 134): Loss/seq after 00650 batchs: 611.1952514648438
INFO:root:Train (Epoch 134): Loss/seq after 00700 batchs: 584.693603515625
INFO:root:Train (Epoch 134): Loss/seq after 00750 batchs: 576.1000366210938
INFO:root:Train (Epoch 134): Loss/seq after 00800 batchs: 582.6705322265625
INFO:root:Train (Epoch 134): Loss/seq after 00850 batchs: 563.5524291992188
INFO:root:Train (Epoch 134): Loss/seq after 00900 batchs: 549.6665649414062
INFO:root:Train (Epoch 134): Loss/seq after 00950 batchs: 544.6049194335938
INFO:root:Train (Epoch 134): Loss/seq after 01000 batchs: 534.5858154296875
INFO:root:Train (Epoch 134): Loss/seq after 01050 batchs: 523.8298950195312
INFO:root:Train (Epoch 134): Loss/seq after 01100 batchs: 515.2374877929688
INFO:root:Train (Epoch 134): Loss/seq after 01150 batchs: 501.1559753417969
INFO:root:Train (Epoch 134): Loss/seq after 01200 batchs: 506.4875183105469
INFO:root:Train (Epoch 134): Loss/seq after 01250 batchs: 505.8852844238281
INFO:root:Train (Epoch 134): Loss/seq after 01300 batchs: 494.7767028808594
INFO:root:Train (Epoch 134): Loss/seq after 01350 batchs: 484.9989318847656
INFO:root:Train (Epoch 134): Loss/seq after 01400 batchs: 486.2521057128906
INFO:root:Train (Epoch 134): Loss/seq after 01450 batchs: 489.1060485839844
INFO:root:Train (Epoch 134): Loss/seq after 01500 batchs: 497.4298095703125
INFO:root:Train (Epoch 134): Loss/seq after 01550 batchs: 499.2810974121094
INFO:root:Train (Epoch 134): Loss/seq after 01600 batchs: 495.6287536621094
INFO:root:Train (Epoch 134): Loss/seq after 01650 batchs: 494.5902404785156
INFO:root:Train (Epoch 134): Loss/seq after 01700 batchs: 498.1308898925781
INFO:root:Train (Epoch 134): Loss/seq after 01750 batchs: 496.2353820800781
INFO:root:Train (Epoch 134): Loss/seq after 01800 batchs: 494.3673400878906
INFO:root:Train (Epoch 134): Loss/seq after 01850 batchs: 491.9557800292969
INFO:root:Train (Epoch 134): Loss/seq after 01900 batchs: 492.1140441894531
INFO:root:Train (Epoch 134): Loss/seq after 01950 batchs: 490.701171875
INFO:root:Train (Epoch 134): Loss/seq after 02000 batchs: 491.0994873046875
INFO:root:Train (Epoch 134): Loss/seq after 02050 batchs: 490.87725830078125
INFO:root:Train (Epoch 134): Loss/seq after 02100 batchs: 489.1737976074219
INFO:root:Train (Epoch 134): Loss/seq after 02150 batchs: 487.8622131347656
INFO:root:Train (Epoch 134): Loss/seq after 02200 batchs: 486.1419372558594
INFO:root:Train (Epoch 134): Loss/seq after 02250 batchs: 485.0391540527344
INFO:root:Train (Epoch 134): Loss/seq after 02300 batchs: 480.72021484375
INFO:root:Train (Epoch 134): Loss/seq after 02350 batchs: 477.77960205078125
INFO:root:Train (Epoch 134): Loss/seq after 02400 batchs: 478.8885803222656
INFO:root:Train (Epoch 134): Loss/seq after 02450 batchs: 475.3426208496094
INFO:root:Train (Epoch 134): Loss/seq after 02500 batchs: 468.03204345703125
INFO:root:Train (Epoch 134): Loss/seq after 02550 batchs: 461.3669128417969
INFO:root:Train (Epoch 134): Loss/seq after 02600 batchs: 458.4453125
INFO:root:Train (Epoch 134): Loss/seq after 02650 batchs: 454.2277526855469
INFO:root:Train (Epoch 134): Loss/seq after 02700 batchs: 451.3135070800781
INFO:root:Train (Epoch 134): Loss/seq after 02750 batchs: 446.9161376953125
INFO:root:Train (Epoch 134): Loss/seq after 02800 batchs: 445.6496276855469
INFO:root:Train (Epoch 134): Loss/seq after 02850 batchs: 445.44134521484375
INFO:root:Train (Epoch 134): Loss/seq after 02900 batchs: 445.9519348144531
INFO:root:Train (Epoch 134): Loss/seq after 02950 batchs: 445.9173889160156
INFO:root:Train (Epoch 134): Loss/seq after 03000 batchs: 451.99835205078125
INFO:root:Train (Epoch 134): Loss/seq after 03050 batchs: 453.8728332519531
INFO:root:Train (Epoch 134): Loss/seq after 03100 batchs: 456.54150390625
INFO:root:Train (Epoch 134): Loss/seq after 03150 batchs: 456.3150634765625
INFO:root:Train (Epoch 134): Loss/seq after 03200 batchs: 456.321044921875
INFO:root:Train (Epoch 134): Loss/seq after 03250 batchs: 456.45611572265625
INFO:root:Train (Epoch 134): Loss/seq after 03300 batchs: 455.6689453125
INFO:root:Train (Epoch 134): Loss/seq after 03350 batchs: 454.23577880859375
INFO:root:Train (Epoch 134): Loss/seq after 03400 batchs: 450.6587829589844
INFO:root:Train (Epoch 134): Loss/seq after 03450 batchs: 449.1894226074219
INFO:root:Train (Epoch 134): Loss/seq after 03500 batchs: 450.2254638671875
INFO:root:Train (Epoch 134): Loss/seq after 03550 batchs: 448.3986511230469
INFO:root:Train (Epoch 134): Loss/seq after 03600 batchs: 455.5110168457031
INFO:root:Train (Epoch 134): Loss/seq after 03650 batchs: 453.89312744140625
INFO:root:Train (Epoch 134): Loss/seq after 03700 batchs: 456.6296081542969
INFO:root:Train (Epoch 134): Loss/seq after 03750 batchs: 461.390625
INFO:root:Train (Epoch 134): Loss/seq after 03800 batchs: 460.2053527832031
INFO:root:Train (Epoch 134): Loss/seq after 03850 batchs: 459.2360534667969
INFO:root:Train (Epoch 134): Loss/seq after 03900 batchs: 461.7268981933594
INFO:root:Train (Epoch 134): Loss/seq after 03950 batchs: 463.9579162597656
INFO:root:Train (Epoch 134): Loss/seq after 04000 batchs: 461.0776672363281
INFO:root:Train (Epoch 134): Loss/seq after 04050 batchs: 458.1013488769531
INFO:root:Train (Epoch 134): Loss/seq after 04100 batchs: 457.19647216796875
INFO:root:Train (Epoch 134): Loss/seq after 04150 batchs: 457.6698913574219
INFO:root:Train (Epoch 134): Loss/seq after 04200 batchs: 456.5472106933594
INFO:root:Train (Epoch 134): Loss/seq after 04250 batchs: 455.1994323730469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 134): Loss/seq after 00000 batches: 390.5029602050781
INFO:root:# Valid (Epoch 134): Loss/seq after 00050 batches: 602.4693603515625
INFO:root:# Valid (Epoch 134): Loss/seq after 00100 batches: 657.5439453125
INFO:root:# Valid (Epoch 134): Loss/seq after 00150 batches: 498.04644775390625
INFO:root:# Valid (Epoch 134): Loss/seq after 00200 batches: 470.56683349609375
INFO:root:Artifacts: Make stick videos for epoch 134
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_134_on_20220422_103116.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_134_index_483_on_20220422_103116.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 135): Loss/seq after 00000 batchs: 699.187744140625
INFO:root:Train (Epoch 135): Loss/seq after 00050 batchs: 659.1688842773438
INFO:root:Train (Epoch 135): Loss/seq after 00100 batchs: 672.9688110351562
INFO:root:Train (Epoch 135): Loss/seq after 00150 batchs: 637.8661499023438
INFO:root:Train (Epoch 135): Loss/seq after 00200 batchs: 689.2711181640625
INFO:root:Train (Epoch 135): Loss/seq after 00250 batchs: 761.5747680664062
INFO:root:Train (Epoch 135): Loss/seq after 00300 batchs: 763.98876953125
INFO:root:Train (Epoch 135): Loss/seq after 00350 batchs: 717.00830078125
INFO:root:Train (Epoch 135): Loss/seq after 00400 batchs: 694.8367309570312
INFO:root:Train (Epoch 135): Loss/seq after 00450 batchs: 690.5572509765625
INFO:root:Train (Epoch 135): Loss/seq after 00500 batchs: 668.252197265625
INFO:root:Train (Epoch 135): Loss/seq after 00550 batchs: 651.2944946289062
INFO:root:Train (Epoch 135): Loss/seq after 00600 batchs: 629.222900390625
INFO:root:Train (Epoch 135): Loss/seq after 00650 batchs: 604.1392822265625
INFO:root:Train (Epoch 135): Loss/seq after 00700 batchs: 577.01904296875
INFO:root:Train (Epoch 135): Loss/seq after 00750 batchs: 570.9649047851562
INFO:root:Train (Epoch 135): Loss/seq after 00800 batchs: 575.9675903320312
INFO:root:Train (Epoch 135): Loss/seq after 00850 batchs: 557.5614013671875
INFO:root:Train (Epoch 135): Loss/seq after 00900 batchs: 546.155517578125
INFO:root:Train (Epoch 135): Loss/seq after 00950 batchs: 541.3681640625
INFO:root:Train (Epoch 135): Loss/seq after 01000 batchs: 531.642333984375
INFO:root:Train (Epoch 135): Loss/seq after 01050 batchs: 521.1220703125
INFO:root:Train (Epoch 135): Loss/seq after 01100 batchs: 512.9301147460938
INFO:root:Train (Epoch 135): Loss/seq after 01150 batchs: 498.78472900390625
INFO:root:Train (Epoch 135): Loss/seq after 01200 batchs: 504.401123046875
INFO:root:Train (Epoch 135): Loss/seq after 01250 batchs: 503.754150390625
INFO:root:Train (Epoch 135): Loss/seq after 01300 batchs: 492.7040710449219
INFO:root:Train (Epoch 135): Loss/seq after 01350 batchs: 483.11419677734375
INFO:root:Train (Epoch 135): Loss/seq after 01400 batchs: 485.0697326660156
INFO:root:Train (Epoch 135): Loss/seq after 01450 batchs: 488.19317626953125
INFO:root:Train (Epoch 135): Loss/seq after 01500 batchs: 496.56396484375
INFO:root:Train (Epoch 135): Loss/seq after 01550 batchs: 498.2327880859375
INFO:root:Train (Epoch 135): Loss/seq after 01600 batchs: 494.75872802734375
INFO:root:Train (Epoch 135): Loss/seq after 01650 batchs: 493.4111633300781
INFO:root:Train (Epoch 135): Loss/seq after 01700 batchs: 497.08990478515625
INFO:root:Train (Epoch 135): Loss/seq after 01750 batchs: 495.1030578613281
INFO:root:Train (Epoch 135): Loss/seq after 01800 batchs: 493.02606201171875
INFO:root:Train (Epoch 135): Loss/seq after 01850 batchs: 490.6478271484375
INFO:root:Train (Epoch 135): Loss/seq after 01900 batchs: 490.6710205078125
INFO:root:Train (Epoch 135): Loss/seq after 01950 batchs: 489.30328369140625
INFO:root:Train (Epoch 135): Loss/seq after 02000 batchs: 489.52178955078125
INFO:root:Train (Epoch 135): Loss/seq after 02050 batchs: 489.1768493652344
INFO:root:Train (Epoch 135): Loss/seq after 02100 batchs: 487.72509765625
INFO:root:Train (Epoch 135): Loss/seq after 02150 batchs: 486.43609619140625
INFO:root:Train (Epoch 135): Loss/seq after 02200 batchs: 484.62835693359375
INFO:root:Train (Epoch 135): Loss/seq after 02250 batchs: 483.7645568847656
INFO:root:Train (Epoch 135): Loss/seq after 02300 batchs: 479.68914794921875
INFO:root:Train (Epoch 135): Loss/seq after 02350 batchs: 476.2419128417969
INFO:root:Train (Epoch 135): Loss/seq after 02400 batchs: 476.84783935546875
INFO:root:Train (Epoch 135): Loss/seq after 02450 batchs: 473.25927734375
INFO:root:Train (Epoch 135): Loss/seq after 02500 batchs: 465.9766540527344
INFO:root:Train (Epoch 135): Loss/seq after 02550 batchs: 459.2574768066406
INFO:root:Train (Epoch 135): Loss/seq after 02600 batchs: 456.5702209472656
INFO:root:Train (Epoch 135): Loss/seq after 02650 batchs: 452.5869445800781
INFO:root:Train (Epoch 135): Loss/seq after 02700 batchs: 449.84637451171875
INFO:root:Train (Epoch 135): Loss/seq after 02750 batchs: 445.2121276855469
INFO:root:Train (Epoch 135): Loss/seq after 02800 batchs: 443.0901794433594
INFO:root:Train (Epoch 135): Loss/seq after 02850 batchs: 442.95269775390625
INFO:root:Train (Epoch 135): Loss/seq after 02900 batchs: 443.5649719238281
INFO:root:Train (Epoch 135): Loss/seq after 02950 batchs: 443.6221618652344
INFO:root:Train (Epoch 135): Loss/seq after 03000 batchs: 449.8222351074219
INFO:root:Train (Epoch 135): Loss/seq after 03050 batchs: 452.0322570800781
INFO:root:Train (Epoch 135): Loss/seq after 03100 batchs: 454.6971740722656
INFO:root:Train (Epoch 135): Loss/seq after 03150 batchs: 454.2121276855469
INFO:root:Train (Epoch 135): Loss/seq after 03200 batchs: 454.08953857421875
INFO:root:Train (Epoch 135): Loss/seq after 03250 batchs: 454.64361572265625
INFO:root:Train (Epoch 135): Loss/seq after 03300 batchs: 453.7414855957031
INFO:root:Train (Epoch 135): Loss/seq after 03350 batchs: 452.29034423828125
INFO:root:Train (Epoch 135): Loss/seq after 03400 batchs: 448.7006530761719
INFO:root:Train (Epoch 135): Loss/seq after 03450 batchs: 447.22332763671875
INFO:root:Train (Epoch 135): Loss/seq after 03500 batchs: 448.38043212890625
INFO:root:Train (Epoch 135): Loss/seq after 03550 batchs: 446.5138854980469
INFO:root:Train (Epoch 135): Loss/seq after 03600 batchs: 453.67803955078125
INFO:root:Train (Epoch 135): Loss/seq after 03650 batchs: 452.341064453125
INFO:root:Train (Epoch 135): Loss/seq after 03700 batchs: 455.4175109863281
INFO:root:Train (Epoch 135): Loss/seq after 03750 batchs: 460.2958679199219
INFO:root:Train (Epoch 135): Loss/seq after 03800 batchs: 459.0815734863281
INFO:root:Train (Epoch 135): Loss/seq after 03850 batchs: 458.1502990722656
INFO:root:Train (Epoch 135): Loss/seq after 03900 batchs: 460.7972412109375
INFO:root:Train (Epoch 135): Loss/seq after 03950 batchs: 463.11676025390625
INFO:root:Train (Epoch 135): Loss/seq after 04000 batchs: 460.1800231933594
INFO:root:Train (Epoch 135): Loss/seq after 04050 batchs: 457.2535095214844
INFO:root:Train (Epoch 135): Loss/seq after 04100 batchs: 456.2776794433594
INFO:root:Train (Epoch 135): Loss/seq after 04150 batchs: 456.65350341796875
INFO:root:Train (Epoch 135): Loss/seq after 04200 batchs: 455.40362548828125
INFO:root:Train (Epoch 135): Loss/seq after 04250 batchs: 454.0589599609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 135): Loss/seq after 00000 batches: 409.7063903808594
INFO:root:# Valid (Epoch 135): Loss/seq after 00050 batches: 640.5712280273438
INFO:root:# Valid (Epoch 135): Loss/seq after 00100 batches: 674.3062744140625
INFO:root:# Valid (Epoch 135): Loss/seq after 00150 batches: 509.548583984375
INFO:root:# Valid (Epoch 135): Loss/seq after 00200 batches: 476.9320068359375
INFO:root:Artifacts: Make stick videos for epoch 135
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_135_on_20220422_103609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_135_index_1098_on_20220422_103609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 136): Loss/seq after 00000 batchs: 786.997314453125
INFO:root:Train (Epoch 136): Loss/seq after 00050 batchs: 632.9104614257812
INFO:root:Train (Epoch 136): Loss/seq after 00100 batchs: 646.3734741210938
INFO:root:Train (Epoch 136): Loss/seq after 00150 batchs: 598.0864868164062
INFO:root:Train (Epoch 136): Loss/seq after 00200 batchs: 657.8438110351562
INFO:root:Train (Epoch 136): Loss/seq after 00250 batchs: 746.4393310546875
INFO:root:Train (Epoch 136): Loss/seq after 00300 batchs: 751.46337890625
INFO:root:Train (Epoch 136): Loss/seq after 00350 batchs: 705.8681640625
INFO:root:Train (Epoch 136): Loss/seq after 00400 batchs: 689.4681396484375
INFO:root:Train (Epoch 136): Loss/seq after 00450 batchs: 685.9725952148438
INFO:root:Train (Epoch 136): Loss/seq after 00500 batchs: 665.7091064453125
INFO:root:Train (Epoch 136): Loss/seq after 00550 batchs: 648.7648315429688
INFO:root:Train (Epoch 136): Loss/seq after 00600 batchs: 628.2544555664062
INFO:root:Train (Epoch 136): Loss/seq after 00650 batchs: 603.0341796875
INFO:root:Train (Epoch 136): Loss/seq after 00700 batchs: 577.2025756835938
INFO:root:Train (Epoch 136): Loss/seq after 00750 batchs: 568.2637329101562
INFO:root:Train (Epoch 136): Loss/seq after 00800 batchs: 573.5538330078125
INFO:root:Train (Epoch 136): Loss/seq after 00850 batchs: 555.4825439453125
INFO:root:Train (Epoch 136): Loss/seq after 00900 batchs: 542.9569702148438
INFO:root:Train (Epoch 136): Loss/seq after 00950 batchs: 538.8665161132812
INFO:root:Train (Epoch 136): Loss/seq after 01000 batchs: 528.6498413085938
INFO:root:Train (Epoch 136): Loss/seq after 01050 batchs: 521.19287109375
INFO:root:Train (Epoch 136): Loss/seq after 01100 batchs: 512.4721069335938
INFO:root:Train (Epoch 136): Loss/seq after 01150 batchs: 498.21954345703125
INFO:root:Train (Epoch 136): Loss/seq after 01200 batchs: 503.70867919921875
INFO:root:Train (Epoch 136): Loss/seq after 01250 batchs: 503.3343200683594
INFO:root:Train (Epoch 136): Loss/seq after 01300 batchs: 491.9267272949219
INFO:root:Train (Epoch 136): Loss/seq after 01350 batchs: 481.902099609375
INFO:root:Train (Epoch 136): Loss/seq after 01400 batchs: 482.80023193359375
INFO:root:Train (Epoch 136): Loss/seq after 01450 batchs: 485.9300842285156
INFO:root:Train (Epoch 136): Loss/seq after 01500 batchs: 494.3082275390625
INFO:root:Train (Epoch 136): Loss/seq after 01550 batchs: 495.9273681640625
INFO:root:Train (Epoch 136): Loss/seq after 01600 batchs: 492.8900451660156
INFO:root:Train (Epoch 136): Loss/seq after 01650 batchs: 491.3086242675781
INFO:root:Train (Epoch 136): Loss/seq after 01700 batchs: 495.07037353515625
INFO:root:Train (Epoch 136): Loss/seq after 01750 batchs: 492.8717041015625
INFO:root:Train (Epoch 136): Loss/seq after 01800 batchs: 491.01373291015625
INFO:root:Train (Epoch 136): Loss/seq after 01850 batchs: 488.50445556640625
INFO:root:Train (Epoch 136): Loss/seq after 01900 batchs: 487.9149169921875
INFO:root:Train (Epoch 136): Loss/seq after 01950 batchs: 486.77239990234375
INFO:root:Train (Epoch 136): Loss/seq after 02000 batchs: 487.1122131347656
INFO:root:Train (Epoch 136): Loss/seq after 02050 batchs: 487.01593017578125
INFO:root:Train (Epoch 136): Loss/seq after 02100 batchs: 485.9732666015625
INFO:root:Train (Epoch 136): Loss/seq after 02150 batchs: 484.76519775390625
INFO:root:Train (Epoch 136): Loss/seq after 02200 batchs: 482.9898986816406
INFO:root:Train (Epoch 136): Loss/seq after 02250 batchs: 482.3243713378906
INFO:root:Train (Epoch 136): Loss/seq after 02300 batchs: 478.2546691894531
INFO:root:Train (Epoch 136): Loss/seq after 02350 batchs: 475.06842041015625
INFO:root:Train (Epoch 136): Loss/seq after 02400 batchs: 475.8387145996094
INFO:root:Train (Epoch 136): Loss/seq after 02450 batchs: 472.1407165527344
INFO:root:Train (Epoch 136): Loss/seq after 02500 batchs: 464.8784484863281
INFO:root:Train (Epoch 136): Loss/seq after 02550 batchs: 458.2017822265625
INFO:root:Train (Epoch 136): Loss/seq after 02600 batchs: 455.1459045410156
INFO:root:Train (Epoch 136): Loss/seq after 02650 batchs: 450.9580383300781
INFO:root:Train (Epoch 136): Loss/seq after 02700 batchs: 448.3927001953125
INFO:root:Train (Epoch 136): Loss/seq after 02750 batchs: 444.1896667480469
INFO:root:Train (Epoch 136): Loss/seq after 02800 batchs: 442.8875427246094
INFO:root:Train (Epoch 136): Loss/seq after 02850 batchs: 442.9911193847656
INFO:root:Train (Epoch 136): Loss/seq after 02900 batchs: 443.8377990722656
INFO:root:Train (Epoch 136): Loss/seq after 02950 batchs: 443.8378601074219
INFO:root:Train (Epoch 136): Loss/seq after 03000 batchs: 449.99810791015625
INFO:root:Train (Epoch 136): Loss/seq after 03050 batchs: 452.015380859375
INFO:root:Train (Epoch 136): Loss/seq after 03100 batchs: 454.5752868652344
INFO:root:Train (Epoch 136): Loss/seq after 03150 batchs: 455.1523132324219
INFO:root:Train (Epoch 136): Loss/seq after 03200 batchs: 455.2796936035156
INFO:root:Train (Epoch 136): Loss/seq after 03250 batchs: 455.462646484375
INFO:root:Train (Epoch 136): Loss/seq after 03300 batchs: 454.9428405761719
INFO:root:Train (Epoch 136): Loss/seq after 03350 batchs: 453.38079833984375
INFO:root:Train (Epoch 136): Loss/seq after 03400 batchs: 449.8903503417969
INFO:root:Train (Epoch 136): Loss/seq after 03450 batchs: 448.73345947265625
INFO:root:Train (Epoch 136): Loss/seq after 03500 batchs: 450.7025146484375
INFO:root:Train (Epoch 136): Loss/seq after 03550 batchs: 449.3077392578125
INFO:root:Train (Epoch 136): Loss/seq after 03600 batchs: 456.7056884765625
INFO:root:Train (Epoch 136): Loss/seq after 03650 batchs: 455.28375244140625
INFO:root:Train (Epoch 136): Loss/seq after 03700 batchs: 458.4641418457031
INFO:root:Train (Epoch 136): Loss/seq after 03750 batchs: 462.99749755859375
INFO:root:Train (Epoch 136): Loss/seq after 03800 batchs: 461.7422180175781
INFO:root:Train (Epoch 136): Loss/seq after 03850 batchs: 460.8178405761719
INFO:root:Train (Epoch 136): Loss/seq after 03900 batchs: 463.23370361328125
INFO:root:Train (Epoch 136): Loss/seq after 03950 batchs: 465.56298828125
INFO:root:Train (Epoch 136): Loss/seq after 04000 batchs: 462.61126708984375
INFO:root:Train (Epoch 136): Loss/seq after 04050 batchs: 459.6183776855469
INFO:root:Train (Epoch 136): Loss/seq after 04100 batchs: 458.6083068847656
INFO:root:Train (Epoch 136): Loss/seq after 04150 batchs: 458.992431640625
INFO:root:Train (Epoch 136): Loss/seq after 04200 batchs: 457.8148498535156
INFO:root:Train (Epoch 136): Loss/seq after 04250 batchs: 456.45758056640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 136): Loss/seq after 00000 batches: 391.9896545410156
INFO:root:# Valid (Epoch 136): Loss/seq after 00050 batches: 621.701904296875
INFO:root:# Valid (Epoch 136): Loss/seq after 00100 batches: 655.3574829101562
INFO:root:# Valid (Epoch 136): Loss/seq after 00150 batches: 493.8618469238281
INFO:root:# Valid (Epoch 136): Loss/seq after 00200 batches: 465.6739501953125
INFO:root:Artifacts: Make stick videos for epoch 136
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_136_on_20220422_104118.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_136_index_325_on_20220422_104118.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 137): Loss/seq after 00000 batchs: 643.7470703125
INFO:root:Train (Epoch 137): Loss/seq after 00050 batchs: 647.0770263671875
INFO:root:Train (Epoch 137): Loss/seq after 00100 batchs: 650.6158447265625
INFO:root:Train (Epoch 137): Loss/seq after 00150 batchs: 599.8159790039062
INFO:root:Train (Epoch 137): Loss/seq after 00200 batchs: 650.5171508789062
INFO:root:Train (Epoch 137): Loss/seq after 00250 batchs: 728.1529541015625
INFO:root:Train (Epoch 137): Loss/seq after 00300 batchs: 734.0440673828125
INFO:root:Train (Epoch 137): Loss/seq after 00350 batchs: 690.8627319335938
INFO:root:Train (Epoch 137): Loss/seq after 00400 batchs: 679.4649047851562
INFO:root:Train (Epoch 137): Loss/seq after 00450 batchs: 676.6006469726562
INFO:root:Train (Epoch 137): Loss/seq after 00500 batchs: 652.4182739257812
INFO:root:Train (Epoch 137): Loss/seq after 00550 batchs: 636.3233032226562
INFO:root:Train (Epoch 137): Loss/seq after 00600 batchs: 614.7459106445312
INFO:root:Train (Epoch 137): Loss/seq after 00650 batchs: 590.4380493164062
INFO:root:Train (Epoch 137): Loss/seq after 00700 batchs: 564.3834228515625
INFO:root:Train (Epoch 137): Loss/seq after 00750 batchs: 559.0303344726562
INFO:root:Train (Epoch 137): Loss/seq after 00800 batchs: 564.585205078125
INFO:root:Train (Epoch 137): Loss/seq after 00850 batchs: 546.4789428710938
INFO:root:Train (Epoch 137): Loss/seq after 00900 batchs: 533.5775756835938
INFO:root:Train (Epoch 137): Loss/seq after 00950 batchs: 529.9415283203125
INFO:root:Train (Epoch 137): Loss/seq after 01000 batchs: 519.7865600585938
INFO:root:Train (Epoch 137): Loss/seq after 01050 batchs: 508.8149719238281
INFO:root:Train (Epoch 137): Loss/seq after 01100 batchs: 499.54888916015625
INFO:root:Train (Epoch 137): Loss/seq after 01150 batchs: 485.60699462890625
INFO:root:Train (Epoch 137): Loss/seq after 01200 batchs: 490.7939147949219
INFO:root:Train (Epoch 137): Loss/seq after 01250 batchs: 490.21917724609375
INFO:root:Train (Epoch 137): Loss/seq after 01300 batchs: 479.360595703125
INFO:root:Train (Epoch 137): Loss/seq after 01350 batchs: 469.8269958496094
INFO:root:Train (Epoch 137): Loss/seq after 01400 batchs: 471.1172180175781
INFO:root:Train (Epoch 137): Loss/seq after 01450 batchs: 474.3840026855469
INFO:root:Train (Epoch 137): Loss/seq after 01500 batchs: 482.8643493652344
INFO:root:Train (Epoch 137): Loss/seq after 01550 batchs: 484.27520751953125
INFO:root:Train (Epoch 137): Loss/seq after 01600 batchs: 480.6855773925781
INFO:root:Train (Epoch 137): Loss/seq after 01650 batchs: 479.8581237792969
INFO:root:Train (Epoch 137): Loss/seq after 01700 batchs: 483.7928161621094
INFO:root:Train (Epoch 137): Loss/seq after 01750 batchs: 481.97857666015625
INFO:root:Train (Epoch 137): Loss/seq after 01800 batchs: 480.4824523925781
INFO:root:Train (Epoch 137): Loss/seq after 01850 batchs: 478.17120361328125
INFO:root:Train (Epoch 137): Loss/seq after 01900 batchs: 477.7040710449219
INFO:root:Train (Epoch 137): Loss/seq after 01950 batchs: 476.5308532714844
INFO:root:Train (Epoch 137): Loss/seq after 02000 batchs: 476.9656982421875
INFO:root:Train (Epoch 137): Loss/seq after 02050 batchs: 476.9165344238281
INFO:root:Train (Epoch 137): Loss/seq after 02100 batchs: 475.3491516113281
INFO:root:Train (Epoch 137): Loss/seq after 02150 batchs: 474.2851257324219
INFO:root:Train (Epoch 137): Loss/seq after 02200 batchs: 473.00238037109375
INFO:root:Train (Epoch 137): Loss/seq after 02250 batchs: 472.5301208496094
INFO:root:Train (Epoch 137): Loss/seq after 02300 batchs: 468.3357238769531
INFO:root:Train (Epoch 137): Loss/seq after 02350 batchs: 465.09271240234375
INFO:root:Train (Epoch 137): Loss/seq after 02400 batchs: 465.9201354980469
INFO:root:Train (Epoch 137): Loss/seq after 02450 batchs: 462.5586853027344
INFO:root:Train (Epoch 137): Loss/seq after 02500 batchs: 455.4803161621094
INFO:root:Train (Epoch 137): Loss/seq after 02550 batchs: 448.9783935546875
INFO:root:Train (Epoch 137): Loss/seq after 02600 batchs: 445.6997375488281
INFO:root:Train (Epoch 137): Loss/seq after 02650 batchs: 441.6812438964844
INFO:root:Train (Epoch 137): Loss/seq after 02700 batchs: 438.83294677734375
INFO:root:Train (Epoch 137): Loss/seq after 02750 batchs: 434.0042419433594
INFO:root:Train (Epoch 137): Loss/seq after 02800 batchs: 432.8161926269531
INFO:root:Train (Epoch 137): Loss/seq after 02850 batchs: 432.87646484375
INFO:root:Train (Epoch 137): Loss/seq after 02900 batchs: 433.9337463378906
INFO:root:Train (Epoch 137): Loss/seq after 02950 batchs: 434.10711669921875
INFO:root:Train (Epoch 137): Loss/seq after 03000 batchs: 440.45819091796875
INFO:root:Train (Epoch 137): Loss/seq after 03050 batchs: 442.49853515625
INFO:root:Train (Epoch 137): Loss/seq after 03100 batchs: 445.0531005859375
INFO:root:Train (Epoch 137): Loss/seq after 03150 batchs: 445.0575256347656
INFO:root:Train (Epoch 137): Loss/seq after 03200 batchs: 444.78851318359375
INFO:root:Train (Epoch 137): Loss/seq after 03250 batchs: 445.193115234375
INFO:root:Train (Epoch 137): Loss/seq after 03300 batchs: 444.3963317871094
INFO:root:Train (Epoch 137): Loss/seq after 03350 batchs: 442.6015625
INFO:root:Train (Epoch 137): Loss/seq after 03400 batchs: 439.178955078125
INFO:root:Train (Epoch 137): Loss/seq after 03450 batchs: 437.7518310546875
INFO:root:Train (Epoch 137): Loss/seq after 03500 batchs: 438.7073059082031
INFO:root:Train (Epoch 137): Loss/seq after 03550 batchs: 436.7747497558594
INFO:root:Train (Epoch 137): Loss/seq after 03600 batchs: 443.8941345214844
INFO:root:Train (Epoch 137): Loss/seq after 03650 batchs: 442.6159362792969
INFO:root:Train (Epoch 137): Loss/seq after 03700 batchs: 445.82476806640625
INFO:root:Train (Epoch 137): Loss/seq after 03750 batchs: 450.62969970703125
INFO:root:Train (Epoch 137): Loss/seq after 03800 batchs: 449.6061096191406
INFO:root:Train (Epoch 137): Loss/seq after 03850 batchs: 448.8410339355469
INFO:root:Train (Epoch 137): Loss/seq after 03900 batchs: 451.42303466796875
INFO:root:Train (Epoch 137): Loss/seq after 03950 batchs: 453.8185729980469
INFO:root:Train (Epoch 137): Loss/seq after 04000 batchs: 450.96197509765625
INFO:root:Train (Epoch 137): Loss/seq after 04050 batchs: 448.0753479003906
INFO:root:Train (Epoch 137): Loss/seq after 04100 batchs: 447.19122314453125
INFO:root:Train (Epoch 137): Loss/seq after 04150 batchs: 447.5731201171875
INFO:root:Train (Epoch 137): Loss/seq after 04200 batchs: 446.4656982421875
INFO:root:Train (Epoch 137): Loss/seq after 04250 batchs: 445.1521301269531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 137): Loss/seq after 00000 batches: 393.3312072753906
INFO:root:# Valid (Epoch 137): Loss/seq after 00050 batches: 601.0062866210938
INFO:root:# Valid (Epoch 137): Loss/seq after 00100 batches: 631.6909790039062
INFO:root:# Valid (Epoch 137): Loss/seq after 00150 batches: 478.10894775390625
INFO:root:# Valid (Epoch 137): Loss/seq after 00200 batches: 452.9004821777344
INFO:root:Artifacts: Make stick videos for epoch 137
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_137_on_20220422_104608.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_137_index_57_on_20220422_104608.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 138): Loss/seq after 00000 batchs: 681.6613159179688
INFO:root:Train (Epoch 138): Loss/seq after 00050 batchs: 621.6279296875
INFO:root:Train (Epoch 138): Loss/seq after 00100 batchs: 647.7665405273438
INFO:root:Train (Epoch 138): Loss/seq after 00150 batchs: 602.2752075195312
INFO:root:Train (Epoch 138): Loss/seq after 00200 batchs: 657.4804077148438
INFO:root:Train (Epoch 138): Loss/seq after 00250 batchs: 739.0768432617188
INFO:root:Train (Epoch 138): Loss/seq after 00300 batchs: 746.545166015625
INFO:root:Train (Epoch 138): Loss/seq after 00350 batchs: 702.4610595703125
INFO:root:Train (Epoch 138): Loss/seq after 00400 batchs: 683.0992431640625
INFO:root:Train (Epoch 138): Loss/seq after 00450 batchs: 680.310791015625
INFO:root:Train (Epoch 138): Loss/seq after 00500 batchs: 653.7178955078125
INFO:root:Train (Epoch 138): Loss/seq after 00550 batchs: 637.3256225585938
INFO:root:Train (Epoch 138): Loss/seq after 00600 batchs: 616.1239013671875
INFO:root:Train (Epoch 138): Loss/seq after 00650 batchs: 591.5709838867188
INFO:root:Train (Epoch 138): Loss/seq after 00700 batchs: 567.9057006835938
INFO:root:Train (Epoch 138): Loss/seq after 00750 batchs: 559.8118896484375
INFO:root:Train (Epoch 138): Loss/seq after 00800 batchs: 564.9957885742188
INFO:root:Train (Epoch 138): Loss/seq after 00850 batchs: 546.418701171875
INFO:root:Train (Epoch 138): Loss/seq after 00900 batchs: 534.20751953125
INFO:root:Train (Epoch 138): Loss/seq after 00950 batchs: 530.3243408203125
INFO:root:Train (Epoch 138): Loss/seq after 01000 batchs: 519.8837280273438
INFO:root:Train (Epoch 138): Loss/seq after 01050 batchs: 509.24993896484375
INFO:root:Train (Epoch 138): Loss/seq after 01100 batchs: 500.0590515136719
INFO:root:Train (Epoch 138): Loss/seq after 01150 batchs: 486.0834655761719
INFO:root:Train (Epoch 138): Loss/seq after 01200 batchs: 491.78662109375
INFO:root:Train (Epoch 138): Loss/seq after 01250 batchs: 491.26123046875
INFO:root:Train (Epoch 138): Loss/seq after 01300 batchs: 480.1081237792969
INFO:root:Train (Epoch 138): Loss/seq after 01350 batchs: 470.5749206542969
INFO:root:Train (Epoch 138): Loss/seq after 01400 batchs: 471.1589050292969
INFO:root:Train (Epoch 138): Loss/seq after 01450 batchs: 473.8954162597656
INFO:root:Train (Epoch 138): Loss/seq after 01500 batchs: 482.4396667480469
INFO:root:Train (Epoch 138): Loss/seq after 01550 batchs: 484.13287353515625
INFO:root:Train (Epoch 138): Loss/seq after 01600 batchs: 480.80419921875
INFO:root:Train (Epoch 138): Loss/seq after 01650 batchs: 479.86077880859375
INFO:root:Train (Epoch 138): Loss/seq after 01700 batchs: 484.02239990234375
INFO:root:Train (Epoch 138): Loss/seq after 01750 batchs: 482.17828369140625
INFO:root:Train (Epoch 138): Loss/seq after 01800 batchs: 480.3293762207031
INFO:root:Train (Epoch 138): Loss/seq after 01850 batchs: 478.06793212890625
INFO:root:Train (Epoch 138): Loss/seq after 01900 batchs: 477.78509521484375
INFO:root:Train (Epoch 138): Loss/seq after 01950 batchs: 476.289794921875
INFO:root:Train (Epoch 138): Loss/seq after 02000 batchs: 477.0987548828125
INFO:root:Train (Epoch 138): Loss/seq after 02050 batchs: 476.9501647949219
INFO:root:Train (Epoch 138): Loss/seq after 02100 batchs: 475.5090637207031
INFO:root:Train (Epoch 138): Loss/seq after 02150 batchs: 474.3497314453125
INFO:root:Train (Epoch 138): Loss/seq after 02200 batchs: 472.8623962402344
INFO:root:Train (Epoch 138): Loss/seq after 02250 batchs: 471.64971923828125
INFO:root:Train (Epoch 138): Loss/seq after 02300 batchs: 467.28802490234375
INFO:root:Train (Epoch 138): Loss/seq after 02350 batchs: 464.3117370605469
INFO:root:Train (Epoch 138): Loss/seq after 02400 batchs: 465.0316162109375
INFO:root:Train (Epoch 138): Loss/seq after 02450 batchs: 461.57598876953125
INFO:root:Train (Epoch 138): Loss/seq after 02500 batchs: 454.47186279296875
INFO:root:Train (Epoch 138): Loss/seq after 02550 batchs: 448.0249328613281
INFO:root:Train (Epoch 138): Loss/seq after 02600 batchs: 444.6110534667969
INFO:root:Train (Epoch 138): Loss/seq after 02650 batchs: 440.53765869140625
INFO:root:Train (Epoch 138): Loss/seq after 02700 batchs: 437.7117919921875
INFO:root:Train (Epoch 138): Loss/seq after 02750 batchs: 433.1162414550781
INFO:root:Train (Epoch 138): Loss/seq after 02800 batchs: 431.2087707519531
INFO:root:Train (Epoch 138): Loss/seq after 02850 batchs: 431.0754699707031
INFO:root:Train (Epoch 138): Loss/seq after 02900 batchs: 431.6181640625
INFO:root:Train (Epoch 138): Loss/seq after 02950 batchs: 431.72979736328125
INFO:root:Train (Epoch 138): Loss/seq after 03000 batchs: 437.98443603515625
INFO:root:Train (Epoch 138): Loss/seq after 03050 batchs: 440.0032958984375
INFO:root:Train (Epoch 138): Loss/seq after 03100 batchs: 442.6068420410156
INFO:root:Train (Epoch 138): Loss/seq after 03150 batchs: 442.9572448730469
INFO:root:Train (Epoch 138): Loss/seq after 03200 batchs: 442.9488220214844
INFO:root:Train (Epoch 138): Loss/seq after 03250 batchs: 443.3273620605469
INFO:root:Train (Epoch 138): Loss/seq after 03300 batchs: 442.7125549316406
INFO:root:Train (Epoch 138): Loss/seq after 03350 batchs: 441.3255310058594
INFO:root:Train (Epoch 138): Loss/seq after 03400 batchs: 437.9244384765625
INFO:root:Train (Epoch 138): Loss/seq after 03450 batchs: 436.6066589355469
INFO:root:Train (Epoch 138): Loss/seq after 03500 batchs: 437.6054382324219
INFO:root:Train (Epoch 138): Loss/seq after 03550 batchs: 435.6813659667969
INFO:root:Train (Epoch 138): Loss/seq after 03600 batchs: 442.683837890625
INFO:root:Train (Epoch 138): Loss/seq after 03650 batchs: 441.25067138671875
INFO:root:Train (Epoch 138): Loss/seq after 03700 batchs: 444.2080078125
INFO:root:Train (Epoch 138): Loss/seq after 03750 batchs: 448.93902587890625
INFO:root:Train (Epoch 138): Loss/seq after 03800 batchs: 447.8798828125
INFO:root:Train (Epoch 138): Loss/seq after 03850 batchs: 447.08343505859375
INFO:root:Train (Epoch 138): Loss/seq after 03900 batchs: 449.5769958496094
INFO:root:Train (Epoch 138): Loss/seq after 03950 batchs: 452.2841796875
INFO:root:Train (Epoch 138): Loss/seq after 04000 batchs: 449.41583251953125
INFO:root:Train (Epoch 138): Loss/seq after 04050 batchs: 446.6040954589844
INFO:root:Train (Epoch 138): Loss/seq after 04100 batchs: 445.7192687988281
INFO:root:Train (Epoch 138): Loss/seq after 04150 batchs: 446.04638671875
INFO:root:Train (Epoch 138): Loss/seq after 04200 batchs: 444.8317565917969
INFO:root:Train (Epoch 138): Loss/seq after 04250 batchs: 443.5123596191406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 138): Loss/seq after 00000 batches: 300.4464416503906
INFO:root:# Valid (Epoch 138): Loss/seq after 00050 batches: 614.0631713867188
INFO:root:# Valid (Epoch 138): Loss/seq after 00100 batches: 650.4175415039062
INFO:root:# Valid (Epoch 138): Loss/seq after 00150 batches: 491.0201721191406
INFO:root:# Valid (Epoch 138): Loss/seq after 00200 batches: 459.4255065917969
INFO:root:Artifacts: Make stick videos for epoch 138
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_138_on_20220422_105052.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_138_index_1423_on_20220422_105052.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 139): Loss/seq after 00000 batchs: 676.2032470703125
INFO:root:Train (Epoch 139): Loss/seq after 00050 batchs: 629.927001953125
INFO:root:Train (Epoch 139): Loss/seq after 00100 batchs: 660.4204711914062
INFO:root:Train (Epoch 139): Loss/seq after 00150 batchs: 608.0880737304688
INFO:root:Train (Epoch 139): Loss/seq after 00200 batchs: 660.6288452148438
INFO:root:Train (Epoch 139): Loss/seq after 00250 batchs: 736.904052734375
INFO:root:Train (Epoch 139): Loss/seq after 00300 batchs: 741.718994140625
INFO:root:Train (Epoch 139): Loss/seq after 00350 batchs: 697.5636596679688
INFO:root:Train (Epoch 139): Loss/seq after 00400 batchs: 680.8396606445312
INFO:root:Train (Epoch 139): Loss/seq after 00450 batchs: 678.2855834960938
INFO:root:Train (Epoch 139): Loss/seq after 00500 batchs: 655.8773803710938
INFO:root:Train (Epoch 139): Loss/seq after 00550 batchs: 639.3519897460938
INFO:root:Train (Epoch 139): Loss/seq after 00600 batchs: 617.6704711914062
INFO:root:Train (Epoch 139): Loss/seq after 00650 batchs: 592.9025268554688
INFO:root:Train (Epoch 139): Loss/seq after 00700 batchs: 566.8526000976562
INFO:root:Train (Epoch 139): Loss/seq after 00750 batchs: 557.6408081054688
INFO:root:Train (Epoch 139): Loss/seq after 00800 batchs: 565.0606689453125
INFO:root:Train (Epoch 139): Loss/seq after 00850 batchs: 547.305419921875
INFO:root:Train (Epoch 139): Loss/seq after 00900 batchs: 534.2596435546875
INFO:root:Train (Epoch 139): Loss/seq after 00950 batchs: 529.099365234375
INFO:root:Train (Epoch 139): Loss/seq after 01000 batchs: 518.931640625
INFO:root:Train (Epoch 139): Loss/seq after 01050 batchs: 508.91436767578125
INFO:root:Train (Epoch 139): Loss/seq after 01100 batchs: 500.17633056640625
INFO:root:Train (Epoch 139): Loss/seq after 01150 batchs: 486.4206237792969
INFO:root:Train (Epoch 139): Loss/seq after 01200 batchs: 492.0226745605469
INFO:root:Train (Epoch 139): Loss/seq after 01250 batchs: 491.5487060546875
INFO:root:Train (Epoch 139): Loss/seq after 01300 batchs: 480.223388671875
INFO:root:Train (Epoch 139): Loss/seq after 01350 batchs: 470.4871826171875
INFO:root:Train (Epoch 139): Loss/seq after 01400 batchs: 472.3093566894531
INFO:root:Train (Epoch 139): Loss/seq after 01450 batchs: 475.2367248535156
INFO:root:Train (Epoch 139): Loss/seq after 01500 batchs: 483.7642822265625
INFO:root:Train (Epoch 139): Loss/seq after 01550 batchs: 485.2554931640625
INFO:root:Train (Epoch 139): Loss/seq after 01600 batchs: 482.0388488769531
INFO:root:Train (Epoch 139): Loss/seq after 01650 batchs: 480.7478942871094
INFO:root:Train (Epoch 139): Loss/seq after 01700 batchs: 484.4901428222656
INFO:root:Train (Epoch 139): Loss/seq after 01750 batchs: 482.6244812011719
INFO:root:Train (Epoch 139): Loss/seq after 01800 batchs: 480.9421691894531
INFO:root:Train (Epoch 139): Loss/seq after 01850 batchs: 478.6232604980469
INFO:root:Train (Epoch 139): Loss/seq after 01900 batchs: 478.0262145996094
INFO:root:Train (Epoch 139): Loss/seq after 01950 batchs: 476.6117858886719
INFO:root:Train (Epoch 139): Loss/seq after 02000 batchs: 477.1891174316406
INFO:root:Train (Epoch 139): Loss/seq after 02050 batchs: 477.18310546875
INFO:root:Train (Epoch 139): Loss/seq after 02100 batchs: 475.83758544921875
INFO:root:Train (Epoch 139): Loss/seq after 02150 batchs: 474.5933837890625
INFO:root:Train (Epoch 139): Loss/seq after 02200 batchs: 473.0896911621094
INFO:root:Train (Epoch 139): Loss/seq after 02250 batchs: 472.3002014160156
INFO:root:Train (Epoch 139): Loss/seq after 02300 batchs: 468.1186218261719
INFO:root:Train (Epoch 139): Loss/seq after 02350 batchs: 464.98876953125
INFO:root:Train (Epoch 139): Loss/seq after 02400 batchs: 465.675048828125
INFO:root:Train (Epoch 139): Loss/seq after 02450 batchs: 462.21990966796875
INFO:root:Train (Epoch 139): Loss/seq after 02500 batchs: 455.1031494140625
INFO:root:Train (Epoch 139): Loss/seq after 02550 batchs: 448.5159606933594
INFO:root:Train (Epoch 139): Loss/seq after 02600 batchs: 445.2108154296875
INFO:root:Train (Epoch 139): Loss/seq after 02650 batchs: 440.921875
INFO:root:Train (Epoch 139): Loss/seq after 02700 batchs: 438.1820373535156
INFO:root:Train (Epoch 139): Loss/seq after 02750 batchs: 433.76611328125
INFO:root:Train (Epoch 139): Loss/seq after 02800 batchs: 432.3118591308594
INFO:root:Train (Epoch 139): Loss/seq after 02850 batchs: 432.2880554199219
INFO:root:Train (Epoch 139): Loss/seq after 02900 batchs: 433.0487060546875
INFO:root:Train (Epoch 139): Loss/seq after 02950 batchs: 433.1727294921875
INFO:root:Train (Epoch 139): Loss/seq after 03000 batchs: 439.4607849121094
INFO:root:Train (Epoch 139): Loss/seq after 03050 batchs: 441.4338073730469
INFO:root:Train (Epoch 139): Loss/seq after 03100 batchs: 443.71746826171875
INFO:root:Train (Epoch 139): Loss/seq after 03150 batchs: 444.2489013671875
INFO:root:Train (Epoch 139): Loss/seq after 03200 batchs: 444.1497497558594
INFO:root:Train (Epoch 139): Loss/seq after 03250 batchs: 443.9701232910156
INFO:root:Train (Epoch 139): Loss/seq after 03300 batchs: 443.2917785644531
INFO:root:Train (Epoch 139): Loss/seq after 03350 batchs: 441.6701965332031
INFO:root:Train (Epoch 139): Loss/seq after 03400 batchs: 438.2562561035156
INFO:root:Train (Epoch 139): Loss/seq after 03450 batchs: 436.7945861816406
INFO:root:Train (Epoch 139): Loss/seq after 03500 batchs: 438.12078857421875
INFO:root:Train (Epoch 139): Loss/seq after 03550 batchs: 436.3581848144531
INFO:root:Train (Epoch 139): Loss/seq after 03600 batchs: 443.2935485839844
INFO:root:Train (Epoch 139): Loss/seq after 03650 batchs: 441.7475280761719
INFO:root:Train (Epoch 139): Loss/seq after 03700 batchs: 444.7503356933594
INFO:root:Train (Epoch 139): Loss/seq after 03750 batchs: 449.6159362792969
INFO:root:Train (Epoch 139): Loss/seq after 03800 batchs: 448.5635681152344
INFO:root:Train (Epoch 139): Loss/seq after 03850 batchs: 447.65814208984375
INFO:root:Train (Epoch 139): Loss/seq after 03900 batchs: 450.18035888671875
INFO:root:Train (Epoch 139): Loss/seq after 03950 batchs: 452.67315673828125
INFO:root:Train (Epoch 139): Loss/seq after 04000 batchs: 449.7703857421875
INFO:root:Train (Epoch 139): Loss/seq after 04050 batchs: 446.9208984375
INFO:root:Train (Epoch 139): Loss/seq after 04100 batchs: 446.06329345703125
INFO:root:Train (Epoch 139): Loss/seq after 04150 batchs: 446.4080810546875
INFO:root:Train (Epoch 139): Loss/seq after 04200 batchs: 445.25958251953125
INFO:root:Train (Epoch 139): Loss/seq after 04250 batchs: 443.98004150390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 139): Loss/seq after 00000 batches: 341.0440368652344
INFO:root:# Valid (Epoch 139): Loss/seq after 00050 batches: 621.7069091796875
INFO:root:# Valid (Epoch 139): Loss/seq after 00100 batches: 641.5208129882812
INFO:root:# Valid (Epoch 139): Loss/seq after 00150 batches: 481.517333984375
INFO:root:# Valid (Epoch 139): Loss/seq after 00200 batches: 456.3208923339844
INFO:root:Artifacts: Make stick videos for epoch 139
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_139_on_20220422_105556.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_139_index_1726_on_20220422_105556.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 140): Loss/seq after 00000 batchs: 550.5850219726562
INFO:root:Train (Epoch 140): Loss/seq after 00050 batchs: 623.9586791992188
INFO:root:Train (Epoch 140): Loss/seq after 00100 batchs: 628.8632202148438
INFO:root:Train (Epoch 140): Loss/seq after 00150 batchs: 581.7838745117188
INFO:root:Train (Epoch 140): Loss/seq after 00200 batchs: 642.49755859375
INFO:root:Train (Epoch 140): Loss/seq after 00250 batchs: 721.4100341796875
INFO:root:Train (Epoch 140): Loss/seq after 00300 batchs: 728.0806274414062
INFO:root:Train (Epoch 140): Loss/seq after 00350 batchs: 684.6412353515625
INFO:root:Train (Epoch 140): Loss/seq after 00400 batchs: 668.2225952148438
INFO:root:Train (Epoch 140): Loss/seq after 00450 batchs: 667.257568359375
INFO:root:Train (Epoch 140): Loss/seq after 00500 batchs: 646.412353515625
INFO:root:Train (Epoch 140): Loss/seq after 00550 batchs: 632.6425170898438
INFO:root:Train (Epoch 140): Loss/seq after 00600 batchs: 611.62060546875
INFO:root:Train (Epoch 140): Loss/seq after 00650 batchs: 586.3831787109375
INFO:root:Train (Epoch 140): Loss/seq after 00700 batchs: 561.0330200195312
INFO:root:Train (Epoch 140): Loss/seq after 00750 batchs: 555.725830078125
INFO:root:Train (Epoch 140): Loss/seq after 00800 batchs: 561.6502075195312
INFO:root:Train (Epoch 140): Loss/seq after 00850 batchs: 543.3447875976562
INFO:root:Train (Epoch 140): Loss/seq after 00900 batchs: 530.261962890625
INFO:root:Train (Epoch 140): Loss/seq after 00950 batchs: 525.94140625
INFO:root:Train (Epoch 140): Loss/seq after 01000 batchs: 515.2800903320312
INFO:root:Train (Epoch 140): Loss/seq after 01050 batchs: 505.7996520996094
INFO:root:Train (Epoch 140): Loss/seq after 01100 batchs: 496.8690490722656
INFO:root:Train (Epoch 140): Loss/seq after 01150 batchs: 483.1873474121094
INFO:root:Train (Epoch 140): Loss/seq after 01200 batchs: 488.86505126953125
INFO:root:Train (Epoch 140): Loss/seq after 01250 batchs: 488.0679931640625
INFO:root:Train (Epoch 140): Loss/seq after 01300 batchs: 476.7897644042969
INFO:root:Train (Epoch 140): Loss/seq after 01350 batchs: 467.7367858886719
INFO:root:Train (Epoch 140): Loss/seq after 01400 batchs: 469.5704345703125
INFO:root:Train (Epoch 140): Loss/seq after 01450 batchs: 472.7916564941406
INFO:root:Train (Epoch 140): Loss/seq after 01500 batchs: 481.13580322265625
INFO:root:Train (Epoch 140): Loss/seq after 01550 batchs: 482.5616760253906
INFO:root:Train (Epoch 140): Loss/seq after 01600 batchs: 478.9831237792969
INFO:root:Train (Epoch 140): Loss/seq after 01650 batchs: 477.6629638671875
INFO:root:Train (Epoch 140): Loss/seq after 01700 batchs: 481.6169738769531
INFO:root:Train (Epoch 140): Loss/seq after 01750 batchs: 479.5655517578125
INFO:root:Train (Epoch 140): Loss/seq after 01800 batchs: 477.8703308105469
INFO:root:Train (Epoch 140): Loss/seq after 01850 batchs: 475.48016357421875
INFO:root:Train (Epoch 140): Loss/seq after 01900 batchs: 474.8388977050781
INFO:root:Train (Epoch 140): Loss/seq after 01950 batchs: 473.7205505371094
INFO:root:Train (Epoch 140): Loss/seq after 02000 batchs: 474.1838073730469
INFO:root:Train (Epoch 140): Loss/seq after 02050 batchs: 473.90008544921875
INFO:root:Train (Epoch 140): Loss/seq after 02100 batchs: 472.37408447265625
INFO:root:Train (Epoch 140): Loss/seq after 02150 batchs: 471.1995849609375
INFO:root:Train (Epoch 140): Loss/seq after 02200 batchs: 469.59930419921875
INFO:root:Train (Epoch 140): Loss/seq after 02250 batchs: 468.92852783203125
INFO:root:Train (Epoch 140): Loss/seq after 02300 batchs: 465.1260681152344
INFO:root:Train (Epoch 140): Loss/seq after 02350 batchs: 462.17779541015625
INFO:root:Train (Epoch 140): Loss/seq after 02400 batchs: 462.8925476074219
INFO:root:Train (Epoch 140): Loss/seq after 02450 batchs: 459.54217529296875
INFO:root:Train (Epoch 140): Loss/seq after 02500 batchs: 452.5011901855469
INFO:root:Train (Epoch 140): Loss/seq after 02550 batchs: 446.03717041015625
INFO:root:Train (Epoch 140): Loss/seq after 02600 batchs: 442.82891845703125
INFO:root:Train (Epoch 140): Loss/seq after 02650 batchs: 438.6507873535156
INFO:root:Train (Epoch 140): Loss/seq after 02700 batchs: 435.8528137207031
INFO:root:Train (Epoch 140): Loss/seq after 02750 batchs: 431.66217041015625
INFO:root:Train (Epoch 140): Loss/seq after 02800 batchs: 429.9332275390625
INFO:root:Train (Epoch 140): Loss/seq after 02850 batchs: 429.8468933105469
INFO:root:Train (Epoch 140): Loss/seq after 02900 batchs: 430.80596923828125
INFO:root:Train (Epoch 140): Loss/seq after 02950 batchs: 430.9010009765625
INFO:root:Train (Epoch 140): Loss/seq after 03000 batchs: 437.1856689453125
INFO:root:Train (Epoch 140): Loss/seq after 03050 batchs: 439.251953125
INFO:root:Train (Epoch 140): Loss/seq after 03100 batchs: 441.37884521484375
INFO:root:Train (Epoch 140): Loss/seq after 03150 batchs: 441.5960388183594
INFO:root:Train (Epoch 140): Loss/seq after 03200 batchs: 441.319580078125
INFO:root:Train (Epoch 140): Loss/seq after 03250 batchs: 441.2492370605469
INFO:root:Train (Epoch 140): Loss/seq after 03300 batchs: 440.4964294433594
INFO:root:Train (Epoch 140): Loss/seq after 03350 batchs: 438.6150207519531
INFO:root:Train (Epoch 140): Loss/seq after 03400 batchs: 435.2674560546875
INFO:root:Train (Epoch 140): Loss/seq after 03450 batchs: 433.9832763671875
INFO:root:Train (Epoch 140): Loss/seq after 03500 batchs: 435.50921630859375
INFO:root:Train (Epoch 140): Loss/seq after 03550 batchs: 433.937255859375
INFO:root:Train (Epoch 140): Loss/seq after 03600 batchs: 441.02044677734375
INFO:root:Train (Epoch 140): Loss/seq after 03650 batchs: 439.50469970703125
INFO:root:Train (Epoch 140): Loss/seq after 03700 batchs: 442.1928405761719
INFO:root:Train (Epoch 140): Loss/seq after 03750 batchs: 447.00335693359375
INFO:root:Train (Epoch 140): Loss/seq after 03800 batchs: 445.9688720703125
INFO:root:Train (Epoch 140): Loss/seq after 03850 batchs: 445.1783752441406
INFO:root:Train (Epoch 140): Loss/seq after 03900 batchs: 447.56219482421875
INFO:root:Train (Epoch 140): Loss/seq after 03950 batchs: 450.03033447265625
INFO:root:Train (Epoch 140): Loss/seq after 04000 batchs: 447.1622619628906
INFO:root:Train (Epoch 140): Loss/seq after 04050 batchs: 444.38287353515625
INFO:root:Train (Epoch 140): Loss/seq after 04100 batchs: 443.45556640625
INFO:root:Train (Epoch 140): Loss/seq after 04150 batchs: 443.8214416503906
INFO:root:Train (Epoch 140): Loss/seq after 04200 batchs: 442.7017822265625
INFO:root:Train (Epoch 140): Loss/seq after 04250 batchs: 441.421630859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 140): Loss/seq after 00000 batches: 419.7716369628906
INFO:root:# Valid (Epoch 140): Loss/seq after 00050 batches: 674.7516479492188
INFO:root:# Valid (Epoch 140): Loss/seq after 00100 batches: 691.3923950195312
INFO:root:# Valid (Epoch 140): Loss/seq after 00150 batches: 522.72705078125
INFO:root:# Valid (Epoch 140): Loss/seq after 00200 batches: 488.7648010253906
INFO:root:Artifacts: Make stick videos for epoch 140
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_140_on_20220422_110050.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_140_index_946_on_20220422_110050.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 141): Loss/seq after 00000 batchs: 731.2450561523438
INFO:root:Train (Epoch 141): Loss/seq after 00050 batchs: 637.7686157226562
INFO:root:Train (Epoch 141): Loss/seq after 00100 batchs: 659.3024291992188
INFO:root:Train (Epoch 141): Loss/seq after 00150 batchs: 606.131103515625
INFO:root:Train (Epoch 141): Loss/seq after 00200 batchs: 667.55859375
INFO:root:Train (Epoch 141): Loss/seq after 00250 batchs: 731.1531982421875
INFO:root:Train (Epoch 141): Loss/seq after 00300 batchs: 735.61962890625
INFO:root:Train (Epoch 141): Loss/seq after 00350 batchs: 692.5907592773438
INFO:root:Train (Epoch 141): Loss/seq after 00400 batchs: 675.1419067382812
INFO:root:Train (Epoch 141): Loss/seq after 00450 batchs: 673.0497436523438
INFO:root:Train (Epoch 141): Loss/seq after 00500 batchs: 649.3466186523438
INFO:root:Train (Epoch 141): Loss/seq after 00550 batchs: 634.98779296875
INFO:root:Train (Epoch 141): Loss/seq after 00600 batchs: 613.5469970703125
INFO:root:Train (Epoch 141): Loss/seq after 00650 batchs: 589.10400390625
INFO:root:Train (Epoch 141): Loss/seq after 00700 batchs: 563.0284423828125
INFO:root:Train (Epoch 141): Loss/seq after 00750 batchs: 555.8689575195312
INFO:root:Train (Epoch 141): Loss/seq after 00800 batchs: 560.228271484375
INFO:root:Train (Epoch 141): Loss/seq after 00850 batchs: 542.42431640625
INFO:root:Train (Epoch 141): Loss/seq after 00900 batchs: 529.8571166992188
INFO:root:Train (Epoch 141): Loss/seq after 00950 batchs: 524.431396484375
INFO:root:Train (Epoch 141): Loss/seq after 01000 batchs: 513.9920043945312
INFO:root:Train (Epoch 141): Loss/seq after 01050 batchs: 504.117919921875
INFO:root:Train (Epoch 141): Loss/seq after 01100 batchs: 494.6726379394531
INFO:root:Train (Epoch 141): Loss/seq after 01150 batchs: 481.0048522949219
INFO:root:Train (Epoch 141): Loss/seq after 01200 batchs: 487.0797119140625
INFO:root:Train (Epoch 141): Loss/seq after 01250 batchs: 486.55279541015625
INFO:root:Train (Epoch 141): Loss/seq after 01300 batchs: 475.64251708984375
INFO:root:Train (Epoch 141): Loss/seq after 01350 batchs: 466.07598876953125
INFO:root:Train (Epoch 141): Loss/seq after 01400 batchs: 466.9490966796875
INFO:root:Train (Epoch 141): Loss/seq after 01450 batchs: 470.05780029296875
INFO:root:Train (Epoch 141): Loss/seq after 01500 batchs: 478.7280578613281
INFO:root:Train (Epoch 141): Loss/seq after 01550 batchs: 479.8182373046875
INFO:root:Train (Epoch 141): Loss/seq after 01600 batchs: 476.8486633300781
INFO:root:Train (Epoch 141): Loss/seq after 01650 batchs: 475.2181701660156
INFO:root:Train (Epoch 141): Loss/seq after 01700 batchs: 479.22869873046875
INFO:root:Train (Epoch 141): Loss/seq after 01750 batchs: 477.15118408203125
INFO:root:Train (Epoch 141): Loss/seq after 01800 batchs: 475.51885986328125
INFO:root:Train (Epoch 141): Loss/seq after 01850 batchs: 473.3072204589844
INFO:root:Train (Epoch 141): Loss/seq after 01900 batchs: 472.9913330078125
INFO:root:Train (Epoch 141): Loss/seq after 01950 batchs: 471.5189208984375
INFO:root:Train (Epoch 141): Loss/seq after 02000 batchs: 472.06304931640625
INFO:root:Train (Epoch 141): Loss/seq after 02050 batchs: 471.9676208496094
INFO:root:Train (Epoch 141): Loss/seq after 02100 batchs: 470.57257080078125
INFO:root:Train (Epoch 141): Loss/seq after 02150 batchs: 469.3995361328125
INFO:root:Train (Epoch 141): Loss/seq after 02200 batchs: 467.9278869628906
INFO:root:Train (Epoch 141): Loss/seq after 02250 batchs: 466.7429504394531
INFO:root:Train (Epoch 141): Loss/seq after 02300 batchs: 462.5969543457031
INFO:root:Train (Epoch 141): Loss/seq after 02350 batchs: 459.5601806640625
INFO:root:Train (Epoch 141): Loss/seq after 02400 batchs: 460.2056579589844
INFO:root:Train (Epoch 141): Loss/seq after 02450 batchs: 456.8236999511719
INFO:root:Train (Epoch 141): Loss/seq after 02500 batchs: 449.7920837402344
INFO:root:Train (Epoch 141): Loss/seq after 02550 batchs: 443.3189392089844
INFO:root:Train (Epoch 141): Loss/seq after 02600 batchs: 440.1060485839844
INFO:root:Train (Epoch 141): Loss/seq after 02650 batchs: 436.0728454589844
INFO:root:Train (Epoch 141): Loss/seq after 02700 batchs: 433.3413391113281
INFO:root:Train (Epoch 141): Loss/seq after 02750 batchs: 428.4698486328125
INFO:root:Train (Epoch 141): Loss/seq after 02800 batchs: 426.5867919921875
INFO:root:Train (Epoch 141): Loss/seq after 02850 batchs: 426.4210510253906
INFO:root:Train (Epoch 141): Loss/seq after 02900 batchs: 427.22998046875
INFO:root:Train (Epoch 141): Loss/seq after 02950 batchs: 427.4062194824219
INFO:root:Train (Epoch 141): Loss/seq after 03000 batchs: 433.659423828125
INFO:root:Train (Epoch 141): Loss/seq after 03050 batchs: 435.6009521484375
INFO:root:Train (Epoch 141): Loss/seq after 03100 batchs: 437.6060485839844
INFO:root:Train (Epoch 141): Loss/seq after 03150 batchs: 437.412841796875
INFO:root:Train (Epoch 141): Loss/seq after 03200 batchs: 437.42669677734375
INFO:root:Train (Epoch 141): Loss/seq after 03250 batchs: 437.5606384277344
INFO:root:Train (Epoch 141): Loss/seq after 03300 batchs: 437.12713623046875
INFO:root:Train (Epoch 141): Loss/seq after 03350 batchs: 435.5244445800781
INFO:root:Train (Epoch 141): Loss/seq after 03400 batchs: 432.1516418457031
INFO:root:Train (Epoch 141): Loss/seq after 03450 batchs: 430.9096984863281
INFO:root:Train (Epoch 141): Loss/seq after 03500 batchs: 432.4772644042969
INFO:root:Train (Epoch 141): Loss/seq after 03550 batchs: 430.5363464355469
INFO:root:Train (Epoch 141): Loss/seq after 03600 batchs: 437.35137939453125
INFO:root:Train (Epoch 141): Loss/seq after 03650 batchs: 435.689453125
INFO:root:Train (Epoch 141): Loss/seq after 03700 batchs: 438.4579162597656
INFO:root:Train (Epoch 141): Loss/seq after 03750 batchs: 443.1305847167969
INFO:root:Train (Epoch 141): Loss/seq after 03800 batchs: 442.0963134765625
INFO:root:Train (Epoch 141): Loss/seq after 03850 batchs: 441.1960144042969
INFO:root:Train (Epoch 141): Loss/seq after 03900 batchs: 443.7236328125
INFO:root:Train (Epoch 141): Loss/seq after 03950 batchs: 446.2872619628906
INFO:root:Train (Epoch 141): Loss/seq after 04000 batchs: 443.45086669921875
INFO:root:Train (Epoch 141): Loss/seq after 04050 batchs: 440.6453552246094
INFO:root:Train (Epoch 141): Loss/seq after 04100 batchs: 439.73388671875
INFO:root:Train (Epoch 141): Loss/seq after 04150 batchs: 440.172607421875
INFO:root:Train (Epoch 141): Loss/seq after 04200 batchs: 439.0831604003906
INFO:root:Train (Epoch 141): Loss/seq after 04250 batchs: 437.8150939941406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 141): Loss/seq after 00000 batches: 343.4745178222656
INFO:root:# Valid (Epoch 141): Loss/seq after 00050 batches: 628.5806884765625
INFO:root:# Valid (Epoch 141): Loss/seq after 00100 batches: 631.810302734375
INFO:root:# Valid (Epoch 141): Loss/seq after 00150 batches: 477.2441101074219
INFO:root:# Valid (Epoch 141): Loss/seq after 00200 batches: 450.76153564453125
INFO:root:Artifacts: Make stick videos for epoch 141
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_141_on_20220422_110553.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_141_index_1805_on_20220422_110553.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 142): Loss/seq after 00000 batchs: 616.9489135742188
INFO:root:Train (Epoch 142): Loss/seq after 00050 batchs: 608.1053466796875
INFO:root:Train (Epoch 142): Loss/seq after 00100 batchs: 629.8710327148438
INFO:root:Train (Epoch 142): Loss/seq after 00150 batchs: 589.399169921875
INFO:root:Train (Epoch 142): Loss/seq after 00200 batchs: 637.6344604492188
INFO:root:Train (Epoch 142): Loss/seq after 00250 batchs: 707.7592163085938
INFO:root:Train (Epoch 142): Loss/seq after 00300 batchs: 717.7417602539062
INFO:root:Train (Epoch 142): Loss/seq after 00350 batchs: 676.1583251953125
INFO:root:Train (Epoch 142): Loss/seq after 00400 batchs: 663.1576538085938
INFO:root:Train (Epoch 142): Loss/seq after 00450 batchs: 662.0821533203125
INFO:root:Train (Epoch 142): Loss/seq after 00500 batchs: 641.7862548828125
INFO:root:Train (Epoch 142): Loss/seq after 00550 batchs: 627.5703125
INFO:root:Train (Epoch 142): Loss/seq after 00600 batchs: 607.802001953125
INFO:root:Train (Epoch 142): Loss/seq after 00650 batchs: 584.658447265625
INFO:root:Train (Epoch 142): Loss/seq after 00700 batchs: 559.9075317382812
INFO:root:Train (Epoch 142): Loss/seq after 00750 batchs: 551.6046752929688
INFO:root:Train (Epoch 142): Loss/seq after 00800 batchs: 558.7899780273438
INFO:root:Train (Epoch 142): Loss/seq after 00850 batchs: 540.93994140625
INFO:root:Train (Epoch 142): Loss/seq after 00900 batchs: 528.3026733398438
INFO:root:Train (Epoch 142): Loss/seq after 00950 batchs: 524.2974853515625
INFO:root:Train (Epoch 142): Loss/seq after 01000 batchs: 513.58251953125
INFO:root:Train (Epoch 142): Loss/seq after 01050 batchs: 504.1376037597656
INFO:root:Train (Epoch 142): Loss/seq after 01100 batchs: 495.7150573730469
INFO:root:Train (Epoch 142): Loss/seq after 01150 batchs: 481.9851989746094
INFO:root:Train (Epoch 142): Loss/seq after 01200 batchs: 487.46282958984375
INFO:root:Train (Epoch 142): Loss/seq after 01250 batchs: 486.8702087402344
INFO:root:Train (Epoch 142): Loss/seq after 01300 batchs: 475.7157897949219
INFO:root:Train (Epoch 142): Loss/seq after 01350 batchs: 466.45660400390625
INFO:root:Train (Epoch 142): Loss/seq after 01400 batchs: 467.692626953125
INFO:root:Train (Epoch 142): Loss/seq after 01450 batchs: 470.70111083984375
INFO:root:Train (Epoch 142): Loss/seq after 01500 batchs: 479.26904296875
INFO:root:Train (Epoch 142): Loss/seq after 01550 batchs: 480.4775085449219
INFO:root:Train (Epoch 142): Loss/seq after 01600 batchs: 477.45574951171875
INFO:root:Train (Epoch 142): Loss/seq after 01650 batchs: 476.06787109375
INFO:root:Train (Epoch 142): Loss/seq after 01700 batchs: 480.0217590332031
INFO:root:Train (Epoch 142): Loss/seq after 01750 batchs: 477.8512878417969
INFO:root:Train (Epoch 142): Loss/seq after 01800 batchs: 475.8383483886719
INFO:root:Train (Epoch 142): Loss/seq after 01850 batchs: 473.2991027832031
INFO:root:Train (Epoch 142): Loss/seq after 01900 batchs: 472.7580261230469
INFO:root:Train (Epoch 142): Loss/seq after 01950 batchs: 471.6150817871094
INFO:root:Train (Epoch 142): Loss/seq after 02000 batchs: 472.1487731933594
INFO:root:Train (Epoch 142): Loss/seq after 02050 batchs: 471.9266662597656
INFO:root:Train (Epoch 142): Loss/seq after 02100 batchs: 470.49334716796875
INFO:root:Train (Epoch 142): Loss/seq after 02150 batchs: 469.5637512207031
INFO:root:Train (Epoch 142): Loss/seq after 02200 batchs: 468.0055847167969
INFO:root:Train (Epoch 142): Loss/seq after 02250 batchs: 467.0744323730469
INFO:root:Train (Epoch 142): Loss/seq after 02300 batchs: 462.8367919921875
INFO:root:Train (Epoch 142): Loss/seq after 02350 batchs: 459.6834716796875
INFO:root:Train (Epoch 142): Loss/seq after 02400 batchs: 460.2801513671875
INFO:root:Train (Epoch 142): Loss/seq after 02450 batchs: 456.82879638671875
INFO:root:Train (Epoch 142): Loss/seq after 02500 batchs: 449.740966796875
INFO:root:Train (Epoch 142): Loss/seq after 02550 batchs: 443.2434387207031
INFO:root:Train (Epoch 142): Loss/seq after 02600 batchs: 439.8511962890625
INFO:root:Train (Epoch 142): Loss/seq after 02650 batchs: 435.6614990234375
INFO:root:Train (Epoch 142): Loss/seq after 02700 batchs: 432.8923645019531
INFO:root:Train (Epoch 142): Loss/seq after 02750 batchs: 428.1358642578125
INFO:root:Train (Epoch 142): Loss/seq after 02800 batchs: 426.5802307128906
INFO:root:Train (Epoch 142): Loss/seq after 02850 batchs: 426.376708984375
INFO:root:Train (Epoch 142): Loss/seq after 02900 batchs: 427.4024353027344
INFO:root:Train (Epoch 142): Loss/seq after 02950 batchs: 427.5100402832031
INFO:root:Train (Epoch 142): Loss/seq after 03000 batchs: 433.74456787109375
INFO:root:Train (Epoch 142): Loss/seq after 03050 batchs: 435.789794921875
INFO:root:Train (Epoch 142): Loss/seq after 03100 batchs: 438.89752197265625
INFO:root:Train (Epoch 142): Loss/seq after 03150 batchs: 439.4956970214844
INFO:root:Train (Epoch 142): Loss/seq after 03200 batchs: 439.5587463378906
INFO:root:Train (Epoch 142): Loss/seq after 03250 batchs: 439.06365966796875
INFO:root:Train (Epoch 142): Loss/seq after 03300 batchs: 438.2968444824219
INFO:root:Train (Epoch 142): Loss/seq after 03350 batchs: 436.44024658203125
INFO:root:Train (Epoch 142): Loss/seq after 03400 batchs: 433.11883544921875
INFO:root:Train (Epoch 142): Loss/seq after 03450 batchs: 431.6365966796875
INFO:root:Train (Epoch 142): Loss/seq after 03500 batchs: 433.12060546875
INFO:root:Train (Epoch 142): Loss/seq after 03550 batchs: 431.4784851074219
INFO:root:Train (Epoch 142): Loss/seq after 03600 batchs: 438.5372619628906
INFO:root:Train (Epoch 142): Loss/seq after 03650 batchs: 436.8403625488281
INFO:root:Train (Epoch 142): Loss/seq after 03700 batchs: 439.4573669433594
INFO:root:Train (Epoch 142): Loss/seq after 03750 batchs: 444.19683837890625
INFO:root:Train (Epoch 142): Loss/seq after 03800 batchs: 443.13726806640625
INFO:root:Train (Epoch 142): Loss/seq after 03850 batchs: 442.38818359375
INFO:root:Train (Epoch 142): Loss/seq after 03900 batchs: 444.5633544921875
INFO:root:Train (Epoch 142): Loss/seq after 03950 batchs: 446.82537841796875
INFO:root:Train (Epoch 142): Loss/seq after 04000 batchs: 443.9731750488281
INFO:root:Train (Epoch 142): Loss/seq after 04050 batchs: 441.16534423828125
INFO:root:Train (Epoch 142): Loss/seq after 04100 batchs: 440.2066345214844
INFO:root:Train (Epoch 142): Loss/seq after 04150 batchs: 440.5846252441406
INFO:root:Train (Epoch 142): Loss/seq after 04200 batchs: 439.4810791015625
INFO:root:Train (Epoch 142): Loss/seq after 04250 batchs: 438.1770324707031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 142): Loss/seq after 00000 batches: 319.5697937011719
INFO:root:# Valid (Epoch 142): Loss/seq after 00050 batches: 607.4356079101562
INFO:root:# Valid (Epoch 142): Loss/seq after 00100 batches: 614.4320068359375
INFO:root:# Valid (Epoch 142): Loss/seq after 00150 batches: 464.16339111328125
INFO:root:# Valid (Epoch 142): Loss/seq after 00200 batches: 439.1873474121094
INFO:root:Artifacts: Make stick videos for epoch 142
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_142_on_20220422_111044.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_142_index_908_on_20220422_111044.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 143): Loss/seq after 00000 batchs: 639.1475830078125
INFO:root:Train (Epoch 143): Loss/seq after 00050 batchs: 608.4536743164062
INFO:root:Train (Epoch 143): Loss/seq after 00100 batchs: 618.2579956054688
INFO:root:Train (Epoch 143): Loss/seq after 00150 batchs: 569.298583984375
INFO:root:Train (Epoch 143): Loss/seq after 00200 batchs: 619.5116577148438
INFO:root:Train (Epoch 143): Loss/seq after 00250 batchs: 702.673828125
INFO:root:Train (Epoch 143): Loss/seq after 00300 batchs: 709.4279174804688
INFO:root:Train (Epoch 143): Loss/seq after 00350 batchs: 668.56591796875
INFO:root:Train (Epoch 143): Loss/seq after 00400 batchs: 653.1320190429688
INFO:root:Train (Epoch 143): Loss/seq after 00450 batchs: 652.7693481445312
INFO:root:Train (Epoch 143): Loss/seq after 00500 batchs: 633.7509155273438
INFO:root:Train (Epoch 143): Loss/seq after 00550 batchs: 619.0150756835938
INFO:root:Train (Epoch 143): Loss/seq after 00600 batchs: 598.6781616210938
INFO:root:Train (Epoch 143): Loss/seq after 00650 batchs: 576.397216796875
INFO:root:Train (Epoch 143): Loss/seq after 00700 batchs: 551.8207397460938
INFO:root:Train (Epoch 143): Loss/seq after 00750 batchs: 543.0619506835938
INFO:root:Train (Epoch 143): Loss/seq after 00800 batchs: 550.3958740234375
INFO:root:Train (Epoch 143): Loss/seq after 00850 batchs: 533.1097412109375
INFO:root:Train (Epoch 143): Loss/seq after 00900 batchs: 520.7677612304688
INFO:root:Train (Epoch 143): Loss/seq after 00950 batchs: 516.69140625
INFO:root:Train (Epoch 143): Loss/seq after 01000 batchs: 506.2442626953125
INFO:root:Train (Epoch 143): Loss/seq after 01050 batchs: 495.0743103027344
INFO:root:Train (Epoch 143): Loss/seq after 01100 batchs: 486.10009765625
INFO:root:Train (Epoch 143): Loss/seq after 01150 batchs: 472.47760009765625
INFO:root:Train (Epoch 143): Loss/seq after 01200 batchs: 477.5795593261719
INFO:root:Train (Epoch 143): Loss/seq after 01250 batchs: 477.27777099609375
INFO:root:Train (Epoch 143): Loss/seq after 01300 batchs: 466.2072448730469
INFO:root:Train (Epoch 143): Loss/seq after 01350 batchs: 456.71380615234375
INFO:root:Train (Epoch 143): Loss/seq after 01400 batchs: 457.6044616699219
INFO:root:Train (Epoch 143): Loss/seq after 01450 batchs: 461.1279602050781
INFO:root:Train (Epoch 143): Loss/seq after 01500 batchs: 469.7250671386719
INFO:root:Train (Epoch 143): Loss/seq after 01550 batchs: 471.0848388671875
INFO:root:Train (Epoch 143): Loss/seq after 01600 batchs: 467.6673889160156
INFO:root:Train (Epoch 143): Loss/seq after 01650 batchs: 466.7137145996094
INFO:root:Train (Epoch 143): Loss/seq after 01700 batchs: 470.8161926269531
INFO:root:Train (Epoch 143): Loss/seq after 01750 batchs: 469.1267395019531
INFO:root:Train (Epoch 143): Loss/seq after 01800 batchs: 467.6412048339844
INFO:root:Train (Epoch 143): Loss/seq after 01850 batchs: 465.4249267578125
INFO:root:Train (Epoch 143): Loss/seq after 01900 batchs: 465.148681640625
INFO:root:Train (Epoch 143): Loss/seq after 01950 batchs: 464.12664794921875
INFO:root:Train (Epoch 143): Loss/seq after 02000 batchs: 464.61846923828125
INFO:root:Train (Epoch 143): Loss/seq after 02050 batchs: 464.4981689453125
INFO:root:Train (Epoch 143): Loss/seq after 02100 batchs: 463.32733154296875
INFO:root:Train (Epoch 143): Loss/seq after 02150 batchs: 462.2073669433594
INFO:root:Train (Epoch 143): Loss/seq after 02200 batchs: 460.9389343261719
INFO:root:Train (Epoch 143): Loss/seq after 02250 batchs: 460.29840087890625
INFO:root:Train (Epoch 143): Loss/seq after 02300 batchs: 456.3405456542969
INFO:root:Train (Epoch 143): Loss/seq after 02350 batchs: 453.32061767578125
INFO:root:Train (Epoch 143): Loss/seq after 02400 batchs: 454.18524169921875
INFO:root:Train (Epoch 143): Loss/seq after 02450 batchs: 450.8450622558594
INFO:root:Train (Epoch 143): Loss/seq after 02500 batchs: 443.9021911621094
INFO:root:Train (Epoch 143): Loss/seq after 02550 batchs: 437.44427490234375
INFO:root:Train (Epoch 143): Loss/seq after 02600 batchs: 433.8939208984375
INFO:root:Train (Epoch 143): Loss/seq after 02650 batchs: 429.63787841796875
INFO:root:Train (Epoch 143): Loss/seq after 02700 batchs: 427.0162048339844
INFO:root:Train (Epoch 143): Loss/seq after 02750 batchs: 422.2725524902344
INFO:root:Train (Epoch 143): Loss/seq after 02800 batchs: 420.2759704589844
INFO:root:Train (Epoch 143): Loss/seq after 02850 batchs: 420.1729736328125
INFO:root:Train (Epoch 143): Loss/seq after 02900 batchs: 420.7334899902344
INFO:root:Train (Epoch 143): Loss/seq after 02950 batchs: 420.96356201171875
INFO:root:Train (Epoch 143): Loss/seq after 03000 batchs: 427.2532653808594
INFO:root:Train (Epoch 143): Loss/seq after 03050 batchs: 429.16455078125
INFO:root:Train (Epoch 143): Loss/seq after 03100 batchs: 431.8784484863281
INFO:root:Train (Epoch 143): Loss/seq after 03150 batchs: 432.5784912109375
INFO:root:Train (Epoch 143): Loss/seq after 03200 batchs: 432.511474609375
INFO:root:Train (Epoch 143): Loss/seq after 03250 batchs: 432.9405822753906
INFO:root:Train (Epoch 143): Loss/seq after 03300 batchs: 432.53582763671875
INFO:root:Train (Epoch 143): Loss/seq after 03350 batchs: 430.8729248046875
INFO:root:Train (Epoch 143): Loss/seq after 03400 batchs: 427.574951171875
INFO:root:Train (Epoch 143): Loss/seq after 03450 batchs: 426.4969482421875
INFO:root:Train (Epoch 143): Loss/seq after 03500 batchs: 428.2004699707031
INFO:root:Train (Epoch 143): Loss/seq after 03550 batchs: 427.1228332519531
INFO:root:Train (Epoch 143): Loss/seq after 03600 batchs: 434.2723083496094
INFO:root:Train (Epoch 143): Loss/seq after 03650 batchs: 432.89373779296875
INFO:root:Train (Epoch 143): Loss/seq after 03700 batchs: 435.4371337890625
INFO:root:Train (Epoch 143): Loss/seq after 03750 batchs: 440.1570739746094
INFO:root:Train (Epoch 143): Loss/seq after 03800 batchs: 439.1481628417969
INFO:root:Train (Epoch 143): Loss/seq after 03850 batchs: 438.44769287109375
INFO:root:Train (Epoch 143): Loss/seq after 03900 batchs: 441.2525634765625
INFO:root:Train (Epoch 143): Loss/seq after 03950 batchs: 443.7288818359375
INFO:root:Train (Epoch 143): Loss/seq after 04000 batchs: 440.9831848144531
INFO:root:Train (Epoch 143): Loss/seq after 04050 batchs: 438.16583251953125
INFO:root:Train (Epoch 143): Loss/seq after 04100 batchs: 437.2902526855469
INFO:root:Train (Epoch 143): Loss/seq after 04150 batchs: 437.70318603515625
INFO:root:Train (Epoch 143): Loss/seq after 04200 batchs: 436.55596923828125
INFO:root:Train (Epoch 143): Loss/seq after 04250 batchs: 435.2951354980469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 143): Loss/seq after 00000 batches: 338.39471435546875
INFO:root:# Valid (Epoch 143): Loss/seq after 00050 batches: 589.3473510742188
INFO:root:# Valid (Epoch 143): Loss/seq after 00100 batches: 595.3079833984375
INFO:root:# Valid (Epoch 143): Loss/seq after 00150 batches: 453.2474670410156
INFO:root:# Valid (Epoch 143): Loss/seq after 00200 batches: 431.5040283203125
INFO:root:Artifacts: Make stick videos for epoch 143
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_143_on_20220422_111543.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_143_index_1192_on_20220422_111543.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 144): Loss/seq after 00000 batchs: 580.227783203125
INFO:root:Train (Epoch 144): Loss/seq after 00050 batchs: 607.8070678710938
INFO:root:Train (Epoch 144): Loss/seq after 00100 batchs: 642.9619750976562
INFO:root:Train (Epoch 144): Loss/seq after 00150 batchs: 588.1490478515625
INFO:root:Train (Epoch 144): Loss/seq after 00200 batchs: 642.3641967773438
INFO:root:Train (Epoch 144): Loss/seq after 00250 batchs: 708.8624877929688
INFO:root:Train (Epoch 144): Loss/seq after 00300 batchs: 716.6387939453125
INFO:root:Train (Epoch 144): Loss/seq after 00350 batchs: 673.9921875
INFO:root:Train (Epoch 144): Loss/seq after 00400 batchs: 658.8013916015625
INFO:root:Train (Epoch 144): Loss/seq after 00450 batchs: 658.0939331054688
INFO:root:Train (Epoch 144): Loss/seq after 00500 batchs: 638.0427856445312
INFO:root:Train (Epoch 144): Loss/seq after 00550 batchs: 625.3626098632812
INFO:root:Train (Epoch 144): Loss/seq after 00600 batchs: 604.7550048828125
INFO:root:Train (Epoch 144): Loss/seq after 00650 batchs: 579.8587036132812
INFO:root:Train (Epoch 144): Loss/seq after 00700 batchs: 554.1978149414062
INFO:root:Train (Epoch 144): Loss/seq after 00750 batchs: 547.06591796875
INFO:root:Train (Epoch 144): Loss/seq after 00800 batchs: 553.4258422851562
INFO:root:Train (Epoch 144): Loss/seq after 00850 batchs: 535.1625366210938
INFO:root:Train (Epoch 144): Loss/seq after 00900 batchs: 521.866455078125
INFO:root:Train (Epoch 144): Loss/seq after 00950 batchs: 515.6380004882812
INFO:root:Train (Epoch 144): Loss/seq after 01000 batchs: 505.7162780761719
INFO:root:Train (Epoch 144): Loss/seq after 01050 batchs: 494.9143981933594
INFO:root:Train (Epoch 144): Loss/seq after 01100 batchs: 486.3819885253906
INFO:root:Train (Epoch 144): Loss/seq after 01150 batchs: 472.8640441894531
INFO:root:Train (Epoch 144): Loss/seq after 01200 batchs: 478.1451416015625
INFO:root:Train (Epoch 144): Loss/seq after 01250 batchs: 477.7750244140625
INFO:root:Train (Epoch 144): Loss/seq after 01300 batchs: 466.6353759765625
INFO:root:Train (Epoch 144): Loss/seq after 01350 batchs: 456.6941833496094
INFO:root:Train (Epoch 144): Loss/seq after 01400 batchs: 457.5977783203125
INFO:root:Train (Epoch 144): Loss/seq after 01450 batchs: 460.737548828125
INFO:root:Train (Epoch 144): Loss/seq after 01500 batchs: 469.00177001953125
INFO:root:Train (Epoch 144): Loss/seq after 01550 batchs: 470.44482421875
INFO:root:Train (Epoch 144): Loss/seq after 01600 batchs: 467.0046691894531
INFO:root:Train (Epoch 144): Loss/seq after 01650 batchs: 465.6182556152344
INFO:root:Train (Epoch 144): Loss/seq after 01700 batchs: 469.7793884277344
INFO:root:Train (Epoch 144): Loss/seq after 01750 batchs: 468.00653076171875
INFO:root:Train (Epoch 144): Loss/seq after 01800 batchs: 466.34014892578125
INFO:root:Train (Epoch 144): Loss/seq after 01850 batchs: 464.09283447265625
INFO:root:Train (Epoch 144): Loss/seq after 01900 batchs: 463.8793029785156
INFO:root:Train (Epoch 144): Loss/seq after 01950 batchs: 463.10955810546875
INFO:root:Train (Epoch 144): Loss/seq after 02000 batchs: 463.84210205078125
INFO:root:Train (Epoch 144): Loss/seq after 02050 batchs: 463.8347473144531
INFO:root:Train (Epoch 144): Loss/seq after 02100 batchs: 462.8536682128906
INFO:root:Train (Epoch 144): Loss/seq after 02150 batchs: 461.8354797363281
INFO:root:Train (Epoch 144): Loss/seq after 02200 batchs: 460.57403564453125
INFO:root:Train (Epoch 144): Loss/seq after 02250 batchs: 459.6641540527344
INFO:root:Train (Epoch 144): Loss/seq after 02300 batchs: 455.82354736328125
INFO:root:Train (Epoch 144): Loss/seq after 02350 batchs: 452.7761535644531
INFO:root:Train (Epoch 144): Loss/seq after 02400 batchs: 453.4427795410156
INFO:root:Train (Epoch 144): Loss/seq after 02450 batchs: 450.1298522949219
INFO:root:Train (Epoch 144): Loss/seq after 02500 batchs: 443.1575927734375
INFO:root:Train (Epoch 144): Loss/seq after 02550 batchs: 436.6952209472656
INFO:root:Train (Epoch 144): Loss/seq after 02600 batchs: 433.0970153808594
INFO:root:Train (Epoch 144): Loss/seq after 02650 batchs: 428.7403869628906
INFO:root:Train (Epoch 144): Loss/seq after 02700 batchs: 426.1695861816406
INFO:root:Train (Epoch 144): Loss/seq after 02750 batchs: 421.7222595214844
INFO:root:Train (Epoch 144): Loss/seq after 02800 batchs: 419.96209716796875
INFO:root:Train (Epoch 144): Loss/seq after 02850 batchs: 419.7417297363281
INFO:root:Train (Epoch 144): Loss/seq after 02900 batchs: 420.3525390625
INFO:root:Train (Epoch 144): Loss/seq after 02950 batchs: 420.53179931640625
INFO:root:Train (Epoch 144): Loss/seq after 03000 batchs: 426.7449035644531
INFO:root:Train (Epoch 144): Loss/seq after 03050 batchs: 428.8888244628906
INFO:root:Train (Epoch 144): Loss/seq after 03100 batchs: 431.86236572265625
INFO:root:Train (Epoch 144): Loss/seq after 03150 batchs: 431.8924255371094
INFO:root:Train (Epoch 144): Loss/seq after 03200 batchs: 432.0438537597656
INFO:root:Train (Epoch 144): Loss/seq after 03250 batchs: 432.3946838378906
INFO:root:Train (Epoch 144): Loss/seq after 03300 batchs: 431.8941955566406
INFO:root:Train (Epoch 144): Loss/seq after 03350 batchs: 430.8433837890625
INFO:root:Train (Epoch 144): Loss/seq after 03400 batchs: 427.55615234375
INFO:root:Train (Epoch 144): Loss/seq after 03450 batchs: 426.23907470703125
INFO:root:Train (Epoch 144): Loss/seq after 03500 batchs: 427.2657470703125
INFO:root:Train (Epoch 144): Loss/seq after 03550 batchs: 425.3375244140625
INFO:root:Train (Epoch 144): Loss/seq after 03600 batchs: 432.32391357421875
INFO:root:Train (Epoch 144): Loss/seq after 03650 batchs: 430.8428039550781
INFO:root:Train (Epoch 144): Loss/seq after 03700 batchs: 433.65399169921875
INFO:root:Train (Epoch 144): Loss/seq after 03750 batchs: 438.2507019042969
INFO:root:Train (Epoch 144): Loss/seq after 03800 batchs: 437.2808837890625
INFO:root:Train (Epoch 144): Loss/seq after 03850 batchs: 436.5198974609375
INFO:root:Train (Epoch 144): Loss/seq after 03900 batchs: 438.5544738769531
INFO:root:Train (Epoch 144): Loss/seq after 03950 batchs: 440.90777587890625
INFO:root:Train (Epoch 144): Loss/seq after 04000 batchs: 438.1347351074219
INFO:root:Train (Epoch 144): Loss/seq after 04050 batchs: 435.3535461425781
INFO:root:Train (Epoch 144): Loss/seq after 04100 batchs: 434.58074951171875
INFO:root:Train (Epoch 144): Loss/seq after 04150 batchs: 434.97772216796875
INFO:root:Train (Epoch 144): Loss/seq after 04200 batchs: 433.9132080078125
INFO:root:Train (Epoch 144): Loss/seq after 04250 batchs: 432.59149169921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 144): Loss/seq after 00000 batches: 317.9423828125
INFO:root:# Valid (Epoch 144): Loss/seq after 00050 batches: 588.8788452148438
INFO:root:# Valid (Epoch 144): Loss/seq after 00100 batches: 605.1710205078125
INFO:root:# Valid (Epoch 144): Loss/seq after 00150 batches: 459.8561096191406
INFO:root:# Valid (Epoch 144): Loss/seq after 00200 batches: 433.0062561035156
INFO:root:Artifacts: Make stick videos for epoch 144
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_144_on_20220422_112029.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_144_index_966_on_20220422_112029.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 145): Loss/seq after 00000 batchs: 766.368896484375
INFO:root:Train (Epoch 145): Loss/seq after 00050 batchs: 605.8341064453125
INFO:root:Train (Epoch 145): Loss/seq after 00100 batchs: 627.5756225585938
INFO:root:Train (Epoch 145): Loss/seq after 00150 batchs: 583.0800170898438
INFO:root:Train (Epoch 145): Loss/seq after 00200 batchs: 637.5814208984375
INFO:root:Train (Epoch 145): Loss/seq after 00250 batchs: 704.072021484375
INFO:root:Train (Epoch 145): Loss/seq after 00300 batchs: 709.1727294921875
INFO:root:Train (Epoch 145): Loss/seq after 00350 batchs: 668.4492797851562
INFO:root:Train (Epoch 145): Loss/seq after 00400 batchs: 649.7904052734375
INFO:root:Train (Epoch 145): Loss/seq after 00450 batchs: 649.724609375
INFO:root:Train (Epoch 145): Loss/seq after 00500 batchs: 628.1752319335938
INFO:root:Train (Epoch 145): Loss/seq after 00550 batchs: 613.356689453125
INFO:root:Train (Epoch 145): Loss/seq after 00600 batchs: 592.6029663085938
INFO:root:Train (Epoch 145): Loss/seq after 00650 batchs: 568.7722778320312
INFO:root:Train (Epoch 145): Loss/seq after 00700 batchs: 543.7470703125
INFO:root:Train (Epoch 145): Loss/seq after 00750 batchs: 534.8218994140625
INFO:root:Train (Epoch 145): Loss/seq after 00800 batchs: 541.784423828125
INFO:root:Train (Epoch 145): Loss/seq after 00850 batchs: 523.9660034179688
INFO:root:Train (Epoch 145): Loss/seq after 00900 batchs: 511.59613037109375
INFO:root:Train (Epoch 145): Loss/seq after 00950 batchs: 506.47528076171875
INFO:root:Train (Epoch 145): Loss/seq after 01000 batchs: 496.7838439941406
INFO:root:Train (Epoch 145): Loss/seq after 01050 batchs: 486.5465393066406
INFO:root:Train (Epoch 145): Loss/seq after 01100 batchs: 477.63262939453125
INFO:root:Train (Epoch 145): Loss/seq after 01150 batchs: 464.41455078125
INFO:root:Train (Epoch 145): Loss/seq after 01200 batchs: 470.3656311035156
INFO:root:Train (Epoch 145): Loss/seq after 01250 batchs: 469.7491149902344
INFO:root:Train (Epoch 145): Loss/seq after 01300 batchs: 458.82415771484375
INFO:root:Train (Epoch 145): Loss/seq after 01350 batchs: 449.4441833496094
INFO:root:Train (Epoch 145): Loss/seq after 01400 batchs: 450.0990295410156
INFO:root:Train (Epoch 145): Loss/seq after 01450 batchs: 453.4920349121094
INFO:root:Train (Epoch 145): Loss/seq after 01500 batchs: 462.23284912109375
INFO:root:Train (Epoch 145): Loss/seq after 01550 batchs: 463.80535888671875
INFO:root:Train (Epoch 145): Loss/seq after 01600 batchs: 460.7563171386719
INFO:root:Train (Epoch 145): Loss/seq after 01650 batchs: 459.7603454589844
INFO:root:Train (Epoch 145): Loss/seq after 01700 batchs: 464.0442199707031
INFO:root:Train (Epoch 145): Loss/seq after 01750 batchs: 462.3336486816406
INFO:root:Train (Epoch 145): Loss/seq after 01800 batchs: 460.7629089355469
INFO:root:Train (Epoch 145): Loss/seq after 01850 batchs: 458.5567321777344
INFO:root:Train (Epoch 145): Loss/seq after 01900 batchs: 458.2616271972656
INFO:root:Train (Epoch 145): Loss/seq after 01950 batchs: 457.2999572753906
INFO:root:Train (Epoch 145): Loss/seq after 02000 batchs: 458.01055908203125
INFO:root:Train (Epoch 145): Loss/seq after 02050 batchs: 457.9954528808594
INFO:root:Train (Epoch 145): Loss/seq after 02100 batchs: 457.14532470703125
INFO:root:Train (Epoch 145): Loss/seq after 02150 batchs: 456.3258056640625
INFO:root:Train (Epoch 145): Loss/seq after 02200 batchs: 455.092041015625
INFO:root:Train (Epoch 145): Loss/seq after 02250 batchs: 453.9676513671875
INFO:root:Train (Epoch 145): Loss/seq after 02300 batchs: 449.93731689453125
INFO:root:Train (Epoch 145): Loss/seq after 02350 batchs: 446.82061767578125
INFO:root:Train (Epoch 145): Loss/seq after 02400 batchs: 447.4081115722656
INFO:root:Train (Epoch 145): Loss/seq after 02450 batchs: 444.2593688964844
INFO:root:Train (Epoch 145): Loss/seq after 02500 batchs: 437.390380859375
INFO:root:Train (Epoch 145): Loss/seq after 02550 batchs: 431.00897216796875
INFO:root:Train (Epoch 145): Loss/seq after 02600 batchs: 427.21917724609375
INFO:root:Train (Epoch 145): Loss/seq after 02650 batchs: 423.184326171875
INFO:root:Train (Epoch 145): Loss/seq after 02700 batchs: 420.62982177734375
INFO:root:Train (Epoch 145): Loss/seq after 02750 batchs: 416.0430908203125
INFO:root:Train (Epoch 145): Loss/seq after 02800 batchs: 414.1629333496094
INFO:root:Train (Epoch 145): Loss/seq after 02850 batchs: 413.9914245605469
INFO:root:Train (Epoch 145): Loss/seq after 02900 batchs: 414.7837219238281
INFO:root:Train (Epoch 145): Loss/seq after 02950 batchs: 415.17742919921875
INFO:root:Train (Epoch 145): Loss/seq after 03000 batchs: 421.40338134765625
INFO:root:Train (Epoch 145): Loss/seq after 03050 batchs: 423.5058288574219
INFO:root:Train (Epoch 145): Loss/seq after 03100 batchs: 425.71337890625
INFO:root:Train (Epoch 145): Loss/seq after 03150 batchs: 425.2899169921875
INFO:root:Train (Epoch 145): Loss/seq after 03200 batchs: 424.9717712402344
INFO:root:Train (Epoch 145): Loss/seq after 03250 batchs: 424.6591796875
INFO:root:Train (Epoch 145): Loss/seq after 03300 batchs: 424.2272033691406
INFO:root:Train (Epoch 145): Loss/seq after 03350 batchs: 422.29119873046875
INFO:root:Train (Epoch 145): Loss/seq after 03400 batchs: 419.1098327636719
INFO:root:Train (Epoch 145): Loss/seq after 03450 batchs: 417.7148132324219
INFO:root:Train (Epoch 145): Loss/seq after 03500 batchs: 418.79248046875
INFO:root:Train (Epoch 145): Loss/seq after 03550 batchs: 417.0995178222656
INFO:root:Train (Epoch 145): Loss/seq after 03600 batchs: 424.156982421875
INFO:root:Train (Epoch 145): Loss/seq after 03650 batchs: 422.72760009765625
INFO:root:Train (Epoch 145): Loss/seq after 03700 batchs: 425.45751953125
INFO:root:Train (Epoch 145): Loss/seq after 03750 batchs: 430.1191711425781
INFO:root:Train (Epoch 145): Loss/seq after 03800 batchs: 429.280517578125
INFO:root:Train (Epoch 145): Loss/seq after 03850 batchs: 428.5032958984375
INFO:root:Train (Epoch 145): Loss/seq after 03900 batchs: 430.584228515625
INFO:root:Train (Epoch 145): Loss/seq after 03950 batchs: 432.8427429199219
INFO:root:Train (Epoch 145): Loss/seq after 04000 batchs: 430.1840515136719
INFO:root:Train (Epoch 145): Loss/seq after 04050 batchs: 427.5010070800781
INFO:root:Train (Epoch 145): Loss/seq after 04100 batchs: 426.73101806640625
INFO:root:Train (Epoch 145): Loss/seq after 04150 batchs: 427.16973876953125
INFO:root:Train (Epoch 145): Loss/seq after 04200 batchs: 426.3925476074219
INFO:root:Train (Epoch 145): Loss/seq after 04250 batchs: 425.2626037597656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 145): Loss/seq after 00000 batches: 353.02935791015625
INFO:root:# Valid (Epoch 145): Loss/seq after 00050 batches: 619.6799926757812
INFO:root:# Valid (Epoch 145): Loss/seq after 00100 batches: 623.1749267578125
INFO:root:# Valid (Epoch 145): Loss/seq after 00150 batches: 475.23333740234375
INFO:root:# Valid (Epoch 145): Loss/seq after 00200 batches: 446.59295654296875
INFO:root:Artifacts: Make stick videos for epoch 145
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_145_on_20220422_112538.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_145_index_1646_on_20220422_112538.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 146): Loss/seq after 00000 batchs: 549.3085327148438
INFO:root:Train (Epoch 146): Loss/seq after 00050 batchs: 595.4553833007812
INFO:root:Train (Epoch 146): Loss/seq after 00100 batchs: 618.6197509765625
INFO:root:Train (Epoch 146): Loss/seq after 00150 batchs: 571.7423706054688
INFO:root:Train (Epoch 146): Loss/seq after 00200 batchs: 628.365234375
INFO:root:Train (Epoch 146): Loss/seq after 00250 batchs: 712.6466674804688
INFO:root:Train (Epoch 146): Loss/seq after 00300 batchs: 717.8026123046875
INFO:root:Train (Epoch 146): Loss/seq after 00350 batchs: 675.13134765625
INFO:root:Train (Epoch 146): Loss/seq after 00400 batchs: 658.4942016601562
INFO:root:Train (Epoch 146): Loss/seq after 00450 batchs: 657.1987915039062
INFO:root:Train (Epoch 146): Loss/seq after 00500 batchs: 635.09130859375
INFO:root:Train (Epoch 146): Loss/seq after 00550 batchs: 619.591064453125
INFO:root:Train (Epoch 146): Loss/seq after 00600 batchs: 598.473876953125
INFO:root:Train (Epoch 146): Loss/seq after 00650 batchs: 574.14990234375
INFO:root:Train (Epoch 146): Loss/seq after 00700 batchs: 548.4364624023438
INFO:root:Train (Epoch 146): Loss/seq after 00750 batchs: 538.5418090820312
INFO:root:Train (Epoch 146): Loss/seq after 00800 batchs: 543.1295776367188
INFO:root:Train (Epoch 146): Loss/seq after 00850 batchs: 525.7355346679688
INFO:root:Train (Epoch 146): Loss/seq after 00900 batchs: 512.6245727539062
INFO:root:Train (Epoch 146): Loss/seq after 00950 batchs: 507.1116638183594
INFO:root:Train (Epoch 146): Loss/seq after 01000 batchs: 497.8573913574219
INFO:root:Train (Epoch 146): Loss/seq after 01050 batchs: 487.40435791015625
INFO:root:Train (Epoch 146): Loss/seq after 01100 batchs: 478.861328125
INFO:root:Train (Epoch 146): Loss/seq after 01150 batchs: 465.54443359375
INFO:root:Train (Epoch 146): Loss/seq after 01200 batchs: 471.13623046875
INFO:root:Train (Epoch 146): Loss/seq after 01250 batchs: 470.8272399902344
INFO:root:Train (Epoch 146): Loss/seq after 01300 batchs: 459.8716735839844
INFO:root:Train (Epoch 146): Loss/seq after 01350 batchs: 450.1972351074219
INFO:root:Train (Epoch 146): Loss/seq after 01400 batchs: 450.36895751953125
INFO:root:Train (Epoch 146): Loss/seq after 01450 batchs: 453.3803405761719
INFO:root:Train (Epoch 146): Loss/seq after 01500 batchs: 462.44366455078125
INFO:root:Train (Epoch 146): Loss/seq after 01550 batchs: 463.75091552734375
INFO:root:Train (Epoch 146): Loss/seq after 01600 batchs: 460.75482177734375
INFO:root:Train (Epoch 146): Loss/seq after 01650 batchs: 459.4591064453125
INFO:root:Train (Epoch 146): Loss/seq after 01700 batchs: 463.5711669921875
INFO:root:Train (Epoch 146): Loss/seq after 01750 batchs: 461.76580810546875
INFO:root:Train (Epoch 146): Loss/seq after 01800 batchs: 460.23284912109375
INFO:root:Train (Epoch 146): Loss/seq after 01850 batchs: 458.1200866699219
INFO:root:Train (Epoch 146): Loss/seq after 01900 batchs: 457.9514465332031
INFO:root:Train (Epoch 146): Loss/seq after 01950 batchs: 457.25042724609375
INFO:root:Train (Epoch 146): Loss/seq after 02000 batchs: 458.1822814941406
INFO:root:Train (Epoch 146): Loss/seq after 02050 batchs: 458.39727783203125
INFO:root:Train (Epoch 146): Loss/seq after 02100 batchs: 457.2899169921875
INFO:root:Train (Epoch 146): Loss/seq after 02150 batchs: 456.1370544433594
INFO:root:Train (Epoch 146): Loss/seq after 02200 batchs: 454.89068603515625
INFO:root:Train (Epoch 146): Loss/seq after 02250 batchs: 453.60980224609375
INFO:root:Train (Epoch 146): Loss/seq after 02300 batchs: 449.8815002441406
INFO:root:Train (Epoch 146): Loss/seq after 02350 batchs: 447.158447265625
INFO:root:Train (Epoch 146): Loss/seq after 02400 batchs: 447.9862976074219
INFO:root:Train (Epoch 146): Loss/seq after 02450 batchs: 444.6656799316406
INFO:root:Train (Epoch 146): Loss/seq after 02500 batchs: 437.81903076171875
INFO:root:Train (Epoch 146): Loss/seq after 02550 batchs: 431.45892333984375
INFO:root:Train (Epoch 146): Loss/seq after 02600 batchs: 427.8368835449219
INFO:root:Train (Epoch 146): Loss/seq after 02650 batchs: 423.773193359375
INFO:root:Train (Epoch 146): Loss/seq after 02700 batchs: 421.2708435058594
INFO:root:Train (Epoch 146): Loss/seq after 02750 batchs: 417.1004333496094
INFO:root:Train (Epoch 146): Loss/seq after 02800 batchs: 415.4523010253906
INFO:root:Train (Epoch 146): Loss/seq after 02850 batchs: 415.3962707519531
INFO:root:Train (Epoch 146): Loss/seq after 02900 batchs: 416.07318115234375
INFO:root:Train (Epoch 146): Loss/seq after 02950 batchs: 416.3377685546875
INFO:root:Train (Epoch 146): Loss/seq after 03000 batchs: 422.5617980957031
INFO:root:Train (Epoch 146): Loss/seq after 03050 batchs: 424.3951416015625
INFO:root:Train (Epoch 146): Loss/seq after 03100 batchs: 426.52386474609375
INFO:root:Train (Epoch 146): Loss/seq after 03150 batchs: 426.258056640625
INFO:root:Train (Epoch 146): Loss/seq after 03200 batchs: 426.2574157714844
INFO:root:Train (Epoch 146): Loss/seq after 03250 batchs: 426.8749084472656
INFO:root:Train (Epoch 146): Loss/seq after 03300 batchs: 426.256591796875
INFO:root:Train (Epoch 146): Loss/seq after 03350 batchs: 424.3909606933594
INFO:root:Train (Epoch 146): Loss/seq after 03400 batchs: 421.198974609375
INFO:root:Train (Epoch 146): Loss/seq after 03450 batchs: 419.8417663574219
INFO:root:Train (Epoch 146): Loss/seq after 03500 batchs: 421.1495666503906
INFO:root:Train (Epoch 146): Loss/seq after 03550 batchs: 419.63922119140625
INFO:root:Train (Epoch 146): Loss/seq after 03600 batchs: 426.4904479980469
INFO:root:Train (Epoch 146): Loss/seq after 03650 batchs: 424.88836669921875
INFO:root:Train (Epoch 146): Loss/seq after 03700 batchs: 427.3080749511719
INFO:root:Train (Epoch 146): Loss/seq after 03750 batchs: 431.9466857910156
INFO:root:Train (Epoch 146): Loss/seq after 03800 batchs: 431.00897216796875
INFO:root:Train (Epoch 146): Loss/seq after 03850 batchs: 430.1379699707031
INFO:root:Train (Epoch 146): Loss/seq after 03900 batchs: 432.25372314453125
INFO:root:Train (Epoch 146): Loss/seq after 03950 batchs: 434.5635681152344
INFO:root:Train (Epoch 146): Loss/seq after 04000 batchs: 431.9764709472656
INFO:root:Train (Epoch 146): Loss/seq after 04050 batchs: 429.296630859375
INFO:root:Train (Epoch 146): Loss/seq after 04100 batchs: 428.50872802734375
INFO:root:Train (Epoch 146): Loss/seq after 04150 batchs: 428.97918701171875
INFO:root:Train (Epoch 146): Loss/seq after 04200 batchs: 427.9388122558594
INFO:root:Train (Epoch 146): Loss/seq after 04250 batchs: 426.6494140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 146): Loss/seq after 00000 batches: 417.5799865722656
INFO:root:# Valid (Epoch 146): Loss/seq after 00050 batches: 638.8716430664062
INFO:root:# Valid (Epoch 146): Loss/seq after 00100 batches: 635.6536254882812
INFO:root:# Valid (Epoch 146): Loss/seq after 00150 batches: 480.3312683105469
INFO:root:# Valid (Epoch 146): Loss/seq after 00200 batches: 457.53326416015625
INFO:root:Artifacts: Make stick videos for epoch 146
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_146_on_20220422_113023.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_146_index_1407_on_20220422_113023.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 147): Loss/seq after 00000 batchs: 690.2623901367188
INFO:root:Train (Epoch 147): Loss/seq after 00050 batchs: 629.392578125
INFO:root:Train (Epoch 147): Loss/seq after 00100 batchs: 657.4560546875
INFO:root:Train (Epoch 147): Loss/seq after 00150 batchs: 605.0750122070312
INFO:root:Train (Epoch 147): Loss/seq after 00200 batchs: 652.6396484375
INFO:root:Train (Epoch 147): Loss/seq after 00250 batchs: 714.105712890625
INFO:root:Train (Epoch 147): Loss/seq after 00300 batchs: 718.184326171875
INFO:root:Train (Epoch 147): Loss/seq after 00350 batchs: 676.8556518554688
INFO:root:Train (Epoch 147): Loss/seq after 00400 batchs: 656.4410400390625
INFO:root:Train (Epoch 147): Loss/seq after 00450 batchs: 656.02978515625
INFO:root:Train (Epoch 147): Loss/seq after 00500 batchs: 636.0874633789062
INFO:root:Train (Epoch 147): Loss/seq after 00550 batchs: 620.2825927734375
INFO:root:Train (Epoch 147): Loss/seq after 00600 batchs: 599.869384765625
INFO:root:Train (Epoch 147): Loss/seq after 00650 batchs: 575.0974731445312
INFO:root:Train (Epoch 147): Loss/seq after 00700 batchs: 549.6076049804688
INFO:root:Train (Epoch 147): Loss/seq after 00750 batchs: 539.85791015625
INFO:root:Train (Epoch 147): Loss/seq after 00800 batchs: 545.027587890625
INFO:root:Train (Epoch 147): Loss/seq after 00850 batchs: 527.2470092773438
INFO:root:Train (Epoch 147): Loss/seq after 00900 batchs: 513.838134765625
INFO:root:Train (Epoch 147): Loss/seq after 00950 batchs: 508.2974548339844
INFO:root:Train (Epoch 147): Loss/seq after 01000 batchs: 498.3854064941406
INFO:root:Train (Epoch 147): Loss/seq after 01050 batchs: 487.7579040527344
INFO:root:Train (Epoch 147): Loss/seq after 01100 batchs: 478.8716125488281
INFO:root:Train (Epoch 147): Loss/seq after 01150 batchs: 465.42376708984375
INFO:root:Train (Epoch 147): Loss/seq after 01200 batchs: 470.598876953125
INFO:root:Train (Epoch 147): Loss/seq after 01250 batchs: 470.4351501464844
INFO:root:Train (Epoch 147): Loss/seq after 01300 batchs: 459.0518798828125
INFO:root:Train (Epoch 147): Loss/seq after 01350 batchs: 449.5235900878906
INFO:root:Train (Epoch 147): Loss/seq after 01400 batchs: 449.60076904296875
INFO:root:Train (Epoch 147): Loss/seq after 01450 batchs: 452.64093017578125
INFO:root:Train (Epoch 147): Loss/seq after 01500 batchs: 460.741943359375
INFO:root:Train (Epoch 147): Loss/seq after 01550 batchs: 461.7625427246094
INFO:root:Train (Epoch 147): Loss/seq after 01600 batchs: 458.5685729980469
INFO:root:Train (Epoch 147): Loss/seq after 01650 batchs: 457.28143310546875
INFO:root:Train (Epoch 147): Loss/seq after 01700 batchs: 461.3936462402344
INFO:root:Train (Epoch 147): Loss/seq after 01750 batchs: 459.69329833984375
INFO:root:Train (Epoch 147): Loss/seq after 01800 batchs: 458.1531982421875
INFO:root:Train (Epoch 147): Loss/seq after 01850 batchs: 455.8186340332031
INFO:root:Train (Epoch 147): Loss/seq after 01900 batchs: 455.37213134765625
INFO:root:Train (Epoch 147): Loss/seq after 01950 batchs: 454.4013671875
INFO:root:Train (Epoch 147): Loss/seq after 02000 batchs: 455.2681579589844
INFO:root:Train (Epoch 147): Loss/seq after 02050 batchs: 455.4857177734375
INFO:root:Train (Epoch 147): Loss/seq after 02100 batchs: 454.2767028808594
INFO:root:Train (Epoch 147): Loss/seq after 02150 batchs: 453.3465881347656
INFO:root:Train (Epoch 147): Loss/seq after 02200 batchs: 452.0351257324219
INFO:root:Train (Epoch 147): Loss/seq after 02250 batchs: 451.28912353515625
INFO:root:Train (Epoch 147): Loss/seq after 02300 batchs: 447.23101806640625
INFO:root:Train (Epoch 147): Loss/seq after 02350 batchs: 444.4757385253906
INFO:root:Train (Epoch 147): Loss/seq after 02400 batchs: 445.3621826171875
INFO:root:Train (Epoch 147): Loss/seq after 02450 batchs: 442.1529846191406
INFO:root:Train (Epoch 147): Loss/seq after 02500 batchs: 435.3662109375
INFO:root:Train (Epoch 147): Loss/seq after 02550 batchs: 429.1358642578125
INFO:root:Train (Epoch 147): Loss/seq after 02600 batchs: 425.728271484375
INFO:root:Train (Epoch 147): Loss/seq after 02650 batchs: 421.7655029296875
INFO:root:Train (Epoch 147): Loss/seq after 02700 batchs: 419.0567932128906
INFO:root:Train (Epoch 147): Loss/seq after 02750 batchs: 414.6031494140625
INFO:root:Train (Epoch 147): Loss/seq after 02800 batchs: 412.6527404785156
INFO:root:Train (Epoch 147): Loss/seq after 02850 batchs: 412.42529296875
INFO:root:Train (Epoch 147): Loss/seq after 02900 batchs: 413.26287841796875
INFO:root:Train (Epoch 147): Loss/seq after 02950 batchs: 413.6993713378906
INFO:root:Train (Epoch 147): Loss/seq after 03000 batchs: 419.7335205078125
INFO:root:Train (Epoch 147): Loss/seq after 03050 batchs: 421.8217468261719
INFO:root:Train (Epoch 147): Loss/seq after 03100 batchs: 424.5671081542969
INFO:root:Train (Epoch 147): Loss/seq after 03150 batchs: 424.3525695800781
INFO:root:Train (Epoch 147): Loss/seq after 03200 batchs: 424.4434509277344
INFO:root:Train (Epoch 147): Loss/seq after 03250 batchs: 424.45697021484375
INFO:root:Train (Epoch 147): Loss/seq after 03300 batchs: 423.94598388671875
INFO:root:Train (Epoch 147): Loss/seq after 03350 batchs: 422.3521423339844
INFO:root:Train (Epoch 147): Loss/seq after 03400 batchs: 419.0928039550781
INFO:root:Train (Epoch 147): Loss/seq after 03450 batchs: 417.7843322753906
INFO:root:Train (Epoch 147): Loss/seq after 03500 batchs: 419.11138916015625
INFO:root:Train (Epoch 147): Loss/seq after 03550 batchs: 417.3690185546875
INFO:root:Train (Epoch 147): Loss/seq after 03600 batchs: 424.0659484863281
INFO:root:Train (Epoch 147): Loss/seq after 03650 batchs: 422.4753723144531
INFO:root:Train (Epoch 147): Loss/seq after 03700 batchs: 425.3131103515625
INFO:root:Train (Epoch 147): Loss/seq after 03750 batchs: 429.86578369140625
INFO:root:Train (Epoch 147): Loss/seq after 03800 batchs: 428.96893310546875
INFO:root:Train (Epoch 147): Loss/seq after 03850 batchs: 428.30419921875
INFO:root:Train (Epoch 147): Loss/seq after 03900 batchs: 430.6064758300781
INFO:root:Train (Epoch 147): Loss/seq after 03950 batchs: 432.9643859863281
INFO:root:Train (Epoch 147): Loss/seq after 04000 batchs: 430.36090087890625
INFO:root:Train (Epoch 147): Loss/seq after 04050 batchs: 427.6679382324219
INFO:root:Train (Epoch 147): Loss/seq after 04100 batchs: 426.9333190917969
INFO:root:Train (Epoch 147): Loss/seq after 04150 batchs: 427.4627685546875
INFO:root:Train (Epoch 147): Loss/seq after 04200 batchs: 426.441650390625
INFO:root:Train (Epoch 147): Loss/seq after 04250 batchs: 425.16351318359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 147): Loss/seq after 00000 batches: 317.0650329589844
INFO:root:# Valid (Epoch 147): Loss/seq after 00050 batches: 608.5216674804688
INFO:root:# Valid (Epoch 147): Loss/seq after 00100 batches: 636.5103759765625
INFO:root:# Valid (Epoch 147): Loss/seq after 00150 batches: 477.9678649902344
INFO:root:# Valid (Epoch 147): Loss/seq after 00200 batches: 448.5545349121094
INFO:root:Artifacts: Make stick videos for epoch 147
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_147_on_20220422_113507.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_147_index_619_on_20220422_113507.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 148): Loss/seq after 00000 batchs: 533.4602661132812
INFO:root:Train (Epoch 148): Loss/seq after 00050 batchs: 615.4686889648438
INFO:root:Train (Epoch 148): Loss/seq after 00100 batchs: 640.4019165039062
INFO:root:Train (Epoch 148): Loss/seq after 00150 batchs: 588.2438354492188
INFO:root:Train (Epoch 148): Loss/seq after 00200 batchs: 630.8048706054688
INFO:root:Train (Epoch 148): Loss/seq after 00250 batchs: 685.0504760742188
INFO:root:Train (Epoch 148): Loss/seq after 00300 batchs: 693.6397705078125
INFO:root:Train (Epoch 148): Loss/seq after 00350 batchs: 653.7210083007812
INFO:root:Train (Epoch 148): Loss/seq after 00400 batchs: 637.6973266601562
INFO:root:Train (Epoch 148): Loss/seq after 00450 batchs: 638.2835083007812
INFO:root:Train (Epoch 148): Loss/seq after 00500 batchs: 614.37890625
INFO:root:Train (Epoch 148): Loss/seq after 00550 batchs: 600.826171875
INFO:root:Train (Epoch 148): Loss/seq after 00600 batchs: 581.9130249023438
INFO:root:Train (Epoch 148): Loss/seq after 00650 batchs: 558.2672729492188
INFO:root:Train (Epoch 148): Loss/seq after 00700 batchs: 534.7040405273438
INFO:root:Train (Epoch 148): Loss/seq after 00750 batchs: 525.7111206054688
INFO:root:Train (Epoch 148): Loss/seq after 00800 batchs: 531.4570922851562
INFO:root:Train (Epoch 148): Loss/seq after 00850 batchs: 514.8206787109375
INFO:root:Train (Epoch 148): Loss/seq after 00900 batchs: 501.99700927734375
INFO:root:Train (Epoch 148): Loss/seq after 00950 batchs: 497.4181213378906
INFO:root:Train (Epoch 148): Loss/seq after 01000 batchs: 487.5979919433594
INFO:root:Train (Epoch 148): Loss/seq after 01050 batchs: 477.77520751953125
INFO:root:Train (Epoch 148): Loss/seq after 01100 batchs: 469.2666320800781
INFO:root:Train (Epoch 148): Loss/seq after 01150 batchs: 456.3199462890625
INFO:root:Train (Epoch 148): Loss/seq after 01200 batchs: 461.4331359863281
INFO:root:Train (Epoch 148): Loss/seq after 01250 batchs: 461.47381591796875
INFO:root:Train (Epoch 148): Loss/seq after 01300 batchs: 450.8066711425781
INFO:root:Train (Epoch 148): Loss/seq after 01350 batchs: 441.5428771972656
INFO:root:Train (Epoch 148): Loss/seq after 01400 batchs: 443.24346923828125
INFO:root:Train (Epoch 148): Loss/seq after 01450 batchs: 446.6824035644531
INFO:root:Train (Epoch 148): Loss/seq after 01500 batchs: 454.9260559082031
INFO:root:Train (Epoch 148): Loss/seq after 01550 batchs: 455.776611328125
INFO:root:Train (Epoch 148): Loss/seq after 01600 batchs: 452.5225830078125
INFO:root:Train (Epoch 148): Loss/seq after 01650 batchs: 451.68634033203125
INFO:root:Train (Epoch 148): Loss/seq after 01700 batchs: 455.9536437988281
INFO:root:Train (Epoch 148): Loss/seq after 01750 batchs: 454.25238037109375
INFO:root:Train (Epoch 148): Loss/seq after 01800 batchs: 452.9610290527344
INFO:root:Train (Epoch 148): Loss/seq after 01850 batchs: 450.8687438964844
INFO:root:Train (Epoch 148): Loss/seq after 01900 batchs: 450.4732666015625
INFO:root:Train (Epoch 148): Loss/seq after 01950 batchs: 449.5343017578125
INFO:root:Train (Epoch 148): Loss/seq after 02000 batchs: 450.33551025390625
INFO:root:Train (Epoch 148): Loss/seq after 02050 batchs: 450.5930480957031
INFO:root:Train (Epoch 148): Loss/seq after 02100 batchs: 450.04315185546875
INFO:root:Train (Epoch 148): Loss/seq after 02150 batchs: 449.1363220214844
INFO:root:Train (Epoch 148): Loss/seq after 02200 batchs: 447.9576721191406
INFO:root:Train (Epoch 148): Loss/seq after 02250 batchs: 447.21710205078125
INFO:root:Train (Epoch 148): Loss/seq after 02300 batchs: 443.4451599121094
INFO:root:Train (Epoch 148): Loss/seq after 02350 batchs: 440.53302001953125
INFO:root:Train (Epoch 148): Loss/seq after 02400 batchs: 441.4091491699219
INFO:root:Train (Epoch 148): Loss/seq after 02450 batchs: 438.1689147949219
INFO:root:Train (Epoch 148): Loss/seq after 02500 batchs: 431.4220886230469
INFO:root:Train (Epoch 148): Loss/seq after 02550 batchs: 425.1561584472656
INFO:root:Train (Epoch 148): Loss/seq after 02600 batchs: 421.2550354003906
INFO:root:Train (Epoch 148): Loss/seq after 02650 batchs: 417.134765625
INFO:root:Train (Epoch 148): Loss/seq after 02700 batchs: 414.4710388183594
INFO:root:Train (Epoch 148): Loss/seq after 02750 batchs: 409.942138671875
INFO:root:Train (Epoch 148): Loss/seq after 02800 batchs: 408.07867431640625
INFO:root:Train (Epoch 148): Loss/seq after 02850 batchs: 408.362548828125
INFO:root:Train (Epoch 148): Loss/seq after 02900 batchs: 409.54644775390625
INFO:root:Train (Epoch 148): Loss/seq after 02950 batchs: 409.88201904296875
INFO:root:Train (Epoch 148): Loss/seq after 03000 batchs: 416.0474853515625
INFO:root:Train (Epoch 148): Loss/seq after 03050 batchs: 418.14825439453125
INFO:root:Train (Epoch 148): Loss/seq after 03100 batchs: 420.6738586425781
INFO:root:Train (Epoch 148): Loss/seq after 03150 batchs: 420.3175964355469
INFO:root:Train (Epoch 148): Loss/seq after 03200 batchs: 420.159912109375
INFO:root:Train (Epoch 148): Loss/seq after 03250 batchs: 420.10699462890625
INFO:root:Train (Epoch 148): Loss/seq after 03300 batchs: 419.6711730957031
INFO:root:Train (Epoch 148): Loss/seq after 03350 batchs: 417.9288330078125
INFO:root:Train (Epoch 148): Loss/seq after 03400 batchs: 414.7757263183594
INFO:root:Train (Epoch 148): Loss/seq after 03450 batchs: 413.2138366699219
INFO:root:Train (Epoch 148): Loss/seq after 03500 batchs: 414.28692626953125
INFO:root:Train (Epoch 148): Loss/seq after 03550 batchs: 412.52288818359375
INFO:root:Train (Epoch 148): Loss/seq after 03600 batchs: 419.38958740234375
INFO:root:Train (Epoch 148): Loss/seq after 03650 batchs: 417.9205322265625
INFO:root:Train (Epoch 148): Loss/seq after 03700 batchs: 420.669189453125
INFO:root:Train (Epoch 148): Loss/seq after 03750 batchs: 425.5353088378906
INFO:root:Train (Epoch 148): Loss/seq after 03800 batchs: 424.6993103027344
INFO:root:Train (Epoch 148): Loss/seq after 03850 batchs: 423.99462890625
INFO:root:Train (Epoch 148): Loss/seq after 03900 batchs: 425.9404602050781
INFO:root:Train (Epoch 148): Loss/seq after 03950 batchs: 427.95379638671875
INFO:root:Train (Epoch 148): Loss/seq after 04000 batchs: 425.2898254394531
INFO:root:Train (Epoch 148): Loss/seq after 04050 batchs: 422.6440734863281
INFO:root:Train (Epoch 148): Loss/seq after 04100 batchs: 421.91497802734375
INFO:root:Train (Epoch 148): Loss/seq after 04150 batchs: 422.3612060546875
INFO:root:Train (Epoch 148): Loss/seq after 04200 batchs: 421.28887939453125
INFO:root:Train (Epoch 148): Loss/seq after 04250 batchs: 420.04742431640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 148): Loss/seq after 00000 batches: 301.055419921875
INFO:root:# Valid (Epoch 148): Loss/seq after 00050 batches: 610.2076416015625
INFO:root:# Valid (Epoch 148): Loss/seq after 00100 batches: 602.940185546875
INFO:root:# Valid (Epoch 148): Loss/seq after 00150 batches: 455.4778137207031
INFO:root:# Valid (Epoch 148): Loss/seq after 00200 batches: 428.1340026855469
INFO:root:Artifacts: Make stick videos for epoch 148
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_148_on_20220422_114007.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_148_index_375_on_20220422_114007.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 149): Loss/seq after 00000 batchs: 553.5943603515625
INFO:root:Train (Epoch 149): Loss/seq after 00050 batchs: 589.2813720703125
INFO:root:Train (Epoch 149): Loss/seq after 00100 batchs: 609.1747436523438
INFO:root:Train (Epoch 149): Loss/seq after 00150 batchs: 560.8271484375
INFO:root:Train (Epoch 149): Loss/seq after 00200 batchs: 613.8616943359375
INFO:root:Train (Epoch 149): Loss/seq after 00250 batchs: 698.7359619140625
INFO:root:Train (Epoch 149): Loss/seq after 00300 batchs: 702.6904907226562
INFO:root:Train (Epoch 149): Loss/seq after 00350 batchs: 661.0350952148438
INFO:root:Train (Epoch 149): Loss/seq after 00400 batchs: 642.4237060546875
INFO:root:Train (Epoch 149): Loss/seq after 00450 batchs: 642.8504028320312
INFO:root:Train (Epoch 149): Loss/seq after 00500 batchs: 622.94482421875
INFO:root:Train (Epoch 149): Loss/seq after 00550 batchs: 608.7476806640625
INFO:root:Train (Epoch 149): Loss/seq after 00600 batchs: 588.6934814453125
INFO:root:Train (Epoch 149): Loss/seq after 00650 batchs: 565.1373291015625
INFO:root:Train (Epoch 149): Loss/seq after 00700 batchs: 540.6873168945312
INFO:root:Train (Epoch 149): Loss/seq after 00750 batchs: 532.823486328125
INFO:root:Train (Epoch 149): Loss/seq after 00800 batchs: 537.1668701171875
INFO:root:Train (Epoch 149): Loss/seq after 00850 batchs: 519.7198486328125
INFO:root:Train (Epoch 149): Loss/seq after 00900 batchs: 506.2781066894531
INFO:root:Train (Epoch 149): Loss/seq after 00950 batchs: 501.3670959472656
INFO:root:Train (Epoch 149): Loss/seq after 01000 batchs: 490.8103942871094
INFO:root:Train (Epoch 149): Loss/seq after 01050 batchs: 480.4183654785156
INFO:root:Train (Epoch 149): Loss/seq after 01100 batchs: 471.3421936035156
INFO:root:Train (Epoch 149): Loss/seq after 01150 batchs: 458.248779296875
INFO:root:Train (Epoch 149): Loss/seq after 01200 batchs: 463.6653747558594
INFO:root:Train (Epoch 149): Loss/seq after 01250 batchs: 463.47686767578125
INFO:root:Train (Epoch 149): Loss/seq after 01300 batchs: 452.6630554199219
INFO:root:Train (Epoch 149): Loss/seq after 01350 batchs: 442.9919738769531
INFO:root:Train (Epoch 149): Loss/seq after 01400 batchs: 443.2271423339844
INFO:root:Train (Epoch 149): Loss/seq after 01450 batchs: 446.5292053222656
INFO:root:Train (Epoch 149): Loss/seq after 01500 batchs: 454.6647033691406
INFO:root:Train (Epoch 149): Loss/seq after 01550 batchs: 455.6924743652344
INFO:root:Train (Epoch 149): Loss/seq after 01600 batchs: 452.6748352050781
INFO:root:Train (Epoch 149): Loss/seq after 01650 batchs: 452.10382080078125
INFO:root:Train (Epoch 149): Loss/seq after 01700 batchs: 457.1097106933594
INFO:root:Train (Epoch 149): Loss/seq after 01750 batchs: 455.7610168457031
INFO:root:Train (Epoch 149): Loss/seq after 01800 batchs: 454.6189880371094
INFO:root:Train (Epoch 149): Loss/seq after 01850 batchs: 452.6432800292969
INFO:root:Train (Epoch 149): Loss/seq after 01900 batchs: 452.736328125
INFO:root:Train (Epoch 149): Loss/seq after 01950 batchs: 451.8100280761719
INFO:root:Train (Epoch 149): Loss/seq after 02000 batchs: 452.5321350097656
INFO:root:Train (Epoch 149): Loss/seq after 02050 batchs: 452.65777587890625
INFO:root:Train (Epoch 149): Loss/seq after 02100 batchs: 451.4066162109375
INFO:root:Train (Epoch 149): Loss/seq after 02150 batchs: 450.3375244140625
INFO:root:Train (Epoch 149): Loss/seq after 02200 batchs: 449.0709228515625
INFO:root:Train (Epoch 149): Loss/seq after 02250 batchs: 448.1711120605469
INFO:root:Train (Epoch 149): Loss/seq after 02300 batchs: 444.04986572265625
INFO:root:Train (Epoch 149): Loss/seq after 02350 batchs: 441.07135009765625
INFO:root:Train (Epoch 149): Loss/seq after 02400 batchs: 441.7687072753906
INFO:root:Train (Epoch 149): Loss/seq after 02450 batchs: 438.60906982421875
INFO:root:Train (Epoch 149): Loss/seq after 02500 batchs: 431.84521484375
INFO:root:Train (Epoch 149): Loss/seq after 02550 batchs: 425.5057678222656
INFO:root:Train (Epoch 149): Loss/seq after 02600 batchs: 421.92974853515625
INFO:root:Train (Epoch 149): Loss/seq after 02650 batchs: 417.771728515625
INFO:root:Train (Epoch 149): Loss/seq after 02700 batchs: 414.9678039550781
INFO:root:Train (Epoch 149): Loss/seq after 02750 batchs: 410.53118896484375
INFO:root:Train (Epoch 149): Loss/seq after 02800 batchs: 408.6876220703125
INFO:root:Train (Epoch 149): Loss/seq after 02850 batchs: 408.38153076171875
INFO:root:Train (Epoch 149): Loss/seq after 02900 batchs: 409.45880126953125
INFO:root:Train (Epoch 149): Loss/seq after 02950 batchs: 409.8984375
INFO:root:Train (Epoch 149): Loss/seq after 03000 batchs: 416.1883239746094
INFO:root:Train (Epoch 149): Loss/seq after 03050 batchs: 418.2793884277344
INFO:root:Train (Epoch 149): Loss/seq after 03100 batchs: 420.29913330078125
INFO:root:Train (Epoch 149): Loss/seq after 03150 batchs: 420.04364013671875
INFO:root:Train (Epoch 149): Loss/seq after 03200 batchs: 419.80889892578125
INFO:root:Train (Epoch 149): Loss/seq after 03250 batchs: 419.1946716308594
INFO:root:Train (Epoch 149): Loss/seq after 03300 batchs: 418.39617919921875
INFO:root:Train (Epoch 149): Loss/seq after 03350 batchs: 416.68365478515625
INFO:root:Train (Epoch 149): Loss/seq after 03400 batchs: 413.5007019042969
INFO:root:Train (Epoch 149): Loss/seq after 03450 batchs: 412.13092041015625
INFO:root:Train (Epoch 149): Loss/seq after 03500 batchs: 413.3345947265625
INFO:root:Train (Epoch 149): Loss/seq after 03550 batchs: 411.54132080078125
INFO:root:Train (Epoch 149): Loss/seq after 03600 batchs: 418.2945861816406
INFO:root:Train (Epoch 149): Loss/seq after 03650 batchs: 417.2649841308594
INFO:root:Train (Epoch 149): Loss/seq after 03700 batchs: 419.9985046386719
INFO:root:Train (Epoch 149): Loss/seq after 03750 batchs: 424.5435791015625
INFO:root:Train (Epoch 149): Loss/seq after 03800 batchs: 423.7060852050781
INFO:root:Train (Epoch 149): Loss/seq after 03850 batchs: 422.97021484375
INFO:root:Train (Epoch 149): Loss/seq after 03900 batchs: 424.98919677734375
INFO:root:Train (Epoch 149): Loss/seq after 03950 batchs: 427.46038818359375
INFO:root:Train (Epoch 149): Loss/seq after 04000 batchs: 424.8575134277344
INFO:root:Train (Epoch 149): Loss/seq after 04050 batchs: 422.21575927734375
INFO:root:Train (Epoch 149): Loss/seq after 04100 batchs: 421.4229431152344
INFO:root:Train (Epoch 149): Loss/seq after 04150 batchs: 421.8282775878906
INFO:root:Train (Epoch 149): Loss/seq after 04200 batchs: 420.9632568359375
INFO:root:Train (Epoch 149): Loss/seq after 04250 batchs: 419.74932861328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 149): Loss/seq after 00000 batches: 435.4018859863281
INFO:root:# Valid (Epoch 149): Loss/seq after 00050 batches: 626.5706787109375
INFO:root:# Valid (Epoch 149): Loss/seq after 00100 batches: 630.5687255859375
INFO:root:# Valid (Epoch 149): Loss/seq after 00150 batches: 479.03564453125
INFO:root:# Valid (Epoch 149): Loss/seq after 00200 batches: 450.64593505859375
INFO:root:Artifacts: Make stick videos for epoch 149
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_149_on_20220422_114456.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_149_index_1250_on_20220422_114456.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 150): Loss/seq after 00000 batchs: 724.9993286132812
INFO:root:Train (Epoch 150): Loss/seq after 00050 batchs: 603.8021850585938
INFO:root:Train (Epoch 150): Loss/seq after 00100 batchs: 627.7337646484375
INFO:root:Train (Epoch 150): Loss/seq after 00150 batchs: 574.3673706054688
INFO:root:Train (Epoch 150): Loss/seq after 00200 batchs: 615.1014404296875
INFO:root:Train (Epoch 150): Loss/seq after 00250 batchs: 686.0518188476562
INFO:root:Train (Epoch 150): Loss/seq after 00300 batchs: 694.2384643554688
INFO:root:Train (Epoch 150): Loss/seq after 00350 batchs: 654.0726928710938
INFO:root:Train (Epoch 150): Loss/seq after 00400 batchs: 635.4422607421875
INFO:root:Train (Epoch 150): Loss/seq after 00450 batchs: 636.7077026367188
INFO:root:Train (Epoch 150): Loss/seq after 00500 batchs: 616.0974731445312
INFO:root:Train (Epoch 150): Loss/seq after 00550 batchs: 601.596923828125
INFO:root:Train (Epoch 150): Loss/seq after 00600 batchs: 581.8129272460938
INFO:root:Train (Epoch 150): Loss/seq after 00650 batchs: 557.9893188476562
INFO:root:Train (Epoch 150): Loss/seq after 00700 batchs: 532.5689086914062
INFO:root:Train (Epoch 150): Loss/seq after 00750 batchs: 521.9685668945312
INFO:root:Train (Epoch 150): Loss/seq after 00800 batchs: 528.3604736328125
INFO:root:Train (Epoch 150): Loss/seq after 00850 batchs: 511.3681945800781
INFO:root:Train (Epoch 150): Loss/seq after 00900 batchs: 499.2789306640625
INFO:root:Train (Epoch 150): Loss/seq after 00950 batchs: 494.98052978515625
INFO:root:Train (Epoch 150): Loss/seq after 01000 batchs: 485.22381591796875
INFO:root:Train (Epoch 150): Loss/seq after 01050 batchs: 479.6830139160156
INFO:root:Train (Epoch 150): Loss/seq after 01100 batchs: 471.45001220703125
INFO:root:Train (Epoch 150): Loss/seq after 01150 batchs: 458.3576965332031
INFO:root:Train (Epoch 150): Loss/seq after 01200 batchs: 463.7767028808594
INFO:root:Train (Epoch 150): Loss/seq after 01250 batchs: 463.5010070800781
INFO:root:Train (Epoch 150): Loss/seq after 01300 batchs: 452.34942626953125
INFO:root:Train (Epoch 150): Loss/seq after 01350 batchs: 442.5545349121094
INFO:root:Train (Epoch 150): Loss/seq after 01400 batchs: 442.4891052246094
INFO:root:Train (Epoch 150): Loss/seq after 01450 batchs: 445.8647766113281
INFO:root:Train (Epoch 150): Loss/seq after 01500 batchs: 454.40447998046875
INFO:root:Train (Epoch 150): Loss/seq after 01550 batchs: 455.6942443847656
INFO:root:Train (Epoch 150): Loss/seq after 01600 batchs: 452.37579345703125
INFO:root:Train (Epoch 150): Loss/seq after 01650 batchs: 451.46051025390625
INFO:root:Train (Epoch 150): Loss/seq after 01700 batchs: 455.6443786621094
INFO:root:Train (Epoch 150): Loss/seq after 01750 batchs: 454.0606689453125
INFO:root:Train (Epoch 150): Loss/seq after 01800 batchs: 452.6339416503906
INFO:root:Train (Epoch 150): Loss/seq after 01850 batchs: 450.4072265625
INFO:root:Train (Epoch 150): Loss/seq after 01900 batchs: 449.95819091796875
INFO:root:Train (Epoch 150): Loss/seq after 01950 batchs: 448.9289245605469
INFO:root:Train (Epoch 150): Loss/seq after 02000 batchs: 449.7453308105469
INFO:root:Train (Epoch 150): Loss/seq after 02050 batchs: 449.9505310058594
INFO:root:Train (Epoch 150): Loss/seq after 02100 batchs: 448.7239685058594
INFO:root:Train (Epoch 150): Loss/seq after 02150 batchs: 447.7991943359375
INFO:root:Train (Epoch 150): Loss/seq after 02200 batchs: 446.6324462890625
INFO:root:Train (Epoch 150): Loss/seq after 02250 batchs: 445.3546142578125
INFO:root:Train (Epoch 150): Loss/seq after 02300 batchs: 441.2196044921875
INFO:root:Train (Epoch 150): Loss/seq after 02350 batchs: 438.1938171386719
INFO:root:Train (Epoch 150): Loss/seq after 02400 batchs: 438.8171691894531
INFO:root:Train (Epoch 150): Loss/seq after 02450 batchs: 435.61529541015625
INFO:root:Train (Epoch 150): Loss/seq after 02500 batchs: 428.8782043457031
INFO:root:Train (Epoch 150): Loss/seq after 02550 batchs: 422.6183166503906
INFO:root:Train (Epoch 150): Loss/seq after 02600 batchs: 419.0464172363281
INFO:root:Train (Epoch 150): Loss/seq after 02650 batchs: 414.77154541015625
INFO:root:Train (Epoch 150): Loss/seq after 02700 batchs: 412.1221008300781
INFO:root:Train (Epoch 150): Loss/seq after 02750 batchs: 407.8923645019531
INFO:root:Train (Epoch 150): Loss/seq after 02800 batchs: 406.17095947265625
INFO:root:Train (Epoch 150): Loss/seq after 02850 batchs: 406.0355224609375
INFO:root:Train (Epoch 150): Loss/seq after 02900 batchs: 406.7034606933594
INFO:root:Train (Epoch 150): Loss/seq after 02950 batchs: 407.0170593261719
INFO:root:Train (Epoch 150): Loss/seq after 03000 batchs: 413.2589416503906
INFO:root:Train (Epoch 150): Loss/seq after 03050 batchs: 415.1602783203125
INFO:root:Train (Epoch 150): Loss/seq after 03100 batchs: 416.9530944824219
INFO:root:Train (Epoch 150): Loss/seq after 03150 batchs: 416.69537353515625
INFO:root:Train (Epoch 150): Loss/seq after 03200 batchs: 416.6105651855469
INFO:root:Train (Epoch 150): Loss/seq after 03250 batchs: 416.4201354980469
INFO:root:Train (Epoch 150): Loss/seq after 03300 batchs: 415.861572265625
INFO:root:Train (Epoch 150): Loss/seq after 03350 batchs: 414.3647155761719
INFO:root:Train (Epoch 150): Loss/seq after 03400 batchs: 411.2107849121094
INFO:root:Train (Epoch 150): Loss/seq after 03450 batchs: 409.53070068359375
INFO:root:Train (Epoch 150): Loss/seq after 03500 batchs: 410.3559265136719
INFO:root:Train (Epoch 150): Loss/seq after 03550 batchs: 408.4979248046875
INFO:root:Train (Epoch 150): Loss/seq after 03600 batchs: 415.0767517089844
INFO:root:Train (Epoch 150): Loss/seq after 03650 batchs: 413.4638366699219
INFO:root:Train (Epoch 150): Loss/seq after 03700 batchs: 415.94354248046875
INFO:root:Train (Epoch 150): Loss/seq after 03750 batchs: 420.5765075683594
INFO:root:Train (Epoch 150): Loss/seq after 03800 batchs: 419.7202453613281
INFO:root:Train (Epoch 150): Loss/seq after 03850 batchs: 418.92962646484375
INFO:root:Train (Epoch 150): Loss/seq after 03900 batchs: 421.0081787109375
INFO:root:Train (Epoch 150): Loss/seq after 03950 batchs: 423.2445373535156
INFO:root:Train (Epoch 150): Loss/seq after 04000 batchs: 420.66632080078125
INFO:root:Train (Epoch 150): Loss/seq after 04050 batchs: 418.0398254394531
INFO:root:Train (Epoch 150): Loss/seq after 04100 batchs: 417.2482604980469
INFO:root:Train (Epoch 150): Loss/seq after 04150 batchs: 417.6826171875
INFO:root:Train (Epoch 150): Loss/seq after 04200 batchs: 416.66229248046875
INFO:root:Train (Epoch 150): Loss/seq after 04250 batchs: 415.4168701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 150): Loss/seq after 00000 batches: 343.6634216308594
INFO:root:# Valid (Epoch 150): Loss/seq after 00050 batches: 629.551513671875
INFO:root:# Valid (Epoch 150): Loss/seq after 00100 batches: 612.7213745117188
INFO:root:# Valid (Epoch 150): Loss/seq after 00150 batches: 465.30255126953125
INFO:root:# Valid (Epoch 150): Loss/seq after 00200 batches: 437.90960693359375
INFO:root:Artifacts: Make stick videos for epoch 150
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_150_on_20220422_114940.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_150_index_1387_on_20220422_114940.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 151): Loss/seq after 00000 batchs: 622.7599487304688
INFO:root:Train (Epoch 151): Loss/seq after 00050 batchs: 571.2992553710938
INFO:root:Train (Epoch 151): Loss/seq after 00100 batchs: 581.5204467773438
INFO:root:Train (Epoch 151): Loss/seq after 00150 batchs: 546.2161254882812
INFO:root:Train (Epoch 151): Loss/seq after 00200 batchs: 596.6646118164062
INFO:root:Train (Epoch 151): Loss/seq after 00250 batchs: 682.692626953125
INFO:root:Train (Epoch 151): Loss/seq after 00300 batchs: 693.6969604492188
INFO:root:Train (Epoch 151): Loss/seq after 00350 batchs: 656.4947509765625
INFO:root:Train (Epoch 151): Loss/seq after 00400 batchs: 643.612060546875
INFO:root:Train (Epoch 151): Loss/seq after 00450 batchs: 645.7034301757812
INFO:root:Train (Epoch 151): Loss/seq after 00500 batchs: 625.5782470703125
INFO:root:Train (Epoch 151): Loss/seq after 00550 batchs: 611.33349609375
INFO:root:Train (Epoch 151): Loss/seq after 00600 batchs: 593.517333984375
INFO:root:Train (Epoch 151): Loss/seq after 00650 batchs: 570.7574462890625
INFO:root:Train (Epoch 151): Loss/seq after 00700 batchs: 545.7137451171875
INFO:root:Train (Epoch 151): Loss/seq after 00750 batchs: 534.9973754882812
INFO:root:Train (Epoch 151): Loss/seq after 00800 batchs: 543.6373901367188
INFO:root:Train (Epoch 151): Loss/seq after 00850 batchs: 525.9718017578125
INFO:root:Train (Epoch 151): Loss/seq after 00900 batchs: 513.88134765625
INFO:root:Train (Epoch 151): Loss/seq after 00950 batchs: 509.75262451171875
INFO:root:Train (Epoch 151): Loss/seq after 01000 batchs: 500.18414306640625
INFO:root:Train (Epoch 151): Loss/seq after 01050 batchs: 494.86163330078125
INFO:root:Train (Epoch 151): Loss/seq after 01100 batchs: 487.3558349609375
INFO:root:Train (Epoch 151): Loss/seq after 01150 batchs: 473.8078308105469
INFO:root:Train (Epoch 151): Loss/seq after 01200 batchs: 478.43896484375
INFO:root:Train (Epoch 151): Loss/seq after 01250 batchs: 477.9426574707031
INFO:root:Train (Epoch 151): Loss/seq after 01300 batchs: 466.26483154296875
INFO:root:Train (Epoch 151): Loss/seq after 01350 batchs: 455.7843933105469
INFO:root:Train (Epoch 151): Loss/seq after 01400 batchs: 456.2014465332031
INFO:root:Train (Epoch 151): Loss/seq after 01450 batchs: 459.613525390625
INFO:root:Train (Epoch 151): Loss/seq after 01500 batchs: 467.4607849121094
INFO:root:Train (Epoch 151): Loss/seq after 01550 batchs: 468.662353515625
INFO:root:Train (Epoch 151): Loss/seq after 01600 batchs: 465.3127136230469
INFO:root:Train (Epoch 151): Loss/seq after 01650 batchs: 463.9395751953125
INFO:root:Train (Epoch 151): Loss/seq after 01700 batchs: 467.7762145996094
INFO:root:Train (Epoch 151): Loss/seq after 01750 batchs: 465.6294860839844
INFO:root:Train (Epoch 151): Loss/seq after 01800 batchs: 463.9808349609375
INFO:root:Train (Epoch 151): Loss/seq after 01850 batchs: 461.62945556640625
INFO:root:Train (Epoch 151): Loss/seq after 01900 batchs: 460.8270263671875
INFO:root:Train (Epoch 151): Loss/seq after 01950 batchs: 459.5509338378906
INFO:root:Train (Epoch 151): Loss/seq after 02000 batchs: 459.8728942871094
INFO:root:Train (Epoch 151): Loss/seq after 02050 batchs: 459.72003173828125
INFO:root:Train (Epoch 151): Loss/seq after 02100 batchs: 458.4287414550781
INFO:root:Train (Epoch 151): Loss/seq after 02150 batchs: 457.16448974609375
INFO:root:Train (Epoch 151): Loss/seq after 02200 batchs: 455.6943054199219
INFO:root:Train (Epoch 151): Loss/seq after 02250 batchs: 454.2973327636719
INFO:root:Train (Epoch 151): Loss/seq after 02300 batchs: 449.9657897949219
INFO:root:Train (Epoch 151): Loss/seq after 02350 batchs: 446.78375244140625
INFO:root:Train (Epoch 151): Loss/seq after 02400 batchs: 447.38275146484375
INFO:root:Train (Epoch 151): Loss/seq after 02450 batchs: 444.0801086425781
INFO:root:Train (Epoch 151): Loss/seq after 02500 batchs: 437.1466369628906
INFO:root:Train (Epoch 151): Loss/seq after 02550 batchs: 430.7236328125
INFO:root:Train (Epoch 151): Loss/seq after 02600 batchs: 426.740234375
INFO:root:Train (Epoch 151): Loss/seq after 02650 batchs: 422.2706604003906
INFO:root:Train (Epoch 151): Loss/seq after 02700 batchs: 419.4347229003906
INFO:root:Train (Epoch 151): Loss/seq after 02750 batchs: 415.68353271484375
INFO:root:Train (Epoch 151): Loss/seq after 02800 batchs: 414.10321044921875
INFO:root:Train (Epoch 151): Loss/seq after 02850 batchs: 413.82196044921875
INFO:root:Train (Epoch 151): Loss/seq after 02900 batchs: 414.32501220703125
INFO:root:Train (Epoch 151): Loss/seq after 02950 batchs: 414.5918884277344
INFO:root:Train (Epoch 151): Loss/seq after 03000 batchs: 420.7100830078125
INFO:root:Train (Epoch 151): Loss/seq after 03050 batchs: 422.572998046875
INFO:root:Train (Epoch 151): Loss/seq after 03100 batchs: 424.8168640136719
INFO:root:Train (Epoch 151): Loss/seq after 03150 batchs: 424.5949401855469
INFO:root:Train (Epoch 151): Loss/seq after 03200 batchs: 423.82525634765625
INFO:root:Train (Epoch 151): Loss/seq after 03250 batchs: 422.92974853515625
INFO:root:Train (Epoch 151): Loss/seq after 03300 batchs: 422.5159912109375
INFO:root:Train (Epoch 151): Loss/seq after 03350 batchs: 421.2299499511719
INFO:root:Train (Epoch 151): Loss/seq after 03400 batchs: 418.0555114746094
INFO:root:Train (Epoch 151): Loss/seq after 03450 batchs: 416.3520812988281
INFO:root:Train (Epoch 151): Loss/seq after 03500 batchs: 417.7434997558594
INFO:root:Train (Epoch 151): Loss/seq after 03550 batchs: 416.2370910644531
INFO:root:Train (Epoch 151): Loss/seq after 03600 batchs: 423.3504943847656
INFO:root:Train (Epoch 151): Loss/seq after 03650 batchs: 422.1587829589844
INFO:root:Train (Epoch 151): Loss/seq after 03700 batchs: 425.18255615234375
INFO:root:Train (Epoch 151): Loss/seq after 03750 batchs: 429.9521789550781
INFO:root:Train (Epoch 151): Loss/seq after 03800 batchs: 429.07977294921875
INFO:root:Train (Epoch 151): Loss/seq after 03850 batchs: 428.46685791015625
INFO:root:Train (Epoch 151): Loss/seq after 03900 batchs: 430.80078125
INFO:root:Train (Epoch 151): Loss/seq after 03950 batchs: 433.88494873046875
INFO:root:Train (Epoch 151): Loss/seq after 04000 batchs: 431.363037109375
INFO:root:Train (Epoch 151): Loss/seq after 04050 batchs: 428.6471862792969
INFO:root:Train (Epoch 151): Loss/seq after 04100 batchs: 427.9670104980469
INFO:root:Train (Epoch 151): Loss/seq after 04150 batchs: 428.42816162109375
INFO:root:Train (Epoch 151): Loss/seq after 04200 batchs: 427.5779724121094
INFO:root:Train (Epoch 151): Loss/seq after 04250 batchs: 426.2291564941406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 151): Loss/seq after 00000 batches: 282.5621032714844
INFO:root:# Valid (Epoch 151): Loss/seq after 00050 batches: 629.3338012695312
INFO:root:# Valid (Epoch 151): Loss/seq after 00100 batches: 618.6309204101562
INFO:root:# Valid (Epoch 151): Loss/seq after 00150 batches: 468.6907958984375
INFO:root:# Valid (Epoch 151): Loss/seq after 00200 batches: 445.18115234375
INFO:root:Artifacts: Make stick videos for epoch 151
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_151_on_20220422_115424.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_151_index_1502_on_20220422_115424.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 152): Loss/seq after 00000 batchs: 556.8858642578125
INFO:root:Train (Epoch 152): Loss/seq after 00050 batchs: 624.6373291015625
INFO:root:Train (Epoch 152): Loss/seq after 00100 batchs: 622.2333374023438
INFO:root:Train (Epoch 152): Loss/seq after 00150 batchs: 575.3919067382812
INFO:root:Train (Epoch 152): Loss/seq after 00200 batchs: 629.1920166015625
INFO:root:Train (Epoch 152): Loss/seq after 00250 batchs: 689.8543090820312
INFO:root:Train (Epoch 152): Loss/seq after 00300 batchs: 697.3206176757812
INFO:root:Train (Epoch 152): Loss/seq after 00350 batchs: 656.9244995117188
INFO:root:Train (Epoch 152): Loss/seq after 00400 batchs: 640.1710205078125
INFO:root:Train (Epoch 152): Loss/seq after 00450 batchs: 640.455078125
INFO:root:Train (Epoch 152): Loss/seq after 00500 batchs: 621.1300659179688
INFO:root:Train (Epoch 152): Loss/seq after 00550 batchs: 606.8803100585938
INFO:root:Train (Epoch 152): Loss/seq after 00600 batchs: 588.7021484375
INFO:root:Train (Epoch 152): Loss/seq after 00650 batchs: 565.9287109375
INFO:root:Train (Epoch 152): Loss/seq after 00700 batchs: 541.094482421875
INFO:root:Train (Epoch 152): Loss/seq after 00750 batchs: 530.4625854492188
INFO:root:Train (Epoch 152): Loss/seq after 00800 batchs: 535.43798828125
INFO:root:Train (Epoch 152): Loss/seq after 00850 batchs: 518.2472534179688
INFO:root:Train (Epoch 152): Loss/seq after 00900 batchs: 506.64111328125
INFO:root:Train (Epoch 152): Loss/seq after 00950 batchs: 503.3375549316406
INFO:root:Train (Epoch 152): Loss/seq after 01000 batchs: 494.9730529785156
INFO:root:Train (Epoch 152): Loss/seq after 01050 batchs: 490.2414855957031
INFO:root:Train (Epoch 152): Loss/seq after 01100 batchs: 482.2408752441406
INFO:root:Train (Epoch 152): Loss/seq after 01150 batchs: 470.062744140625
INFO:root:Train (Epoch 152): Loss/seq after 01200 batchs: 476.13592529296875
INFO:root:Train (Epoch 152): Loss/seq after 01250 batchs: 475.4519348144531
INFO:root:Train (Epoch 152): Loss/seq after 01300 batchs: 464.1394958496094
INFO:root:Train (Epoch 152): Loss/seq after 01350 batchs: 453.9443359375
INFO:root:Train (Epoch 152): Loss/seq after 01400 batchs: 454.8126220703125
INFO:root:Train (Epoch 152): Loss/seq after 01450 batchs: 458.03759765625
INFO:root:Train (Epoch 152): Loss/seq after 01500 batchs: 465.7660827636719
INFO:root:Train (Epoch 152): Loss/seq after 01550 batchs: 466.5852966308594
INFO:root:Train (Epoch 152): Loss/seq after 01600 batchs: 462.8822937011719
INFO:root:Train (Epoch 152): Loss/seq after 01650 batchs: 461.0458984375
INFO:root:Train (Epoch 152): Loss/seq after 01700 batchs: 464.7190246582031
INFO:root:Train (Epoch 152): Loss/seq after 01750 batchs: 462.6092529296875
INFO:root:Train (Epoch 152): Loss/seq after 01800 batchs: 460.72906494140625
INFO:root:Train (Epoch 152): Loss/seq after 01850 batchs: 458.2209777832031
INFO:root:Train (Epoch 152): Loss/seq after 01900 batchs: 457.8026123046875
INFO:root:Train (Epoch 152): Loss/seq after 01950 batchs: 456.579833984375
INFO:root:Train (Epoch 152): Loss/seq after 02000 batchs: 457.2005310058594
INFO:root:Train (Epoch 152): Loss/seq after 02050 batchs: 457.03070068359375
INFO:root:Train (Epoch 152): Loss/seq after 02100 batchs: 455.6827087402344
INFO:root:Train (Epoch 152): Loss/seq after 02150 batchs: 454.547119140625
INFO:root:Train (Epoch 152): Loss/seq after 02200 batchs: 453.22711181640625
INFO:root:Train (Epoch 152): Loss/seq after 02250 batchs: 452.05914306640625
INFO:root:Train (Epoch 152): Loss/seq after 02300 batchs: 447.7057189941406
INFO:root:Train (Epoch 152): Loss/seq after 02350 batchs: 444.57269287109375
INFO:root:Train (Epoch 152): Loss/seq after 02400 batchs: 445.1358947753906
INFO:root:Train (Epoch 152): Loss/seq after 02450 batchs: 441.8754577636719
INFO:root:Train (Epoch 152): Loss/seq after 02500 batchs: 434.9852600097656
INFO:root:Train (Epoch 152): Loss/seq after 02550 batchs: 428.6361083984375
INFO:root:Train (Epoch 152): Loss/seq after 02600 batchs: 424.4960021972656
INFO:root:Train (Epoch 152): Loss/seq after 02650 batchs: 420.1795959472656
INFO:root:Train (Epoch 152): Loss/seq after 02700 batchs: 417.2097473144531
INFO:root:Train (Epoch 152): Loss/seq after 02750 batchs: 413.05584716796875
INFO:root:Train (Epoch 152): Loss/seq after 02800 batchs: 411.6675720214844
INFO:root:Train (Epoch 152): Loss/seq after 02850 batchs: 411.7890319824219
INFO:root:Train (Epoch 152): Loss/seq after 02900 batchs: 412.766357421875
INFO:root:Train (Epoch 152): Loss/seq after 02950 batchs: 413.178466796875
INFO:root:Train (Epoch 152): Loss/seq after 03000 batchs: 419.1873779296875
INFO:root:Train (Epoch 152): Loss/seq after 03050 batchs: 421.6424255371094
INFO:root:Train (Epoch 152): Loss/seq after 03100 batchs: 423.76446533203125
INFO:root:Train (Epoch 152): Loss/seq after 03150 batchs: 424.1586608886719
INFO:root:Train (Epoch 152): Loss/seq after 03200 batchs: 423.8839111328125
INFO:root:Train (Epoch 152): Loss/seq after 03250 batchs: 423.4444274902344
INFO:root:Train (Epoch 152): Loss/seq after 03300 batchs: 423.3314208984375
INFO:root:Train (Epoch 152): Loss/seq after 03350 batchs: 421.2950439453125
INFO:root:Train (Epoch 152): Loss/seq after 03400 batchs: 418.0047302246094
INFO:root:Train (Epoch 152): Loss/seq after 03450 batchs: 416.28253173828125
INFO:root:Train (Epoch 152): Loss/seq after 03500 batchs: 417.90972900390625
INFO:root:Train (Epoch 152): Loss/seq after 03550 batchs: 416.3332824707031
INFO:root:Train (Epoch 152): Loss/seq after 03600 batchs: 423.0341796875
INFO:root:Train (Epoch 152): Loss/seq after 03650 batchs: 421.7235107421875
INFO:root:Train (Epoch 152): Loss/seq after 03700 batchs: 424.3805847167969
INFO:root:Train (Epoch 152): Loss/seq after 03750 batchs: 429.0598449707031
INFO:root:Train (Epoch 152): Loss/seq after 03800 batchs: 428.1407775878906
INFO:root:Train (Epoch 152): Loss/seq after 03850 batchs: 427.352783203125
INFO:root:Train (Epoch 152): Loss/seq after 03900 batchs: 429.2141418457031
INFO:root:Train (Epoch 152): Loss/seq after 03950 batchs: 431.859375
INFO:root:Train (Epoch 152): Loss/seq after 04000 batchs: 429.1988220214844
INFO:root:Train (Epoch 152): Loss/seq after 04050 batchs: 426.50604248046875
INFO:root:Train (Epoch 152): Loss/seq after 04100 batchs: 425.7054748535156
INFO:root:Train (Epoch 152): Loss/seq after 04150 batchs: 425.96234130859375
INFO:root:Train (Epoch 152): Loss/seq after 04200 batchs: 425.04718017578125
INFO:root:Train (Epoch 152): Loss/seq after 04250 batchs: 423.87445068359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 152): Loss/seq after 00000 batches: 293.9027404785156
INFO:root:# Valid (Epoch 152): Loss/seq after 00050 batches: 623.3751831054688
INFO:root:# Valid (Epoch 152): Loss/seq after 00100 batches: 613.391357421875
INFO:root:# Valid (Epoch 152): Loss/seq after 00150 batches: 465.8092346191406
INFO:root:# Valid (Epoch 152): Loss/seq after 00200 batches: 440.33258056640625
INFO:root:Artifacts: Make stick videos for epoch 152
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_152_on_20220422_115918.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_152_index_691_on_20220422_115918.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 153): Loss/seq after 00000 batchs: 673.8536987304688
INFO:root:Train (Epoch 153): Loss/seq after 00050 batchs: 616.1000366210938
INFO:root:Train (Epoch 153): Loss/seq after 00100 batchs: 615.3916625976562
INFO:root:Train (Epoch 153): Loss/seq after 00150 batchs: 571.547119140625
INFO:root:Train (Epoch 153): Loss/seq after 00200 batchs: 617.5034790039062
INFO:root:Train (Epoch 153): Loss/seq after 00250 batchs: 686.7244262695312
INFO:root:Train (Epoch 153): Loss/seq after 00300 batchs: 695.9345092773438
INFO:root:Train (Epoch 153): Loss/seq after 00350 batchs: 656.5247192382812
INFO:root:Train (Epoch 153): Loss/seq after 00400 batchs: 642.2228393554688
INFO:root:Train (Epoch 153): Loss/seq after 00450 batchs: 642.1072998046875
INFO:root:Train (Epoch 153): Loss/seq after 00500 batchs: 620.6087036132812
INFO:root:Train (Epoch 153): Loss/seq after 00550 batchs: 607.8421020507812
INFO:root:Train (Epoch 153): Loss/seq after 00600 batchs: 588.69775390625
INFO:root:Train (Epoch 153): Loss/seq after 00650 batchs: 564.6537475585938
INFO:root:Train (Epoch 153): Loss/seq after 00700 batchs: 538.6456298828125
INFO:root:Train (Epoch 153): Loss/seq after 00750 batchs: 530.1242065429688
INFO:root:Train (Epoch 153): Loss/seq after 00800 batchs: 536.5655517578125
INFO:root:Train (Epoch 153): Loss/seq after 00850 batchs: 519.8753662109375
INFO:root:Train (Epoch 153): Loss/seq after 00900 batchs: 507.2353820800781
INFO:root:Train (Epoch 153): Loss/seq after 00950 batchs: 505.1075134277344
INFO:root:Train (Epoch 153): Loss/seq after 01000 batchs: 494.2885437011719
INFO:root:Train (Epoch 153): Loss/seq after 01050 batchs: 486.5377197265625
INFO:root:Train (Epoch 153): Loss/seq after 01100 batchs: 477.24530029296875
INFO:root:Train (Epoch 153): Loss/seq after 01150 batchs: 463.7971496582031
INFO:root:Train (Epoch 153): Loss/seq after 01200 batchs: 469.43536376953125
INFO:root:Train (Epoch 153): Loss/seq after 01250 batchs: 468.8200988769531
INFO:root:Train (Epoch 153): Loss/seq after 01300 batchs: 457.8525695800781
INFO:root:Train (Epoch 153): Loss/seq after 01350 batchs: 447.5773010253906
INFO:root:Train (Epoch 153): Loss/seq after 01400 batchs: 448.4458312988281
INFO:root:Train (Epoch 153): Loss/seq after 01450 batchs: 451.6485290527344
INFO:root:Train (Epoch 153): Loss/seq after 01500 batchs: 459.74383544921875
INFO:root:Train (Epoch 153): Loss/seq after 01550 batchs: 460.8638610839844
INFO:root:Train (Epoch 153): Loss/seq after 01600 batchs: 457.1131591796875
INFO:root:Train (Epoch 153): Loss/seq after 01650 batchs: 455.7694091796875
INFO:root:Train (Epoch 153): Loss/seq after 01700 batchs: 459.82806396484375
INFO:root:Train (Epoch 153): Loss/seq after 01750 batchs: 457.8594665527344
INFO:root:Train (Epoch 153): Loss/seq after 01800 batchs: 456.2447814941406
INFO:root:Train (Epoch 153): Loss/seq after 01850 batchs: 453.88177490234375
INFO:root:Train (Epoch 153): Loss/seq after 01900 batchs: 453.1410827636719
INFO:root:Train (Epoch 153): Loss/seq after 01950 batchs: 452.1407775878906
INFO:root:Train (Epoch 153): Loss/seq after 02000 batchs: 452.80853271484375
INFO:root:Train (Epoch 153): Loss/seq after 02050 batchs: 452.82098388671875
INFO:root:Train (Epoch 153): Loss/seq after 02100 batchs: 451.59820556640625
INFO:root:Train (Epoch 153): Loss/seq after 02150 batchs: 450.6505432128906
INFO:root:Train (Epoch 153): Loss/seq after 02200 batchs: 449.3458557128906
INFO:root:Train (Epoch 153): Loss/seq after 02250 batchs: 448.0339050292969
INFO:root:Train (Epoch 153): Loss/seq after 02300 batchs: 443.8072204589844
INFO:root:Train (Epoch 153): Loss/seq after 02350 batchs: 440.70135498046875
INFO:root:Train (Epoch 153): Loss/seq after 02400 batchs: 441.32891845703125
INFO:root:Train (Epoch 153): Loss/seq after 02450 batchs: 438.0634460449219
INFO:root:Train (Epoch 153): Loss/seq after 02500 batchs: 431.1787414550781
INFO:root:Train (Epoch 153): Loss/seq after 02550 batchs: 424.866943359375
INFO:root:Train (Epoch 153): Loss/seq after 02600 batchs: 421.03564453125
INFO:root:Train (Epoch 153): Loss/seq after 02650 batchs: 416.85772705078125
INFO:root:Train (Epoch 153): Loss/seq after 02700 batchs: 414.03167724609375
INFO:root:Train (Epoch 153): Loss/seq after 02750 batchs: 409.7989196777344
INFO:root:Train (Epoch 153): Loss/seq after 02800 batchs: 408.58416748046875
INFO:root:Train (Epoch 153): Loss/seq after 02850 batchs: 408.5279846191406
INFO:root:Train (Epoch 153): Loss/seq after 02900 batchs: 409.3818664550781
INFO:root:Train (Epoch 153): Loss/seq after 02950 batchs: 409.7087097167969
INFO:root:Train (Epoch 153): Loss/seq after 03000 batchs: 415.60211181640625
INFO:root:Train (Epoch 153): Loss/seq after 03050 batchs: 417.4682922363281
INFO:root:Train (Epoch 153): Loss/seq after 03100 batchs: 419.7740478515625
INFO:root:Train (Epoch 153): Loss/seq after 03150 batchs: 419.69207763671875
INFO:root:Train (Epoch 153): Loss/seq after 03200 batchs: 418.94512939453125
INFO:root:Train (Epoch 153): Loss/seq after 03250 batchs: 418.7464599609375
INFO:root:Train (Epoch 153): Loss/seq after 03300 batchs: 417.7918395996094
INFO:root:Train (Epoch 153): Loss/seq after 03350 batchs: 416.1577453613281
INFO:root:Train (Epoch 153): Loss/seq after 03400 batchs: 412.9421081542969
INFO:root:Train (Epoch 153): Loss/seq after 03450 batchs: 411.4788513183594
INFO:root:Train (Epoch 153): Loss/seq after 03500 batchs: 413.0067443847656
INFO:root:Train (Epoch 153): Loss/seq after 03550 batchs: 411.5899658203125
INFO:root:Train (Epoch 153): Loss/seq after 03600 batchs: 418.3266296386719
INFO:root:Train (Epoch 153): Loss/seq after 03650 batchs: 416.80035400390625
INFO:root:Train (Epoch 153): Loss/seq after 03700 batchs: 419.5232238769531
INFO:root:Train (Epoch 153): Loss/seq after 03750 batchs: 424.156982421875
INFO:root:Train (Epoch 153): Loss/seq after 03800 batchs: 423.29144287109375
INFO:root:Train (Epoch 153): Loss/seq after 03850 batchs: 422.4524841308594
INFO:root:Train (Epoch 153): Loss/seq after 03900 batchs: 424.5757751464844
INFO:root:Train (Epoch 153): Loss/seq after 03950 batchs: 426.6636962890625
INFO:root:Train (Epoch 153): Loss/seq after 04000 batchs: 424.07452392578125
INFO:root:Train (Epoch 153): Loss/seq after 04050 batchs: 421.36907958984375
INFO:root:Train (Epoch 153): Loss/seq after 04100 batchs: 420.52886962890625
INFO:root:Train (Epoch 153): Loss/seq after 04150 batchs: 420.8907165527344
INFO:root:Train (Epoch 153): Loss/seq after 04200 batchs: 419.82421875
INFO:root:Train (Epoch 153): Loss/seq after 04250 batchs: 418.4822082519531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 153): Loss/seq after 00000 batches: 273.29718017578125
INFO:root:# Valid (Epoch 153): Loss/seq after 00050 batches: 599.4052124023438
INFO:root:# Valid (Epoch 153): Loss/seq after 00100 batches: 603.7252807617188
INFO:root:# Valid (Epoch 153): Loss/seq after 00150 batches: 458.69830322265625
INFO:root:# Valid (Epoch 153): Loss/seq after 00200 batches: 434.2054748535156
INFO:root:Artifacts: Make stick videos for epoch 153
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_153_on_20220422_120419.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_153_index_1673_on_20220422_120419.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 154): Loss/seq after 00000 batchs: 540.7828369140625
INFO:root:Train (Epoch 154): Loss/seq after 00050 batchs: 577.2410888671875
INFO:root:Train (Epoch 154): Loss/seq after 00100 batchs: 573.8750610351562
INFO:root:Train (Epoch 154): Loss/seq after 00150 batchs: 535.4445190429688
INFO:root:Train (Epoch 154): Loss/seq after 00200 batchs: 581.030517578125
INFO:root:Train (Epoch 154): Loss/seq after 00250 batchs: 641.034912109375
INFO:root:Train (Epoch 154): Loss/seq after 00300 batchs: 653.6896362304688
INFO:root:Train (Epoch 154): Loss/seq after 00350 batchs: 617.3901977539062
INFO:root:Train (Epoch 154): Loss/seq after 00400 batchs: 600.7374877929688
INFO:root:Train (Epoch 154): Loss/seq after 00450 batchs: 605.6367797851562
INFO:root:Train (Epoch 154): Loss/seq after 00500 batchs: 586.7914428710938
INFO:root:Train (Epoch 154): Loss/seq after 00550 batchs: 575.1441650390625
INFO:root:Train (Epoch 154): Loss/seq after 00600 batchs: 556.8428955078125
INFO:root:Train (Epoch 154): Loss/seq after 00650 batchs: 535.2276000976562
INFO:root:Train (Epoch 154): Loss/seq after 00700 batchs: 511.97210693359375
INFO:root:Train (Epoch 154): Loss/seq after 00750 batchs: 502.4696960449219
INFO:root:Train (Epoch 154): Loss/seq after 00800 batchs: 508.77679443359375
INFO:root:Train (Epoch 154): Loss/seq after 00850 batchs: 492.8077087402344
INFO:root:Train (Epoch 154): Loss/seq after 00900 batchs: 481.14422607421875
INFO:root:Train (Epoch 154): Loss/seq after 00950 batchs: 476.74591064453125
INFO:root:Train (Epoch 154): Loss/seq after 01000 batchs: 467.4440612792969
INFO:root:Train (Epoch 154): Loss/seq after 01050 batchs: 458.5302734375
INFO:root:Train (Epoch 154): Loss/seq after 01100 batchs: 450.23040771484375
INFO:root:Train (Epoch 154): Loss/seq after 01150 batchs: 437.9734191894531
INFO:root:Train (Epoch 154): Loss/seq after 01200 batchs: 443.75201416015625
INFO:root:Train (Epoch 154): Loss/seq after 01250 batchs: 443.8872375488281
INFO:root:Train (Epoch 154): Loss/seq after 01300 batchs: 433.2261657714844
INFO:root:Train (Epoch 154): Loss/seq after 01350 batchs: 424.2801513671875
INFO:root:Train (Epoch 154): Loss/seq after 01400 batchs: 425.5618591308594
INFO:root:Train (Epoch 154): Loss/seq after 01450 batchs: 429.20751953125
INFO:root:Train (Epoch 154): Loss/seq after 01500 batchs: 438.0737609863281
INFO:root:Train (Epoch 154): Loss/seq after 01550 batchs: 439.3387451171875
INFO:root:Train (Epoch 154): Loss/seq after 01600 batchs: 436.301513671875
INFO:root:Train (Epoch 154): Loss/seq after 01650 batchs: 435.9416198730469
INFO:root:Train (Epoch 154): Loss/seq after 01700 batchs: 440.54693603515625
INFO:root:Train (Epoch 154): Loss/seq after 01750 batchs: 439.0572814941406
INFO:root:Train (Epoch 154): Loss/seq after 01800 batchs: 437.7644958496094
INFO:root:Train (Epoch 154): Loss/seq after 01850 batchs: 436.08673095703125
INFO:root:Train (Epoch 154): Loss/seq after 01900 batchs: 435.8700256347656
INFO:root:Train (Epoch 154): Loss/seq after 01950 batchs: 435.8321533203125
INFO:root:Train (Epoch 154): Loss/seq after 02000 batchs: 437.06121826171875
INFO:root:Train (Epoch 154): Loss/seq after 02050 batchs: 437.3848571777344
INFO:root:Train (Epoch 154): Loss/seq after 02100 batchs: 436.368896484375
INFO:root:Train (Epoch 154): Loss/seq after 02150 batchs: 435.61761474609375
INFO:root:Train (Epoch 154): Loss/seq after 02200 batchs: 434.59368896484375
INFO:root:Train (Epoch 154): Loss/seq after 02250 batchs: 433.9066467285156
INFO:root:Train (Epoch 154): Loss/seq after 02300 batchs: 430.05224609375
INFO:root:Train (Epoch 154): Loss/seq after 02350 batchs: 427.4985656738281
INFO:root:Train (Epoch 154): Loss/seq after 02400 batchs: 428.32647705078125
INFO:root:Train (Epoch 154): Loss/seq after 02450 batchs: 425.427978515625
INFO:root:Train (Epoch 154): Loss/seq after 02500 batchs: 418.8027648925781
INFO:root:Train (Epoch 154): Loss/seq after 02550 batchs: 412.7269592285156
INFO:root:Train (Epoch 154): Loss/seq after 02600 batchs: 408.8540954589844
INFO:root:Train (Epoch 154): Loss/seq after 02650 batchs: 404.7679138183594
INFO:root:Train (Epoch 154): Loss/seq after 02700 batchs: 402.0466613769531
INFO:root:Train (Epoch 154): Loss/seq after 02750 batchs: 397.7264709472656
INFO:root:Train (Epoch 154): Loss/seq after 02800 batchs: 396.6470031738281
INFO:root:Train (Epoch 154): Loss/seq after 02850 batchs: 396.4912414550781
INFO:root:Train (Epoch 154): Loss/seq after 02900 batchs: 397.2083740234375
INFO:root:Train (Epoch 154): Loss/seq after 02950 batchs: 397.69451904296875
INFO:root:Train (Epoch 154): Loss/seq after 03000 batchs: 403.8370361328125
INFO:root:Train (Epoch 154): Loss/seq after 03050 batchs: 405.8402404785156
INFO:root:Train (Epoch 154): Loss/seq after 03100 batchs: 407.9864501953125
INFO:root:Train (Epoch 154): Loss/seq after 03150 batchs: 407.2362060546875
INFO:root:Train (Epoch 154): Loss/seq after 03200 batchs: 407.22845458984375
INFO:root:Train (Epoch 154): Loss/seq after 03250 batchs: 406.916015625
INFO:root:Train (Epoch 154): Loss/seq after 03300 batchs: 406.323974609375
INFO:root:Train (Epoch 154): Loss/seq after 03350 batchs: 404.4439392089844
INFO:root:Train (Epoch 154): Loss/seq after 03400 batchs: 401.3651428222656
INFO:root:Train (Epoch 154): Loss/seq after 03450 batchs: 399.7113037109375
INFO:root:Train (Epoch 154): Loss/seq after 03500 batchs: 401.0993347167969
INFO:root:Train (Epoch 154): Loss/seq after 03550 batchs: 399.4369812011719
INFO:root:Train (Epoch 154): Loss/seq after 03600 batchs: 406.0700378417969
INFO:root:Train (Epoch 154): Loss/seq after 03650 batchs: 404.6250305175781
INFO:root:Train (Epoch 154): Loss/seq after 03700 batchs: 407.28802490234375
INFO:root:Train (Epoch 154): Loss/seq after 03750 batchs: 411.94891357421875
INFO:root:Train (Epoch 154): Loss/seq after 03800 batchs: 411.2228698730469
INFO:root:Train (Epoch 154): Loss/seq after 03850 batchs: 410.5568542480469
INFO:root:Train (Epoch 154): Loss/seq after 03900 batchs: 412.6812438964844
INFO:root:Train (Epoch 154): Loss/seq after 03950 batchs: 415.0757751464844
INFO:root:Train (Epoch 154): Loss/seq after 04000 batchs: 412.6009521484375
INFO:root:Train (Epoch 154): Loss/seq after 04050 batchs: 410.07373046875
INFO:root:Train (Epoch 154): Loss/seq after 04100 batchs: 409.37652587890625
INFO:root:Train (Epoch 154): Loss/seq after 04150 batchs: 409.81427001953125
INFO:root:Train (Epoch 154): Loss/seq after 04200 batchs: 408.8583984375
INFO:root:Train (Epoch 154): Loss/seq after 04250 batchs: 407.67547607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 154): Loss/seq after 00000 batches: 331.1207580566406
INFO:root:# Valid (Epoch 154): Loss/seq after 00050 batches: 605.21435546875
INFO:root:# Valid (Epoch 154): Loss/seq after 00100 batches: 587.9979858398438
INFO:root:# Valid (Epoch 154): Loss/seq after 00150 batches: 447.5949401855469
INFO:root:# Valid (Epoch 154): Loss/seq after 00200 batches: 422.0518493652344
INFO:root:Artifacts: Make stick videos for epoch 154
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_154_on_20220422_120907.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_154_index_1552_on_20220422_120907.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 155): Loss/seq after 00000 batchs: 719.1989135742188
INFO:root:Train (Epoch 155): Loss/seq after 00050 batchs: 575.3161010742188
INFO:root:Train (Epoch 155): Loss/seq after 00100 batchs: 582.5761108398438
INFO:root:Train (Epoch 155): Loss/seq after 00150 batchs: 543.4556274414062
INFO:root:Train (Epoch 155): Loss/seq after 00200 batchs: 588.0095825195312
INFO:root:Train (Epoch 155): Loss/seq after 00250 batchs: 662.9574584960938
INFO:root:Train (Epoch 155): Loss/seq after 00300 batchs: 672.761962890625
INFO:root:Train (Epoch 155): Loss/seq after 00350 batchs: 635.5402221679688
INFO:root:Train (Epoch 155): Loss/seq after 00400 batchs: 618.7012939453125
INFO:root:Train (Epoch 155): Loss/seq after 00450 batchs: 621.4547729492188
INFO:root:Train (Epoch 155): Loss/seq after 00500 batchs: 600.6765747070312
INFO:root:Train (Epoch 155): Loss/seq after 00550 batchs: 587.8623046875
INFO:root:Train (Epoch 155): Loss/seq after 00600 batchs: 568.54736328125
INFO:root:Train (Epoch 155): Loss/seq after 00650 batchs: 544.447998046875
INFO:root:Train (Epoch 155): Loss/seq after 00700 batchs: 520.5402221679688
INFO:root:Train (Epoch 155): Loss/seq after 00750 batchs: 509.7845153808594
INFO:root:Train (Epoch 155): Loss/seq after 00800 batchs: 517.3279418945312
INFO:root:Train (Epoch 155): Loss/seq after 00850 batchs: 501.03277587890625
INFO:root:Train (Epoch 155): Loss/seq after 00900 batchs: 488.811767578125
INFO:root:Train (Epoch 155): Loss/seq after 00950 batchs: 484.24810791015625
INFO:root:Train (Epoch 155): Loss/seq after 01000 batchs: 474.8299560546875
INFO:root:Train (Epoch 155): Loss/seq after 01050 batchs: 468.4053955078125
INFO:root:Train (Epoch 155): Loss/seq after 01100 batchs: 459.84356689453125
INFO:root:Train (Epoch 155): Loss/seq after 01150 batchs: 447.0656433105469
INFO:root:Train (Epoch 155): Loss/seq after 01200 batchs: 452.4391174316406
INFO:root:Train (Epoch 155): Loss/seq after 01250 batchs: 452.3022155761719
INFO:root:Train (Epoch 155): Loss/seq after 01300 batchs: 441.6481628417969
INFO:root:Train (Epoch 155): Loss/seq after 01350 batchs: 432.02880859375
INFO:root:Train (Epoch 155): Loss/seq after 01400 batchs: 433.8893127441406
INFO:root:Train (Epoch 155): Loss/seq after 01450 batchs: 437.61871337890625
INFO:root:Train (Epoch 155): Loss/seq after 01500 batchs: 445.5772399902344
INFO:root:Train (Epoch 155): Loss/seq after 01550 batchs: 447.3624572753906
INFO:root:Train (Epoch 155): Loss/seq after 01600 batchs: 444.7322082519531
INFO:root:Train (Epoch 155): Loss/seq after 01650 batchs: 444.0732421875
INFO:root:Train (Epoch 155): Loss/seq after 01700 batchs: 448.36248779296875
INFO:root:Train (Epoch 155): Loss/seq after 01750 batchs: 446.62786865234375
INFO:root:Train (Epoch 155): Loss/seq after 01800 batchs: 445.24322509765625
INFO:root:Train (Epoch 155): Loss/seq after 01850 batchs: 443.0348205566406
INFO:root:Train (Epoch 155): Loss/seq after 01900 batchs: 442.6266784667969
INFO:root:Train (Epoch 155): Loss/seq after 01950 batchs: 441.9996032714844
INFO:root:Train (Epoch 155): Loss/seq after 02000 batchs: 443.027587890625
INFO:root:Train (Epoch 155): Loss/seq after 02050 batchs: 443.50897216796875
INFO:root:Train (Epoch 155): Loss/seq after 02100 batchs: 442.8244934082031
INFO:root:Train (Epoch 155): Loss/seq after 02150 batchs: 441.9876403808594
INFO:root:Train (Epoch 155): Loss/seq after 02200 batchs: 440.8123779296875
INFO:root:Train (Epoch 155): Loss/seq after 02250 batchs: 439.6032409667969
INFO:root:Train (Epoch 155): Loss/seq after 02300 batchs: 435.8692626953125
INFO:root:Train (Epoch 155): Loss/seq after 02350 batchs: 433.12054443359375
INFO:root:Train (Epoch 155): Loss/seq after 02400 batchs: 433.72833251953125
INFO:root:Train (Epoch 155): Loss/seq after 02450 batchs: 430.56573486328125
INFO:root:Train (Epoch 155): Loss/seq after 02500 batchs: 423.84930419921875
INFO:root:Train (Epoch 155): Loss/seq after 02550 batchs: 417.525390625
INFO:root:Train (Epoch 155): Loss/seq after 02600 batchs: 413.5674743652344
INFO:root:Train (Epoch 155): Loss/seq after 02650 batchs: 409.3290710449219
INFO:root:Train (Epoch 155): Loss/seq after 02700 batchs: 406.5126647949219
INFO:root:Train (Epoch 155): Loss/seq after 02750 batchs: 401.9747009277344
INFO:root:Train (Epoch 155): Loss/seq after 02800 batchs: 399.937255859375
INFO:root:Train (Epoch 155): Loss/seq after 02850 batchs: 399.7399597167969
INFO:root:Train (Epoch 155): Loss/seq after 02900 batchs: 400.4664611816406
INFO:root:Train (Epoch 155): Loss/seq after 02950 batchs: 400.77447509765625
INFO:root:Train (Epoch 155): Loss/seq after 03000 batchs: 406.8930358886719
INFO:root:Train (Epoch 155): Loss/seq after 03050 batchs: 408.8712463378906
INFO:root:Train (Epoch 155): Loss/seq after 03100 batchs: 410.38848876953125
INFO:root:Train (Epoch 155): Loss/seq after 03150 batchs: 410.0424499511719
INFO:root:Train (Epoch 155): Loss/seq after 03200 batchs: 409.8080749511719
INFO:root:Train (Epoch 155): Loss/seq after 03250 batchs: 409.5500793457031
INFO:root:Train (Epoch 155): Loss/seq after 03300 batchs: 408.6861267089844
INFO:root:Train (Epoch 155): Loss/seq after 03350 batchs: 406.7116394042969
INFO:root:Train (Epoch 155): Loss/seq after 03400 batchs: 403.6348876953125
INFO:root:Train (Epoch 155): Loss/seq after 03450 batchs: 402.11004638671875
INFO:root:Train (Epoch 155): Loss/seq after 03500 batchs: 403.4060974121094
INFO:root:Train (Epoch 155): Loss/seq after 03550 batchs: 401.7190856933594
INFO:root:Train (Epoch 155): Loss/seq after 03600 batchs: 408.34906005859375
INFO:root:Train (Epoch 155): Loss/seq after 03650 batchs: 406.9795837402344
INFO:root:Train (Epoch 155): Loss/seq after 03700 batchs: 409.362548828125
INFO:root:Train (Epoch 155): Loss/seq after 03750 batchs: 413.9419860839844
INFO:root:Train (Epoch 155): Loss/seq after 03800 batchs: 413.1734924316406
INFO:root:Train (Epoch 155): Loss/seq after 03850 batchs: 412.4288024902344
INFO:root:Train (Epoch 155): Loss/seq after 03900 batchs: 414.2803039550781
INFO:root:Train (Epoch 155): Loss/seq after 03950 batchs: 416.24517822265625
INFO:root:Train (Epoch 155): Loss/seq after 04000 batchs: 413.7524108886719
INFO:root:Train (Epoch 155): Loss/seq after 04050 batchs: 411.29052734375
INFO:root:Train (Epoch 155): Loss/seq after 04100 batchs: 410.5513000488281
INFO:root:Train (Epoch 155): Loss/seq after 04150 batchs: 410.98309326171875
INFO:root:Train (Epoch 155): Loss/seq after 04200 batchs: 409.9775390625
INFO:root:Train (Epoch 155): Loss/seq after 04250 batchs: 408.7444763183594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 155): Loss/seq after 00000 batches: 290.030517578125
INFO:root:# Valid (Epoch 155): Loss/seq after 00050 batches: 603.046142578125
INFO:root:# Valid (Epoch 155): Loss/seq after 00100 batches: 592.6336059570312
INFO:root:# Valid (Epoch 155): Loss/seq after 00150 batches: 451.86175537109375
INFO:root:# Valid (Epoch 155): Loss/seq after 00200 batches: 426.7651062011719
INFO:root:Artifacts: Make stick videos for epoch 155
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_155_on_20220422_121358.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_155_index_659_on_20220422_121358.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 156): Loss/seq after 00000 batchs: 660.1333618164062
INFO:root:Train (Epoch 156): Loss/seq after 00050 batchs: 559.5123901367188
INFO:root:Train (Epoch 156): Loss/seq after 00100 batchs: 569.4505615234375
INFO:root:Train (Epoch 156): Loss/seq after 00150 batchs: 535.1234741210938
INFO:root:Train (Epoch 156): Loss/seq after 00200 batchs: 586.8633422851562
INFO:root:Train (Epoch 156): Loss/seq after 00250 batchs: 656.5366821289062
INFO:root:Train (Epoch 156): Loss/seq after 00300 batchs: 669.724365234375
INFO:root:Train (Epoch 156): Loss/seq after 00350 batchs: 632.794189453125
INFO:root:Train (Epoch 156): Loss/seq after 00400 batchs: 617.0679931640625
INFO:root:Train (Epoch 156): Loss/seq after 00450 batchs: 619.2225952148438
INFO:root:Train (Epoch 156): Loss/seq after 00500 batchs: 597.8826293945312
INFO:root:Train (Epoch 156): Loss/seq after 00550 batchs: 585.866943359375
INFO:root:Train (Epoch 156): Loss/seq after 00600 batchs: 568.2378540039062
INFO:root:Train (Epoch 156): Loss/seq after 00650 batchs: 546.1383666992188
INFO:root:Train (Epoch 156): Loss/seq after 00700 batchs: 522.2149047851562
INFO:root:Train (Epoch 156): Loss/seq after 00750 batchs: 511.7516784667969
INFO:root:Train (Epoch 156): Loss/seq after 00800 batchs: 518.695556640625
INFO:root:Train (Epoch 156): Loss/seq after 00850 batchs: 501.64361572265625
INFO:root:Train (Epoch 156): Loss/seq after 00900 batchs: 489.8827209472656
INFO:root:Train (Epoch 156): Loss/seq after 00950 batchs: 484.6824035644531
INFO:root:Train (Epoch 156): Loss/seq after 01000 batchs: 474.79327392578125
INFO:root:Train (Epoch 156): Loss/seq after 01050 batchs: 465.6399230957031
INFO:root:Train (Epoch 156): Loss/seq after 01100 batchs: 457.08538818359375
INFO:root:Train (Epoch 156): Loss/seq after 01150 batchs: 444.4186096191406
INFO:root:Train (Epoch 156): Loss/seq after 01200 batchs: 449.5898742675781
INFO:root:Train (Epoch 156): Loss/seq after 01250 batchs: 449.4521789550781
INFO:root:Train (Epoch 156): Loss/seq after 01300 batchs: 438.5047607421875
INFO:root:Train (Epoch 156): Loss/seq after 01350 batchs: 429.4580383300781
INFO:root:Train (Epoch 156): Loss/seq after 01400 batchs: 430.4884033203125
INFO:root:Train (Epoch 156): Loss/seq after 01450 batchs: 434.357666015625
INFO:root:Train (Epoch 156): Loss/seq after 01500 batchs: 442.8075256347656
INFO:root:Train (Epoch 156): Loss/seq after 01550 batchs: 443.9489440917969
INFO:root:Train (Epoch 156): Loss/seq after 01600 batchs: 440.7137145996094
INFO:root:Train (Epoch 156): Loss/seq after 01650 batchs: 439.67132568359375
INFO:root:Train (Epoch 156): Loss/seq after 01700 batchs: 444.30230712890625
INFO:root:Train (Epoch 156): Loss/seq after 01750 batchs: 442.8486633300781
INFO:root:Train (Epoch 156): Loss/seq after 01800 batchs: 441.4836730957031
INFO:root:Train (Epoch 156): Loss/seq after 01850 batchs: 439.4054260253906
INFO:root:Train (Epoch 156): Loss/seq after 01900 batchs: 439.04876708984375
INFO:root:Train (Epoch 156): Loss/seq after 01950 batchs: 438.15496826171875
INFO:root:Train (Epoch 156): Loss/seq after 02000 batchs: 439.0397033691406
INFO:root:Train (Epoch 156): Loss/seq after 02050 batchs: 439.05157470703125
INFO:root:Train (Epoch 156): Loss/seq after 02100 batchs: 437.9490051269531
INFO:root:Train (Epoch 156): Loss/seq after 02150 batchs: 437.0704345703125
INFO:root:Train (Epoch 156): Loss/seq after 02200 batchs: 435.954345703125
INFO:root:Train (Epoch 156): Loss/seq after 02250 batchs: 435.00946044921875
INFO:root:Train (Epoch 156): Loss/seq after 02300 batchs: 431.0888366699219
INFO:root:Train (Epoch 156): Loss/seq after 02350 batchs: 428.4720153808594
INFO:root:Train (Epoch 156): Loss/seq after 02400 batchs: 429.20599365234375
INFO:root:Train (Epoch 156): Loss/seq after 02450 batchs: 426.13153076171875
INFO:root:Train (Epoch 156): Loss/seq after 02500 batchs: 419.4904479980469
INFO:root:Train (Epoch 156): Loss/seq after 02550 batchs: 413.3446044921875
INFO:root:Train (Epoch 156): Loss/seq after 02600 batchs: 409.658935546875
INFO:root:Train (Epoch 156): Loss/seq after 02650 batchs: 405.62078857421875
INFO:root:Train (Epoch 156): Loss/seq after 02700 batchs: 402.8445739746094
INFO:root:Train (Epoch 156): Loss/seq after 02750 batchs: 398.4664001464844
INFO:root:Train (Epoch 156): Loss/seq after 02800 batchs: 396.5719909667969
INFO:root:Train (Epoch 156): Loss/seq after 02850 batchs: 396.45208740234375
INFO:root:Train (Epoch 156): Loss/seq after 02900 batchs: 397.2142639160156
INFO:root:Train (Epoch 156): Loss/seq after 02950 batchs: 397.6707458496094
INFO:root:Train (Epoch 156): Loss/seq after 03000 batchs: 403.4934387207031
INFO:root:Train (Epoch 156): Loss/seq after 03050 batchs: 405.4520263671875
INFO:root:Train (Epoch 156): Loss/seq after 03100 batchs: 407.2109680175781
INFO:root:Train (Epoch 156): Loss/seq after 03150 batchs: 406.8946533203125
INFO:root:Train (Epoch 156): Loss/seq after 03200 batchs: 406.83123779296875
INFO:root:Train (Epoch 156): Loss/seq after 03250 batchs: 406.6878967285156
INFO:root:Train (Epoch 156): Loss/seq after 03300 batchs: 406.2715148925781
INFO:root:Train (Epoch 156): Loss/seq after 03350 batchs: 404.2390441894531
INFO:root:Train (Epoch 156): Loss/seq after 03400 batchs: 401.25933837890625
INFO:root:Train (Epoch 156): Loss/seq after 03450 batchs: 399.6894226074219
INFO:root:Train (Epoch 156): Loss/seq after 03500 batchs: 401.55633544921875
INFO:root:Train (Epoch 156): Loss/seq after 03550 batchs: 400.5398254394531
INFO:root:Train (Epoch 156): Loss/seq after 03600 batchs: 407.54779052734375
INFO:root:Train (Epoch 156): Loss/seq after 03650 batchs: 406.0757141113281
INFO:root:Train (Epoch 156): Loss/seq after 03700 batchs: 408.7957763671875
INFO:root:Train (Epoch 156): Loss/seq after 03750 batchs: 413.46307373046875
INFO:root:Train (Epoch 156): Loss/seq after 03800 batchs: 412.6676330566406
INFO:root:Train (Epoch 156): Loss/seq after 03850 batchs: 412.044189453125
INFO:root:Train (Epoch 156): Loss/seq after 03900 batchs: 414.2333984375
INFO:root:Train (Epoch 156): Loss/seq after 03950 batchs: 416.31622314453125
INFO:root:Train (Epoch 156): Loss/seq after 04000 batchs: 413.7946472167969
INFO:root:Train (Epoch 156): Loss/seq after 04050 batchs: 411.2781982421875
INFO:root:Train (Epoch 156): Loss/seq after 04100 batchs: 410.58660888671875
INFO:root:Train (Epoch 156): Loss/seq after 04150 batchs: 410.9615478515625
INFO:root:Train (Epoch 156): Loss/seq after 04200 batchs: 409.9085693359375
INFO:root:Train (Epoch 156): Loss/seq after 04250 batchs: 408.7492370605469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 156): Loss/seq after 00000 batches: 313.5469665527344
INFO:root:# Valid (Epoch 156): Loss/seq after 00050 batches: 585.4286499023438
INFO:root:# Valid (Epoch 156): Loss/seq after 00100 batches: 613.1884765625
INFO:root:# Valid (Epoch 156): Loss/seq after 00150 batches: 465.7606506347656
INFO:root:# Valid (Epoch 156): Loss/seq after 00200 batches: 445.0020446777344
INFO:root:Artifacts: Make stick videos for epoch 156
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_156_on_20220422_121847.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_156_index_1611_on_20220422_121847.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 157): Loss/seq after 00000 batchs: 739.9248046875
INFO:root:Train (Epoch 157): Loss/seq after 00050 batchs: 582.1105346679688
INFO:root:Train (Epoch 157): Loss/seq after 00100 batchs: 595.8717041015625
INFO:root:Train (Epoch 157): Loss/seq after 00150 batchs: 549.2825927734375
INFO:root:Train (Epoch 157): Loss/seq after 00200 batchs: 595.5679321289062
INFO:root:Train (Epoch 157): Loss/seq after 00250 batchs: 654.7816772460938
INFO:root:Train (Epoch 157): Loss/seq after 00300 batchs: 666.5028686523438
INFO:root:Train (Epoch 157): Loss/seq after 00350 batchs: 629.57177734375
INFO:root:Train (Epoch 157): Loss/seq after 00400 batchs: 611.2437133789062
INFO:root:Train (Epoch 157): Loss/seq after 00450 batchs: 614.14501953125
INFO:root:Train (Epoch 157): Loss/seq after 00500 batchs: 592.0985717773438
INFO:root:Train (Epoch 157): Loss/seq after 00550 batchs: 579.0656127929688
INFO:root:Train (Epoch 157): Loss/seq after 00600 batchs: 560.7648315429688
INFO:root:Train (Epoch 157): Loss/seq after 00650 batchs: 536.9631958007812
INFO:root:Train (Epoch 157): Loss/seq after 00700 batchs: 512.5101928710938
INFO:root:Train (Epoch 157): Loss/seq after 00750 batchs: 501.8487548828125
INFO:root:Train (Epoch 157): Loss/seq after 00800 batchs: 507.3802185058594
INFO:root:Train (Epoch 157): Loss/seq after 00850 batchs: 490.5692138671875
INFO:root:Train (Epoch 157): Loss/seq after 00900 batchs: 478.34136962890625
INFO:root:Train (Epoch 157): Loss/seq after 00950 batchs: 473.79736328125
INFO:root:Train (Epoch 157): Loss/seq after 01000 batchs: 464.4725036621094
INFO:root:Train (Epoch 157): Loss/seq after 01050 batchs: 456.129150390625
INFO:root:Train (Epoch 157): Loss/seq after 01100 batchs: 448.3833923339844
INFO:root:Train (Epoch 157): Loss/seq after 01150 batchs: 436.0154113769531
INFO:root:Train (Epoch 157): Loss/seq after 01200 batchs: 440.9740905761719
INFO:root:Train (Epoch 157): Loss/seq after 01250 batchs: 441.3792419433594
INFO:root:Train (Epoch 157): Loss/seq after 01300 batchs: 431.0377502441406
INFO:root:Train (Epoch 157): Loss/seq after 01350 batchs: 421.855224609375
INFO:root:Train (Epoch 157): Loss/seq after 01400 batchs: 422.966796875
INFO:root:Train (Epoch 157): Loss/seq after 01450 batchs: 426.7418212890625
INFO:root:Train (Epoch 157): Loss/seq after 01500 batchs: 435.03497314453125
INFO:root:Train (Epoch 157): Loss/seq after 01550 batchs: 436.36041259765625
INFO:root:Train (Epoch 157): Loss/seq after 01600 batchs: 433.4128723144531
INFO:root:Train (Epoch 157): Loss/seq after 01650 batchs: 432.4112854003906
INFO:root:Train (Epoch 157): Loss/seq after 01700 batchs: 436.81793212890625
INFO:root:Train (Epoch 157): Loss/seq after 01750 batchs: 435.3346252441406
INFO:root:Train (Epoch 157): Loss/seq after 01800 batchs: 434.1276550292969
INFO:root:Train (Epoch 157): Loss/seq after 01850 batchs: 432.1174011230469
INFO:root:Train (Epoch 157): Loss/seq after 01900 batchs: 431.813720703125
INFO:root:Train (Epoch 157): Loss/seq after 01950 batchs: 430.81744384765625
INFO:root:Train (Epoch 157): Loss/seq after 02000 batchs: 431.8879089355469
INFO:root:Train (Epoch 157): Loss/seq after 02050 batchs: 432.0964050292969
INFO:root:Train (Epoch 157): Loss/seq after 02100 batchs: 431.2193603515625
INFO:root:Train (Epoch 157): Loss/seq after 02150 batchs: 430.50970458984375
INFO:root:Train (Epoch 157): Loss/seq after 02200 batchs: 429.595458984375
INFO:root:Train (Epoch 157): Loss/seq after 02250 batchs: 428.5537414550781
INFO:root:Train (Epoch 157): Loss/seq after 02300 batchs: 424.6755065917969
INFO:root:Train (Epoch 157): Loss/seq after 02350 batchs: 422.45904541015625
INFO:root:Train (Epoch 157): Loss/seq after 02400 batchs: 423.3141784667969
INFO:root:Train (Epoch 157): Loss/seq after 02450 batchs: 420.4291076660156
INFO:root:Train (Epoch 157): Loss/seq after 02500 batchs: 413.8592834472656
INFO:root:Train (Epoch 157): Loss/seq after 02550 batchs: 407.77294921875
INFO:root:Train (Epoch 157): Loss/seq after 02600 batchs: 404.1159973144531
INFO:root:Train (Epoch 157): Loss/seq after 02650 batchs: 399.9894714355469
INFO:root:Train (Epoch 157): Loss/seq after 02700 batchs: 397.3143310546875
INFO:root:Train (Epoch 157): Loss/seq after 02750 batchs: 393.55322265625
INFO:root:Train (Epoch 157): Loss/seq after 02800 batchs: 391.8699951171875
INFO:root:Train (Epoch 157): Loss/seq after 02850 batchs: 391.6017761230469
INFO:root:Train (Epoch 157): Loss/seq after 02900 batchs: 392.2151184082031
INFO:root:Train (Epoch 157): Loss/seq after 02950 batchs: 392.665283203125
INFO:root:Train (Epoch 157): Loss/seq after 03000 batchs: 398.73193359375
INFO:root:Train (Epoch 157): Loss/seq after 03050 batchs: 400.695068359375
INFO:root:Train (Epoch 157): Loss/seq after 03100 batchs: 402.4158935546875
INFO:root:Train (Epoch 157): Loss/seq after 03150 batchs: 402.15252685546875
INFO:root:Train (Epoch 157): Loss/seq after 03200 batchs: 401.75823974609375
INFO:root:Train (Epoch 157): Loss/seq after 03250 batchs: 401.4540100097656
INFO:root:Train (Epoch 157): Loss/seq after 03300 batchs: 401.01177978515625
INFO:root:Train (Epoch 157): Loss/seq after 03350 batchs: 398.94000244140625
INFO:root:Train (Epoch 157): Loss/seq after 03400 batchs: 396.02117919921875
INFO:root:Train (Epoch 157): Loss/seq after 03450 batchs: 394.4148864746094
INFO:root:Train (Epoch 157): Loss/seq after 03500 batchs: 395.4375915527344
INFO:root:Train (Epoch 157): Loss/seq after 03550 batchs: 393.7908020019531
INFO:root:Train (Epoch 157): Loss/seq after 03600 batchs: 400.6462707519531
INFO:root:Train (Epoch 157): Loss/seq after 03650 batchs: 399.2920227050781
INFO:root:Train (Epoch 157): Loss/seq after 03700 batchs: 401.8399963378906
INFO:root:Train (Epoch 157): Loss/seq after 03750 batchs: 406.5381774902344
INFO:root:Train (Epoch 157): Loss/seq after 03800 batchs: 405.9354553222656
INFO:root:Train (Epoch 157): Loss/seq after 03850 batchs: 405.40240478515625
INFO:root:Train (Epoch 157): Loss/seq after 03900 batchs: 407.3785095214844
INFO:root:Train (Epoch 157): Loss/seq after 03950 batchs: 409.16864013671875
INFO:root:Train (Epoch 157): Loss/seq after 04000 batchs: 406.84820556640625
INFO:root:Train (Epoch 157): Loss/seq after 04050 batchs: 404.35491943359375
INFO:root:Train (Epoch 157): Loss/seq after 04100 batchs: 403.7817687988281
INFO:root:Train (Epoch 157): Loss/seq after 04150 batchs: 404.2702331542969
INFO:root:Train (Epoch 157): Loss/seq after 04200 batchs: 403.3061828613281
INFO:root:Train (Epoch 157): Loss/seq after 04250 batchs: 402.2224426269531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 157): Loss/seq after 00000 batches: 285.3341979980469
INFO:root:# Valid (Epoch 157): Loss/seq after 00050 batches: 591.2265014648438
INFO:root:# Valid (Epoch 157): Loss/seq after 00100 batches: 580.7608032226562
INFO:root:# Valid (Epoch 157): Loss/seq after 00150 batches: 440.3255920410156
INFO:root:# Valid (Epoch 157): Loss/seq after 00200 batches: 418.2149658203125
INFO:root:Artifacts: Make stick videos for epoch 157
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_157_on_20220422_122341.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_157_index_472_on_20220422_122341.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 158): Loss/seq after 00000 batchs: 652.8744506835938
INFO:root:Train (Epoch 158): Loss/seq after 00050 batchs: 550.0653686523438
INFO:root:Train (Epoch 158): Loss/seq after 00100 batchs: 562.3580322265625
INFO:root:Train (Epoch 158): Loss/seq after 00150 batchs: 523.7609252929688
INFO:root:Train (Epoch 158): Loss/seq after 00200 batchs: 573.3292846679688
INFO:root:Train (Epoch 158): Loss/seq after 00250 batchs: 643.2009887695312
INFO:root:Train (Epoch 158): Loss/seq after 00300 batchs: 654.7601318359375
INFO:root:Train (Epoch 158): Loss/seq after 00350 batchs: 619.6219482421875
INFO:root:Train (Epoch 158): Loss/seq after 00400 batchs: 603.6231689453125
INFO:root:Train (Epoch 158): Loss/seq after 00450 batchs: 607.4157104492188
INFO:root:Train (Epoch 158): Loss/seq after 00500 batchs: 586.7867431640625
INFO:root:Train (Epoch 158): Loss/seq after 00550 batchs: 574.9711303710938
INFO:root:Train (Epoch 158): Loss/seq after 00600 batchs: 556.9754638671875
INFO:root:Train (Epoch 158): Loss/seq after 00650 batchs: 534.91552734375
INFO:root:Train (Epoch 158): Loss/seq after 00700 batchs: 511.0702209472656
INFO:root:Train (Epoch 158): Loss/seq after 00750 batchs: 500.8134460449219
INFO:root:Train (Epoch 158): Loss/seq after 00800 batchs: 505.5455627441406
INFO:root:Train (Epoch 158): Loss/seq after 00850 batchs: 489.4930114746094
INFO:root:Train (Epoch 158): Loss/seq after 00900 batchs: 477.4178161621094
INFO:root:Train (Epoch 158): Loss/seq after 00950 batchs: 473.1025695800781
INFO:root:Train (Epoch 158): Loss/seq after 01000 batchs: 464.4422607421875
INFO:root:Train (Epoch 158): Loss/seq after 01050 batchs: 455.1963806152344
INFO:root:Train (Epoch 158): Loss/seq after 01100 batchs: 446.4443359375
INFO:root:Train (Epoch 158): Loss/seq after 01150 batchs: 433.9945068359375
INFO:root:Train (Epoch 158): Loss/seq after 01200 batchs: 439.0713806152344
INFO:root:Train (Epoch 158): Loss/seq after 01250 batchs: 439.060302734375
INFO:root:Train (Epoch 158): Loss/seq after 01300 batchs: 428.5898742675781
INFO:root:Train (Epoch 158): Loss/seq after 01350 batchs: 419.1093444824219
INFO:root:Train (Epoch 158): Loss/seq after 01400 batchs: 419.869873046875
INFO:root:Train (Epoch 158): Loss/seq after 01450 batchs: 423.57550048828125
INFO:root:Train (Epoch 158): Loss/seq after 01500 batchs: 431.39630126953125
INFO:root:Train (Epoch 158): Loss/seq after 01550 batchs: 432.2937927246094
INFO:root:Train (Epoch 158): Loss/seq after 01600 batchs: 429.4703063964844
INFO:root:Train (Epoch 158): Loss/seq after 01650 batchs: 428.3621520996094
INFO:root:Train (Epoch 158): Loss/seq after 01700 batchs: 433.1647644042969
INFO:root:Train (Epoch 158): Loss/seq after 01750 batchs: 431.76287841796875
INFO:root:Train (Epoch 158): Loss/seq after 01800 batchs: 430.6552429199219
INFO:root:Train (Epoch 158): Loss/seq after 01850 batchs: 428.66351318359375
INFO:root:Train (Epoch 158): Loss/seq after 01900 batchs: 428.25341796875
INFO:root:Train (Epoch 158): Loss/seq after 01950 batchs: 427.5187072753906
INFO:root:Train (Epoch 158): Loss/seq after 02000 batchs: 428.56805419921875
INFO:root:Train (Epoch 158): Loss/seq after 02050 batchs: 428.8256530761719
INFO:root:Train (Epoch 158): Loss/seq after 02100 batchs: 428.1694641113281
INFO:root:Train (Epoch 158): Loss/seq after 02150 batchs: 427.45941162109375
INFO:root:Train (Epoch 158): Loss/seq after 02200 batchs: 426.674072265625
INFO:root:Train (Epoch 158): Loss/seq after 02250 batchs: 425.7511901855469
INFO:root:Train (Epoch 158): Loss/seq after 02300 batchs: 421.82403564453125
INFO:root:Train (Epoch 158): Loss/seq after 02350 batchs: 419.5323486328125
INFO:root:Train (Epoch 158): Loss/seq after 02400 batchs: 420.44659423828125
INFO:root:Train (Epoch 158): Loss/seq after 02450 batchs: 417.58551025390625
INFO:root:Train (Epoch 158): Loss/seq after 02500 batchs: 411.11907958984375
INFO:root:Train (Epoch 158): Loss/seq after 02550 batchs: 405.0230712890625
INFO:root:Train (Epoch 158): Loss/seq after 02600 batchs: 401.0456848144531
INFO:root:Train (Epoch 158): Loss/seq after 02650 batchs: 397.0496520996094
INFO:root:Train (Epoch 158): Loss/seq after 02700 batchs: 394.43115234375
INFO:root:Train (Epoch 158): Loss/seq after 02750 batchs: 390.2720031738281
INFO:root:Train (Epoch 158): Loss/seq after 02800 batchs: 388.3852233886719
INFO:root:Train (Epoch 158): Loss/seq after 02850 batchs: 388.12188720703125
INFO:root:Train (Epoch 158): Loss/seq after 02900 batchs: 388.6286926269531
INFO:root:Train (Epoch 158): Loss/seq after 02950 batchs: 389.10986328125
INFO:root:Train (Epoch 158): Loss/seq after 03000 batchs: 395.10919189453125
INFO:root:Train (Epoch 158): Loss/seq after 03050 batchs: 397.17938232421875
INFO:root:Train (Epoch 158): Loss/seq after 03100 batchs: 398.88958740234375
INFO:root:Train (Epoch 158): Loss/seq after 03150 batchs: 398.4451599121094
INFO:root:Train (Epoch 158): Loss/seq after 03200 batchs: 398.37298583984375
INFO:root:Train (Epoch 158): Loss/seq after 03250 batchs: 397.8651428222656
INFO:root:Train (Epoch 158): Loss/seq after 03300 batchs: 397.0283203125
INFO:root:Train (Epoch 158): Loss/seq after 03350 batchs: 395.0068664550781
INFO:root:Train (Epoch 158): Loss/seq after 03400 batchs: 392.1147766113281
INFO:root:Train (Epoch 158): Loss/seq after 03450 batchs: 390.55615234375
INFO:root:Train (Epoch 158): Loss/seq after 03500 batchs: 391.6941833496094
INFO:root:Train (Epoch 158): Loss/seq after 03550 batchs: 390.1618957519531
INFO:root:Train (Epoch 158): Loss/seq after 03600 batchs: 396.9393005371094
INFO:root:Train (Epoch 158): Loss/seq after 03650 batchs: 395.61444091796875
INFO:root:Train (Epoch 158): Loss/seq after 03700 batchs: 398.2164001464844
INFO:root:Train (Epoch 158): Loss/seq after 03750 batchs: 402.9886169433594
INFO:root:Train (Epoch 158): Loss/seq after 03800 batchs: 402.31915283203125
INFO:root:Train (Epoch 158): Loss/seq after 03850 batchs: 401.7852478027344
INFO:root:Train (Epoch 158): Loss/seq after 03900 batchs: 403.3836364746094
INFO:root:Train (Epoch 158): Loss/seq after 03950 batchs: 405.72528076171875
INFO:root:Train (Epoch 158): Loss/seq after 04000 batchs: 403.3634338378906
INFO:root:Train (Epoch 158): Loss/seq after 04050 batchs: 400.9127197265625
INFO:root:Train (Epoch 158): Loss/seq after 04100 batchs: 400.2742004394531
INFO:root:Train (Epoch 158): Loss/seq after 04150 batchs: 400.7429504394531
INFO:root:Train (Epoch 158): Loss/seq after 04200 batchs: 399.7850646972656
INFO:root:Train (Epoch 158): Loss/seq after 04250 batchs: 398.56756591796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 158): Loss/seq after 00000 batches: 282.5937805175781
INFO:root:# Valid (Epoch 158): Loss/seq after 00050 batches: 625.75830078125
INFO:root:# Valid (Epoch 158): Loss/seq after 00100 batches: 609.0326538085938
INFO:root:# Valid (Epoch 158): Loss/seq after 00150 batches: 463.6505432128906
INFO:root:# Valid (Epoch 158): Loss/seq after 00200 batches: 438.3184814453125
INFO:root:Artifacts: Make stick videos for epoch 158
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_158_on_20220422_122844.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_158_index_309_on_20220422_122844.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 159): Loss/seq after 00000 batchs: 606.8017578125
INFO:root:Train (Epoch 159): Loss/seq after 00050 batchs: 552.626220703125
INFO:root:Train (Epoch 159): Loss/seq after 00100 batchs: 556.42041015625
INFO:root:Train (Epoch 159): Loss/seq after 00150 batchs: 525.7398681640625
INFO:root:Train (Epoch 159): Loss/seq after 00200 batchs: 568.8538208007812
INFO:root:Train (Epoch 159): Loss/seq after 00250 batchs: 629.9100341796875
INFO:root:Train (Epoch 159): Loss/seq after 00300 batchs: 644.5401000976562
INFO:root:Train (Epoch 159): Loss/seq after 00350 batchs: 609.393310546875
INFO:root:Train (Epoch 159): Loss/seq after 00400 batchs: 591.5774536132812
INFO:root:Train (Epoch 159): Loss/seq after 00450 batchs: 597.131591796875
INFO:root:Train (Epoch 159): Loss/seq after 00500 batchs: 577.1300048828125
INFO:root:Train (Epoch 159): Loss/seq after 00550 batchs: 566.5304565429688
INFO:root:Train (Epoch 159): Loss/seq after 00600 batchs: 550.474365234375
INFO:root:Train (Epoch 159): Loss/seq after 00650 batchs: 528.5217895507812
INFO:root:Train (Epoch 159): Loss/seq after 00700 batchs: 505.6409606933594
INFO:root:Train (Epoch 159): Loss/seq after 00750 batchs: 496.2918701171875
INFO:root:Train (Epoch 159): Loss/seq after 00800 batchs: 501.45355224609375
INFO:root:Train (Epoch 159): Loss/seq after 00850 batchs: 485.265380859375
INFO:root:Train (Epoch 159): Loss/seq after 00900 batchs: 473.65509033203125
INFO:root:Train (Epoch 159): Loss/seq after 00950 batchs: 469.77203369140625
INFO:root:Train (Epoch 159): Loss/seq after 01000 batchs: 460.6604309082031
INFO:root:Train (Epoch 159): Loss/seq after 01050 batchs: 452.1106262207031
INFO:root:Train (Epoch 159): Loss/seq after 01100 batchs: 443.6236877441406
INFO:root:Train (Epoch 159): Loss/seq after 01150 batchs: 431.27044677734375
INFO:root:Train (Epoch 159): Loss/seq after 01200 batchs: 437.2184143066406
INFO:root:Train (Epoch 159): Loss/seq after 01250 batchs: 437.1444396972656
INFO:root:Train (Epoch 159): Loss/seq after 01300 batchs: 426.5527038574219
INFO:root:Train (Epoch 159): Loss/seq after 01350 batchs: 417.1219787597656
INFO:root:Train (Epoch 159): Loss/seq after 01400 batchs: 418.1778259277344
INFO:root:Train (Epoch 159): Loss/seq after 01450 batchs: 422.31048583984375
INFO:root:Train (Epoch 159): Loss/seq after 01500 batchs: 430.58233642578125
INFO:root:Train (Epoch 159): Loss/seq after 01550 batchs: 431.8270263671875
INFO:root:Train (Epoch 159): Loss/seq after 01600 batchs: 428.934814453125
INFO:root:Train (Epoch 159): Loss/seq after 01650 batchs: 427.8459777832031
INFO:root:Train (Epoch 159): Loss/seq after 01700 batchs: 432.620849609375
INFO:root:Train (Epoch 159): Loss/seq after 01750 batchs: 431.34686279296875
INFO:root:Train (Epoch 159): Loss/seq after 01800 batchs: 430.06573486328125
INFO:root:Train (Epoch 159): Loss/seq after 01850 batchs: 428.0177307128906
INFO:root:Train (Epoch 159): Loss/seq after 01900 batchs: 427.4097900390625
INFO:root:Train (Epoch 159): Loss/seq after 01950 batchs: 426.80364990234375
INFO:root:Train (Epoch 159): Loss/seq after 02000 batchs: 427.8689880371094
INFO:root:Train (Epoch 159): Loss/seq after 02050 batchs: 427.9411926269531
INFO:root:Train (Epoch 159): Loss/seq after 02100 batchs: 426.8948669433594
INFO:root:Train (Epoch 159): Loss/seq after 02150 batchs: 426.1842346191406
INFO:root:Train (Epoch 159): Loss/seq after 02200 batchs: 425.34930419921875
INFO:root:Train (Epoch 159): Loss/seq after 02250 batchs: 424.2744140625
INFO:root:Train (Epoch 159): Loss/seq after 02300 batchs: 420.44268798828125
INFO:root:Train (Epoch 159): Loss/seq after 02350 batchs: 417.8640441894531
INFO:root:Train (Epoch 159): Loss/seq after 02400 batchs: 418.6099853515625
INFO:root:Train (Epoch 159): Loss/seq after 02450 batchs: 415.77685546875
INFO:root:Train (Epoch 159): Loss/seq after 02500 batchs: 409.3056640625
INFO:root:Train (Epoch 159): Loss/seq after 02550 batchs: 403.28173828125
INFO:root:Train (Epoch 159): Loss/seq after 02600 batchs: 399.30267333984375
INFO:root:Train (Epoch 159): Loss/seq after 02650 batchs: 395.21978759765625
INFO:root:Train (Epoch 159): Loss/seq after 02700 batchs: 392.5727233886719
INFO:root:Train (Epoch 159): Loss/seq after 02750 batchs: 388.2223815917969
INFO:root:Train (Epoch 159): Loss/seq after 02800 batchs: 386.087646484375
INFO:root:Train (Epoch 159): Loss/seq after 02850 batchs: 385.9023132324219
INFO:root:Train (Epoch 159): Loss/seq after 02900 batchs: 386.630859375
INFO:root:Train (Epoch 159): Loss/seq after 02950 batchs: 387.11431884765625
INFO:root:Train (Epoch 159): Loss/seq after 03000 batchs: 392.9945983886719
INFO:root:Train (Epoch 159): Loss/seq after 03050 batchs: 395.2032165527344
INFO:root:Train (Epoch 159): Loss/seq after 03100 batchs: 396.86297607421875
INFO:root:Train (Epoch 159): Loss/seq after 03150 batchs: 396.2497253417969
INFO:root:Train (Epoch 159): Loss/seq after 03200 batchs: 395.88433837890625
INFO:root:Train (Epoch 159): Loss/seq after 03250 batchs: 395.3742980957031
INFO:root:Train (Epoch 159): Loss/seq after 03300 batchs: 395.0062255859375
INFO:root:Train (Epoch 159): Loss/seq after 03350 batchs: 393.01177978515625
INFO:root:Train (Epoch 159): Loss/seq after 03400 batchs: 390.1082458496094
INFO:root:Train (Epoch 159): Loss/seq after 03450 batchs: 388.5211486816406
INFO:root:Train (Epoch 159): Loss/seq after 03500 batchs: 389.3338317871094
INFO:root:Train (Epoch 159): Loss/seq after 03550 batchs: 387.7127380371094
INFO:root:Train (Epoch 159): Loss/seq after 03600 batchs: 394.3208312988281
INFO:root:Train (Epoch 159): Loss/seq after 03650 batchs: 393.1328430175781
INFO:root:Train (Epoch 159): Loss/seq after 03700 batchs: 396.02008056640625
INFO:root:Train (Epoch 159): Loss/seq after 03750 batchs: 400.86273193359375
INFO:root:Train (Epoch 159): Loss/seq after 03800 batchs: 400.26068115234375
INFO:root:Train (Epoch 159): Loss/seq after 03850 batchs: 399.7201232910156
INFO:root:Train (Epoch 159): Loss/seq after 03900 batchs: 401.1268310546875
INFO:root:Train (Epoch 159): Loss/seq after 03950 batchs: 403.3492431640625
INFO:root:Train (Epoch 159): Loss/seq after 04000 batchs: 401.00634765625
INFO:root:Train (Epoch 159): Loss/seq after 04050 batchs: 398.5533447265625
INFO:root:Train (Epoch 159): Loss/seq after 04100 batchs: 397.98284912109375
INFO:root:Train (Epoch 159): Loss/seq after 04150 batchs: 398.4169006347656
INFO:root:Train (Epoch 159): Loss/seq after 04200 batchs: 397.4595031738281
INFO:root:Train (Epoch 159): Loss/seq after 04250 batchs: 396.3173522949219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 159): Loss/seq after 00000 batches: 289.2998962402344
INFO:root:# Valid (Epoch 159): Loss/seq after 00050 batches: 588.2130126953125
INFO:root:# Valid (Epoch 159): Loss/seq after 00100 batches: 577.7618408203125
INFO:root:# Valid (Epoch 159): Loss/seq after 00150 batches: 440.76904296875
INFO:root:# Valid (Epoch 159): Loss/seq after 00200 batches: 420.0489196777344
INFO:root:Artifacts: Make stick videos for epoch 159
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_159_on_20220422_123342.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_159_index_1777_on_20220422_123342.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 160): Loss/seq after 00000 batchs: 581.3837280273438
INFO:root:Train (Epoch 160): Loss/seq after 00050 batchs: 549.2109375
INFO:root:Train (Epoch 160): Loss/seq after 00100 batchs: 560.8304443359375
INFO:root:Train (Epoch 160): Loss/seq after 00150 batchs: 522.7286987304688
INFO:root:Train (Epoch 160): Loss/seq after 00200 batchs: 582.735107421875
INFO:root:Train (Epoch 160): Loss/seq after 00250 batchs: 641.805419921875
INFO:root:Train (Epoch 160): Loss/seq after 00300 batchs: 651.9512939453125
INFO:root:Train (Epoch 160): Loss/seq after 00350 batchs: 616.0576171875
INFO:root:Train (Epoch 160): Loss/seq after 00400 batchs: 604.41796875
INFO:root:Train (Epoch 160): Loss/seq after 00450 batchs: 608.1197509765625
INFO:root:Train (Epoch 160): Loss/seq after 00500 batchs: 586.8316650390625
INFO:root:Train (Epoch 160): Loss/seq after 00550 batchs: 573.8230590820312
INFO:root:Train (Epoch 160): Loss/seq after 00600 batchs: 555.8614501953125
INFO:root:Train (Epoch 160): Loss/seq after 00650 batchs: 532.5745849609375
INFO:root:Train (Epoch 160): Loss/seq after 00700 batchs: 509.4921569824219
INFO:root:Train (Epoch 160): Loss/seq after 00750 batchs: 500.01873779296875
INFO:root:Train (Epoch 160): Loss/seq after 00800 batchs: 505.446044921875
INFO:root:Train (Epoch 160): Loss/seq after 00850 batchs: 489.2003479003906
INFO:root:Train (Epoch 160): Loss/seq after 00900 batchs: 477.1197204589844
INFO:root:Train (Epoch 160): Loss/seq after 00950 batchs: 472.42645263671875
INFO:root:Train (Epoch 160): Loss/seq after 01000 batchs: 463.7408142089844
INFO:root:Train (Epoch 160): Loss/seq after 01050 batchs: 454.6904296875
INFO:root:Train (Epoch 160): Loss/seq after 01100 batchs: 445.8675842285156
INFO:root:Train (Epoch 160): Loss/seq after 01150 batchs: 433.6534118652344
INFO:root:Train (Epoch 160): Loss/seq after 01200 batchs: 439.29864501953125
INFO:root:Train (Epoch 160): Loss/seq after 01250 batchs: 439.2503967285156
INFO:root:Train (Epoch 160): Loss/seq after 01300 batchs: 428.64239501953125
INFO:root:Train (Epoch 160): Loss/seq after 01350 batchs: 419.15643310546875
INFO:root:Train (Epoch 160): Loss/seq after 01400 batchs: 420.30438232421875
INFO:root:Train (Epoch 160): Loss/seq after 01450 batchs: 423.8378601074219
INFO:root:Train (Epoch 160): Loss/seq after 01500 batchs: 431.82568359375
INFO:root:Train (Epoch 160): Loss/seq after 01550 batchs: 432.7452697753906
INFO:root:Train (Epoch 160): Loss/seq after 01600 batchs: 429.7436828613281
INFO:root:Train (Epoch 160): Loss/seq after 01650 batchs: 428.7518310546875
INFO:root:Train (Epoch 160): Loss/seq after 01700 batchs: 433.34503173828125
INFO:root:Train (Epoch 160): Loss/seq after 01750 batchs: 431.82818603515625
INFO:root:Train (Epoch 160): Loss/seq after 01800 batchs: 430.4580993652344
INFO:root:Train (Epoch 160): Loss/seq after 01850 batchs: 428.35650634765625
INFO:root:Train (Epoch 160): Loss/seq after 01900 batchs: 427.5521240234375
INFO:root:Train (Epoch 160): Loss/seq after 01950 batchs: 426.9729919433594
INFO:root:Train (Epoch 160): Loss/seq after 02000 batchs: 427.97344970703125
INFO:root:Train (Epoch 160): Loss/seq after 02050 batchs: 427.89752197265625
INFO:root:Train (Epoch 160): Loss/seq after 02100 batchs: 427.135986328125
INFO:root:Train (Epoch 160): Loss/seq after 02150 batchs: 426.5095520019531
INFO:root:Train (Epoch 160): Loss/seq after 02200 batchs: 425.48553466796875
INFO:root:Train (Epoch 160): Loss/seq after 02250 batchs: 424.1376037597656
INFO:root:Train (Epoch 160): Loss/seq after 02300 batchs: 420.24456787109375
INFO:root:Train (Epoch 160): Loss/seq after 02350 batchs: 417.610107421875
INFO:root:Train (Epoch 160): Loss/seq after 02400 batchs: 418.36431884765625
INFO:root:Train (Epoch 160): Loss/seq after 02450 batchs: 415.4322814941406
INFO:root:Train (Epoch 160): Loss/seq after 02500 batchs: 408.99554443359375
INFO:root:Train (Epoch 160): Loss/seq after 02550 batchs: 402.9591064453125
INFO:root:Train (Epoch 160): Loss/seq after 02600 batchs: 398.8997497558594
INFO:root:Train (Epoch 160): Loss/seq after 02650 batchs: 394.75421142578125
INFO:root:Train (Epoch 160): Loss/seq after 02700 batchs: 392.007568359375
INFO:root:Train (Epoch 160): Loss/seq after 02750 batchs: 387.468994140625
INFO:root:Train (Epoch 160): Loss/seq after 02800 batchs: 385.5161437988281
INFO:root:Train (Epoch 160): Loss/seq after 02850 batchs: 385.4177551269531
INFO:root:Train (Epoch 160): Loss/seq after 02900 batchs: 386.33929443359375
INFO:root:Train (Epoch 160): Loss/seq after 02950 batchs: 386.9317932128906
INFO:root:Train (Epoch 160): Loss/seq after 03000 batchs: 392.9505615234375
INFO:root:Train (Epoch 160): Loss/seq after 03050 batchs: 394.87518310546875
INFO:root:Train (Epoch 160): Loss/seq after 03100 batchs: 396.3690490722656
INFO:root:Train (Epoch 160): Loss/seq after 03150 batchs: 395.7850341796875
INFO:root:Train (Epoch 160): Loss/seq after 03200 batchs: 394.99359130859375
INFO:root:Train (Epoch 160): Loss/seq after 03250 batchs: 394.0968322753906
INFO:root:Train (Epoch 160): Loss/seq after 03300 batchs: 393.3816833496094
INFO:root:Train (Epoch 160): Loss/seq after 03350 batchs: 391.23834228515625
INFO:root:Train (Epoch 160): Loss/seq after 03400 batchs: 388.32440185546875
INFO:root:Train (Epoch 160): Loss/seq after 03450 batchs: 386.6448974609375
INFO:root:Train (Epoch 160): Loss/seq after 03500 batchs: 387.6864929199219
INFO:root:Train (Epoch 160): Loss/seq after 03550 batchs: 386.24420166015625
INFO:root:Train (Epoch 160): Loss/seq after 03600 batchs: 392.9591369628906
INFO:root:Train (Epoch 160): Loss/seq after 03650 batchs: 391.79541015625
INFO:root:Train (Epoch 160): Loss/seq after 03700 batchs: 394.4027404785156
INFO:root:Train (Epoch 160): Loss/seq after 03750 batchs: 399.1387939453125
INFO:root:Train (Epoch 160): Loss/seq after 03800 batchs: 398.53594970703125
INFO:root:Train (Epoch 160): Loss/seq after 03850 batchs: 397.8113708496094
INFO:root:Train (Epoch 160): Loss/seq after 03900 batchs: 399.6898193359375
INFO:root:Train (Epoch 160): Loss/seq after 03950 batchs: 401.6181335449219
INFO:root:Train (Epoch 160): Loss/seq after 04000 batchs: 399.2794189453125
INFO:root:Train (Epoch 160): Loss/seq after 04050 batchs: 396.8499450683594
INFO:root:Train (Epoch 160): Loss/seq after 04100 batchs: 396.1940002441406
INFO:root:Train (Epoch 160): Loss/seq after 04150 batchs: 396.6788635253906
INFO:root:Train (Epoch 160): Loss/seq after 04200 batchs: 395.71099853515625
INFO:root:Train (Epoch 160): Loss/seq after 04250 batchs: 394.54718017578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 160): Loss/seq after 00000 batches: 297.7472839355469
INFO:root:# Valid (Epoch 160): Loss/seq after 00050 batches: 594.0128173828125
INFO:root:# Valid (Epoch 160): Loss/seq after 00100 batches: 589.986083984375
INFO:root:# Valid (Epoch 160): Loss/seq after 00150 batches: 447.478271484375
INFO:root:# Valid (Epoch 160): Loss/seq after 00200 batches: 422.4341125488281
INFO:root:Artifacts: Make stick videos for epoch 160
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_160_on_20220422_123825.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_160_index_1454_on_20220422_123825.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 161): Loss/seq after 00000 batchs: 596.2041015625
INFO:root:Train (Epoch 161): Loss/seq after 00050 batchs: 549.2522583007812
INFO:root:Train (Epoch 161): Loss/seq after 00100 batchs: 541.7206420898438
INFO:root:Train (Epoch 161): Loss/seq after 00150 batchs: 509.2305603027344
INFO:root:Train (Epoch 161): Loss/seq after 00200 batchs: 554.8991088867188
INFO:root:Train (Epoch 161): Loss/seq after 00250 batchs: 611.8075561523438
INFO:root:Train (Epoch 161): Loss/seq after 00300 batchs: 627.2779541015625
INFO:root:Train (Epoch 161): Loss/seq after 00350 batchs: 593.6026611328125
INFO:root:Train (Epoch 161): Loss/seq after 00400 batchs: 577.12353515625
INFO:root:Train (Epoch 161): Loss/seq after 00450 batchs: 583.70458984375
INFO:root:Train (Epoch 161): Loss/seq after 00500 batchs: 568.479248046875
INFO:root:Train (Epoch 161): Loss/seq after 00550 batchs: 559.2361450195312
INFO:root:Train (Epoch 161): Loss/seq after 00600 batchs: 543.3261108398438
INFO:root:Train (Epoch 161): Loss/seq after 00650 batchs: 520.9652709960938
INFO:root:Train (Epoch 161): Loss/seq after 00700 batchs: 498.64739990234375
INFO:root:Train (Epoch 161): Loss/seq after 00750 batchs: 488.6596984863281
INFO:root:Train (Epoch 161): Loss/seq after 00800 batchs: 494.1844482421875
INFO:root:Train (Epoch 161): Loss/seq after 00850 batchs: 479.1539306640625
INFO:root:Train (Epoch 161): Loss/seq after 00900 batchs: 468.4605712890625
INFO:root:Train (Epoch 161): Loss/seq after 00950 batchs: 464.107421875
INFO:root:Train (Epoch 161): Loss/seq after 01000 batchs: 454.9248962402344
INFO:root:Train (Epoch 161): Loss/seq after 01050 batchs: 447.4464416503906
INFO:root:Train (Epoch 161): Loss/seq after 01100 batchs: 438.85595703125
INFO:root:Train (Epoch 161): Loss/seq after 01150 batchs: 426.9363708496094
INFO:root:Train (Epoch 161): Loss/seq after 01200 batchs: 432.91650390625
INFO:root:Train (Epoch 161): Loss/seq after 01250 batchs: 432.9554443359375
INFO:root:Train (Epoch 161): Loss/seq after 01300 batchs: 422.6617431640625
INFO:root:Train (Epoch 161): Loss/seq after 01350 batchs: 413.3646545410156
INFO:root:Train (Epoch 161): Loss/seq after 01400 batchs: 413.22149658203125
INFO:root:Train (Epoch 161): Loss/seq after 01450 batchs: 417.1423645019531
INFO:root:Train (Epoch 161): Loss/seq after 01500 batchs: 425.38555908203125
INFO:root:Train (Epoch 161): Loss/seq after 01550 batchs: 426.46038818359375
INFO:root:Train (Epoch 161): Loss/seq after 01600 batchs: 423.6870422363281
INFO:root:Train (Epoch 161): Loss/seq after 01650 batchs: 422.69671630859375
INFO:root:Train (Epoch 161): Loss/seq after 01700 batchs: 427.2040100097656
INFO:root:Train (Epoch 161): Loss/seq after 01750 batchs: 425.9024658203125
INFO:root:Train (Epoch 161): Loss/seq after 01800 batchs: 424.5616149902344
INFO:root:Train (Epoch 161): Loss/seq after 01850 batchs: 422.5391540527344
INFO:root:Train (Epoch 161): Loss/seq after 01900 batchs: 422.2185363769531
INFO:root:Train (Epoch 161): Loss/seq after 01950 batchs: 421.4625244140625
INFO:root:Train (Epoch 161): Loss/seq after 02000 batchs: 422.51837158203125
INFO:root:Train (Epoch 161): Loss/seq after 02050 batchs: 422.691162109375
INFO:root:Train (Epoch 161): Loss/seq after 02100 batchs: 421.79656982421875
INFO:root:Train (Epoch 161): Loss/seq after 02150 batchs: 421.3349609375
INFO:root:Train (Epoch 161): Loss/seq after 02200 batchs: 420.5524597167969
INFO:root:Train (Epoch 161): Loss/seq after 02250 batchs: 419.55706787109375
INFO:root:Train (Epoch 161): Loss/seq after 02300 batchs: 416.0262451171875
INFO:root:Train (Epoch 161): Loss/seq after 02350 batchs: 413.541748046875
INFO:root:Train (Epoch 161): Loss/seq after 02400 batchs: 414.42864990234375
INFO:root:Train (Epoch 161): Loss/seq after 02450 batchs: 411.5689392089844
INFO:root:Train (Epoch 161): Loss/seq after 02500 batchs: 405.0909423828125
INFO:root:Train (Epoch 161): Loss/seq after 02550 batchs: 399.12615966796875
INFO:root:Train (Epoch 161): Loss/seq after 02600 batchs: 395.13006591796875
INFO:root:Train (Epoch 161): Loss/seq after 02650 batchs: 391.1446533203125
INFO:root:Train (Epoch 161): Loss/seq after 02700 batchs: 388.24810791015625
INFO:root:Train (Epoch 161): Loss/seq after 02750 batchs: 383.908447265625
INFO:root:Train (Epoch 161): Loss/seq after 02800 batchs: 381.55523681640625
INFO:root:Train (Epoch 161): Loss/seq after 02850 batchs: 381.36798095703125
INFO:root:Train (Epoch 161): Loss/seq after 02900 batchs: 382.3270568847656
INFO:root:Train (Epoch 161): Loss/seq after 02950 batchs: 383.0376281738281
INFO:root:Train (Epoch 161): Loss/seq after 03000 batchs: 389.19281005859375
INFO:root:Train (Epoch 161): Loss/seq after 03050 batchs: 391.3292541503906
INFO:root:Train (Epoch 161): Loss/seq after 03100 batchs: 393.4561767578125
INFO:root:Train (Epoch 161): Loss/seq after 03150 batchs: 394.41387939453125
INFO:root:Train (Epoch 161): Loss/seq after 03200 batchs: 394.380859375
INFO:root:Train (Epoch 161): Loss/seq after 03250 batchs: 393.6080017089844
INFO:root:Train (Epoch 161): Loss/seq after 03300 batchs: 393.19598388671875
INFO:root:Train (Epoch 161): Loss/seq after 03350 batchs: 391.268310546875
INFO:root:Train (Epoch 161): Loss/seq after 03400 batchs: 388.4042663574219
INFO:root:Train (Epoch 161): Loss/seq after 03450 batchs: 386.9434509277344
INFO:root:Train (Epoch 161): Loss/seq after 03500 batchs: 389.3501892089844
INFO:root:Train (Epoch 161): Loss/seq after 03550 batchs: 388.6768798828125
INFO:root:Train (Epoch 161): Loss/seq after 03600 batchs: 396.059326171875
INFO:root:Train (Epoch 161): Loss/seq after 03650 batchs: 394.7142333984375
INFO:root:Train (Epoch 161): Loss/seq after 03700 batchs: 398.4642028808594
INFO:root:Train (Epoch 161): Loss/seq after 03750 batchs: 403.1247253417969
INFO:root:Train (Epoch 161): Loss/seq after 03800 batchs: 402.51025390625
INFO:root:Train (Epoch 161): Loss/seq after 03850 batchs: 401.9617614746094
INFO:root:Train (Epoch 161): Loss/seq after 03900 batchs: 403.8784484863281
INFO:root:Train (Epoch 161): Loss/seq after 03950 batchs: 405.98956298828125
INFO:root:Train (Epoch 161): Loss/seq after 04000 batchs: 403.63531494140625
INFO:root:Train (Epoch 161): Loss/seq after 04050 batchs: 401.1336669921875
INFO:root:Train (Epoch 161): Loss/seq after 04100 batchs: 400.53057861328125
INFO:root:Train (Epoch 161): Loss/seq after 04150 batchs: 401.06097412109375
INFO:root:Train (Epoch 161): Loss/seq after 04200 batchs: 400.0618591308594
INFO:root:Train (Epoch 161): Loss/seq after 04250 batchs: 398.8592834472656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 161): Loss/seq after 00000 batches: 320.377685546875
INFO:root:# Valid (Epoch 161): Loss/seq after 00050 batches: 599.8214721679688
INFO:root:# Valid (Epoch 161): Loss/seq after 00100 batches: 603.5349731445312
INFO:root:# Valid (Epoch 161): Loss/seq after 00150 batches: 461.5987243652344
INFO:root:# Valid (Epoch 161): Loss/seq after 00200 batches: 444.0648498535156
INFO:root:Artifacts: Make stick videos for epoch 161
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_161_on_20220422_124328.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_161_index_1247_on_20220422_124328.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 162): Loss/seq after 00000 batchs: 561.6040649414062
INFO:root:Train (Epoch 162): Loss/seq after 00050 batchs: 576.13720703125
INFO:root:Train (Epoch 162): Loss/seq after 00100 batchs: 578.636962890625
INFO:root:Train (Epoch 162): Loss/seq after 00150 batchs: 548.2059326171875
INFO:root:Train (Epoch 162): Loss/seq after 00200 batchs: 588.7833862304688
INFO:root:Train (Epoch 162): Loss/seq after 00250 batchs: 642.9937744140625
INFO:root:Train (Epoch 162): Loss/seq after 00300 batchs: 653.5743408203125
INFO:root:Train (Epoch 162): Loss/seq after 00350 batchs: 619.6876831054688
INFO:root:Train (Epoch 162): Loss/seq after 00400 batchs: 603.3110961914062
INFO:root:Train (Epoch 162): Loss/seq after 00450 batchs: 607.0245971679688
INFO:root:Train (Epoch 162): Loss/seq after 00500 batchs: 587.30029296875
INFO:root:Train (Epoch 162): Loss/seq after 00550 batchs: 576.171875
INFO:root:Train (Epoch 162): Loss/seq after 00600 batchs: 557.844970703125
INFO:root:Train (Epoch 162): Loss/seq after 00650 batchs: 534.524169921875
INFO:root:Train (Epoch 162): Loss/seq after 00700 batchs: 509.9447021484375
INFO:root:Train (Epoch 162): Loss/seq after 00750 batchs: 501.0585632324219
INFO:root:Train (Epoch 162): Loss/seq after 00800 batchs: 507.5977478027344
INFO:root:Train (Epoch 162): Loss/seq after 00850 batchs: 491.1195983886719
INFO:root:Train (Epoch 162): Loss/seq after 00900 batchs: 478.6059875488281
INFO:root:Train (Epoch 162): Loss/seq after 00950 batchs: 473.5787658691406
INFO:root:Train (Epoch 162): Loss/seq after 01000 batchs: 464.12200927734375
INFO:root:Train (Epoch 162): Loss/seq after 01050 batchs: 454.74420166015625
INFO:root:Train (Epoch 162): Loss/seq after 01100 batchs: 445.3710021972656
INFO:root:Train (Epoch 162): Loss/seq after 01150 batchs: 432.5541687011719
INFO:root:Train (Epoch 162): Loss/seq after 01200 batchs: 437.28564453125
INFO:root:Train (Epoch 162): Loss/seq after 01250 batchs: 437.10540771484375
INFO:root:Train (Epoch 162): Loss/seq after 01300 batchs: 426.4075622558594
INFO:root:Train (Epoch 162): Loss/seq after 01350 batchs: 416.4457702636719
INFO:root:Train (Epoch 162): Loss/seq after 01400 batchs: 418.1558532714844
INFO:root:Train (Epoch 162): Loss/seq after 01450 batchs: 421.6433410644531
INFO:root:Train (Epoch 162): Loss/seq after 01500 batchs: 429.0783386230469
INFO:root:Train (Epoch 162): Loss/seq after 01550 batchs: 430.09368896484375
INFO:root:Train (Epoch 162): Loss/seq after 01600 batchs: 427.10125732421875
INFO:root:Train (Epoch 162): Loss/seq after 01650 batchs: 426.2501220703125
INFO:root:Train (Epoch 162): Loss/seq after 01700 batchs: 430.76251220703125
INFO:root:Train (Epoch 162): Loss/seq after 01750 batchs: 429.40289306640625
INFO:root:Train (Epoch 162): Loss/seq after 01800 batchs: 428.114990234375
INFO:root:Train (Epoch 162): Loss/seq after 01850 batchs: 426.12237548828125
INFO:root:Train (Epoch 162): Loss/seq after 01900 batchs: 425.84307861328125
INFO:root:Train (Epoch 162): Loss/seq after 01950 batchs: 425.17510986328125
INFO:root:Train (Epoch 162): Loss/seq after 02000 batchs: 425.9581298828125
INFO:root:Train (Epoch 162): Loss/seq after 02050 batchs: 426.3644714355469
INFO:root:Train (Epoch 162): Loss/seq after 02100 batchs: 426.32110595703125
INFO:root:Train (Epoch 162): Loss/seq after 02150 batchs: 425.743408203125
INFO:root:Train (Epoch 162): Loss/seq after 02200 batchs: 424.7947082519531
INFO:root:Train (Epoch 162): Loss/seq after 02250 batchs: 423.7154235839844
INFO:root:Train (Epoch 162): Loss/seq after 02300 batchs: 419.7998046875
INFO:root:Train (Epoch 162): Loss/seq after 02350 batchs: 417.0835876464844
INFO:root:Train (Epoch 162): Loss/seq after 02400 batchs: 417.77099609375
INFO:root:Train (Epoch 162): Loss/seq after 02450 batchs: 414.80914306640625
INFO:root:Train (Epoch 162): Loss/seq after 02500 batchs: 408.3064270019531
INFO:root:Train (Epoch 162): Loss/seq after 02550 batchs: 402.2018737792969
INFO:root:Train (Epoch 162): Loss/seq after 02600 batchs: 398.54229736328125
INFO:root:Train (Epoch 162): Loss/seq after 02650 batchs: 394.424072265625
INFO:root:Train (Epoch 162): Loss/seq after 02700 batchs: 391.6389465332031
INFO:root:Train (Epoch 162): Loss/seq after 02750 batchs: 387.6915283203125
INFO:root:Train (Epoch 162): Loss/seq after 02800 batchs: 385.4129638671875
INFO:root:Train (Epoch 162): Loss/seq after 02850 batchs: 385.1390380859375
INFO:root:Train (Epoch 162): Loss/seq after 02900 batchs: 385.90582275390625
INFO:root:Train (Epoch 162): Loss/seq after 02950 batchs: 386.5328674316406
INFO:root:Train (Epoch 162): Loss/seq after 03000 batchs: 392.44970703125
INFO:root:Train (Epoch 162): Loss/seq after 03050 batchs: 394.5773620605469
INFO:root:Train (Epoch 162): Loss/seq after 03100 batchs: 396.5606994628906
INFO:root:Train (Epoch 162): Loss/seq after 03150 batchs: 396.13519287109375
INFO:root:Train (Epoch 162): Loss/seq after 03200 batchs: 395.7727355957031
INFO:root:Train (Epoch 162): Loss/seq after 03250 batchs: 395.54193115234375
INFO:root:Train (Epoch 162): Loss/seq after 03300 batchs: 394.703857421875
INFO:root:Train (Epoch 162): Loss/seq after 03350 batchs: 392.45477294921875
INFO:root:Train (Epoch 162): Loss/seq after 03400 batchs: 389.51605224609375
INFO:root:Train (Epoch 162): Loss/seq after 03450 batchs: 387.8154296875
INFO:root:Train (Epoch 162): Loss/seq after 03500 batchs: 389.0865783691406
INFO:root:Train (Epoch 162): Loss/seq after 03550 batchs: 387.60699462890625
INFO:root:Train (Epoch 162): Loss/seq after 03600 batchs: 394.3350830078125
INFO:root:Train (Epoch 162): Loss/seq after 03650 batchs: 393.0129699707031
INFO:root:Train (Epoch 162): Loss/seq after 03700 batchs: 395.6898193359375
INFO:root:Train (Epoch 162): Loss/seq after 03750 batchs: 400.1863098144531
INFO:root:Train (Epoch 162): Loss/seq after 03800 batchs: 399.5555114746094
INFO:root:Train (Epoch 162): Loss/seq after 03850 batchs: 398.9125671386719
INFO:root:Train (Epoch 162): Loss/seq after 03900 batchs: 400.4967956542969
INFO:root:Train (Epoch 162): Loss/seq after 03950 batchs: 402.7881774902344
INFO:root:Train (Epoch 162): Loss/seq after 04000 batchs: 400.41845703125
INFO:root:Train (Epoch 162): Loss/seq after 04050 batchs: 397.9650573730469
INFO:root:Train (Epoch 162): Loss/seq after 04100 batchs: 397.3605651855469
INFO:root:Train (Epoch 162): Loss/seq after 04150 batchs: 397.7977294921875
INFO:root:Train (Epoch 162): Loss/seq after 04200 batchs: 396.8117980957031
INFO:root:Train (Epoch 162): Loss/seq after 04250 batchs: 395.60333251953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 162): Loss/seq after 00000 batches: 311.1871337890625
INFO:root:# Valid (Epoch 162): Loss/seq after 00050 batches: 616.2122802734375
INFO:root:# Valid (Epoch 162): Loss/seq after 00100 batches: 595.3887329101562
INFO:root:# Valid (Epoch 162): Loss/seq after 00150 batches: 452.6130065917969
INFO:root:# Valid (Epoch 162): Loss/seq after 00200 batches: 429.0092468261719
INFO:root:Artifacts: Make stick videos for epoch 162
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_162_on_20220422_124818.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_162_index_1813_on_20220422_124818.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 163): Loss/seq after 00000 batchs: 633.955810546875
INFO:root:Train (Epoch 163): Loss/seq after 00050 batchs: 558.739013671875
INFO:root:Train (Epoch 163): Loss/seq after 00100 batchs: 550.0609130859375
INFO:root:Train (Epoch 163): Loss/seq after 00150 batchs: 515.2933349609375
INFO:root:Train (Epoch 163): Loss/seq after 00200 batchs: 562.3885498046875
INFO:root:Train (Epoch 163): Loss/seq after 00250 batchs: 614.7496948242188
INFO:root:Train (Epoch 163): Loss/seq after 00300 batchs: 630.20654296875
INFO:root:Train (Epoch 163): Loss/seq after 00350 batchs: 598.2540283203125
INFO:root:Train (Epoch 163): Loss/seq after 00400 batchs: 581.1173706054688
INFO:root:Train (Epoch 163): Loss/seq after 00450 batchs: 586.8955078125
INFO:root:Train (Epoch 163): Loss/seq after 00500 batchs: 564.807373046875
INFO:root:Train (Epoch 163): Loss/seq after 00550 batchs: 554.2633056640625
INFO:root:Train (Epoch 163): Loss/seq after 00600 batchs: 537.2352905273438
INFO:root:Train (Epoch 163): Loss/seq after 00650 batchs: 514.775634765625
INFO:root:Train (Epoch 163): Loss/seq after 00700 batchs: 492.8166198730469
INFO:root:Train (Epoch 163): Loss/seq after 00750 batchs: 483.1060485839844
INFO:root:Train (Epoch 163): Loss/seq after 00800 batchs: 488.5245361328125
INFO:root:Train (Epoch 163): Loss/seq after 00850 batchs: 472.9320983886719
INFO:root:Train (Epoch 163): Loss/seq after 00900 batchs: 461.3860168457031
INFO:root:Train (Epoch 163): Loss/seq after 00950 batchs: 457.23095703125
INFO:root:Train (Epoch 163): Loss/seq after 01000 batchs: 448.9703063964844
INFO:root:Train (Epoch 163): Loss/seq after 01050 batchs: 442.10723876953125
INFO:root:Train (Epoch 163): Loss/seq after 01100 batchs: 434.1842346191406
INFO:root:Train (Epoch 163): Loss/seq after 01150 batchs: 422.3145751953125
INFO:root:Train (Epoch 163): Loss/seq after 01200 batchs: 427.74176025390625
INFO:root:Train (Epoch 163): Loss/seq after 01250 batchs: 428.16021728515625
INFO:root:Train (Epoch 163): Loss/seq after 01300 batchs: 417.732666015625
INFO:root:Train (Epoch 163): Loss/seq after 01350 batchs: 408.4229736328125
INFO:root:Train (Epoch 163): Loss/seq after 01400 batchs: 409.8384704589844
INFO:root:Train (Epoch 163): Loss/seq after 01450 batchs: 413.6695861816406
INFO:root:Train (Epoch 163): Loss/seq after 01500 batchs: 421.5142517089844
INFO:root:Train (Epoch 163): Loss/seq after 01550 batchs: 423.52105712890625
INFO:root:Train (Epoch 163): Loss/seq after 01600 batchs: 421.78240966796875
INFO:root:Train (Epoch 163): Loss/seq after 01650 batchs: 421.30596923828125
INFO:root:Train (Epoch 163): Loss/seq after 01700 batchs: 425.8579406738281
INFO:root:Train (Epoch 163): Loss/seq after 01750 batchs: 424.67474365234375
INFO:root:Train (Epoch 163): Loss/seq after 01800 batchs: 423.31048583984375
INFO:root:Train (Epoch 163): Loss/seq after 01850 batchs: 421.385009765625
INFO:root:Train (Epoch 163): Loss/seq after 01900 batchs: 420.9944763183594
INFO:root:Train (Epoch 163): Loss/seq after 01950 batchs: 421.3804931640625
INFO:root:Train (Epoch 163): Loss/seq after 02000 batchs: 422.4529113769531
INFO:root:Train (Epoch 163): Loss/seq after 02050 batchs: 422.8934631347656
INFO:root:Train (Epoch 163): Loss/seq after 02100 batchs: 421.8766174316406
INFO:root:Train (Epoch 163): Loss/seq after 02150 batchs: 421.1546325683594
INFO:root:Train (Epoch 163): Loss/seq after 02200 batchs: 420.0983581542969
INFO:root:Train (Epoch 163): Loss/seq after 02250 batchs: 419.1285095214844
INFO:root:Train (Epoch 163): Loss/seq after 02300 batchs: 415.37744140625
INFO:root:Train (Epoch 163): Loss/seq after 02350 batchs: 412.8899841308594
INFO:root:Train (Epoch 163): Loss/seq after 02400 batchs: 413.5729675292969
INFO:root:Train (Epoch 163): Loss/seq after 02450 batchs: 410.6492614746094
INFO:root:Train (Epoch 163): Loss/seq after 02500 batchs: 404.2315979003906
INFO:root:Train (Epoch 163): Loss/seq after 02550 batchs: 398.3175964355469
INFO:root:Train (Epoch 163): Loss/seq after 02600 batchs: 394.3637390136719
INFO:root:Train (Epoch 163): Loss/seq after 02650 batchs: 390.3049621582031
INFO:root:Train (Epoch 163): Loss/seq after 02700 batchs: 387.5480651855469
INFO:root:Train (Epoch 163): Loss/seq after 02750 batchs: 383.2038879394531
INFO:root:Train (Epoch 163): Loss/seq after 02800 batchs: 381.379638671875
INFO:root:Train (Epoch 163): Loss/seq after 02850 batchs: 381.0648498535156
INFO:root:Train (Epoch 163): Loss/seq after 02900 batchs: 381.4913330078125
INFO:root:Train (Epoch 163): Loss/seq after 02950 batchs: 382.04620361328125
INFO:root:Train (Epoch 163): Loss/seq after 03000 batchs: 387.8609313964844
INFO:root:Train (Epoch 163): Loss/seq after 03050 batchs: 389.802001953125
INFO:root:Train (Epoch 163): Loss/seq after 03100 batchs: 391.4512939453125
INFO:root:Train (Epoch 163): Loss/seq after 03150 batchs: 390.6667785644531
INFO:root:Train (Epoch 163): Loss/seq after 03200 batchs: 389.9423522949219
INFO:root:Train (Epoch 163): Loss/seq after 03250 batchs: 389.0895080566406
INFO:root:Train (Epoch 163): Loss/seq after 03300 batchs: 388.2934875488281
INFO:root:Train (Epoch 163): Loss/seq after 03350 batchs: 385.9389953613281
INFO:root:Train (Epoch 163): Loss/seq after 03400 batchs: 383.0600280761719
INFO:root:Train (Epoch 163): Loss/seq after 03450 batchs: 381.3685302734375
INFO:root:Train (Epoch 163): Loss/seq after 03500 batchs: 382.5056457519531
INFO:root:Train (Epoch 163): Loss/seq after 03550 batchs: 380.9082336425781
INFO:root:Train (Epoch 163): Loss/seq after 03600 batchs: 387.435791015625
INFO:root:Train (Epoch 163): Loss/seq after 03650 batchs: 386.0856018066406
INFO:root:Train (Epoch 163): Loss/seq after 03700 batchs: 388.7205505371094
INFO:root:Train (Epoch 163): Loss/seq after 03750 batchs: 393.4634094238281
INFO:root:Train (Epoch 163): Loss/seq after 03800 batchs: 392.89739990234375
INFO:root:Train (Epoch 163): Loss/seq after 03850 batchs: 392.3634033203125
INFO:root:Train (Epoch 163): Loss/seq after 03900 batchs: 393.7883605957031
INFO:root:Train (Epoch 163): Loss/seq after 03950 batchs: 395.8992919921875
INFO:root:Train (Epoch 163): Loss/seq after 04000 batchs: 393.7538146972656
INFO:root:Train (Epoch 163): Loss/seq after 04050 batchs: 391.3590087890625
INFO:root:Train (Epoch 163): Loss/seq after 04100 batchs: 390.7502136230469
INFO:root:Train (Epoch 163): Loss/seq after 04150 batchs: 391.21685791015625
INFO:root:Train (Epoch 163): Loss/seq after 04200 batchs: 390.29931640625
INFO:root:Train (Epoch 163): Loss/seq after 04250 batchs: 389.09075927734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 163): Loss/seq after 00000 batches: 311.4611511230469
INFO:root:# Valid (Epoch 163): Loss/seq after 00050 batches: 624.1544189453125
INFO:root:# Valid (Epoch 163): Loss/seq after 00100 batches: 600.1700439453125
INFO:root:# Valid (Epoch 163): Loss/seq after 00150 batches: 456.26123046875
INFO:root:# Valid (Epoch 163): Loss/seq after 00200 batches: 429.1771545410156
INFO:root:Artifacts: Make stick videos for epoch 163
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_163_on_20220422_125326.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_163_index_995_on_20220422_125326.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 164): Loss/seq after 00000 batchs: 604.8713989257812
INFO:root:Train (Epoch 164): Loss/seq after 00050 batchs: 538.8279418945312
INFO:root:Train (Epoch 164): Loss/seq after 00100 batchs: 540.6929931640625
INFO:root:Train (Epoch 164): Loss/seq after 00150 batchs: 510.5744934082031
INFO:root:Train (Epoch 164): Loss/seq after 00200 batchs: 549.0443115234375
INFO:root:Train (Epoch 164): Loss/seq after 00250 batchs: 623.5330810546875
INFO:root:Train (Epoch 164): Loss/seq after 00300 batchs: 638.7062377929688
INFO:root:Train (Epoch 164): Loss/seq after 00350 batchs: 603.9957885742188
INFO:root:Train (Epoch 164): Loss/seq after 00400 batchs: 587.5869750976562
INFO:root:Train (Epoch 164): Loss/seq after 00450 batchs: 592.4940185546875
INFO:root:Train (Epoch 164): Loss/seq after 00500 batchs: 573.4754028320312
INFO:root:Train (Epoch 164): Loss/seq after 00550 batchs: 561.5191040039062
INFO:root:Train (Epoch 164): Loss/seq after 00600 batchs: 544.2198486328125
INFO:root:Train (Epoch 164): Loss/seq after 00650 batchs: 521.822021484375
INFO:root:Train (Epoch 164): Loss/seq after 00700 batchs: 498.6238098144531
INFO:root:Train (Epoch 164): Loss/seq after 00750 batchs: 487.51776123046875
INFO:root:Train (Epoch 164): Loss/seq after 00800 batchs: 493.1068115234375
INFO:root:Train (Epoch 164): Loss/seq after 00850 batchs: 477.40625
INFO:root:Train (Epoch 164): Loss/seq after 00900 batchs: 466.12921142578125
INFO:root:Train (Epoch 164): Loss/seq after 00950 batchs: 462.1677551269531
INFO:root:Train (Epoch 164): Loss/seq after 01000 batchs: 453.08184814453125
INFO:root:Train (Epoch 164): Loss/seq after 01050 batchs: 443.85418701171875
INFO:root:Train (Epoch 164): Loss/seq after 01100 batchs: 435.24407958984375
INFO:root:Train (Epoch 164): Loss/seq after 01150 batchs: 423.1606750488281
INFO:root:Train (Epoch 164): Loss/seq after 01200 batchs: 428.52398681640625
INFO:root:Train (Epoch 164): Loss/seq after 01250 batchs: 428.5489501953125
INFO:root:Train (Epoch 164): Loss/seq after 01300 batchs: 418.43560791015625
INFO:root:Train (Epoch 164): Loss/seq after 01350 batchs: 409.2679443359375
INFO:root:Train (Epoch 164): Loss/seq after 01400 batchs: 410.0270690917969
INFO:root:Train (Epoch 164): Loss/seq after 01450 batchs: 413.7559509277344
INFO:root:Train (Epoch 164): Loss/seq after 01500 batchs: 421.0668029785156
INFO:root:Train (Epoch 164): Loss/seq after 01550 batchs: 422.3260192871094
INFO:root:Train (Epoch 164): Loss/seq after 01600 batchs: 419.4886169433594
INFO:root:Train (Epoch 164): Loss/seq after 01650 batchs: 418.6668395996094
INFO:root:Train (Epoch 164): Loss/seq after 01700 batchs: 423.7191467285156
INFO:root:Train (Epoch 164): Loss/seq after 01750 batchs: 422.58001708984375
INFO:root:Train (Epoch 164): Loss/seq after 01800 batchs: 421.69415283203125
INFO:root:Train (Epoch 164): Loss/seq after 01850 batchs: 419.75311279296875
INFO:root:Train (Epoch 164): Loss/seq after 01900 batchs: 419.216796875
INFO:root:Train (Epoch 164): Loss/seq after 01950 batchs: 418.7411804199219
INFO:root:Train (Epoch 164): Loss/seq after 02000 batchs: 419.7979736328125
INFO:root:Train (Epoch 164): Loss/seq after 02050 batchs: 420.27294921875
INFO:root:Train (Epoch 164): Loss/seq after 02100 batchs: 419.3936462402344
INFO:root:Train (Epoch 164): Loss/seq after 02150 batchs: 418.9226989746094
INFO:root:Train (Epoch 164): Loss/seq after 02200 batchs: 418.0904541015625
INFO:root:Train (Epoch 164): Loss/seq after 02250 batchs: 416.8424987792969
INFO:root:Train (Epoch 164): Loss/seq after 02300 batchs: 413.11871337890625
INFO:root:Train (Epoch 164): Loss/seq after 02350 batchs: 410.7298889160156
INFO:root:Train (Epoch 164): Loss/seq after 02400 batchs: 411.53082275390625
INFO:root:Train (Epoch 164): Loss/seq after 02450 batchs: 408.63592529296875
INFO:root:Train (Epoch 164): Loss/seq after 02500 batchs: 402.24798583984375
INFO:root:Train (Epoch 164): Loss/seq after 02550 batchs: 396.3522644042969
INFO:root:Train (Epoch 164): Loss/seq after 02600 batchs: 392.3615417480469
INFO:root:Train (Epoch 164): Loss/seq after 02650 batchs: 388.4148254394531
INFO:root:Train (Epoch 164): Loss/seq after 02700 batchs: 385.5932312011719
INFO:root:Train (Epoch 164): Loss/seq after 02750 batchs: 381.34149169921875
INFO:root:Train (Epoch 164): Loss/seq after 02800 batchs: 380.05426025390625
INFO:root:Train (Epoch 164): Loss/seq after 02850 batchs: 380.09246826171875
INFO:root:Train (Epoch 164): Loss/seq after 02900 batchs: 380.82464599609375
INFO:root:Train (Epoch 164): Loss/seq after 02950 batchs: 381.4369201660156
INFO:root:Train (Epoch 164): Loss/seq after 03000 batchs: 387.5256652832031
INFO:root:Train (Epoch 164): Loss/seq after 03050 batchs: 389.46368408203125
INFO:root:Train (Epoch 164): Loss/seq after 03100 batchs: 390.9974060058594
INFO:root:Train (Epoch 164): Loss/seq after 03150 batchs: 389.8165283203125
INFO:root:Train (Epoch 164): Loss/seq after 03200 batchs: 389.1061706542969
INFO:root:Train (Epoch 164): Loss/seq after 03250 batchs: 388.3778381347656
INFO:root:Train (Epoch 164): Loss/seq after 03300 batchs: 387.581298828125
INFO:root:Train (Epoch 164): Loss/seq after 03350 batchs: 385.4818115234375
INFO:root:Train (Epoch 164): Loss/seq after 03400 batchs: 382.6510314941406
INFO:root:Train (Epoch 164): Loss/seq after 03450 batchs: 381.076416015625
INFO:root:Train (Epoch 164): Loss/seq after 03500 batchs: 382.0704040527344
INFO:root:Train (Epoch 164): Loss/seq after 03550 batchs: 380.5650329589844
INFO:root:Train (Epoch 164): Loss/seq after 03600 batchs: 387.4767761230469
INFO:root:Train (Epoch 164): Loss/seq after 03650 batchs: 386.0273742675781
INFO:root:Train (Epoch 164): Loss/seq after 03700 batchs: 388.6549377441406
INFO:root:Train (Epoch 164): Loss/seq after 03750 batchs: 393.2141418457031
INFO:root:Train (Epoch 164): Loss/seq after 03800 batchs: 392.61187744140625
INFO:root:Train (Epoch 164): Loss/seq after 03850 batchs: 392.02154541015625
INFO:root:Train (Epoch 164): Loss/seq after 03900 batchs: 393.711181640625
INFO:root:Train (Epoch 164): Loss/seq after 03950 batchs: 396.9127502441406
INFO:root:Train (Epoch 164): Loss/seq after 04000 batchs: 394.6970520019531
INFO:root:Train (Epoch 164): Loss/seq after 04050 batchs: 392.2897033691406
INFO:root:Train (Epoch 164): Loss/seq after 04100 batchs: 391.6957702636719
INFO:root:Train (Epoch 164): Loss/seq after 04150 batchs: 392.21502685546875
INFO:root:Train (Epoch 164): Loss/seq after 04200 batchs: 391.307373046875
INFO:root:Train (Epoch 164): Loss/seq after 04250 batchs: 390.14935302734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 164): Loss/seq after 00000 batches: 323.0987854003906
INFO:root:# Valid (Epoch 164): Loss/seq after 00050 batches: 601.9669799804688
INFO:root:# Valid (Epoch 164): Loss/seq after 00100 batches: 582.6076049804688
INFO:root:# Valid (Epoch 164): Loss/seq after 00150 batches: 443.97222900390625
INFO:root:# Valid (Epoch 164): Loss/seq after 00200 batches: 422.7961120605469
INFO:root:Artifacts: Make stick videos for epoch 164
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_164_on_20220422_125831.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_164_index_583_on_20220422_125831.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 165): Loss/seq after 00000 batchs: 623.8041381835938
INFO:root:Train (Epoch 165): Loss/seq after 00050 batchs: 537.906005859375
INFO:root:Train (Epoch 165): Loss/seq after 00100 batchs: 537.7655029296875
INFO:root:Train (Epoch 165): Loss/seq after 00150 batchs: 503.7461853027344
INFO:root:Train (Epoch 165): Loss/seq after 00200 batchs: 548.6435546875
INFO:root:Train (Epoch 165): Loss/seq after 00250 batchs: 620.298828125
INFO:root:Train (Epoch 165): Loss/seq after 00300 batchs: 632.1115112304688
INFO:root:Train (Epoch 165): Loss/seq after 00350 batchs: 598.1990966796875
INFO:root:Train (Epoch 165): Loss/seq after 00400 batchs: 587.0194702148438
INFO:root:Train (Epoch 165): Loss/seq after 00450 batchs: 592.589599609375
INFO:root:Train (Epoch 165): Loss/seq after 00500 batchs: 574.229248046875
INFO:root:Train (Epoch 165): Loss/seq after 00550 batchs: 562.902099609375
INFO:root:Train (Epoch 165): Loss/seq after 00600 batchs: 545.3706665039062
INFO:root:Train (Epoch 165): Loss/seq after 00650 batchs: 523.69482421875
INFO:root:Train (Epoch 165): Loss/seq after 00700 batchs: 501.7373962402344
INFO:root:Train (Epoch 165): Loss/seq after 00750 batchs: 491.6239013671875
INFO:root:Train (Epoch 165): Loss/seq after 00800 batchs: 496.3164978027344
INFO:root:Train (Epoch 165): Loss/seq after 00850 batchs: 480.4660339355469
INFO:root:Train (Epoch 165): Loss/seq after 00900 batchs: 468.3635559082031
INFO:root:Train (Epoch 165): Loss/seq after 00950 batchs: 463.4541931152344
INFO:root:Train (Epoch 165): Loss/seq after 01000 batchs: 454.52618408203125
INFO:root:Train (Epoch 165): Loss/seq after 01050 batchs: 445.33428955078125
INFO:root:Train (Epoch 165): Loss/seq after 01100 batchs: 436.7116394042969
INFO:root:Train (Epoch 165): Loss/seq after 01150 batchs: 424.6596374511719
INFO:root:Train (Epoch 165): Loss/seq after 01200 batchs: 429.47674560546875
INFO:root:Train (Epoch 165): Loss/seq after 01250 batchs: 429.67071533203125
INFO:root:Train (Epoch 165): Loss/seq after 01300 batchs: 419.32965087890625
INFO:root:Train (Epoch 165): Loss/seq after 01350 batchs: 409.6514587402344
INFO:root:Train (Epoch 165): Loss/seq after 01400 batchs: 410.2303161621094
INFO:root:Train (Epoch 165): Loss/seq after 01450 batchs: 413.9859619140625
INFO:root:Train (Epoch 165): Loss/seq after 01500 batchs: 422.0533142089844
INFO:root:Train (Epoch 165): Loss/seq after 01550 batchs: 423.3571472167969
INFO:root:Train (Epoch 165): Loss/seq after 01600 batchs: 420.6027526855469
INFO:root:Train (Epoch 165): Loss/seq after 01650 batchs: 419.868408203125
INFO:root:Train (Epoch 165): Loss/seq after 01700 batchs: 424.5321960449219
INFO:root:Train (Epoch 165): Loss/seq after 01750 batchs: 422.8642883300781
INFO:root:Train (Epoch 165): Loss/seq after 01800 batchs: 421.50140380859375
INFO:root:Train (Epoch 165): Loss/seq after 01850 batchs: 419.5768737792969
INFO:root:Train (Epoch 165): Loss/seq after 01900 batchs: 419.28082275390625
INFO:root:Train (Epoch 165): Loss/seq after 01950 batchs: 419.401611328125
INFO:root:Train (Epoch 165): Loss/seq after 02000 batchs: 420.72589111328125
INFO:root:Train (Epoch 165): Loss/seq after 02050 batchs: 421.00726318359375
INFO:root:Train (Epoch 165): Loss/seq after 02100 batchs: 419.97442626953125
INFO:root:Train (Epoch 165): Loss/seq after 02150 batchs: 419.4569091796875
INFO:root:Train (Epoch 165): Loss/seq after 02200 batchs: 418.57318115234375
INFO:root:Train (Epoch 165): Loss/seq after 02250 batchs: 417.32135009765625
INFO:root:Train (Epoch 165): Loss/seq after 02300 batchs: 413.6041259765625
INFO:root:Train (Epoch 165): Loss/seq after 02350 batchs: 411.1245422363281
INFO:root:Train (Epoch 165): Loss/seq after 02400 batchs: 411.82562255859375
INFO:root:Train (Epoch 165): Loss/seq after 02450 batchs: 408.9205627441406
INFO:root:Train (Epoch 165): Loss/seq after 02500 batchs: 402.5243835449219
INFO:root:Train (Epoch 165): Loss/seq after 02550 batchs: 396.56512451171875
INFO:root:Train (Epoch 165): Loss/seq after 02600 batchs: 392.4404602050781
INFO:root:Train (Epoch 165): Loss/seq after 02650 batchs: 388.3932800292969
INFO:root:Train (Epoch 165): Loss/seq after 02700 batchs: 385.5580139160156
INFO:root:Train (Epoch 165): Loss/seq after 02750 batchs: 381.2623291015625
INFO:root:Train (Epoch 165): Loss/seq after 02800 batchs: 379.1865234375
INFO:root:Train (Epoch 165): Loss/seq after 02850 batchs: 378.89404296875
INFO:root:Train (Epoch 165): Loss/seq after 02900 batchs: 379.9881896972656
INFO:root:Train (Epoch 165): Loss/seq after 02950 batchs: 380.5318603515625
INFO:root:Train (Epoch 165): Loss/seq after 03000 batchs: 386.3306884765625
INFO:root:Train (Epoch 165): Loss/seq after 03050 batchs: 388.5069885253906
INFO:root:Train (Epoch 165): Loss/seq after 03100 batchs: 390.9750671386719
INFO:root:Train (Epoch 165): Loss/seq after 03150 batchs: 390.2982482910156
INFO:root:Train (Epoch 165): Loss/seq after 03200 batchs: 390.1175231933594
INFO:root:Train (Epoch 165): Loss/seq after 03250 batchs: 389.8260498046875
INFO:root:Train (Epoch 165): Loss/seq after 03300 batchs: 389.5478515625
INFO:root:Train (Epoch 165): Loss/seq after 03350 batchs: 387.5555114746094
INFO:root:Train (Epoch 165): Loss/seq after 03400 batchs: 384.7215881347656
INFO:root:Train (Epoch 165): Loss/seq after 03450 batchs: 383.1451721191406
INFO:root:Train (Epoch 165): Loss/seq after 03500 batchs: 384.3370666503906
INFO:root:Train (Epoch 165): Loss/seq after 03550 batchs: 382.8408508300781
INFO:root:Train (Epoch 165): Loss/seq after 03600 batchs: 389.6675720214844
INFO:root:Train (Epoch 165): Loss/seq after 03650 batchs: 388.1580810546875
INFO:root:Train (Epoch 165): Loss/seq after 03700 batchs: 391.2146911621094
INFO:root:Train (Epoch 165): Loss/seq after 03750 batchs: 395.8692932128906
INFO:root:Train (Epoch 165): Loss/seq after 03800 batchs: 395.27557373046875
INFO:root:Train (Epoch 165): Loss/seq after 03850 batchs: 394.7640686035156
INFO:root:Train (Epoch 165): Loss/seq after 03900 batchs: 396.4609069824219
INFO:root:Train (Epoch 165): Loss/seq after 03950 batchs: 398.6820983886719
INFO:root:Train (Epoch 165): Loss/seq after 04000 batchs: 396.37188720703125
INFO:root:Train (Epoch 165): Loss/seq after 04050 batchs: 393.9963073730469
INFO:root:Train (Epoch 165): Loss/seq after 04100 batchs: 393.4171142578125
INFO:root:Train (Epoch 165): Loss/seq after 04150 batchs: 393.8448791503906
INFO:root:Train (Epoch 165): Loss/seq after 04200 batchs: 392.9045715332031
INFO:root:Train (Epoch 165): Loss/seq after 04250 batchs: 391.86029052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 165): Loss/seq after 00000 batches: 316.4239501953125
INFO:root:# Valid (Epoch 165): Loss/seq after 00050 batches: 596.3637084960938
INFO:root:# Valid (Epoch 165): Loss/seq after 00100 batches: 600.2675170898438
INFO:root:# Valid (Epoch 165): Loss/seq after 00150 batches: 456.9413146972656
INFO:root:# Valid (Epoch 165): Loss/seq after 00200 batches: 429.39434814453125
INFO:root:Artifacts: Make stick videos for epoch 165
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_165_on_20220422_130319.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_165_index_1447_on_20220422_130319.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 166): Loss/seq after 00000 batchs: 554.1701049804688
INFO:root:Train (Epoch 166): Loss/seq after 00050 batchs: 542.8201904296875
INFO:root:Train (Epoch 166): Loss/seq after 00100 batchs: 544.2369384765625
INFO:root:Train (Epoch 166): Loss/seq after 00150 batchs: 522.0030517578125
INFO:root:Train (Epoch 166): Loss/seq after 00200 batchs: 568.0167236328125
INFO:root:Train (Epoch 166): Loss/seq after 00250 batchs: 620.5901489257812
INFO:root:Train (Epoch 166): Loss/seq after 00300 batchs: 634.0059204101562
INFO:root:Train (Epoch 166): Loss/seq after 00350 batchs: 600.0571899414062
INFO:root:Train (Epoch 166): Loss/seq after 00400 batchs: 585.5439453125
INFO:root:Train (Epoch 166): Loss/seq after 00450 batchs: 591.0152587890625
INFO:root:Train (Epoch 166): Loss/seq after 00500 batchs: 569.7564697265625
INFO:root:Train (Epoch 166): Loss/seq after 00550 batchs: 558.1387329101562
INFO:root:Train (Epoch 166): Loss/seq after 00600 batchs: 541.4864501953125
INFO:root:Train (Epoch 166): Loss/seq after 00650 batchs: 520.19873046875
INFO:root:Train (Epoch 166): Loss/seq after 00700 batchs: 497.4302978515625
INFO:root:Train (Epoch 166): Loss/seq after 00750 batchs: 487.8960876464844
INFO:root:Train (Epoch 166): Loss/seq after 00800 batchs: 494.7030029296875
INFO:root:Train (Epoch 166): Loss/seq after 00850 batchs: 479.90716552734375
INFO:root:Train (Epoch 166): Loss/seq after 00900 batchs: 468.779541015625
INFO:root:Train (Epoch 166): Loss/seq after 00950 batchs: 464.123046875
INFO:root:Train (Epoch 166): Loss/seq after 01000 batchs: 454.5468444824219
INFO:root:Train (Epoch 166): Loss/seq after 01050 batchs: 445.5268249511719
INFO:root:Train (Epoch 166): Loss/seq after 01100 batchs: 437.06573486328125
INFO:root:Train (Epoch 166): Loss/seq after 01150 batchs: 424.81353759765625
INFO:root:Train (Epoch 166): Loss/seq after 01200 batchs: 429.74847412109375
INFO:root:Train (Epoch 166): Loss/seq after 01250 batchs: 429.6341552734375
INFO:root:Train (Epoch 166): Loss/seq after 01300 batchs: 419.1923828125
INFO:root:Train (Epoch 166): Loss/seq after 01350 batchs: 409.5783386230469
INFO:root:Train (Epoch 166): Loss/seq after 01400 batchs: 410.13275146484375
INFO:root:Train (Epoch 166): Loss/seq after 01450 batchs: 413.833740234375
INFO:root:Train (Epoch 166): Loss/seq after 01500 batchs: 421.5689697265625
INFO:root:Train (Epoch 166): Loss/seq after 01550 batchs: 422.3212585449219
INFO:root:Train (Epoch 166): Loss/seq after 01600 batchs: 419.5763854980469
INFO:root:Train (Epoch 166): Loss/seq after 01650 batchs: 418.3555603027344
INFO:root:Train (Epoch 166): Loss/seq after 01700 batchs: 422.9253845214844
INFO:root:Train (Epoch 166): Loss/seq after 01750 batchs: 421.5109558105469
INFO:root:Train (Epoch 166): Loss/seq after 01800 batchs: 420.0195617675781
INFO:root:Train (Epoch 166): Loss/seq after 01850 batchs: 418.0861511230469
INFO:root:Train (Epoch 166): Loss/seq after 01900 batchs: 417.9571228027344
INFO:root:Train (Epoch 166): Loss/seq after 01950 batchs: 417.8638000488281
INFO:root:Train (Epoch 166): Loss/seq after 02000 batchs: 419.0054016113281
INFO:root:Train (Epoch 166): Loss/seq after 02050 batchs: 419.13079833984375
INFO:root:Train (Epoch 166): Loss/seq after 02100 batchs: 418.1213684082031
INFO:root:Train (Epoch 166): Loss/seq after 02150 batchs: 417.4045715332031
INFO:root:Train (Epoch 166): Loss/seq after 02200 batchs: 416.6658630371094
INFO:root:Train (Epoch 166): Loss/seq after 02250 batchs: 415.52056884765625
INFO:root:Train (Epoch 166): Loss/seq after 02300 batchs: 411.7832336425781
INFO:root:Train (Epoch 166): Loss/seq after 02350 batchs: 409.2724609375
INFO:root:Train (Epoch 166): Loss/seq after 02400 batchs: 409.9931335449219
INFO:root:Train (Epoch 166): Loss/seq after 02450 batchs: 407.1628112792969
INFO:root:Train (Epoch 166): Loss/seq after 02500 batchs: 400.8121643066406
INFO:root:Train (Epoch 166): Loss/seq after 02550 batchs: 394.797119140625
INFO:root:Train (Epoch 166): Loss/seq after 02600 batchs: 390.783447265625
INFO:root:Train (Epoch 166): Loss/seq after 02650 batchs: 386.51507568359375
INFO:root:Train (Epoch 166): Loss/seq after 02700 batchs: 383.537109375
INFO:root:Train (Epoch 166): Loss/seq after 02750 batchs: 378.96820068359375
INFO:root:Train (Epoch 166): Loss/seq after 02800 batchs: 376.6337890625
INFO:root:Train (Epoch 166): Loss/seq after 02850 batchs: 376.4474792480469
INFO:root:Train (Epoch 166): Loss/seq after 02900 batchs: 377.2790222167969
INFO:root:Train (Epoch 166): Loss/seq after 02950 batchs: 377.8782958984375
INFO:root:Train (Epoch 166): Loss/seq after 03000 batchs: 383.7911682128906
INFO:root:Train (Epoch 166): Loss/seq after 03050 batchs: 385.7458801269531
INFO:root:Train (Epoch 166): Loss/seq after 03100 batchs: 387.3616943359375
INFO:root:Train (Epoch 166): Loss/seq after 03150 batchs: 386.9138488769531
INFO:root:Train (Epoch 166): Loss/seq after 03200 batchs: 386.6270446777344
INFO:root:Train (Epoch 166): Loss/seq after 03250 batchs: 385.98492431640625
INFO:root:Train (Epoch 166): Loss/seq after 03300 batchs: 385.4090270996094
INFO:root:Train (Epoch 166): Loss/seq after 03350 batchs: 383.1292419433594
INFO:root:Train (Epoch 166): Loss/seq after 03400 batchs: 380.3005065917969
INFO:root:Train (Epoch 166): Loss/seq after 03450 batchs: 378.6784362792969
INFO:root:Train (Epoch 166): Loss/seq after 03500 batchs: 379.5801086425781
INFO:root:Train (Epoch 166): Loss/seq after 03550 batchs: 377.99603271484375
INFO:root:Train (Epoch 166): Loss/seq after 03600 batchs: 384.7473449707031
INFO:root:Train (Epoch 166): Loss/seq after 03650 batchs: 383.6114196777344
INFO:root:Train (Epoch 166): Loss/seq after 03700 batchs: 386.32293701171875
INFO:root:Train (Epoch 166): Loss/seq after 03750 batchs: 391.7381286621094
INFO:root:Train (Epoch 166): Loss/seq after 03800 batchs: 391.3382873535156
INFO:root:Train (Epoch 166): Loss/seq after 03850 batchs: 390.77532958984375
INFO:root:Train (Epoch 166): Loss/seq after 03900 batchs: 392.58807373046875
INFO:root:Train (Epoch 166): Loss/seq after 03950 batchs: 394.4569396972656
INFO:root:Train (Epoch 166): Loss/seq after 04000 batchs: 392.1614990234375
INFO:root:Train (Epoch 166): Loss/seq after 04050 batchs: 389.7480773925781
INFO:root:Train (Epoch 166): Loss/seq after 04100 batchs: 389.15960693359375
INFO:root:Train (Epoch 166): Loss/seq after 04150 batchs: 389.4836730957031
INFO:root:Train (Epoch 166): Loss/seq after 04200 batchs: 388.60894775390625
INFO:root:Train (Epoch 166): Loss/seq after 04250 batchs: 387.5818786621094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 166): Loss/seq after 00000 batches: 265.37872314453125
INFO:root:# Valid (Epoch 166): Loss/seq after 00050 batches: 574.21728515625
INFO:root:# Valid (Epoch 166): Loss/seq after 00100 batches: 586.0597534179688
INFO:root:# Valid (Epoch 166): Loss/seq after 00150 batches: 447.0037841796875
INFO:root:# Valid (Epoch 166): Loss/seq after 00200 batches: 428.9033203125
INFO:root:Artifacts: Make stick videos for epoch 166
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_166_on_20220422_130807.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_166_index_1438_on_20220422_130807.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 167): Loss/seq after 00000 batchs: 522.8683471679688
INFO:root:Train (Epoch 167): Loss/seq after 00050 batchs: 525.8173217773438
INFO:root:Train (Epoch 167): Loss/seq after 00100 batchs: 538.21435546875
INFO:root:Train (Epoch 167): Loss/seq after 00150 batchs: 513.3207397460938
INFO:root:Train (Epoch 167): Loss/seq after 00200 batchs: 552.7684326171875
INFO:root:Train (Epoch 167): Loss/seq after 00250 batchs: 613.793701171875
INFO:root:Train (Epoch 167): Loss/seq after 00300 batchs: 628.1740112304688
INFO:root:Train (Epoch 167): Loss/seq after 00350 batchs: 595.0006103515625
INFO:root:Train (Epoch 167): Loss/seq after 00400 batchs: 578.2939453125
INFO:root:Train (Epoch 167): Loss/seq after 00450 batchs: 584.60986328125
INFO:root:Train (Epoch 167): Loss/seq after 00500 batchs: 562.7860107421875
INFO:root:Train (Epoch 167): Loss/seq after 00550 batchs: 551.8272094726562
INFO:root:Train (Epoch 167): Loss/seq after 00600 batchs: 535.3713989257812
INFO:root:Train (Epoch 167): Loss/seq after 00650 batchs: 512.6571044921875
INFO:root:Train (Epoch 167): Loss/seq after 00700 batchs: 490.6476745605469
INFO:root:Train (Epoch 167): Loss/seq after 00750 batchs: 479.5904541015625
INFO:root:Train (Epoch 167): Loss/seq after 00800 batchs: 487.491943359375
INFO:root:Train (Epoch 167): Loss/seq after 00850 batchs: 472.91326904296875
INFO:root:Train (Epoch 167): Loss/seq after 00900 batchs: 461.90130615234375
INFO:root:Train (Epoch 167): Loss/seq after 00950 batchs: 457.1785888671875
INFO:root:Train (Epoch 167): Loss/seq after 01000 batchs: 447.37127685546875
INFO:root:Train (Epoch 167): Loss/seq after 01050 batchs: 438.23834228515625
INFO:root:Train (Epoch 167): Loss/seq after 01100 batchs: 430.3406066894531
INFO:root:Train (Epoch 167): Loss/seq after 01150 batchs: 418.4355773925781
INFO:root:Train (Epoch 167): Loss/seq after 01200 batchs: 423.3960876464844
INFO:root:Train (Epoch 167): Loss/seq after 01250 batchs: 423.6100158691406
INFO:root:Train (Epoch 167): Loss/seq after 01300 batchs: 413.6360778808594
INFO:root:Train (Epoch 167): Loss/seq after 01350 batchs: 404.8468017578125
INFO:root:Train (Epoch 167): Loss/seq after 01400 batchs: 406.0154724121094
INFO:root:Train (Epoch 167): Loss/seq after 01450 batchs: 410.0133972167969
INFO:root:Train (Epoch 167): Loss/seq after 01500 batchs: 417.8370361328125
INFO:root:Train (Epoch 167): Loss/seq after 01550 batchs: 418.84625244140625
INFO:root:Train (Epoch 167): Loss/seq after 01600 batchs: 416.53265380859375
INFO:root:Train (Epoch 167): Loss/seq after 01650 batchs: 415.5894775390625
INFO:root:Train (Epoch 167): Loss/seq after 01700 batchs: 420.4306945800781
INFO:root:Train (Epoch 167): Loss/seq after 01750 batchs: 419.4727783203125
INFO:root:Train (Epoch 167): Loss/seq after 01800 batchs: 418.3061218261719
INFO:root:Train (Epoch 167): Loss/seq after 01850 batchs: 416.337158203125
INFO:root:Train (Epoch 167): Loss/seq after 01900 batchs: 415.89996337890625
INFO:root:Train (Epoch 167): Loss/seq after 01950 batchs: 415.5159912109375
INFO:root:Train (Epoch 167): Loss/seq after 02000 batchs: 416.4250183105469
INFO:root:Train (Epoch 167): Loss/seq after 02050 batchs: 416.7022705078125
INFO:root:Train (Epoch 167): Loss/seq after 02100 batchs: 415.7363586425781
INFO:root:Train (Epoch 167): Loss/seq after 02150 batchs: 415.0377197265625
INFO:root:Train (Epoch 167): Loss/seq after 02200 batchs: 414.1814270019531
INFO:root:Train (Epoch 167): Loss/seq after 02250 batchs: 413.1446228027344
INFO:root:Train (Epoch 167): Loss/seq after 02300 batchs: 409.37445068359375
INFO:root:Train (Epoch 167): Loss/seq after 02350 batchs: 406.9786682128906
INFO:root:Train (Epoch 167): Loss/seq after 02400 batchs: 407.725830078125
INFO:root:Train (Epoch 167): Loss/seq after 02450 batchs: 404.905029296875
INFO:root:Train (Epoch 167): Loss/seq after 02500 batchs: 398.5328674316406
INFO:root:Train (Epoch 167): Loss/seq after 02550 batchs: 392.5148620605469
INFO:root:Train (Epoch 167): Loss/seq after 02600 batchs: 388.3941345214844
INFO:root:Train (Epoch 167): Loss/seq after 02650 batchs: 384.3226013183594
INFO:root:Train (Epoch 167): Loss/seq after 02700 batchs: 381.407470703125
INFO:root:Train (Epoch 167): Loss/seq after 02750 batchs: 377.3885192871094
INFO:root:Train (Epoch 167): Loss/seq after 02800 batchs: 375.30047607421875
INFO:root:Train (Epoch 167): Loss/seq after 02850 batchs: 375.00347900390625
INFO:root:Train (Epoch 167): Loss/seq after 02900 batchs: 375.8413391113281
INFO:root:Train (Epoch 167): Loss/seq after 02950 batchs: 376.61932373046875
INFO:root:Train (Epoch 167): Loss/seq after 03000 batchs: 382.7473449707031
INFO:root:Train (Epoch 167): Loss/seq after 03050 batchs: 385.0694274902344
INFO:root:Train (Epoch 167): Loss/seq after 03100 batchs: 386.1677551269531
INFO:root:Train (Epoch 167): Loss/seq after 03150 batchs: 385.6015319824219
INFO:root:Train (Epoch 167): Loss/seq after 03200 batchs: 384.80419921875
INFO:root:Train (Epoch 167): Loss/seq after 03250 batchs: 383.9096984863281
INFO:root:Train (Epoch 167): Loss/seq after 03300 batchs: 383.3381042480469
INFO:root:Train (Epoch 167): Loss/seq after 03350 batchs: 381.05291748046875
INFO:root:Train (Epoch 167): Loss/seq after 03400 batchs: 378.2242431640625
INFO:root:Train (Epoch 167): Loss/seq after 03450 batchs: 376.5992431640625
INFO:root:Train (Epoch 167): Loss/seq after 03500 batchs: 377.6884460449219
INFO:root:Train (Epoch 167): Loss/seq after 03550 batchs: 376.3300476074219
INFO:root:Train (Epoch 167): Loss/seq after 03600 batchs: 382.9222106933594
INFO:root:Train (Epoch 167): Loss/seq after 03650 batchs: 381.9414978027344
INFO:root:Train (Epoch 167): Loss/seq after 03700 batchs: 384.5291748046875
INFO:root:Train (Epoch 167): Loss/seq after 03750 batchs: 389.2188415527344
INFO:root:Train (Epoch 167): Loss/seq after 03800 batchs: 388.71356201171875
INFO:root:Train (Epoch 167): Loss/seq after 03850 batchs: 388.2136535644531
INFO:root:Train (Epoch 167): Loss/seq after 03900 batchs: 389.5098571777344
INFO:root:Train (Epoch 167): Loss/seq after 03950 batchs: 391.30755615234375
INFO:root:Train (Epoch 167): Loss/seq after 04000 batchs: 389.2181091308594
INFO:root:Train (Epoch 167): Loss/seq after 04050 batchs: 386.8456726074219
INFO:root:Train (Epoch 167): Loss/seq after 04100 batchs: 386.2859191894531
INFO:root:Train (Epoch 167): Loss/seq after 04150 batchs: 386.70977783203125
INFO:root:Train (Epoch 167): Loss/seq after 04200 batchs: 385.849609375
INFO:root:Train (Epoch 167): Loss/seq after 04250 batchs: 384.717529296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 167): Loss/seq after 00000 batches: 274.3821716308594
INFO:root:# Valid (Epoch 167): Loss/seq after 00050 batches: 604.85107421875
INFO:root:# Valid (Epoch 167): Loss/seq after 00100 batches: 600.31640625
INFO:root:# Valid (Epoch 167): Loss/seq after 00150 batches: 454.61309814453125
INFO:root:# Valid (Epoch 167): Loss/seq after 00200 batches: 430.5261535644531
INFO:root:Artifacts: Make stick videos for epoch 167
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_167_on_20220422_131250.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_167_index_1531_on_20220422_131250.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 168): Loss/seq after 00000 batchs: 613.831298828125
INFO:root:Train (Epoch 168): Loss/seq after 00050 batchs: 545.7325439453125
INFO:root:Train (Epoch 168): Loss/seq after 00100 batchs: 542.7142333984375
INFO:root:Train (Epoch 168): Loss/seq after 00150 batchs: 508.9936218261719
INFO:root:Train (Epoch 168): Loss/seq after 00200 batchs: 541.2592163085938
INFO:root:Train (Epoch 168): Loss/seq after 00250 batchs: 607.2279052734375
INFO:root:Train (Epoch 168): Loss/seq after 00300 batchs: 625.0243530273438
INFO:root:Train (Epoch 168): Loss/seq after 00350 batchs: 591.1865234375
INFO:root:Train (Epoch 168): Loss/seq after 00400 batchs: 578.9137573242188
INFO:root:Train (Epoch 168): Loss/seq after 00450 batchs: 585.625244140625
INFO:root:Train (Epoch 168): Loss/seq after 00500 batchs: 566.51318359375
INFO:root:Train (Epoch 168): Loss/seq after 00550 batchs: 557.8871459960938
INFO:root:Train (Epoch 168): Loss/seq after 00600 batchs: 541.7385864257812
INFO:root:Train (Epoch 168): Loss/seq after 00650 batchs: 519.37109375
INFO:root:Train (Epoch 168): Loss/seq after 00700 batchs: 495.7542419433594
INFO:root:Train (Epoch 168): Loss/seq after 00750 batchs: 484.0549011230469
INFO:root:Train (Epoch 168): Loss/seq after 00800 batchs: 489.1887512207031
INFO:root:Train (Epoch 168): Loss/seq after 00850 batchs: 474.0072021484375
INFO:root:Train (Epoch 168): Loss/seq after 00900 batchs: 462.0130615234375
INFO:root:Train (Epoch 168): Loss/seq after 00950 batchs: 458.1758728027344
INFO:root:Train (Epoch 168): Loss/seq after 01000 batchs: 449.5242919921875
INFO:root:Train (Epoch 168): Loss/seq after 01050 batchs: 440.88916015625
INFO:root:Train (Epoch 168): Loss/seq after 01100 batchs: 431.8656311035156
INFO:root:Train (Epoch 168): Loss/seq after 01150 batchs: 419.7289123535156
INFO:root:Train (Epoch 168): Loss/seq after 01200 batchs: 424.9017028808594
INFO:root:Train (Epoch 168): Loss/seq after 01250 batchs: 425.2803649902344
INFO:root:Train (Epoch 168): Loss/seq after 01300 batchs: 414.9493713378906
INFO:root:Train (Epoch 168): Loss/seq after 01350 batchs: 405.962890625
INFO:root:Train (Epoch 168): Loss/seq after 01400 batchs: 407.23406982421875
INFO:root:Train (Epoch 168): Loss/seq after 01450 batchs: 410.880859375
INFO:root:Train (Epoch 168): Loss/seq after 01500 batchs: 418.0654296875
INFO:root:Train (Epoch 168): Loss/seq after 01550 batchs: 418.8212585449219
INFO:root:Train (Epoch 168): Loss/seq after 01600 batchs: 415.936767578125
INFO:root:Train (Epoch 168): Loss/seq after 01650 batchs: 414.9734802246094
INFO:root:Train (Epoch 168): Loss/seq after 01700 batchs: 419.5671081542969
INFO:root:Train (Epoch 168): Loss/seq after 01750 batchs: 418.1719665527344
INFO:root:Train (Epoch 168): Loss/seq after 01800 batchs: 417.01177978515625
INFO:root:Train (Epoch 168): Loss/seq after 01850 batchs: 414.89935302734375
INFO:root:Train (Epoch 168): Loss/seq after 01900 batchs: 414.5539245605469
INFO:root:Train (Epoch 168): Loss/seq after 01950 batchs: 414.5262756347656
INFO:root:Train (Epoch 168): Loss/seq after 02000 batchs: 415.598876953125
INFO:root:Train (Epoch 168): Loss/seq after 02050 batchs: 415.84368896484375
INFO:root:Train (Epoch 168): Loss/seq after 02100 batchs: 415.0154113769531
INFO:root:Train (Epoch 168): Loss/seq after 02150 batchs: 414.3470458984375
INFO:root:Train (Epoch 168): Loss/seq after 02200 batchs: 413.5118408203125
INFO:root:Train (Epoch 168): Loss/seq after 02250 batchs: 412.5606384277344
INFO:root:Train (Epoch 168): Loss/seq after 02300 batchs: 408.80072021484375
INFO:root:Train (Epoch 168): Loss/seq after 02350 batchs: 406.2389221191406
INFO:root:Train (Epoch 168): Loss/seq after 02400 batchs: 406.7734680175781
INFO:root:Train (Epoch 168): Loss/seq after 02450 batchs: 403.92718505859375
INFO:root:Train (Epoch 168): Loss/seq after 02500 batchs: 397.52935791015625
INFO:root:Train (Epoch 168): Loss/seq after 02550 batchs: 391.5814208984375
INFO:root:Train (Epoch 168): Loss/seq after 02600 batchs: 387.6519775390625
INFO:root:Train (Epoch 168): Loss/seq after 02650 batchs: 383.4582824707031
INFO:root:Train (Epoch 168): Loss/seq after 02700 batchs: 380.62933349609375
INFO:root:Train (Epoch 168): Loss/seq after 02750 batchs: 376.31201171875
INFO:root:Train (Epoch 168): Loss/seq after 02800 batchs: 374.27215576171875
INFO:root:Train (Epoch 168): Loss/seq after 02850 batchs: 373.9490661621094
INFO:root:Train (Epoch 168): Loss/seq after 02900 batchs: 374.71038818359375
INFO:root:Train (Epoch 168): Loss/seq after 02950 batchs: 375.3079528808594
INFO:root:Train (Epoch 168): Loss/seq after 03000 batchs: 381.3981628417969
INFO:root:Train (Epoch 168): Loss/seq after 03050 batchs: 383.468994140625
INFO:root:Train (Epoch 168): Loss/seq after 03100 batchs: 386.01239013671875
INFO:root:Train (Epoch 168): Loss/seq after 03150 batchs: 385.9194641113281
INFO:root:Train (Epoch 168): Loss/seq after 03200 batchs: 385.8131408691406
INFO:root:Train (Epoch 168): Loss/seq after 03250 batchs: 385.7475280761719
INFO:root:Train (Epoch 168): Loss/seq after 03300 batchs: 385.33428955078125
INFO:root:Train (Epoch 168): Loss/seq after 03350 batchs: 383.24609375
INFO:root:Train (Epoch 168): Loss/seq after 03400 batchs: 380.3805847167969
INFO:root:Train (Epoch 168): Loss/seq after 03450 batchs: 378.698974609375
INFO:root:Train (Epoch 168): Loss/seq after 03500 batchs: 380.3908996582031
INFO:root:Train (Epoch 168): Loss/seq after 03550 batchs: 379.56341552734375
INFO:root:Train (Epoch 168): Loss/seq after 03600 batchs: 386.4574279785156
INFO:root:Train (Epoch 168): Loss/seq after 03650 batchs: 385.11566162109375
INFO:root:Train (Epoch 168): Loss/seq after 03700 batchs: 388.2265319824219
INFO:root:Train (Epoch 168): Loss/seq after 03750 batchs: 392.8050537109375
INFO:root:Train (Epoch 168): Loss/seq after 03800 batchs: 392.19970703125
INFO:root:Train (Epoch 168): Loss/seq after 03850 batchs: 391.61199951171875
INFO:root:Train (Epoch 168): Loss/seq after 03900 batchs: 393.0555419921875
INFO:root:Train (Epoch 168): Loss/seq after 03950 batchs: 394.94158935546875
INFO:root:Train (Epoch 168): Loss/seq after 04000 batchs: 392.6683044433594
INFO:root:Train (Epoch 168): Loss/seq after 04050 batchs: 390.29351806640625
INFO:root:Train (Epoch 168): Loss/seq after 04100 batchs: 389.6771545410156
INFO:root:Train (Epoch 168): Loss/seq after 04150 batchs: 390.0855407714844
INFO:root:Train (Epoch 168): Loss/seq after 04200 batchs: 389.0279846191406
INFO:root:Train (Epoch 168): Loss/seq after 04250 batchs: 387.77685546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 168): Loss/seq after 00000 batches: 246.9855194091797
INFO:root:# Valid (Epoch 168): Loss/seq after 00050 batches: 599.5697021484375
INFO:root:# Valid (Epoch 168): Loss/seq after 00100 batches: 590.91650390625
INFO:root:# Valid (Epoch 168): Loss/seq after 00150 batches: 450.7803039550781
INFO:root:# Valid (Epoch 168): Loss/seq after 00200 batches: 427.6014404296875
INFO:root:Artifacts: Make stick videos for epoch 168
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_168_on_20220422_131734.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_168_index_1752_on_20220422_131734.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 169): Loss/seq after 00000 batchs: 594.0407104492188
INFO:root:Train (Epoch 169): Loss/seq after 00050 batchs: 541.63037109375
INFO:root:Train (Epoch 169): Loss/seq after 00100 batchs: 552.2250366210938
INFO:root:Train (Epoch 169): Loss/seq after 00150 batchs: 521.1097412109375
INFO:root:Train (Epoch 169): Loss/seq after 00200 batchs: 556.8323974609375
INFO:root:Train (Epoch 169): Loss/seq after 00250 batchs: 613.0145263671875
INFO:root:Train (Epoch 169): Loss/seq after 00300 batchs: 626.5023803710938
INFO:root:Train (Epoch 169): Loss/seq after 00350 batchs: 592.0984497070312
INFO:root:Train (Epoch 169): Loss/seq after 00400 batchs: 574.3677368164062
INFO:root:Train (Epoch 169): Loss/seq after 00450 batchs: 580.9033813476562
INFO:root:Train (Epoch 169): Loss/seq after 00500 batchs: 558.6217651367188
INFO:root:Train (Epoch 169): Loss/seq after 00550 batchs: 547.6044921875
INFO:root:Train (Epoch 169): Loss/seq after 00600 batchs: 531.6778564453125
INFO:root:Train (Epoch 169): Loss/seq after 00650 batchs: 510.2843322753906
INFO:root:Train (Epoch 169): Loss/seq after 00700 batchs: 487.0058898925781
INFO:root:Train (Epoch 169): Loss/seq after 00750 batchs: 475.34857177734375
INFO:root:Train (Epoch 169): Loss/seq after 00800 batchs: 481.25860595703125
INFO:root:Train (Epoch 169): Loss/seq after 00850 batchs: 465.4144592285156
INFO:root:Train (Epoch 169): Loss/seq after 00900 batchs: 454.0953674316406
INFO:root:Train (Epoch 169): Loss/seq after 00950 batchs: 449.20361328125
INFO:root:Train (Epoch 169): Loss/seq after 01000 batchs: 441.1530456542969
INFO:root:Train (Epoch 169): Loss/seq after 01050 batchs: 432.3458557128906
INFO:root:Train (Epoch 169): Loss/seq after 01100 batchs: 424.2348327636719
INFO:root:Train (Epoch 169): Loss/seq after 01150 batchs: 412.3983154296875
INFO:root:Train (Epoch 169): Loss/seq after 01200 batchs: 417.1115417480469
INFO:root:Train (Epoch 169): Loss/seq after 01250 batchs: 417.1590270996094
INFO:root:Train (Epoch 169): Loss/seq after 01300 batchs: 406.8817138671875
INFO:root:Train (Epoch 169): Loss/seq after 01350 batchs: 398.2800598144531
INFO:root:Train (Epoch 169): Loss/seq after 01400 batchs: 399.2955322265625
INFO:root:Train (Epoch 169): Loss/seq after 01450 batchs: 403.0592956542969
INFO:root:Train (Epoch 169): Loss/seq after 01500 batchs: 410.8270568847656
INFO:root:Train (Epoch 169): Loss/seq after 01550 batchs: 411.9751281738281
INFO:root:Train (Epoch 169): Loss/seq after 01600 batchs: 409.60064697265625
INFO:root:Train (Epoch 169): Loss/seq after 01650 batchs: 408.6546630859375
INFO:root:Train (Epoch 169): Loss/seq after 01700 batchs: 413.51397705078125
INFO:root:Train (Epoch 169): Loss/seq after 01750 batchs: 412.36663818359375
INFO:root:Train (Epoch 169): Loss/seq after 01800 batchs: 411.2774658203125
INFO:root:Train (Epoch 169): Loss/seq after 01850 batchs: 409.5498046875
INFO:root:Train (Epoch 169): Loss/seq after 01900 batchs: 409.1814880371094
INFO:root:Train (Epoch 169): Loss/seq after 01950 batchs: 408.7260437011719
INFO:root:Train (Epoch 169): Loss/seq after 02000 batchs: 409.7952880859375
INFO:root:Train (Epoch 169): Loss/seq after 02050 batchs: 410.2505187988281
INFO:root:Train (Epoch 169): Loss/seq after 02100 batchs: 409.5680236816406
INFO:root:Train (Epoch 169): Loss/seq after 02150 batchs: 409.0465393066406
INFO:root:Train (Epoch 169): Loss/seq after 02200 batchs: 408.2787170410156
INFO:root:Train (Epoch 169): Loss/seq after 02250 batchs: 407.2933044433594
INFO:root:Train (Epoch 169): Loss/seq after 02300 batchs: 403.6875915527344
INFO:root:Train (Epoch 169): Loss/seq after 02350 batchs: 401.23089599609375
INFO:root:Train (Epoch 169): Loss/seq after 02400 batchs: 401.8893737792969
INFO:root:Train (Epoch 169): Loss/seq after 02450 batchs: 399.1622619628906
INFO:root:Train (Epoch 169): Loss/seq after 02500 batchs: 392.87384033203125
INFO:root:Train (Epoch 169): Loss/seq after 02550 batchs: 387.018310546875
INFO:root:Train (Epoch 169): Loss/seq after 02600 batchs: 383.1026306152344
INFO:root:Train (Epoch 169): Loss/seq after 02650 batchs: 379.1049499511719
INFO:root:Train (Epoch 169): Loss/seq after 02700 batchs: 376.35577392578125
INFO:root:Train (Epoch 169): Loss/seq after 02750 batchs: 372.27032470703125
INFO:root:Train (Epoch 169): Loss/seq after 02800 batchs: 369.8880310058594
INFO:root:Train (Epoch 169): Loss/seq after 02850 batchs: 369.65850830078125
INFO:root:Train (Epoch 169): Loss/seq after 02900 batchs: 370.4520263671875
INFO:root:Train (Epoch 169): Loss/seq after 02950 batchs: 371.1249084472656
INFO:root:Train (Epoch 169): Loss/seq after 03000 batchs: 377.26324462890625
INFO:root:Train (Epoch 169): Loss/seq after 03050 batchs: 379.41802978515625
INFO:root:Train (Epoch 169): Loss/seq after 03100 batchs: 381.1869812011719
INFO:root:Train (Epoch 169): Loss/seq after 03150 batchs: 380.42047119140625
INFO:root:Train (Epoch 169): Loss/seq after 03200 batchs: 379.7522277832031
INFO:root:Train (Epoch 169): Loss/seq after 03250 batchs: 378.9861755371094
INFO:root:Train (Epoch 169): Loss/seq after 03300 batchs: 377.96478271484375
INFO:root:Train (Epoch 169): Loss/seq after 03350 batchs: 375.7333679199219
INFO:root:Train (Epoch 169): Loss/seq after 03400 batchs: 373.05426025390625
INFO:root:Train (Epoch 169): Loss/seq after 03450 batchs: 371.4696350097656
INFO:root:Train (Epoch 169): Loss/seq after 03500 batchs: 372.5934143066406
INFO:root:Train (Epoch 169): Loss/seq after 03550 batchs: 371.0221862792969
INFO:root:Train (Epoch 169): Loss/seq after 03600 batchs: 377.4065856933594
INFO:root:Train (Epoch 169): Loss/seq after 03650 batchs: 375.996826171875
INFO:root:Train (Epoch 169): Loss/seq after 03700 batchs: 378.679931640625
INFO:root:Train (Epoch 169): Loss/seq after 03750 batchs: 383.36138916015625
INFO:root:Train (Epoch 169): Loss/seq after 03800 batchs: 382.8851623535156
INFO:root:Train (Epoch 169): Loss/seq after 03850 batchs: 382.2734680175781
INFO:root:Train (Epoch 169): Loss/seq after 03900 batchs: 383.66937255859375
INFO:root:Train (Epoch 169): Loss/seq after 03950 batchs: 385.3484191894531
INFO:root:Train (Epoch 169): Loss/seq after 04000 batchs: 383.220703125
INFO:root:Train (Epoch 169): Loss/seq after 04050 batchs: 380.88238525390625
INFO:root:Train (Epoch 169): Loss/seq after 04100 batchs: 380.3085632324219
INFO:root:Train (Epoch 169): Loss/seq after 04150 batchs: 380.69378662109375
INFO:root:Train (Epoch 169): Loss/seq after 04200 batchs: 379.9145202636719
INFO:root:Train (Epoch 169): Loss/seq after 04250 batchs: 378.90240478515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 169): Loss/seq after 00000 batches: 288.9724426269531
INFO:root:# Valid (Epoch 169): Loss/seq after 00050 batches: 593.4318237304688
INFO:root:# Valid (Epoch 169): Loss/seq after 00100 batches: 578.4180297851562
INFO:root:# Valid (Epoch 169): Loss/seq after 00150 batches: 443.70831298828125
INFO:root:# Valid (Epoch 169): Loss/seq after 00200 batches: 422.1307678222656
INFO:root:Artifacts: Make stick videos for epoch 169
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_169_on_20220422_132235.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_169_index_757_on_20220422_132235.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 170): Loss/seq after 00000 batchs: 649.067138671875
INFO:root:Train (Epoch 170): Loss/seq after 00050 batchs: 525.4789428710938
INFO:root:Train (Epoch 170): Loss/seq after 00100 batchs: 522.827392578125
INFO:root:Train (Epoch 170): Loss/seq after 00150 batchs: 493.7496337890625
INFO:root:Train (Epoch 170): Loss/seq after 00200 batchs: 545.98388671875
INFO:root:Train (Epoch 170): Loss/seq after 00250 batchs: 591.7742309570312
INFO:root:Train (Epoch 170): Loss/seq after 00300 batchs: 609.7950439453125
INFO:root:Train (Epoch 170): Loss/seq after 00350 batchs: 578.4989013671875
INFO:root:Train (Epoch 170): Loss/seq after 00400 batchs: 560.6754150390625
INFO:root:Train (Epoch 170): Loss/seq after 00450 batchs: 569.1197509765625
INFO:root:Train (Epoch 170): Loss/seq after 00500 batchs: 551.1942138671875
INFO:root:Train (Epoch 170): Loss/seq after 00550 batchs: 541.324462890625
INFO:root:Train (Epoch 170): Loss/seq after 00600 batchs: 524.4456176757812
INFO:root:Train (Epoch 170): Loss/seq after 00650 batchs: 503.7294616699219
INFO:root:Train (Epoch 170): Loss/seq after 00700 batchs: 480.71612548828125
INFO:root:Train (Epoch 170): Loss/seq after 00750 batchs: 470.3912658691406
INFO:root:Train (Epoch 170): Loss/seq after 00800 batchs: 476.9897155761719
INFO:root:Train (Epoch 170): Loss/seq after 00850 batchs: 461.9405822753906
INFO:root:Train (Epoch 170): Loss/seq after 00900 batchs: 450.54327392578125
INFO:root:Train (Epoch 170): Loss/seq after 00950 batchs: 446.0554504394531
INFO:root:Train (Epoch 170): Loss/seq after 01000 batchs: 437.80712890625
INFO:root:Train (Epoch 170): Loss/seq after 01050 batchs: 430.6301574707031
INFO:root:Train (Epoch 170): Loss/seq after 01100 batchs: 422.1070556640625
INFO:root:Train (Epoch 170): Loss/seq after 01150 batchs: 410.92230224609375
INFO:root:Train (Epoch 170): Loss/seq after 01200 batchs: 415.7841796875
INFO:root:Train (Epoch 170): Loss/seq after 01250 batchs: 416.0342712402344
INFO:root:Train (Epoch 170): Loss/seq after 01300 batchs: 406.0635070800781
INFO:root:Train (Epoch 170): Loss/seq after 01350 batchs: 397.0887145996094
INFO:root:Train (Epoch 170): Loss/seq after 01400 batchs: 397.70849609375
INFO:root:Train (Epoch 170): Loss/seq after 01450 batchs: 401.5896301269531
INFO:root:Train (Epoch 170): Loss/seq after 01500 batchs: 408.9203186035156
INFO:root:Train (Epoch 170): Loss/seq after 01550 batchs: 409.7349853515625
INFO:root:Train (Epoch 170): Loss/seq after 01600 batchs: 407.1755676269531
INFO:root:Train (Epoch 170): Loss/seq after 01650 batchs: 406.1497497558594
INFO:root:Train (Epoch 170): Loss/seq after 01700 batchs: 410.9197082519531
INFO:root:Train (Epoch 170): Loss/seq after 01750 batchs: 409.5159606933594
INFO:root:Train (Epoch 170): Loss/seq after 01800 batchs: 408.34228515625
INFO:root:Train (Epoch 170): Loss/seq after 01850 batchs: 406.64129638671875
INFO:root:Train (Epoch 170): Loss/seq after 01900 batchs: 406.1789855957031
INFO:root:Train (Epoch 170): Loss/seq after 01950 batchs: 405.6668701171875
INFO:root:Train (Epoch 170): Loss/seq after 02000 batchs: 406.8864440917969
INFO:root:Train (Epoch 170): Loss/seq after 02050 batchs: 407.3374328613281
INFO:root:Train (Epoch 170): Loss/seq after 02100 batchs: 406.4505615234375
INFO:root:Train (Epoch 170): Loss/seq after 02150 batchs: 405.99200439453125
INFO:root:Train (Epoch 170): Loss/seq after 02200 batchs: 405.26220703125
INFO:root:Train (Epoch 170): Loss/seq after 02250 batchs: 404.1917419433594
INFO:root:Train (Epoch 170): Loss/seq after 02300 batchs: 400.44976806640625
INFO:root:Train (Epoch 170): Loss/seq after 02350 batchs: 398.06640625
INFO:root:Train (Epoch 170): Loss/seq after 02400 batchs: 398.7723693847656
INFO:root:Train (Epoch 170): Loss/seq after 02450 batchs: 395.9982604980469
INFO:root:Train (Epoch 170): Loss/seq after 02500 batchs: 389.7279968261719
INFO:root:Train (Epoch 170): Loss/seq after 02550 batchs: 383.9507141113281
INFO:root:Train (Epoch 170): Loss/seq after 02600 batchs: 379.8346252441406
INFO:root:Train (Epoch 170): Loss/seq after 02650 batchs: 375.93438720703125
INFO:root:Train (Epoch 170): Loss/seq after 02700 batchs: 373.2293701171875
INFO:root:Train (Epoch 170): Loss/seq after 02750 batchs: 368.7374267578125
INFO:root:Train (Epoch 170): Loss/seq after 02800 batchs: 366.2991638183594
INFO:root:Train (Epoch 170): Loss/seq after 02850 batchs: 365.9832458496094
INFO:root:Train (Epoch 170): Loss/seq after 02900 batchs: 366.82061767578125
INFO:root:Train (Epoch 170): Loss/seq after 02950 batchs: 367.6328430175781
INFO:root:Train (Epoch 170): Loss/seq after 03000 batchs: 373.7170715332031
INFO:root:Train (Epoch 170): Loss/seq after 03050 batchs: 376.04205322265625
INFO:root:Train (Epoch 170): Loss/seq after 03100 batchs: 377.5224304199219
INFO:root:Train (Epoch 170): Loss/seq after 03150 batchs: 376.9379577636719
INFO:root:Train (Epoch 170): Loss/seq after 03200 batchs: 376.6571960449219
INFO:root:Train (Epoch 170): Loss/seq after 03250 batchs: 376.2441101074219
INFO:root:Train (Epoch 170): Loss/seq after 03300 batchs: 375.19970703125
INFO:root:Train (Epoch 170): Loss/seq after 03350 batchs: 373.012451171875
INFO:root:Train (Epoch 170): Loss/seq after 03400 batchs: 370.2796936035156
INFO:root:Train (Epoch 170): Loss/seq after 03450 batchs: 368.68011474609375
INFO:root:Train (Epoch 170): Loss/seq after 03500 batchs: 369.6119689941406
INFO:root:Train (Epoch 170): Loss/seq after 03550 batchs: 368.02276611328125
INFO:root:Train (Epoch 170): Loss/seq after 03600 batchs: 374.40252685546875
INFO:root:Train (Epoch 170): Loss/seq after 03650 batchs: 373.0391540527344
INFO:root:Train (Epoch 170): Loss/seq after 03700 batchs: 375.5282287597656
INFO:root:Train (Epoch 170): Loss/seq after 03750 batchs: 380.2525634765625
INFO:root:Train (Epoch 170): Loss/seq after 03800 batchs: 379.8642883300781
INFO:root:Train (Epoch 170): Loss/seq after 03850 batchs: 379.402099609375
INFO:root:Train (Epoch 170): Loss/seq after 03900 batchs: 380.8560485839844
INFO:root:Train (Epoch 170): Loss/seq after 03950 batchs: 382.520751953125
INFO:root:Train (Epoch 170): Loss/seq after 04000 batchs: 380.3912353515625
INFO:root:Train (Epoch 170): Loss/seq after 04050 batchs: 378.085205078125
INFO:root:Train (Epoch 170): Loss/seq after 04100 batchs: 377.62225341796875
INFO:root:Train (Epoch 170): Loss/seq after 04150 batchs: 377.98211669921875
INFO:root:Train (Epoch 170): Loss/seq after 04200 batchs: 377.06817626953125
INFO:root:Train (Epoch 170): Loss/seq after 04250 batchs: 376.02587890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 170): Loss/seq after 00000 batches: 273.391357421875
INFO:root:# Valid (Epoch 170): Loss/seq after 00050 batches: 618.0385131835938
INFO:root:# Valid (Epoch 170): Loss/seq after 00100 batches: 607.8950805664062
INFO:root:# Valid (Epoch 170): Loss/seq after 00150 batches: 460.72149658203125
INFO:root:# Valid (Epoch 170): Loss/seq after 00200 batches: 431.40728759765625
INFO:root:Artifacts: Make stick videos for epoch 170
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_170_on_20220422_132725.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_170_index_1135_on_20220422_132725.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 171): Loss/seq after 00000 batchs: 414.3385314941406
INFO:root:Train (Epoch 171): Loss/seq after 00050 batchs: 517.9932250976562
INFO:root:Train (Epoch 171): Loss/seq after 00100 batchs: 529.7869873046875
INFO:root:Train (Epoch 171): Loss/seq after 00150 batchs: 507.4165954589844
INFO:root:Train (Epoch 171): Loss/seq after 00200 batchs: 553.7357788085938
INFO:root:Train (Epoch 171): Loss/seq after 00250 batchs: 619.3526000976562
INFO:root:Train (Epoch 171): Loss/seq after 00300 batchs: 632.1951904296875
INFO:root:Train (Epoch 171): Loss/seq after 00350 batchs: 596.2396850585938
INFO:root:Train (Epoch 171): Loss/seq after 00400 batchs: 580.6027221679688
INFO:root:Train (Epoch 171): Loss/seq after 00450 batchs: 585.8800659179688
INFO:root:Train (Epoch 171): Loss/seq after 00500 batchs: 567.9219970703125
INFO:root:Train (Epoch 171): Loss/seq after 00550 batchs: 559.9194946289062
INFO:root:Train (Epoch 171): Loss/seq after 00600 batchs: 546.4331665039062
INFO:root:Train (Epoch 171): Loss/seq after 00650 batchs: 525.03271484375
INFO:root:Train (Epoch 171): Loss/seq after 00700 batchs: 501.7605285644531
INFO:root:Train (Epoch 171): Loss/seq after 00750 batchs: 490.71533203125
INFO:root:Train (Epoch 171): Loss/seq after 00800 batchs: 495.8746032714844
INFO:root:Train (Epoch 171): Loss/seq after 00850 batchs: 480.27294921875
INFO:root:Train (Epoch 171): Loss/seq after 00900 batchs: 467.31365966796875
INFO:root:Train (Epoch 171): Loss/seq after 00950 batchs: 462.5783996582031
INFO:root:Train (Epoch 171): Loss/seq after 01000 batchs: 453.1160888671875
INFO:root:Train (Epoch 171): Loss/seq after 01050 batchs: 444.7662658691406
INFO:root:Train (Epoch 171): Loss/seq after 01100 batchs: 436.10333251953125
INFO:root:Train (Epoch 171): Loss/seq after 01150 batchs: 423.95391845703125
INFO:root:Train (Epoch 171): Loss/seq after 01200 batchs: 428.3537292480469
INFO:root:Train (Epoch 171): Loss/seq after 01250 batchs: 427.824951171875
INFO:root:Train (Epoch 171): Loss/seq after 01300 batchs: 417.0927734375
INFO:root:Train (Epoch 171): Loss/seq after 01350 batchs: 407.397705078125
INFO:root:Train (Epoch 171): Loss/seq after 01400 batchs: 406.97723388671875
INFO:root:Train (Epoch 171): Loss/seq after 01450 batchs: 410.43768310546875
INFO:root:Train (Epoch 171): Loss/seq after 01500 batchs: 417.22760009765625
INFO:root:Train (Epoch 171): Loss/seq after 01550 batchs: 417.74603271484375
INFO:root:Train (Epoch 171): Loss/seq after 01600 batchs: 414.7276611328125
INFO:root:Train (Epoch 171): Loss/seq after 01650 batchs: 413.62774658203125
INFO:root:Train (Epoch 171): Loss/seq after 01700 batchs: 418.340087890625
INFO:root:Train (Epoch 171): Loss/seq after 01750 batchs: 417.05584716796875
INFO:root:Train (Epoch 171): Loss/seq after 01800 batchs: 415.65020751953125
INFO:root:Train (Epoch 171): Loss/seq after 01850 batchs: 413.6202697753906
INFO:root:Train (Epoch 171): Loss/seq after 01900 batchs: 413.3229064941406
INFO:root:Train (Epoch 171): Loss/seq after 01950 batchs: 412.76416015625
INFO:root:Train (Epoch 171): Loss/seq after 02000 batchs: 413.7809143066406
INFO:root:Train (Epoch 171): Loss/seq after 02050 batchs: 413.80291748046875
INFO:root:Train (Epoch 171): Loss/seq after 02100 batchs: 412.9746398925781
INFO:root:Train (Epoch 171): Loss/seq after 02150 batchs: 412.31011962890625
INFO:root:Train (Epoch 171): Loss/seq after 02200 batchs: 411.5178527832031
INFO:root:Train (Epoch 171): Loss/seq after 02250 batchs: 410.2762145996094
INFO:root:Train (Epoch 171): Loss/seq after 02300 batchs: 406.3609619140625
INFO:root:Train (Epoch 171): Loss/seq after 02350 batchs: 404.083251953125
INFO:root:Train (Epoch 171): Loss/seq after 02400 batchs: 404.7277526855469
INFO:root:Train (Epoch 171): Loss/seq after 02450 batchs: 401.8632507324219
INFO:root:Train (Epoch 171): Loss/seq after 02500 batchs: 395.4710388183594
INFO:root:Train (Epoch 171): Loss/seq after 02550 batchs: 389.4678649902344
INFO:root:Train (Epoch 171): Loss/seq after 02600 batchs: 385.2257995605469
INFO:root:Train (Epoch 171): Loss/seq after 02650 batchs: 381.053955078125
INFO:root:Train (Epoch 171): Loss/seq after 02700 batchs: 378.02996826171875
INFO:root:Train (Epoch 171): Loss/seq after 02750 batchs: 373.4730224609375
INFO:root:Train (Epoch 171): Loss/seq after 02800 batchs: 371.5538330078125
INFO:root:Train (Epoch 171): Loss/seq after 02850 batchs: 371.14544677734375
INFO:root:Train (Epoch 171): Loss/seq after 02900 batchs: 371.7378845214844
INFO:root:Train (Epoch 171): Loss/seq after 02950 batchs: 372.322509765625
INFO:root:Train (Epoch 171): Loss/seq after 03000 batchs: 378.1241760253906
INFO:root:Train (Epoch 171): Loss/seq after 03050 batchs: 380.2368469238281
INFO:root:Train (Epoch 171): Loss/seq after 03100 batchs: 382.0027770996094
INFO:root:Train (Epoch 171): Loss/seq after 03150 batchs: 381.0155944824219
INFO:root:Train (Epoch 171): Loss/seq after 03200 batchs: 380.27459716796875
INFO:root:Train (Epoch 171): Loss/seq after 03250 batchs: 379.3542785644531
INFO:root:Train (Epoch 171): Loss/seq after 03300 batchs: 378.52313232421875
INFO:root:Train (Epoch 171): Loss/seq after 03350 batchs: 376.1923828125
INFO:root:Train (Epoch 171): Loss/seq after 03400 batchs: 373.36822509765625
INFO:root:Train (Epoch 171): Loss/seq after 03450 batchs: 371.7506408691406
INFO:root:Train (Epoch 171): Loss/seq after 03500 batchs: 372.66436767578125
INFO:root:Train (Epoch 171): Loss/seq after 03550 batchs: 371.05401611328125
INFO:root:Train (Epoch 171): Loss/seq after 03600 batchs: 377.4844055175781
INFO:root:Train (Epoch 171): Loss/seq after 03650 batchs: 376.0223693847656
INFO:root:Train (Epoch 171): Loss/seq after 03700 batchs: 378.5485534667969
INFO:root:Train (Epoch 171): Loss/seq after 03750 batchs: 383.120849609375
INFO:root:Train (Epoch 171): Loss/seq after 03800 batchs: 382.6339416503906
INFO:root:Train (Epoch 171): Loss/seq after 03850 batchs: 382.065185546875
INFO:root:Train (Epoch 171): Loss/seq after 03900 batchs: 383.4057922363281
INFO:root:Train (Epoch 171): Loss/seq after 03950 batchs: 384.9286804199219
INFO:root:Train (Epoch 171): Loss/seq after 04000 batchs: 382.7344970703125
INFO:root:Train (Epoch 171): Loss/seq after 04050 batchs: 380.3722839355469
INFO:root:Train (Epoch 171): Loss/seq after 04100 batchs: 379.8487548828125
INFO:root:Train (Epoch 171): Loss/seq after 04150 batchs: 380.28973388671875
INFO:root:Train (Epoch 171): Loss/seq after 04200 batchs: 379.465576171875
INFO:root:Train (Epoch 171): Loss/seq after 04250 batchs: 378.38995361328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 171): Loss/seq after 00000 batches: 298.0795593261719
INFO:root:# Valid (Epoch 171): Loss/seq after 00050 batches: 624.0082397460938
INFO:root:# Valid (Epoch 171): Loss/seq after 00100 batches: 592.7578735351562
INFO:root:# Valid (Epoch 171): Loss/seq after 00150 batches: 455.1947326660156
INFO:root:# Valid (Epoch 171): Loss/seq after 00200 batches: 426.96435546875
INFO:root:Artifacts: Make stick videos for epoch 171
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_171_on_20220422_133218.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_171_index_1415_on_20220422_133218.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 172): Loss/seq after 00000 batchs: 513.1012573242188
INFO:root:Train (Epoch 172): Loss/seq after 00050 batchs: 507.9277038574219
INFO:root:Train (Epoch 172): Loss/seq after 00100 batchs: 504.9092102050781
INFO:root:Train (Epoch 172): Loss/seq after 00150 batchs: 481.8232116699219
INFO:root:Train (Epoch 172): Loss/seq after 00200 batchs: 530.82861328125
INFO:root:Train (Epoch 172): Loss/seq after 00250 batchs: 584.0336303710938
INFO:root:Train (Epoch 172): Loss/seq after 00300 batchs: 599.8121337890625
INFO:root:Train (Epoch 172): Loss/seq after 00350 batchs: 568.9307250976562
INFO:root:Train (Epoch 172): Loss/seq after 00400 batchs: 552.481689453125
INFO:root:Train (Epoch 172): Loss/seq after 00450 batchs: 560.6546020507812
INFO:root:Train (Epoch 172): Loss/seq after 00500 batchs: 541.7302856445312
INFO:root:Train (Epoch 172): Loss/seq after 00550 batchs: 532.0377197265625
INFO:root:Train (Epoch 172): Loss/seq after 00600 batchs: 515.8670654296875
INFO:root:Train (Epoch 172): Loss/seq after 00650 batchs: 493.80108642578125
INFO:root:Train (Epoch 172): Loss/seq after 00700 batchs: 471.0697326660156
INFO:root:Train (Epoch 172): Loss/seq after 00750 batchs: 461.0712585449219
INFO:root:Train (Epoch 172): Loss/seq after 00800 batchs: 466.871337890625
INFO:root:Train (Epoch 172): Loss/seq after 00850 batchs: 451.5430908203125
INFO:root:Train (Epoch 172): Loss/seq after 00900 batchs: 440.5274353027344
INFO:root:Train (Epoch 172): Loss/seq after 00950 batchs: 436.1291198730469
INFO:root:Train (Epoch 172): Loss/seq after 01000 batchs: 427.6775817871094
INFO:root:Train (Epoch 172): Loss/seq after 01050 batchs: 419.321044921875
INFO:root:Train (Epoch 172): Loss/seq after 01100 batchs: 411.19683837890625
INFO:root:Train (Epoch 172): Loss/seq after 01150 batchs: 399.8004455566406
INFO:root:Train (Epoch 172): Loss/seq after 01200 batchs: 404.9859924316406
INFO:root:Train (Epoch 172): Loss/seq after 01250 batchs: 405.3472900390625
INFO:root:Train (Epoch 172): Loss/seq after 01300 batchs: 395.5306396484375
INFO:root:Train (Epoch 172): Loss/seq after 01350 batchs: 386.5028991699219
INFO:root:Train (Epoch 172): Loss/seq after 01400 batchs: 387.04345703125
INFO:root:Train (Epoch 172): Loss/seq after 01450 batchs: 391.02783203125
INFO:root:Train (Epoch 172): Loss/seq after 01500 batchs: 398.869140625
INFO:root:Train (Epoch 172): Loss/seq after 01550 batchs: 400.0344543457031
INFO:root:Train (Epoch 172): Loss/seq after 01600 batchs: 398.05255126953125
INFO:root:Train (Epoch 172): Loss/seq after 01650 batchs: 397.08770751953125
INFO:root:Train (Epoch 172): Loss/seq after 01700 batchs: 402.6792907714844
INFO:root:Train (Epoch 172): Loss/seq after 01750 batchs: 401.85888671875
INFO:root:Train (Epoch 172): Loss/seq after 01800 batchs: 400.76141357421875
INFO:root:Train (Epoch 172): Loss/seq after 01850 batchs: 399.2195129394531
INFO:root:Train (Epoch 172): Loss/seq after 01900 batchs: 399.0096435546875
INFO:root:Train (Epoch 172): Loss/seq after 01950 batchs: 398.9724426269531
INFO:root:Train (Epoch 172): Loss/seq after 02000 batchs: 400.2516784667969
INFO:root:Train (Epoch 172): Loss/seq after 02050 batchs: 400.62017822265625
INFO:root:Train (Epoch 172): Loss/seq after 02100 batchs: 399.9836730957031
INFO:root:Train (Epoch 172): Loss/seq after 02150 batchs: 399.5788269042969
INFO:root:Train (Epoch 172): Loss/seq after 02200 batchs: 399.14764404296875
INFO:root:Train (Epoch 172): Loss/seq after 02250 batchs: 397.9624938964844
INFO:root:Train (Epoch 172): Loss/seq after 02300 batchs: 394.5556335449219
INFO:root:Train (Epoch 172): Loss/seq after 02350 batchs: 392.39996337890625
INFO:root:Train (Epoch 172): Loss/seq after 02400 batchs: 393.1744384765625
INFO:root:Train (Epoch 172): Loss/seq after 02450 batchs: 390.51959228515625
INFO:root:Train (Epoch 172): Loss/seq after 02500 batchs: 384.3124694824219
INFO:root:Train (Epoch 172): Loss/seq after 02550 batchs: 378.53692626953125
INFO:root:Train (Epoch 172): Loss/seq after 02600 batchs: 374.6529235839844
INFO:root:Train (Epoch 172): Loss/seq after 02650 batchs: 370.8223571777344
INFO:root:Train (Epoch 172): Loss/seq after 02700 batchs: 368.025634765625
INFO:root:Train (Epoch 172): Loss/seq after 02750 batchs: 363.7513732910156
INFO:root:Train (Epoch 172): Loss/seq after 02800 batchs: 361.7794189453125
INFO:root:Train (Epoch 172): Loss/seq after 02850 batchs: 361.7170715332031
INFO:root:Train (Epoch 172): Loss/seq after 02900 batchs: 362.4999084472656
INFO:root:Train (Epoch 172): Loss/seq after 02950 batchs: 363.1636657714844
INFO:root:Train (Epoch 172): Loss/seq after 03000 batchs: 369.1103515625
INFO:root:Train (Epoch 172): Loss/seq after 03050 batchs: 371.103759765625
INFO:root:Train (Epoch 172): Loss/seq after 03100 batchs: 373.3507995605469
INFO:root:Train (Epoch 172): Loss/seq after 03150 batchs: 372.7628173828125
INFO:root:Train (Epoch 172): Loss/seq after 03200 batchs: 372.35302734375
INFO:root:Train (Epoch 172): Loss/seq after 03250 batchs: 372.02337646484375
INFO:root:Train (Epoch 172): Loss/seq after 03300 batchs: 371.49871826171875
INFO:root:Train (Epoch 172): Loss/seq after 03350 batchs: 369.1337585449219
INFO:root:Train (Epoch 172): Loss/seq after 03400 batchs: 366.4390869140625
INFO:root:Train (Epoch 172): Loss/seq after 03450 batchs: 364.89935302734375
INFO:root:Train (Epoch 172): Loss/seq after 03500 batchs: 365.9726867675781
INFO:root:Train (Epoch 172): Loss/seq after 03550 batchs: 364.4297790527344
INFO:root:Train (Epoch 172): Loss/seq after 03600 batchs: 370.66644287109375
INFO:root:Train (Epoch 172): Loss/seq after 03650 batchs: 369.43743896484375
INFO:root:Train (Epoch 172): Loss/seq after 03700 batchs: 371.88836669921875
INFO:root:Train (Epoch 172): Loss/seq after 03750 batchs: 376.5126647949219
INFO:root:Train (Epoch 172): Loss/seq after 03800 batchs: 376.0975036621094
INFO:root:Train (Epoch 172): Loss/seq after 03850 batchs: 375.5057373046875
INFO:root:Train (Epoch 172): Loss/seq after 03900 batchs: 376.53997802734375
INFO:root:Train (Epoch 172): Loss/seq after 03950 batchs: 378.617431640625
INFO:root:Train (Epoch 172): Loss/seq after 04000 batchs: 376.5014343261719
INFO:root:Train (Epoch 172): Loss/seq after 04050 batchs: 374.22119140625
INFO:root:Train (Epoch 172): Loss/seq after 04100 batchs: 373.728759765625
INFO:root:Train (Epoch 172): Loss/seq after 04150 batchs: 374.12042236328125
INFO:root:Train (Epoch 172): Loss/seq after 04200 batchs: 373.34234619140625
INFO:root:Train (Epoch 172): Loss/seq after 04250 batchs: 372.2332458496094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 172): Loss/seq after 00000 batches: 298.7113952636719
INFO:root:# Valid (Epoch 172): Loss/seq after 00050 batches: 607.5602416992188
INFO:root:# Valid (Epoch 172): Loss/seq after 00100 batches: 589.7196655273438
INFO:root:# Valid (Epoch 172): Loss/seq after 00150 batches: 450.90460205078125
INFO:root:# Valid (Epoch 172): Loss/seq after 00200 batches: 425.7469177246094
INFO:root:Artifacts: Make stick videos for epoch 172
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_172_on_20220422_133719.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_172_index_1561_on_20220422_133719.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 173): Loss/seq after 00000 batchs: 497.0367126464844
INFO:root:Train (Epoch 173): Loss/seq after 00050 batchs: 518.45947265625
INFO:root:Train (Epoch 173): Loss/seq after 00100 batchs: 523.9662475585938
INFO:root:Train (Epoch 173): Loss/seq after 00150 batchs: 496.2322998046875
INFO:root:Train (Epoch 173): Loss/seq after 00200 batchs: 540.8580932617188
INFO:root:Train (Epoch 173): Loss/seq after 00250 batchs: 606.990966796875
INFO:root:Train (Epoch 173): Loss/seq after 00300 batchs: 625.4160766601562
INFO:root:Train (Epoch 173): Loss/seq after 00350 batchs: 591.57763671875
INFO:root:Train (Epoch 173): Loss/seq after 00400 batchs: 575.1923828125
INFO:root:Train (Epoch 173): Loss/seq after 00450 batchs: 581.2843017578125
INFO:root:Train (Epoch 173): Loss/seq after 00500 batchs: 560.2548828125
INFO:root:Train (Epoch 173): Loss/seq after 00550 batchs: 549.2584228515625
INFO:root:Train (Epoch 173): Loss/seq after 00600 batchs: 531.6416015625
INFO:root:Train (Epoch 173): Loss/seq after 00650 batchs: 507.911865234375
INFO:root:Train (Epoch 173): Loss/seq after 00700 batchs: 485.3359680175781
INFO:root:Train (Epoch 173): Loss/seq after 00750 batchs: 474.4524230957031
INFO:root:Train (Epoch 173): Loss/seq after 00800 batchs: 479.45977783203125
INFO:root:Train (Epoch 173): Loss/seq after 00850 batchs: 463.7567443847656
INFO:root:Train (Epoch 173): Loss/seq after 00900 batchs: 451.7967834472656
INFO:root:Train (Epoch 173): Loss/seq after 00950 batchs: 447.418212890625
INFO:root:Train (Epoch 173): Loss/seq after 01000 batchs: 438.22430419921875
INFO:root:Train (Epoch 173): Loss/seq after 01050 batchs: 430.36602783203125
INFO:root:Train (Epoch 173): Loss/seq after 01100 batchs: 421.8094177246094
INFO:root:Train (Epoch 173): Loss/seq after 01150 batchs: 409.6462097167969
INFO:root:Train (Epoch 173): Loss/seq after 01200 batchs: 414.6153564453125
INFO:root:Train (Epoch 173): Loss/seq after 01250 batchs: 414.2878112792969
INFO:root:Train (Epoch 173): Loss/seq after 01300 batchs: 403.991455078125
INFO:root:Train (Epoch 173): Loss/seq after 01350 batchs: 394.90533447265625
INFO:root:Train (Epoch 173): Loss/seq after 01400 batchs: 395.52203369140625
INFO:root:Train (Epoch 173): Loss/seq after 01450 batchs: 399.1287841796875
INFO:root:Train (Epoch 173): Loss/seq after 01500 batchs: 407.08563232421875
INFO:root:Train (Epoch 173): Loss/seq after 01550 batchs: 408.1943664550781
INFO:root:Train (Epoch 173): Loss/seq after 01600 batchs: 406.382080078125
INFO:root:Train (Epoch 173): Loss/seq after 01650 batchs: 405.55438232421875
INFO:root:Train (Epoch 173): Loss/seq after 01700 batchs: 410.628662109375
INFO:root:Train (Epoch 173): Loss/seq after 01750 batchs: 409.1089172363281
INFO:root:Train (Epoch 173): Loss/seq after 01800 batchs: 407.8976745605469
INFO:root:Train (Epoch 173): Loss/seq after 01850 batchs: 406.0323181152344
INFO:root:Train (Epoch 173): Loss/seq after 01900 batchs: 405.4379577636719
INFO:root:Train (Epoch 173): Loss/seq after 01950 batchs: 405.27099609375
INFO:root:Train (Epoch 173): Loss/seq after 02000 batchs: 406.50689697265625
INFO:root:Train (Epoch 173): Loss/seq after 02050 batchs: 406.4817810058594
INFO:root:Train (Epoch 173): Loss/seq after 02100 batchs: 405.5316467285156
INFO:root:Train (Epoch 173): Loss/seq after 02150 batchs: 404.9759521484375
INFO:root:Train (Epoch 173): Loss/seq after 02200 batchs: 404.2576599121094
INFO:root:Train (Epoch 173): Loss/seq after 02250 batchs: 402.9129943847656
INFO:root:Train (Epoch 173): Loss/seq after 02300 batchs: 399.16033935546875
INFO:root:Train (Epoch 173): Loss/seq after 02350 batchs: 396.7882385253906
INFO:root:Train (Epoch 173): Loss/seq after 02400 batchs: 397.6483154296875
INFO:root:Train (Epoch 173): Loss/seq after 02450 batchs: 394.7738342285156
INFO:root:Train (Epoch 173): Loss/seq after 02500 batchs: 388.49359130859375
INFO:root:Train (Epoch 173): Loss/seq after 02550 batchs: 382.6857604980469
INFO:root:Train (Epoch 173): Loss/seq after 02600 batchs: 378.708740234375
INFO:root:Train (Epoch 173): Loss/seq after 02650 batchs: 374.575927734375
INFO:root:Train (Epoch 173): Loss/seq after 02700 batchs: 371.64617919921875
INFO:root:Train (Epoch 173): Loss/seq after 02750 batchs: 367.5997314453125
INFO:root:Train (Epoch 173): Loss/seq after 02800 batchs: 365.48876953125
INFO:root:Train (Epoch 173): Loss/seq after 02850 batchs: 365.1875915527344
INFO:root:Train (Epoch 173): Loss/seq after 02900 batchs: 365.66668701171875
INFO:root:Train (Epoch 173): Loss/seq after 02950 batchs: 366.40997314453125
INFO:root:Train (Epoch 173): Loss/seq after 03000 batchs: 372.13372802734375
INFO:root:Train (Epoch 173): Loss/seq after 03050 batchs: 374.4031982421875
INFO:root:Train (Epoch 173): Loss/seq after 03100 batchs: 375.999755859375
INFO:root:Train (Epoch 173): Loss/seq after 03150 batchs: 375.8110656738281
INFO:root:Train (Epoch 173): Loss/seq after 03200 batchs: 375.4627990722656
INFO:root:Train (Epoch 173): Loss/seq after 03250 batchs: 374.6773986816406
INFO:root:Train (Epoch 173): Loss/seq after 03300 batchs: 375.23223876953125
INFO:root:Train (Epoch 173): Loss/seq after 03350 batchs: 373.5172119140625
INFO:root:Train (Epoch 173): Loss/seq after 03400 batchs: 370.8226318359375
INFO:root:Train (Epoch 173): Loss/seq after 03450 batchs: 369.1059875488281
INFO:root:Train (Epoch 173): Loss/seq after 03500 batchs: 370.2766418457031
INFO:root:Train (Epoch 173): Loss/seq after 03550 batchs: 369.1723937988281
INFO:root:Train (Epoch 173): Loss/seq after 03600 batchs: 375.6199645996094
INFO:root:Train (Epoch 173): Loss/seq after 03650 batchs: 374.3173522949219
INFO:root:Train (Epoch 173): Loss/seq after 03700 batchs: 376.7849426269531
INFO:root:Train (Epoch 173): Loss/seq after 03750 batchs: 381.36480712890625
INFO:root:Train (Epoch 173): Loss/seq after 03800 batchs: 380.9749450683594
INFO:root:Train (Epoch 173): Loss/seq after 03850 batchs: 380.39910888671875
INFO:root:Train (Epoch 173): Loss/seq after 03900 batchs: 381.92620849609375
INFO:root:Train (Epoch 173): Loss/seq after 03950 batchs: 384.0967102050781
INFO:root:Train (Epoch 173): Loss/seq after 04000 batchs: 381.9016418457031
INFO:root:Train (Epoch 173): Loss/seq after 04050 batchs: 379.5683288574219
INFO:root:Train (Epoch 173): Loss/seq after 04100 batchs: 378.97576904296875
INFO:root:Train (Epoch 173): Loss/seq after 04150 batchs: 379.3974304199219
INFO:root:Train (Epoch 173): Loss/seq after 04200 batchs: 378.6151123046875
INFO:root:Train (Epoch 173): Loss/seq after 04250 batchs: 377.4154968261719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 173): Loss/seq after 00000 batches: 294.3689270019531
INFO:root:# Valid (Epoch 173): Loss/seq after 00050 batches: 590.4217529296875
INFO:root:# Valid (Epoch 173): Loss/seq after 00100 batches: 605.9962768554688
INFO:root:# Valid (Epoch 173): Loss/seq after 00150 batches: 457.73602294921875
INFO:root:# Valid (Epoch 173): Loss/seq after 00200 batches: 428.2855529785156
INFO:root:Artifacts: Make stick videos for epoch 173
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_173_on_20220422_134206.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_173_index_1027_on_20220422_134206.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 174): Loss/seq after 00000 batchs: 520.4094848632812
INFO:root:Train (Epoch 174): Loss/seq after 00050 batchs: 517.5950317382812
INFO:root:Train (Epoch 174): Loss/seq after 00100 batchs: 531.484375
INFO:root:Train (Epoch 174): Loss/seq after 00150 batchs: 505.2507629394531
INFO:root:Train (Epoch 174): Loss/seq after 00200 batchs: 545.3549194335938
INFO:root:Train (Epoch 174): Loss/seq after 00250 batchs: 587.37109375
INFO:root:Train (Epoch 174): Loss/seq after 00300 batchs: 603.0626831054688
INFO:root:Train (Epoch 174): Loss/seq after 00350 batchs: 573.1322631835938
INFO:root:Train (Epoch 174): Loss/seq after 00400 batchs: 560.4705810546875
INFO:root:Train (Epoch 174): Loss/seq after 00450 batchs: 567.37939453125
INFO:root:Train (Epoch 174): Loss/seq after 00500 batchs: 548.114990234375
INFO:root:Train (Epoch 174): Loss/seq after 00550 batchs: 539.3319702148438
INFO:root:Train (Epoch 174): Loss/seq after 00600 batchs: 524.3031616210938
INFO:root:Train (Epoch 174): Loss/seq after 00650 batchs: 502.4749755859375
INFO:root:Train (Epoch 174): Loss/seq after 00700 batchs: 479.93231201171875
INFO:root:Train (Epoch 174): Loss/seq after 00750 batchs: 468.4584045410156
INFO:root:Train (Epoch 174): Loss/seq after 00800 batchs: 474.1463317871094
INFO:root:Train (Epoch 174): Loss/seq after 00850 batchs: 459.4359436035156
INFO:root:Train (Epoch 174): Loss/seq after 00900 batchs: 448.0006103515625
INFO:root:Train (Epoch 174): Loss/seq after 00950 batchs: 443.5005798339844
INFO:root:Train (Epoch 174): Loss/seq after 01000 batchs: 434.5257568359375
INFO:root:Train (Epoch 174): Loss/seq after 01050 batchs: 428.02838134765625
INFO:root:Train (Epoch 174): Loss/seq after 01100 batchs: 419.075927734375
INFO:root:Train (Epoch 174): Loss/seq after 01150 batchs: 407.5578308105469
INFO:root:Train (Epoch 174): Loss/seq after 01200 batchs: 412.2677001953125
INFO:root:Train (Epoch 174): Loss/seq after 01250 batchs: 411.9344787597656
INFO:root:Train (Epoch 174): Loss/seq after 01300 batchs: 401.62445068359375
INFO:root:Train (Epoch 174): Loss/seq after 01350 batchs: 392.0972900390625
INFO:root:Train (Epoch 174): Loss/seq after 01400 batchs: 393.1858825683594
INFO:root:Train (Epoch 174): Loss/seq after 01450 batchs: 396.9026184082031
INFO:root:Train (Epoch 174): Loss/seq after 01500 batchs: 404.1905822753906
INFO:root:Train (Epoch 174): Loss/seq after 01550 batchs: 404.85150146484375
INFO:root:Train (Epoch 174): Loss/seq after 01600 batchs: 402.3222351074219
INFO:root:Train (Epoch 174): Loss/seq after 01650 batchs: 401.3919677734375
INFO:root:Train (Epoch 174): Loss/seq after 01700 batchs: 406.43072509765625
INFO:root:Train (Epoch 174): Loss/seq after 01750 batchs: 405.0022888183594
INFO:root:Train (Epoch 174): Loss/seq after 01800 batchs: 403.62890625
INFO:root:Train (Epoch 174): Loss/seq after 01850 batchs: 401.87225341796875
INFO:root:Train (Epoch 174): Loss/seq after 01900 batchs: 401.1889343261719
INFO:root:Train (Epoch 174): Loss/seq after 01950 batchs: 400.48919677734375
INFO:root:Train (Epoch 174): Loss/seq after 02000 batchs: 401.6289978027344
INFO:root:Train (Epoch 174): Loss/seq after 02050 batchs: 401.5716857910156
INFO:root:Train (Epoch 174): Loss/seq after 02100 batchs: 401.1820068359375
INFO:root:Train (Epoch 174): Loss/seq after 02150 batchs: 400.69195556640625
INFO:root:Train (Epoch 174): Loss/seq after 02200 batchs: 400.0364685058594
INFO:root:Train (Epoch 174): Loss/seq after 02250 batchs: 399.20062255859375
INFO:root:Train (Epoch 174): Loss/seq after 02300 batchs: 395.62982177734375
INFO:root:Train (Epoch 174): Loss/seq after 02350 batchs: 393.4607849121094
INFO:root:Train (Epoch 174): Loss/seq after 02400 batchs: 394.2652587890625
INFO:root:Train (Epoch 174): Loss/seq after 02450 batchs: 391.556640625
INFO:root:Train (Epoch 174): Loss/seq after 02500 batchs: 385.2808837890625
INFO:root:Train (Epoch 174): Loss/seq after 02550 batchs: 379.4709167480469
INFO:root:Train (Epoch 174): Loss/seq after 02600 batchs: 375.4570007324219
INFO:root:Train (Epoch 174): Loss/seq after 02650 batchs: 371.427490234375
INFO:root:Train (Epoch 174): Loss/seq after 02700 batchs: 368.59869384765625
INFO:root:Train (Epoch 174): Loss/seq after 02750 batchs: 364.25390625
INFO:root:Train (Epoch 174): Loss/seq after 02800 batchs: 361.827392578125
INFO:root:Train (Epoch 174): Loss/seq after 02850 batchs: 361.5361633300781
INFO:root:Train (Epoch 174): Loss/seq after 02900 batchs: 362.0721740722656
INFO:root:Train (Epoch 174): Loss/seq after 02950 batchs: 362.8083190917969
INFO:root:Train (Epoch 174): Loss/seq after 03000 batchs: 368.7863464355469
INFO:root:Train (Epoch 174): Loss/seq after 03050 batchs: 370.96337890625
INFO:root:Train (Epoch 174): Loss/seq after 03100 batchs: 373.045654296875
INFO:root:Train (Epoch 174): Loss/seq after 03150 batchs: 372.46038818359375
INFO:root:Train (Epoch 174): Loss/seq after 03200 batchs: 372.05413818359375
INFO:root:Train (Epoch 174): Loss/seq after 03250 batchs: 371.19317626953125
INFO:root:Train (Epoch 174): Loss/seq after 03300 batchs: 370.38079833984375
INFO:root:Train (Epoch 174): Loss/seq after 03350 batchs: 368.3839416503906
INFO:root:Train (Epoch 174): Loss/seq after 03400 batchs: 365.6934814453125
INFO:root:Train (Epoch 174): Loss/seq after 03450 batchs: 364.0404357910156
INFO:root:Train (Epoch 174): Loss/seq after 03500 batchs: 365.20037841796875
INFO:root:Train (Epoch 174): Loss/seq after 03550 batchs: 363.98638916015625
INFO:root:Train (Epoch 174): Loss/seq after 03600 batchs: 370.30609130859375
INFO:root:Train (Epoch 174): Loss/seq after 03650 batchs: 368.9051513671875
INFO:root:Train (Epoch 174): Loss/seq after 03700 batchs: 371.74334716796875
INFO:root:Train (Epoch 174): Loss/seq after 03750 batchs: 376.44512939453125
INFO:root:Train (Epoch 174): Loss/seq after 03800 batchs: 376.084228515625
INFO:root:Train (Epoch 174): Loss/seq after 03850 batchs: 375.5322265625
INFO:root:Train (Epoch 174): Loss/seq after 03900 batchs: 376.51708984375
INFO:root:Train (Epoch 174): Loss/seq after 03950 batchs: 378.178955078125
INFO:root:Train (Epoch 174): Loss/seq after 04000 batchs: 376.05682373046875
INFO:root:Train (Epoch 174): Loss/seq after 04050 batchs: 373.81561279296875
INFO:root:Train (Epoch 174): Loss/seq after 04100 batchs: 373.3079528808594
INFO:root:Train (Epoch 174): Loss/seq after 04150 batchs: 373.6988220214844
INFO:root:Train (Epoch 174): Loss/seq after 04200 batchs: 372.78118896484375
INFO:root:Train (Epoch 174): Loss/seq after 04250 batchs: 371.6522521972656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 174): Loss/seq after 00000 batches: 273.0560302734375
INFO:root:# Valid (Epoch 174): Loss/seq after 00050 batches: 619.21142578125
INFO:root:# Valid (Epoch 174): Loss/seq after 00100 batches: 601.791015625
INFO:root:# Valid (Epoch 174): Loss/seq after 00150 batches: 457.703369140625
INFO:root:# Valid (Epoch 174): Loss/seq after 00200 batches: 429.87493896484375
INFO:root:Artifacts: Make stick videos for epoch 174
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_174_on_20220422_134654.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_174_index_34_on_20220422_134654.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 175): Loss/seq after 00000 batchs: 606.6734619140625
INFO:root:Train (Epoch 175): Loss/seq after 00050 batchs: 513.1455688476562
INFO:root:Train (Epoch 175): Loss/seq after 00100 batchs: 527.8004150390625
INFO:root:Train (Epoch 175): Loss/seq after 00150 batchs: 500.550537109375
INFO:root:Train (Epoch 175): Loss/seq after 00200 batchs: 534.5988159179688
INFO:root:Train (Epoch 175): Loss/seq after 00250 batchs: 571.1532592773438
INFO:root:Train (Epoch 175): Loss/seq after 00300 batchs: 586.2725830078125
INFO:root:Train (Epoch 175): Loss/seq after 00350 batchs: 556.8909912109375
INFO:root:Train (Epoch 175): Loss/seq after 00400 batchs: 540.2327880859375
INFO:root:Train (Epoch 175): Loss/seq after 00450 batchs: 548.9058227539062
INFO:root:Train (Epoch 175): Loss/seq after 00500 batchs: 528.3731079101562
INFO:root:Train (Epoch 175): Loss/seq after 00550 batchs: 520.5306396484375
INFO:root:Train (Epoch 175): Loss/seq after 00600 batchs: 505.6434020996094
INFO:root:Train (Epoch 175): Loss/seq after 00650 batchs: 483.8315124511719
INFO:root:Train (Epoch 175): Loss/seq after 00700 batchs: 462.265869140625
INFO:root:Train (Epoch 175): Loss/seq after 00750 batchs: 450.72613525390625
INFO:root:Train (Epoch 175): Loss/seq after 00800 batchs: 457.0885009765625
INFO:root:Train (Epoch 175): Loss/seq after 00850 batchs: 442.28955078125
INFO:root:Train (Epoch 175): Loss/seq after 00900 batchs: 431.6976623535156
INFO:root:Train (Epoch 175): Loss/seq after 00950 batchs: 428.0430603027344
INFO:root:Train (Epoch 175): Loss/seq after 01000 batchs: 420.486083984375
INFO:root:Train (Epoch 175): Loss/seq after 01050 batchs: 412.52728271484375
INFO:root:Train (Epoch 175): Loss/seq after 01100 batchs: 404.7271728515625
INFO:root:Train (Epoch 175): Loss/seq after 01150 batchs: 393.8298645019531
INFO:root:Train (Epoch 175): Loss/seq after 01200 batchs: 399.4794006347656
INFO:root:Train (Epoch 175): Loss/seq after 01250 batchs: 399.76788330078125
INFO:root:Train (Epoch 175): Loss/seq after 01300 batchs: 390.26715087890625
INFO:root:Train (Epoch 175): Loss/seq after 01350 batchs: 381.3073425292969
INFO:root:Train (Epoch 175): Loss/seq after 01400 batchs: 382.3403015136719
INFO:root:Train (Epoch 175): Loss/seq after 01450 batchs: 386.4036865234375
INFO:root:Train (Epoch 175): Loss/seq after 01500 batchs: 393.4639587402344
INFO:root:Train (Epoch 175): Loss/seq after 01550 batchs: 394.3074951171875
INFO:root:Train (Epoch 175): Loss/seq after 01600 batchs: 391.9221496582031
INFO:root:Train (Epoch 175): Loss/seq after 01650 batchs: 391.1229248046875
INFO:root:Train (Epoch 175): Loss/seq after 01700 batchs: 396.06976318359375
INFO:root:Train (Epoch 175): Loss/seq after 01750 batchs: 395.05377197265625
INFO:root:Train (Epoch 175): Loss/seq after 01800 batchs: 394.0883483886719
INFO:root:Train (Epoch 175): Loss/seq after 01850 batchs: 392.5374450683594
INFO:root:Train (Epoch 175): Loss/seq after 01900 batchs: 392.20587158203125
INFO:root:Train (Epoch 175): Loss/seq after 01950 batchs: 392.0604248046875
INFO:root:Train (Epoch 175): Loss/seq after 02000 batchs: 393.8348693847656
INFO:root:Train (Epoch 175): Loss/seq after 02050 batchs: 394.7016296386719
INFO:root:Train (Epoch 175): Loss/seq after 02100 batchs: 394.55157470703125
INFO:root:Train (Epoch 175): Loss/seq after 02150 batchs: 394.27850341796875
INFO:root:Train (Epoch 175): Loss/seq after 02200 batchs: 393.8289489746094
INFO:root:Train (Epoch 175): Loss/seq after 02250 batchs: 392.6016845703125
INFO:root:Train (Epoch 175): Loss/seq after 02300 batchs: 388.96484375
INFO:root:Train (Epoch 175): Loss/seq after 02350 batchs: 386.9166259765625
INFO:root:Train (Epoch 175): Loss/seq after 02400 batchs: 387.933837890625
INFO:root:Train (Epoch 175): Loss/seq after 02450 batchs: 385.3252258300781
INFO:root:Train (Epoch 175): Loss/seq after 02500 batchs: 379.25921630859375
INFO:root:Train (Epoch 175): Loss/seq after 02550 batchs: 373.64111328125
INFO:root:Train (Epoch 175): Loss/seq after 02600 batchs: 369.634521484375
INFO:root:Train (Epoch 175): Loss/seq after 02650 batchs: 365.6671142578125
INFO:root:Train (Epoch 175): Loss/seq after 02700 batchs: 362.8432312011719
INFO:root:Train (Epoch 175): Loss/seq after 02750 batchs: 358.5885314941406
INFO:root:Train (Epoch 175): Loss/seq after 02800 batchs: 355.942626953125
INFO:root:Train (Epoch 175): Loss/seq after 02850 batchs: 355.712158203125
INFO:root:Train (Epoch 175): Loss/seq after 02900 batchs: 356.3993225097656
INFO:root:Train (Epoch 175): Loss/seq after 02950 batchs: 357.2385559082031
INFO:root:Train (Epoch 175): Loss/seq after 03000 batchs: 363.13714599609375
INFO:root:Train (Epoch 175): Loss/seq after 03050 batchs: 365.178466796875
INFO:root:Train (Epoch 175): Loss/seq after 03100 batchs: 366.77227783203125
INFO:root:Train (Epoch 175): Loss/seq after 03150 batchs: 366.5347900390625
INFO:root:Train (Epoch 175): Loss/seq after 03200 batchs: 366.2590637207031
INFO:root:Train (Epoch 175): Loss/seq after 03250 batchs: 365.70831298828125
INFO:root:Train (Epoch 175): Loss/seq after 03300 batchs: 364.9022216796875
INFO:root:Train (Epoch 175): Loss/seq after 03350 batchs: 362.93621826171875
INFO:root:Train (Epoch 175): Loss/seq after 03400 batchs: 360.35443115234375
INFO:root:Train (Epoch 175): Loss/seq after 03450 batchs: 358.94927978515625
INFO:root:Train (Epoch 175): Loss/seq after 03500 batchs: 360.62109375
INFO:root:Train (Epoch 175): Loss/seq after 03550 batchs: 360.2832946777344
INFO:root:Train (Epoch 175): Loss/seq after 03600 batchs: 367.11981201171875
INFO:root:Train (Epoch 175): Loss/seq after 03650 batchs: 366.0898742675781
INFO:root:Train (Epoch 175): Loss/seq after 03700 batchs: 369.4606628417969
INFO:root:Train (Epoch 175): Loss/seq after 03750 batchs: 374.2440185546875
INFO:root:Train (Epoch 175): Loss/seq after 03800 batchs: 373.91546630859375
INFO:root:Train (Epoch 175): Loss/seq after 03850 batchs: 373.60699462890625
INFO:root:Train (Epoch 175): Loss/seq after 03900 batchs: 374.6023864746094
INFO:root:Train (Epoch 175): Loss/seq after 03950 batchs: 376.29150390625
INFO:root:Train (Epoch 175): Loss/seq after 04000 batchs: 374.25787353515625
INFO:root:Train (Epoch 175): Loss/seq after 04050 batchs: 372.0020446777344
INFO:root:Train (Epoch 175): Loss/seq after 04100 batchs: 371.4993896484375
INFO:root:Train (Epoch 175): Loss/seq after 04150 batchs: 371.9613342285156
INFO:root:Train (Epoch 175): Loss/seq after 04200 batchs: 371.2098083496094
INFO:root:Train (Epoch 175): Loss/seq after 04250 batchs: 370.1396179199219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 175): Loss/seq after 00000 batches: 261.84039306640625
INFO:root:# Valid (Epoch 175): Loss/seq after 00050 batches: 639.2723388671875
INFO:root:# Valid (Epoch 175): Loss/seq after 00100 batches: 630.8833618164062
INFO:root:# Valid (Epoch 175): Loss/seq after 00150 batches: 479.3333435058594
INFO:root:# Valid (Epoch 175): Loss/seq after 00200 batches: 456.8809814453125
INFO:root:Artifacts: Make stick videos for epoch 175
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_175_on_20220422_135142.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_175_index_529_on_20220422_135142.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 176): Loss/seq after 00000 batchs: 771.7564697265625
INFO:root:Train (Epoch 176): Loss/seq after 00050 batchs: 552.0960083007812
INFO:root:Train (Epoch 176): Loss/seq after 00100 batchs: 542.6669921875
INFO:root:Train (Epoch 176): Loss/seq after 00150 batchs: 509.6595458984375
INFO:root:Train (Epoch 176): Loss/seq after 00200 batchs: 546.2236938476562
INFO:root:Train (Epoch 176): Loss/seq after 00250 batchs: 598.833984375
INFO:root:Train (Epoch 176): Loss/seq after 00300 batchs: 613.0029907226562
INFO:root:Train (Epoch 176): Loss/seq after 00350 batchs: 581.3653564453125
INFO:root:Train (Epoch 176): Loss/seq after 00400 batchs: 565.5615844726562
INFO:root:Train (Epoch 176): Loss/seq after 00450 batchs: 572.3141479492188
INFO:root:Train (Epoch 176): Loss/seq after 00500 batchs: 552.1051025390625
INFO:root:Train (Epoch 176): Loss/seq after 00550 batchs: 542.3403930664062
INFO:root:Train (Epoch 176): Loss/seq after 00600 batchs: 526.8820190429688
INFO:root:Train (Epoch 176): Loss/seq after 00650 batchs: 503.255126953125
INFO:root:Train (Epoch 176): Loss/seq after 00700 batchs: 479.5079040527344
INFO:root:Train (Epoch 176): Loss/seq after 00750 batchs: 467.81549072265625
INFO:root:Train (Epoch 176): Loss/seq after 00800 batchs: 473.9818420410156
INFO:root:Train (Epoch 176): Loss/seq after 00850 batchs: 459.5608825683594
INFO:root:Train (Epoch 176): Loss/seq after 00900 batchs: 448.9778137207031
INFO:root:Train (Epoch 176): Loss/seq after 00950 batchs: 445.2737121582031
INFO:root:Train (Epoch 176): Loss/seq after 01000 batchs: 436.6699523925781
INFO:root:Train (Epoch 176): Loss/seq after 01050 batchs: 431.61181640625
INFO:root:Train (Epoch 176): Loss/seq after 01100 batchs: 422.7951965332031
INFO:root:Train (Epoch 176): Loss/seq after 01150 batchs: 410.6616516113281
INFO:root:Train (Epoch 176): Loss/seq after 01200 batchs: 414.5193786621094
INFO:root:Train (Epoch 176): Loss/seq after 01250 batchs: 413.9515686035156
INFO:root:Train (Epoch 176): Loss/seq after 01300 batchs: 403.8638000488281
INFO:root:Train (Epoch 176): Loss/seq after 01350 batchs: 394.0577697753906
INFO:root:Train (Epoch 176): Loss/seq after 01400 batchs: 393.9665222167969
INFO:root:Train (Epoch 176): Loss/seq after 01450 batchs: 397.3634033203125
INFO:root:Train (Epoch 176): Loss/seq after 01500 batchs: 404.4729919433594
INFO:root:Train (Epoch 176): Loss/seq after 01550 batchs: 405.595947265625
INFO:root:Train (Epoch 176): Loss/seq after 01600 batchs: 403.26336669921875
INFO:root:Train (Epoch 176): Loss/seq after 01650 batchs: 402.31292724609375
INFO:root:Train (Epoch 176): Loss/seq after 01700 batchs: 406.96832275390625
INFO:root:Train (Epoch 176): Loss/seq after 01750 batchs: 405.6709289550781
INFO:root:Train (Epoch 176): Loss/seq after 01800 batchs: 404.4180603027344
INFO:root:Train (Epoch 176): Loss/seq after 01850 batchs: 402.54998779296875
INFO:root:Train (Epoch 176): Loss/seq after 01900 batchs: 402.1809997558594
INFO:root:Train (Epoch 176): Loss/seq after 01950 batchs: 401.888671875
INFO:root:Train (Epoch 176): Loss/seq after 02000 batchs: 402.86248779296875
INFO:root:Train (Epoch 176): Loss/seq after 02050 batchs: 403.603759765625
INFO:root:Train (Epoch 176): Loss/seq after 02100 batchs: 403.0562744140625
INFO:root:Train (Epoch 176): Loss/seq after 02150 batchs: 402.55615234375
INFO:root:Train (Epoch 176): Loss/seq after 02200 batchs: 401.76513671875
INFO:root:Train (Epoch 176): Loss/seq after 02250 batchs: 400.449951171875
INFO:root:Train (Epoch 176): Loss/seq after 02300 batchs: 396.8887023925781
INFO:root:Train (Epoch 176): Loss/seq after 02350 batchs: 394.4871520996094
INFO:root:Train (Epoch 176): Loss/seq after 02400 batchs: 395.2732849121094
INFO:root:Train (Epoch 176): Loss/seq after 02450 batchs: 392.4595642089844
INFO:root:Train (Epoch 176): Loss/seq after 02500 batchs: 386.2093200683594
INFO:root:Train (Epoch 176): Loss/seq after 02550 batchs: 380.37713623046875
INFO:root:Train (Epoch 176): Loss/seq after 02600 batchs: 376.210693359375
INFO:root:Train (Epoch 176): Loss/seq after 02650 batchs: 372.20947265625
INFO:root:Train (Epoch 176): Loss/seq after 02700 batchs: 369.2547912597656
INFO:root:Train (Epoch 176): Loss/seq after 02750 batchs: 365.2038269042969
INFO:root:Train (Epoch 176): Loss/seq after 02800 batchs: 362.9444885253906
INFO:root:Train (Epoch 176): Loss/seq after 02850 batchs: 362.6513671875
INFO:root:Train (Epoch 176): Loss/seq after 02900 batchs: 363.0298156738281
INFO:root:Train (Epoch 176): Loss/seq after 02950 batchs: 363.61212158203125
INFO:root:Train (Epoch 176): Loss/seq after 03000 batchs: 369.46044921875
INFO:root:Train (Epoch 176): Loss/seq after 03050 batchs: 371.3461608886719
INFO:root:Train (Epoch 176): Loss/seq after 03100 batchs: 372.8722229003906
INFO:root:Train (Epoch 176): Loss/seq after 03150 batchs: 371.8375549316406
INFO:root:Train (Epoch 176): Loss/seq after 03200 batchs: 371.4366760253906
INFO:root:Train (Epoch 176): Loss/seq after 03250 batchs: 370.9291687011719
INFO:root:Train (Epoch 176): Loss/seq after 03300 batchs: 370.107177734375
INFO:root:Train (Epoch 176): Loss/seq after 03350 batchs: 368.0084533691406
INFO:root:Train (Epoch 176): Loss/seq after 03400 batchs: 365.2565002441406
INFO:root:Train (Epoch 176): Loss/seq after 03450 batchs: 363.6058654785156
INFO:root:Train (Epoch 176): Loss/seq after 03500 batchs: 364.8995056152344
INFO:root:Train (Epoch 176): Loss/seq after 03550 batchs: 363.6756896972656
INFO:root:Train (Epoch 176): Loss/seq after 03600 batchs: 369.8983459472656
INFO:root:Train (Epoch 176): Loss/seq after 03650 batchs: 368.7727966308594
INFO:root:Train (Epoch 176): Loss/seq after 03700 batchs: 371.532958984375
INFO:root:Train (Epoch 176): Loss/seq after 03750 batchs: 376.212646484375
INFO:root:Train (Epoch 176): Loss/seq after 03800 batchs: 375.85247802734375
INFO:root:Train (Epoch 176): Loss/seq after 03850 batchs: 375.5067138671875
INFO:root:Train (Epoch 176): Loss/seq after 03900 batchs: 377.5345764160156
INFO:root:Train (Epoch 176): Loss/seq after 03950 batchs: 379.2951354980469
INFO:root:Train (Epoch 176): Loss/seq after 04000 batchs: 377.1902160644531
INFO:root:Train (Epoch 176): Loss/seq after 04050 batchs: 374.89886474609375
INFO:root:Train (Epoch 176): Loss/seq after 04100 batchs: 374.4277038574219
INFO:root:Train (Epoch 176): Loss/seq after 04150 batchs: 374.6358337402344
INFO:root:Train (Epoch 176): Loss/seq after 04200 batchs: 373.8768615722656
INFO:root:Train (Epoch 176): Loss/seq after 04250 batchs: 372.7975158691406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 176): Loss/seq after 00000 batches: 255.68777465820312
INFO:root:# Valid (Epoch 176): Loss/seq after 00050 batches: 598.8334350585938
INFO:root:# Valid (Epoch 176): Loss/seq after 00100 batches: 593.1683349609375
INFO:root:# Valid (Epoch 176): Loss/seq after 00150 batches: 452.0938415527344
INFO:root:# Valid (Epoch 176): Loss/seq after 00200 batches: 428.557373046875
INFO:root:Artifacts: Make stick videos for epoch 176
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_176_on_20220422_135639.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_176_index_423_on_20220422_135639.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 177): Loss/seq after 00000 batchs: 508.4578857421875
INFO:root:Train (Epoch 177): Loss/seq after 00050 batchs: 499.35601806640625
INFO:root:Train (Epoch 177): Loss/seq after 00100 batchs: 501.2694396972656
INFO:root:Train (Epoch 177): Loss/seq after 00150 batchs: 475.9193420410156
INFO:root:Train (Epoch 177): Loss/seq after 00200 batchs: 518.4130249023438
INFO:root:Train (Epoch 177): Loss/seq after 00250 batchs: 572.6018676757812
INFO:root:Train (Epoch 177): Loss/seq after 00300 batchs: 589.9677124023438
INFO:root:Train (Epoch 177): Loss/seq after 00350 batchs: 558.4169921875
INFO:root:Train (Epoch 177): Loss/seq after 00400 batchs: 540.3838500976562
INFO:root:Train (Epoch 177): Loss/seq after 00450 batchs: 549.458984375
INFO:root:Train (Epoch 177): Loss/seq after 00500 batchs: 530.252685546875
INFO:root:Train (Epoch 177): Loss/seq after 00550 batchs: 521.170654296875
INFO:root:Train (Epoch 177): Loss/seq after 00600 batchs: 506.186767578125
INFO:root:Train (Epoch 177): Loss/seq after 00650 batchs: 484.8155822753906
INFO:root:Train (Epoch 177): Loss/seq after 00700 batchs: 464.3962707519531
INFO:root:Train (Epoch 177): Loss/seq after 00750 batchs: 453.06488037109375
INFO:root:Train (Epoch 177): Loss/seq after 00800 batchs: 458.3733215332031
INFO:root:Train (Epoch 177): Loss/seq after 00850 batchs: 443.9317321777344
INFO:root:Train (Epoch 177): Loss/seq after 00900 batchs: 433.0796203613281
INFO:root:Train (Epoch 177): Loss/seq after 00950 batchs: 429.8533935546875
INFO:root:Train (Epoch 177): Loss/seq after 01000 batchs: 421.5878601074219
INFO:root:Train (Epoch 177): Loss/seq after 01050 batchs: 415.5896301269531
INFO:root:Train (Epoch 177): Loss/seq after 01100 batchs: 407.14959716796875
INFO:root:Train (Epoch 177): Loss/seq after 01150 batchs: 396.2451171875
INFO:root:Train (Epoch 177): Loss/seq after 01200 batchs: 401.4150390625
INFO:root:Train (Epoch 177): Loss/seq after 01250 batchs: 402.29388427734375
INFO:root:Train (Epoch 177): Loss/seq after 01300 batchs: 392.5835266113281
INFO:root:Train (Epoch 177): Loss/seq after 01350 batchs: 383.5216979980469
INFO:root:Train (Epoch 177): Loss/seq after 01400 batchs: 384.1961975097656
INFO:root:Train (Epoch 177): Loss/seq after 01450 batchs: 388.3529052734375
INFO:root:Train (Epoch 177): Loss/seq after 01500 batchs: 395.8057556152344
INFO:root:Train (Epoch 177): Loss/seq after 01550 batchs: 396.7286376953125
INFO:root:Train (Epoch 177): Loss/seq after 01600 batchs: 394.56536865234375
INFO:root:Train (Epoch 177): Loss/seq after 01650 batchs: 393.9403381347656
INFO:root:Train (Epoch 177): Loss/seq after 01700 batchs: 398.9310607910156
INFO:root:Train (Epoch 177): Loss/seq after 01750 batchs: 397.73114013671875
INFO:root:Train (Epoch 177): Loss/seq after 01800 batchs: 396.6248779296875
INFO:root:Train (Epoch 177): Loss/seq after 01850 batchs: 394.9275207519531
INFO:root:Train (Epoch 177): Loss/seq after 01900 batchs: 394.6533508300781
INFO:root:Train (Epoch 177): Loss/seq after 01950 batchs: 394.57568359375
INFO:root:Train (Epoch 177): Loss/seq after 02000 batchs: 395.91668701171875
INFO:root:Train (Epoch 177): Loss/seq after 02050 batchs: 396.3992919921875
INFO:root:Train (Epoch 177): Loss/seq after 02100 batchs: 395.7230529785156
INFO:root:Train (Epoch 177): Loss/seq after 02150 batchs: 395.3544616699219
INFO:root:Train (Epoch 177): Loss/seq after 02200 batchs: 394.7650451660156
INFO:root:Train (Epoch 177): Loss/seq after 02250 batchs: 393.52685546875
INFO:root:Train (Epoch 177): Loss/seq after 02300 batchs: 389.8643493652344
INFO:root:Train (Epoch 177): Loss/seq after 02350 batchs: 387.7174072265625
INFO:root:Train (Epoch 177): Loss/seq after 02400 batchs: 388.52386474609375
INFO:root:Train (Epoch 177): Loss/seq after 02450 batchs: 385.7957763671875
INFO:root:Train (Epoch 177): Loss/seq after 02500 batchs: 379.6335144042969
INFO:root:Train (Epoch 177): Loss/seq after 02550 batchs: 373.8663330078125
INFO:root:Train (Epoch 177): Loss/seq after 02600 batchs: 369.8373107910156
INFO:root:Train (Epoch 177): Loss/seq after 02650 batchs: 365.91168212890625
INFO:root:Train (Epoch 177): Loss/seq after 02700 batchs: 363.1101989746094
INFO:root:Train (Epoch 177): Loss/seq after 02750 batchs: 359.167236328125
INFO:root:Train (Epoch 177): Loss/seq after 02800 batchs: 357.0106506347656
INFO:root:Train (Epoch 177): Loss/seq after 02850 batchs: 356.84112548828125
INFO:root:Train (Epoch 177): Loss/seq after 02900 batchs: 357.4084167480469
INFO:root:Train (Epoch 177): Loss/seq after 02950 batchs: 358.1733703613281
INFO:root:Train (Epoch 177): Loss/seq after 03000 batchs: 364.008544921875
INFO:root:Train (Epoch 177): Loss/seq after 03050 batchs: 366.2121887207031
INFO:root:Train (Epoch 177): Loss/seq after 03100 batchs: 367.9596862792969
INFO:root:Train (Epoch 177): Loss/seq after 03150 batchs: 367.1922607421875
INFO:root:Train (Epoch 177): Loss/seq after 03200 batchs: 366.8501281738281
INFO:root:Train (Epoch 177): Loss/seq after 03250 batchs: 365.8947448730469
INFO:root:Train (Epoch 177): Loss/seq after 03300 batchs: 365.4894104003906
INFO:root:Train (Epoch 177): Loss/seq after 03350 batchs: 363.48382568359375
INFO:root:Train (Epoch 177): Loss/seq after 03400 batchs: 360.8794250488281
INFO:root:Train (Epoch 177): Loss/seq after 03450 batchs: 359.2521667480469
INFO:root:Train (Epoch 177): Loss/seq after 03500 batchs: 360.1225280761719
INFO:root:Train (Epoch 177): Loss/seq after 03550 batchs: 358.61859130859375
INFO:root:Train (Epoch 177): Loss/seq after 03600 batchs: 364.8106384277344
INFO:root:Train (Epoch 177): Loss/seq after 03650 batchs: 363.62213134765625
INFO:root:Train (Epoch 177): Loss/seq after 03700 batchs: 366.9642028808594
INFO:root:Train (Epoch 177): Loss/seq after 03750 batchs: 371.63690185546875
INFO:root:Train (Epoch 177): Loss/seq after 03800 batchs: 371.2847595214844
INFO:root:Train (Epoch 177): Loss/seq after 03850 batchs: 370.7774353027344
INFO:root:Train (Epoch 177): Loss/seq after 03900 batchs: 371.953857421875
INFO:root:Train (Epoch 177): Loss/seq after 03950 batchs: 373.16607666015625
INFO:root:Train (Epoch 177): Loss/seq after 04000 batchs: 371.2784729003906
INFO:root:Train (Epoch 177): Loss/seq after 04050 batchs: 369.0579833984375
INFO:root:Train (Epoch 177): Loss/seq after 04100 batchs: 368.6298828125
INFO:root:Train (Epoch 177): Loss/seq after 04150 batchs: 368.9718322753906
INFO:root:Train (Epoch 177): Loss/seq after 04200 batchs: 368.089111328125
INFO:root:Train (Epoch 177): Loss/seq after 04250 batchs: 366.9096984863281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 177): Loss/seq after 00000 batches: 318.18878173828125
INFO:root:# Valid (Epoch 177): Loss/seq after 00050 batches: 627.70947265625
INFO:root:# Valid (Epoch 177): Loss/seq after 00100 batches: 602.5867919921875
INFO:root:# Valid (Epoch 177): Loss/seq after 00150 batches: 457.9795227050781
INFO:root:# Valid (Epoch 177): Loss/seq after 00200 batches: 434.5592956542969
INFO:root:Artifacts: Make stick videos for epoch 177
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_177_on_20220422_140138.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_177_index_464_on_20220422_140138.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 178): Loss/seq after 00000 batchs: 485.6947937011719
INFO:root:Train (Epoch 178): Loss/seq after 00050 batchs: 514.8245849609375
INFO:root:Train (Epoch 178): Loss/seq after 00100 batchs: 515.5855102539062
INFO:root:Train (Epoch 178): Loss/seq after 00150 batchs: 490.97381591796875
INFO:root:Train (Epoch 178): Loss/seq after 00200 batchs: 530.0183715820312
INFO:root:Train (Epoch 178): Loss/seq after 00250 batchs: 573.0967407226562
INFO:root:Train (Epoch 178): Loss/seq after 00300 batchs: 592.20654296875
INFO:root:Train (Epoch 178): Loss/seq after 00350 batchs: 563.5741577148438
INFO:root:Train (Epoch 178): Loss/seq after 00400 batchs: 548.4788818359375
INFO:root:Train (Epoch 178): Loss/seq after 00450 batchs: 557.1107788085938
INFO:root:Train (Epoch 178): Loss/seq after 00500 batchs: 537.1698608398438
INFO:root:Train (Epoch 178): Loss/seq after 00550 batchs: 527.3721923828125
INFO:root:Train (Epoch 178): Loss/seq after 00600 batchs: 513.079345703125
INFO:root:Train (Epoch 178): Loss/seq after 00650 batchs: 490.7283630371094
INFO:root:Train (Epoch 178): Loss/seq after 00700 batchs: 468.46759033203125
INFO:root:Train (Epoch 178): Loss/seq after 00750 batchs: 457.7010192871094
INFO:root:Train (Epoch 178): Loss/seq after 00800 batchs: 464.0502014160156
INFO:root:Train (Epoch 178): Loss/seq after 00850 batchs: 449.2390441894531
INFO:root:Train (Epoch 178): Loss/seq after 00900 batchs: 437.8626708984375
INFO:root:Train (Epoch 178): Loss/seq after 00950 batchs: 433.77099609375
INFO:root:Train (Epoch 178): Loss/seq after 01000 batchs: 424.47308349609375
INFO:root:Train (Epoch 178): Loss/seq after 01050 batchs: 416.8182678222656
INFO:root:Train (Epoch 178): Loss/seq after 01100 batchs: 409.3135070800781
INFO:root:Train (Epoch 178): Loss/seq after 01150 batchs: 398.22137451171875
INFO:root:Train (Epoch 178): Loss/seq after 01200 batchs: 403.0323791503906
INFO:root:Train (Epoch 178): Loss/seq after 01250 batchs: 403.7594299316406
INFO:root:Train (Epoch 178): Loss/seq after 01300 batchs: 394.3006286621094
INFO:root:Train (Epoch 178): Loss/seq after 01350 batchs: 384.8372497558594
INFO:root:Train (Epoch 178): Loss/seq after 01400 batchs: 386.124267578125
INFO:root:Train (Epoch 178): Loss/seq after 01450 batchs: 390.1430358886719
INFO:root:Train (Epoch 178): Loss/seq after 01500 batchs: 397.34027099609375
INFO:root:Train (Epoch 178): Loss/seq after 01550 batchs: 398.23138427734375
INFO:root:Train (Epoch 178): Loss/seq after 01600 batchs: 396.00823974609375
INFO:root:Train (Epoch 178): Loss/seq after 01650 batchs: 394.9178466796875
INFO:root:Train (Epoch 178): Loss/seq after 01700 batchs: 399.978515625
INFO:root:Train (Epoch 178): Loss/seq after 01750 batchs: 398.58868408203125
INFO:root:Train (Epoch 178): Loss/seq after 01800 batchs: 397.3118896484375
INFO:root:Train (Epoch 178): Loss/seq after 01850 batchs: 395.6133117675781
INFO:root:Train (Epoch 178): Loss/seq after 01900 batchs: 395.0157775878906
INFO:root:Train (Epoch 178): Loss/seq after 01950 batchs: 394.70684814453125
INFO:root:Train (Epoch 178): Loss/seq after 02000 batchs: 395.9296875
INFO:root:Train (Epoch 178): Loss/seq after 02050 batchs: 396.19232177734375
INFO:root:Train (Epoch 178): Loss/seq after 02100 batchs: 395.6667175292969
INFO:root:Train (Epoch 178): Loss/seq after 02150 batchs: 395.2445373535156
INFO:root:Train (Epoch 178): Loss/seq after 02200 batchs: 394.69525146484375
INFO:root:Train (Epoch 178): Loss/seq after 02250 batchs: 393.4742126464844
INFO:root:Train (Epoch 178): Loss/seq after 02300 batchs: 389.92138671875
INFO:root:Train (Epoch 178): Loss/seq after 02350 batchs: 387.7731628417969
INFO:root:Train (Epoch 178): Loss/seq after 02400 batchs: 388.6051025390625
INFO:root:Train (Epoch 178): Loss/seq after 02450 batchs: 385.90142822265625
INFO:root:Train (Epoch 178): Loss/seq after 02500 batchs: 379.79986572265625
INFO:root:Train (Epoch 178): Loss/seq after 02550 batchs: 374.0382995605469
INFO:root:Train (Epoch 178): Loss/seq after 02600 batchs: 369.9905090332031
INFO:root:Train (Epoch 178): Loss/seq after 02650 batchs: 365.9615478515625
INFO:root:Train (Epoch 178): Loss/seq after 02700 batchs: 363.0506591796875
INFO:root:Train (Epoch 178): Loss/seq after 02750 batchs: 358.9244384765625
INFO:root:Train (Epoch 178): Loss/seq after 02800 batchs: 356.7837829589844
INFO:root:Train (Epoch 178): Loss/seq after 02850 batchs: 356.4909973144531
INFO:root:Train (Epoch 178): Loss/seq after 02900 batchs: 357.2340087890625
INFO:root:Train (Epoch 178): Loss/seq after 02950 batchs: 358.09869384765625
INFO:root:Train (Epoch 178): Loss/seq after 03000 batchs: 364.0090026855469
INFO:root:Train (Epoch 178): Loss/seq after 03050 batchs: 366.2183837890625
INFO:root:Train (Epoch 178): Loss/seq after 03100 batchs: 368.00677490234375
INFO:root:Train (Epoch 178): Loss/seq after 03150 batchs: 367.1492614746094
INFO:root:Train (Epoch 178): Loss/seq after 03200 batchs: 366.4267578125
INFO:root:Train (Epoch 178): Loss/seq after 03250 batchs: 365.2052307128906
INFO:root:Train (Epoch 178): Loss/seq after 03300 batchs: 364.4346008300781
INFO:root:Train (Epoch 178): Loss/seq after 03350 batchs: 362.1761169433594
INFO:root:Train (Epoch 178): Loss/seq after 03400 batchs: 359.51885986328125
INFO:root:Train (Epoch 178): Loss/seq after 03450 batchs: 357.8594665527344
INFO:root:Train (Epoch 178): Loss/seq after 03500 batchs: 358.8743591308594
INFO:root:Train (Epoch 178): Loss/seq after 03550 batchs: 357.3716735839844
INFO:root:Train (Epoch 178): Loss/seq after 03600 batchs: 363.4355163574219
INFO:root:Train (Epoch 178): Loss/seq after 03650 batchs: 362.161865234375
INFO:root:Train (Epoch 178): Loss/seq after 03700 batchs: 364.6804504394531
INFO:root:Train (Epoch 178): Loss/seq after 03750 batchs: 369.2928771972656
INFO:root:Train (Epoch 178): Loss/seq after 03800 batchs: 369.0093994140625
INFO:root:Train (Epoch 178): Loss/seq after 03850 batchs: 368.45599365234375
INFO:root:Train (Epoch 178): Loss/seq after 03900 batchs: 369.4241943359375
INFO:root:Train (Epoch 178): Loss/seq after 03950 batchs: 371.0295104980469
INFO:root:Train (Epoch 178): Loss/seq after 04000 batchs: 369.0443115234375
INFO:root:Train (Epoch 178): Loss/seq after 04050 batchs: 366.8527526855469
INFO:root:Train (Epoch 178): Loss/seq after 04100 batchs: 366.4128723144531
INFO:root:Train (Epoch 178): Loss/seq after 04150 batchs: 366.7606506347656
INFO:root:Train (Epoch 178): Loss/seq after 04200 batchs: 365.9052734375
INFO:root:Train (Epoch 178): Loss/seq after 04250 batchs: 364.7154541015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 178): Loss/seq after 00000 batches: 251.06813049316406
INFO:root:# Valid (Epoch 178): Loss/seq after 00050 batches: 610.1156005859375
INFO:root:# Valid (Epoch 178): Loss/seq after 00100 batches: 597.9730224609375
INFO:root:# Valid (Epoch 178): Loss/seq after 00150 batches: 455.68505859375
INFO:root:# Valid (Epoch 178): Loss/seq after 00200 batches: 429.54180908203125
INFO:root:Artifacts: Make stick videos for epoch 178
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_178_on_20220422_140624.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_178_index_713_on_20220422_140624.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 179): Loss/seq after 00000 batchs: 535.2373046875
INFO:root:Train (Epoch 179): Loss/seq after 00050 batchs: 529.2872314453125
INFO:root:Train (Epoch 179): Loss/seq after 00100 batchs: 515.345458984375
INFO:root:Train (Epoch 179): Loss/seq after 00150 batchs: 495.0663146972656
INFO:root:Train (Epoch 179): Loss/seq after 00200 batchs: 538.1129760742188
INFO:root:Train (Epoch 179): Loss/seq after 00250 batchs: 590.8714599609375
INFO:root:Train (Epoch 179): Loss/seq after 00300 batchs: 605.9796752929688
INFO:root:Train (Epoch 179): Loss/seq after 00350 batchs: 576.1727294921875
INFO:root:Train (Epoch 179): Loss/seq after 00400 batchs: 561.5436401367188
INFO:root:Train (Epoch 179): Loss/seq after 00450 batchs: 570.5541381835938
INFO:root:Train (Epoch 179): Loss/seq after 00500 batchs: 551.3531494140625
INFO:root:Train (Epoch 179): Loss/seq after 00550 batchs: 542.246826171875
INFO:root:Train (Epoch 179): Loss/seq after 00600 batchs: 526.3112182617188
INFO:root:Train (Epoch 179): Loss/seq after 00650 batchs: 505.107177734375
INFO:root:Train (Epoch 179): Loss/seq after 00700 batchs: 482.5281982421875
INFO:root:Train (Epoch 179): Loss/seq after 00750 batchs: 469.8014831542969
INFO:root:Train (Epoch 179): Loss/seq after 00800 batchs: 476.30889892578125
INFO:root:Train (Epoch 179): Loss/seq after 00850 batchs: 460.814208984375
INFO:root:Train (Epoch 179): Loss/seq after 00900 batchs: 448.7963562011719
INFO:root:Train (Epoch 179): Loss/seq after 00950 batchs: 444.0061340332031
INFO:root:Train (Epoch 179): Loss/seq after 01000 batchs: 434.5633544921875
INFO:root:Train (Epoch 179): Loss/seq after 01050 batchs: 427.60833740234375
INFO:root:Train (Epoch 179): Loss/seq after 01100 batchs: 419.8089294433594
INFO:root:Train (Epoch 179): Loss/seq after 01150 batchs: 408.0130920410156
INFO:root:Train (Epoch 179): Loss/seq after 01200 batchs: 412.1446533203125
INFO:root:Train (Epoch 179): Loss/seq after 01250 batchs: 411.56585693359375
INFO:root:Train (Epoch 179): Loss/seq after 01300 batchs: 401.3916931152344
INFO:root:Train (Epoch 179): Loss/seq after 01350 batchs: 392.1567687988281
INFO:root:Train (Epoch 179): Loss/seq after 01400 batchs: 392.5051574707031
INFO:root:Train (Epoch 179): Loss/seq after 01450 batchs: 396.1683654785156
INFO:root:Train (Epoch 179): Loss/seq after 01500 batchs: 403.17864990234375
INFO:root:Train (Epoch 179): Loss/seq after 01550 batchs: 404.2474365234375
INFO:root:Train (Epoch 179): Loss/seq after 01600 batchs: 401.5340881347656
INFO:root:Train (Epoch 179): Loss/seq after 01650 batchs: 400.338134765625
INFO:root:Train (Epoch 179): Loss/seq after 01700 batchs: 405.27362060546875
INFO:root:Train (Epoch 179): Loss/seq after 01750 batchs: 403.8185119628906
INFO:root:Train (Epoch 179): Loss/seq after 01800 batchs: 402.30743408203125
INFO:root:Train (Epoch 179): Loss/seq after 01850 batchs: 400.4950256347656
INFO:root:Train (Epoch 179): Loss/seq after 01900 batchs: 399.8672790527344
INFO:root:Train (Epoch 179): Loss/seq after 01950 batchs: 399.6072998046875
INFO:root:Train (Epoch 179): Loss/seq after 02000 batchs: 400.635009765625
INFO:root:Train (Epoch 179): Loss/seq after 02050 batchs: 400.8697509765625
INFO:root:Train (Epoch 179): Loss/seq after 02100 batchs: 400.0589904785156
INFO:root:Train (Epoch 179): Loss/seq after 02150 batchs: 399.57855224609375
INFO:root:Train (Epoch 179): Loss/seq after 02200 batchs: 398.7550964355469
INFO:root:Train (Epoch 179): Loss/seq after 02250 batchs: 397.53564453125
INFO:root:Train (Epoch 179): Loss/seq after 02300 batchs: 393.8252868652344
INFO:root:Train (Epoch 179): Loss/seq after 02350 batchs: 391.5621643066406
INFO:root:Train (Epoch 179): Loss/seq after 02400 batchs: 392.28387451171875
INFO:root:Train (Epoch 179): Loss/seq after 02450 batchs: 389.5496520996094
INFO:root:Train (Epoch 179): Loss/seq after 02500 batchs: 383.3493957519531
INFO:root:Train (Epoch 179): Loss/seq after 02550 batchs: 377.55328369140625
INFO:root:Train (Epoch 179): Loss/seq after 02600 batchs: 373.1628723144531
INFO:root:Train (Epoch 179): Loss/seq after 02650 batchs: 369.0907897949219
INFO:root:Train (Epoch 179): Loss/seq after 02700 batchs: 366.20733642578125
INFO:root:Train (Epoch 179): Loss/seq after 02750 batchs: 362.18572998046875
INFO:root:Train (Epoch 179): Loss/seq after 02800 batchs: 360.25469970703125
INFO:root:Train (Epoch 179): Loss/seq after 02850 batchs: 360.0918273925781
INFO:root:Train (Epoch 179): Loss/seq after 02900 batchs: 360.697265625
INFO:root:Train (Epoch 179): Loss/seq after 02950 batchs: 361.447509765625
INFO:root:Train (Epoch 179): Loss/seq after 03000 batchs: 367.34576416015625
INFO:root:Train (Epoch 179): Loss/seq after 03050 batchs: 369.4889831542969
INFO:root:Train (Epoch 179): Loss/seq after 03100 batchs: 370.9292907714844
INFO:root:Train (Epoch 179): Loss/seq after 03150 batchs: 369.9679260253906
INFO:root:Train (Epoch 179): Loss/seq after 03200 batchs: 369.1744689941406
INFO:root:Train (Epoch 179): Loss/seq after 03250 batchs: 368.0711669921875
INFO:root:Train (Epoch 179): Loss/seq after 03300 batchs: 367.611328125
INFO:root:Train (Epoch 179): Loss/seq after 03350 batchs: 365.2886962890625
INFO:root:Train (Epoch 179): Loss/seq after 03400 batchs: 362.6325988769531
INFO:root:Train (Epoch 179): Loss/seq after 03450 batchs: 360.947021484375
INFO:root:Train (Epoch 179): Loss/seq after 03500 batchs: 362.1239929199219
INFO:root:Train (Epoch 179): Loss/seq after 03550 batchs: 360.8262634277344
INFO:root:Train (Epoch 179): Loss/seq after 03600 batchs: 366.8221130371094
INFO:root:Train (Epoch 179): Loss/seq after 03650 batchs: 365.7485656738281
INFO:root:Train (Epoch 179): Loss/seq after 03700 batchs: 368.8131408691406
INFO:root:Train (Epoch 179): Loss/seq after 03750 batchs: 373.4135437011719
INFO:root:Train (Epoch 179): Loss/seq after 03800 batchs: 373.0801696777344
INFO:root:Train (Epoch 179): Loss/seq after 03850 batchs: 372.749267578125
INFO:root:Train (Epoch 179): Loss/seq after 03900 batchs: 374.23199462890625
INFO:root:Train (Epoch 179): Loss/seq after 03950 batchs: 376.2313537597656
INFO:root:Train (Epoch 179): Loss/seq after 04000 batchs: 374.3152770996094
INFO:root:Train (Epoch 179): Loss/seq after 04050 batchs: 372.0851135253906
INFO:root:Train (Epoch 179): Loss/seq after 04100 batchs: 371.6694641113281
INFO:root:Train (Epoch 179): Loss/seq after 04150 batchs: 372.06439208984375
INFO:root:Train (Epoch 179): Loss/seq after 04200 batchs: 371.2496032714844
INFO:root:Train (Epoch 179): Loss/seq after 04250 batchs: 370.1459655761719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 179): Loss/seq after 00000 batches: 306.5136413574219
INFO:root:# Valid (Epoch 179): Loss/seq after 00050 batches: 597.7784423828125
INFO:root:# Valid (Epoch 179): Loss/seq after 00100 batches: 582.3273315429688
INFO:root:# Valid (Epoch 179): Loss/seq after 00150 batches: 451.32818603515625
INFO:root:# Valid (Epoch 179): Loss/seq after 00200 batches: 424.9493408203125
INFO:root:Artifacts: Make stick videos for epoch 179
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_179_on_20220422_141133.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_179_index_1903_on_20220422_141133.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 180): Loss/seq after 00000 batchs: 655.6485595703125
INFO:root:Train (Epoch 180): Loss/seq after 00050 batchs: 520.2361450195312
INFO:root:Train (Epoch 180): Loss/seq after 00100 batchs: 512.380126953125
INFO:root:Train (Epoch 180): Loss/seq after 00150 batchs: 483.13037109375
INFO:root:Train (Epoch 180): Loss/seq after 00200 batchs: 529.4530639648438
INFO:root:Train (Epoch 180): Loss/seq after 00250 batchs: 588.1502685546875
INFO:root:Train (Epoch 180): Loss/seq after 00300 batchs: 602.9131469726562
INFO:root:Train (Epoch 180): Loss/seq after 00350 batchs: 574.0509033203125
INFO:root:Train (Epoch 180): Loss/seq after 00400 batchs: 563.88916015625
INFO:root:Train (Epoch 180): Loss/seq after 00450 batchs: 570.7391357421875
INFO:root:Train (Epoch 180): Loss/seq after 00500 batchs: 552.341796875
INFO:root:Train (Epoch 180): Loss/seq after 00550 batchs: 542.1299438476562
INFO:root:Train (Epoch 180): Loss/seq after 00600 batchs: 525.9838256835938
INFO:root:Train (Epoch 180): Loss/seq after 00650 batchs: 503.648193359375
INFO:root:Train (Epoch 180): Loss/seq after 00700 batchs: 479.8517761230469
INFO:root:Train (Epoch 180): Loss/seq after 00750 batchs: 467.5105895996094
INFO:root:Train (Epoch 180): Loss/seq after 00800 batchs: 472.2059020996094
INFO:root:Train (Epoch 180): Loss/seq after 00850 batchs: 456.506591796875
INFO:root:Train (Epoch 180): Loss/seq after 00900 batchs: 445.0459289550781
INFO:root:Train (Epoch 180): Loss/seq after 00950 batchs: 440.18310546875
INFO:root:Train (Epoch 180): Loss/seq after 01000 batchs: 430.85345458984375
INFO:root:Train (Epoch 180): Loss/seq after 01050 batchs: 422.9019775390625
INFO:root:Train (Epoch 180): Loss/seq after 01100 batchs: 413.6990661621094
INFO:root:Train (Epoch 180): Loss/seq after 01150 batchs: 401.8829345703125
INFO:root:Train (Epoch 180): Loss/seq after 01200 batchs: 405.4658203125
INFO:root:Train (Epoch 180): Loss/seq after 01250 batchs: 405.5372619628906
INFO:root:Train (Epoch 180): Loss/seq after 01300 batchs: 395.3558654785156
INFO:root:Train (Epoch 180): Loss/seq after 01350 batchs: 385.9695129394531
INFO:root:Train (Epoch 180): Loss/seq after 01400 batchs: 385.71746826171875
INFO:root:Train (Epoch 180): Loss/seq after 01450 batchs: 389.3411865234375
INFO:root:Train (Epoch 180): Loss/seq after 01500 batchs: 396.68231201171875
INFO:root:Train (Epoch 180): Loss/seq after 01550 batchs: 397.78765869140625
INFO:root:Train (Epoch 180): Loss/seq after 01600 batchs: 395.1923828125
INFO:root:Train (Epoch 180): Loss/seq after 01650 batchs: 394.3426513671875
INFO:root:Train (Epoch 180): Loss/seq after 01700 batchs: 399.5800476074219
INFO:root:Train (Epoch 180): Loss/seq after 01750 batchs: 398.3337707519531
INFO:root:Train (Epoch 180): Loss/seq after 01800 batchs: 396.9869689941406
INFO:root:Train (Epoch 180): Loss/seq after 01850 batchs: 395.25909423828125
INFO:root:Train (Epoch 180): Loss/seq after 01900 batchs: 394.79620361328125
INFO:root:Train (Epoch 180): Loss/seq after 01950 batchs: 394.6103515625
INFO:root:Train (Epoch 180): Loss/seq after 02000 batchs: 396.0002746582031
INFO:root:Train (Epoch 180): Loss/seq after 02050 batchs: 396.3724365234375
INFO:root:Train (Epoch 180): Loss/seq after 02100 batchs: 395.51287841796875
INFO:root:Train (Epoch 180): Loss/seq after 02150 batchs: 395.1077880859375
INFO:root:Train (Epoch 180): Loss/seq after 02200 batchs: 394.4476318359375
INFO:root:Train (Epoch 180): Loss/seq after 02250 batchs: 393.20745849609375
INFO:root:Train (Epoch 180): Loss/seq after 02300 batchs: 389.58990478515625
INFO:root:Train (Epoch 180): Loss/seq after 02350 batchs: 387.2698669433594
INFO:root:Train (Epoch 180): Loss/seq after 02400 batchs: 388.1321105957031
INFO:root:Train (Epoch 180): Loss/seq after 02450 batchs: 385.45452880859375
INFO:root:Train (Epoch 180): Loss/seq after 02500 batchs: 379.2598571777344
INFO:root:Train (Epoch 180): Loss/seq after 02550 batchs: 373.5124206542969
INFO:root:Train (Epoch 180): Loss/seq after 02600 batchs: 369.38055419921875
INFO:root:Train (Epoch 180): Loss/seq after 02650 batchs: 365.420654296875
INFO:root:Train (Epoch 180): Loss/seq after 02700 batchs: 362.5781555175781
INFO:root:Train (Epoch 180): Loss/seq after 02750 batchs: 358.2573547363281
INFO:root:Train (Epoch 180): Loss/seq after 02800 batchs: 355.798583984375
INFO:root:Train (Epoch 180): Loss/seq after 02850 batchs: 355.4707336425781
INFO:root:Train (Epoch 180): Loss/seq after 02900 batchs: 355.9324035644531
INFO:root:Train (Epoch 180): Loss/seq after 02950 batchs: 356.6775207519531
INFO:root:Train (Epoch 180): Loss/seq after 03000 batchs: 362.6343078613281
INFO:root:Train (Epoch 180): Loss/seq after 03050 batchs: 364.8428955078125
INFO:root:Train (Epoch 180): Loss/seq after 03100 batchs: 366.81109619140625
INFO:root:Train (Epoch 180): Loss/seq after 03150 batchs: 365.6946716308594
INFO:root:Train (Epoch 180): Loss/seq after 03200 batchs: 365.1691589355469
INFO:root:Train (Epoch 180): Loss/seq after 03250 batchs: 364.51580810546875
INFO:root:Train (Epoch 180): Loss/seq after 03300 batchs: 363.5819091796875
INFO:root:Train (Epoch 180): Loss/seq after 03350 batchs: 361.3514404296875
INFO:root:Train (Epoch 180): Loss/seq after 03400 batchs: 358.6886901855469
INFO:root:Train (Epoch 180): Loss/seq after 03450 batchs: 356.9592590332031
INFO:root:Train (Epoch 180): Loss/seq after 03500 batchs: 357.816162109375
INFO:root:Train (Epoch 180): Loss/seq after 03550 batchs: 356.277587890625
INFO:root:Train (Epoch 180): Loss/seq after 03600 batchs: 362.0232238769531
INFO:root:Train (Epoch 180): Loss/seq after 03650 batchs: 360.8283996582031
INFO:root:Train (Epoch 180): Loss/seq after 03700 batchs: 363.49456787109375
INFO:root:Train (Epoch 180): Loss/seq after 03750 batchs: 368.1422424316406
INFO:root:Train (Epoch 180): Loss/seq after 03800 batchs: 367.8896789550781
INFO:root:Train (Epoch 180): Loss/seq after 03850 batchs: 367.42706298828125
INFO:root:Train (Epoch 180): Loss/seq after 03900 batchs: 368.4123840332031
INFO:root:Train (Epoch 180): Loss/seq after 03950 batchs: 369.8006591796875
INFO:root:Train (Epoch 180): Loss/seq after 04000 batchs: 367.7716064453125
INFO:root:Train (Epoch 180): Loss/seq after 04050 batchs: 365.55230712890625
INFO:root:Train (Epoch 180): Loss/seq after 04100 batchs: 365.1573181152344
INFO:root:Train (Epoch 180): Loss/seq after 04150 batchs: 365.55169677734375
INFO:root:Train (Epoch 180): Loss/seq after 04200 batchs: 364.71502685546875
INFO:root:Train (Epoch 180): Loss/seq after 04250 batchs: 363.5189514160156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 180): Loss/seq after 00000 batches: 261.82293701171875
INFO:root:# Valid (Epoch 180): Loss/seq after 00050 batches: 602.38330078125
INFO:root:# Valid (Epoch 180): Loss/seq after 00100 batches: 574.2543334960938
INFO:root:# Valid (Epoch 180): Loss/seq after 00150 batches: 437.218994140625
INFO:root:# Valid (Epoch 180): Loss/seq after 00200 batches: 411.161376953125
INFO:root:Artifacts: Make stick videos for epoch 180
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_180_on_20220422_141618.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_180_index_16_on_20220422_141618.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 181): Loss/seq after 00000 batchs: 512.2471313476562
INFO:root:Train (Epoch 181): Loss/seq after 00050 batchs: 492.0965576171875
INFO:root:Train (Epoch 181): Loss/seq after 00100 batchs: 504.48553466796875
INFO:root:Train (Epoch 181): Loss/seq after 00150 batchs: 477.9311828613281
INFO:root:Train (Epoch 181): Loss/seq after 00200 batchs: 519.73779296875
INFO:root:Train (Epoch 181): Loss/seq after 00250 batchs: 574.7650756835938
INFO:root:Train (Epoch 181): Loss/seq after 00300 batchs: 591.7630004882812
INFO:root:Train (Epoch 181): Loss/seq after 00350 batchs: 561.8290405273438
INFO:root:Train (Epoch 181): Loss/seq after 00400 batchs: 547.8975219726562
INFO:root:Train (Epoch 181): Loss/seq after 00450 batchs: 556.5987548828125
INFO:root:Train (Epoch 181): Loss/seq after 00500 batchs: 539.0807495117188
INFO:root:Train (Epoch 181): Loss/seq after 00550 batchs: 529.5780029296875
INFO:root:Train (Epoch 181): Loss/seq after 00600 batchs: 513.9342651367188
INFO:root:Train (Epoch 181): Loss/seq after 00650 batchs: 491.28387451171875
INFO:root:Train (Epoch 181): Loss/seq after 00700 batchs: 468.3796081542969
INFO:root:Train (Epoch 181): Loss/seq after 00750 batchs: 455.47552490234375
INFO:root:Train (Epoch 181): Loss/seq after 00800 batchs: 462.30731201171875
INFO:root:Train (Epoch 181): Loss/seq after 00850 batchs: 447.6668395996094
INFO:root:Train (Epoch 181): Loss/seq after 00900 batchs: 436.3135986328125
INFO:root:Train (Epoch 181): Loss/seq after 00950 batchs: 432.156982421875
INFO:root:Train (Epoch 181): Loss/seq after 01000 batchs: 423.65228271484375
INFO:root:Train (Epoch 181): Loss/seq after 01050 batchs: 415.6500549316406
INFO:root:Train (Epoch 181): Loss/seq after 01100 batchs: 407.05035400390625
INFO:root:Train (Epoch 181): Loss/seq after 01150 batchs: 395.59454345703125
INFO:root:Train (Epoch 181): Loss/seq after 01200 batchs: 399.8583679199219
INFO:root:Train (Epoch 181): Loss/seq after 01250 batchs: 400.0055847167969
INFO:root:Train (Epoch 181): Loss/seq after 01300 batchs: 390.5199890136719
INFO:root:Train (Epoch 181): Loss/seq after 01350 batchs: 381.4584045410156
INFO:root:Train (Epoch 181): Loss/seq after 01400 batchs: 381.7154541015625
INFO:root:Train (Epoch 181): Loss/seq after 01450 batchs: 385.6460266113281
INFO:root:Train (Epoch 181): Loss/seq after 01500 batchs: 392.8794250488281
INFO:root:Train (Epoch 181): Loss/seq after 01550 batchs: 393.4395751953125
INFO:root:Train (Epoch 181): Loss/seq after 01600 batchs: 391.052001953125
INFO:root:Train (Epoch 181): Loss/seq after 01650 batchs: 390.6767578125
INFO:root:Train (Epoch 181): Loss/seq after 01700 batchs: 395.75347900390625
INFO:root:Train (Epoch 181): Loss/seq after 01750 batchs: 394.67730712890625
INFO:root:Train (Epoch 181): Loss/seq after 01800 batchs: 393.5953369140625
INFO:root:Train (Epoch 181): Loss/seq after 01850 batchs: 392.00787353515625
INFO:root:Train (Epoch 181): Loss/seq after 01900 batchs: 391.57000732421875
INFO:root:Train (Epoch 181): Loss/seq after 01950 batchs: 391.4484558105469
INFO:root:Train (Epoch 181): Loss/seq after 02000 batchs: 392.8651428222656
INFO:root:Train (Epoch 181): Loss/seq after 02050 batchs: 393.0863952636719
INFO:root:Train (Epoch 181): Loss/seq after 02100 batchs: 392.27899169921875
INFO:root:Train (Epoch 181): Loss/seq after 02150 batchs: 391.8192138671875
INFO:root:Train (Epoch 181): Loss/seq after 02200 batchs: 391.26470947265625
INFO:root:Train (Epoch 181): Loss/seq after 02250 batchs: 390.6301574707031
INFO:root:Train (Epoch 181): Loss/seq after 02300 batchs: 387.56256103515625
INFO:root:Train (Epoch 181): Loss/seq after 02350 batchs: 385.6857604980469
INFO:root:Train (Epoch 181): Loss/seq after 02400 batchs: 386.5614929199219
INFO:root:Train (Epoch 181): Loss/seq after 02450 batchs: 384.0043640136719
INFO:root:Train (Epoch 181): Loss/seq after 02500 batchs: 377.9585876464844
INFO:root:Train (Epoch 181): Loss/seq after 02550 batchs: 372.2639465332031
INFO:root:Train (Epoch 181): Loss/seq after 02600 batchs: 368.2320556640625
INFO:root:Train (Epoch 181): Loss/seq after 02650 batchs: 364.265380859375
INFO:root:Train (Epoch 181): Loss/seq after 02700 batchs: 361.572998046875
INFO:root:Train (Epoch 181): Loss/seq after 02750 batchs: 357.48822021484375
INFO:root:Train (Epoch 181): Loss/seq after 02800 batchs: 355.3073425292969
INFO:root:Train (Epoch 181): Loss/seq after 02850 batchs: 355.0306091308594
INFO:root:Train (Epoch 181): Loss/seq after 02900 batchs: 355.6591796875
INFO:root:Train (Epoch 181): Loss/seq after 02950 batchs: 356.36199951171875
INFO:root:Train (Epoch 181): Loss/seq after 03000 batchs: 362.2923583984375
INFO:root:Train (Epoch 181): Loss/seq after 03050 batchs: 364.2770080566406
INFO:root:Train (Epoch 181): Loss/seq after 03100 batchs: 365.41851806640625
INFO:root:Train (Epoch 181): Loss/seq after 03150 batchs: 364.41278076171875
INFO:root:Train (Epoch 181): Loss/seq after 03200 batchs: 363.718994140625
INFO:root:Train (Epoch 181): Loss/seq after 03250 batchs: 362.547607421875
INFO:root:Train (Epoch 181): Loss/seq after 03300 batchs: 361.55133056640625
INFO:root:Train (Epoch 181): Loss/seq after 03350 batchs: 359.3124694824219
INFO:root:Train (Epoch 181): Loss/seq after 03400 batchs: 356.7158508300781
INFO:root:Train (Epoch 181): Loss/seq after 03450 batchs: 354.98931884765625
INFO:root:Train (Epoch 181): Loss/seq after 03500 batchs: 355.80499267578125
INFO:root:Train (Epoch 181): Loss/seq after 03550 batchs: 354.41290283203125
INFO:root:Train (Epoch 181): Loss/seq after 03600 batchs: 360.14361572265625
INFO:root:Train (Epoch 181): Loss/seq after 03650 batchs: 359.091796875
INFO:root:Train (Epoch 181): Loss/seq after 03700 batchs: 361.734375
INFO:root:Train (Epoch 181): Loss/seq after 03750 batchs: 366.4720764160156
INFO:root:Train (Epoch 181): Loss/seq after 03800 batchs: 366.2176208496094
INFO:root:Train (Epoch 181): Loss/seq after 03850 batchs: 365.7479553222656
INFO:root:Train (Epoch 181): Loss/seq after 03900 batchs: 366.8980407714844
INFO:root:Train (Epoch 181): Loss/seq after 03950 batchs: 368.9412536621094
INFO:root:Train (Epoch 181): Loss/seq after 04000 batchs: 367.1050720214844
INFO:root:Train (Epoch 181): Loss/seq after 04050 batchs: 364.9316711425781
INFO:root:Train (Epoch 181): Loss/seq after 04100 batchs: 364.5688781738281
INFO:root:Train (Epoch 181): Loss/seq after 04150 batchs: 365.1197814941406
INFO:root:Train (Epoch 181): Loss/seq after 04200 batchs: 364.3746643066406
INFO:root:Train (Epoch 181): Loss/seq after 04250 batchs: 363.3817138671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 181): Loss/seq after 00000 batches: 261.2060852050781
INFO:root:# Valid (Epoch 181): Loss/seq after 00050 batches: 600.5100708007812
INFO:root:# Valid (Epoch 181): Loss/seq after 00100 batches: 578.1785278320312
INFO:root:# Valid (Epoch 181): Loss/seq after 00150 batches: 439.9940490722656
INFO:root:# Valid (Epoch 181): Loss/seq after 00200 batches: 416.09619140625
INFO:root:Artifacts: Make stick videos for epoch 181
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_181_on_20220422_142109.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_181_index_1022_on_20220422_142109.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 182): Loss/seq after 00000 batchs: 559.5391235351562
INFO:root:Train (Epoch 182): Loss/seq after 00050 batchs: 505.78778076171875
INFO:root:Train (Epoch 182): Loss/seq after 00100 batchs: 501.21343994140625
INFO:root:Train (Epoch 182): Loss/seq after 00150 batchs: 476.2162780761719
INFO:root:Train (Epoch 182): Loss/seq after 00200 batchs: 518.75732421875
INFO:root:Train (Epoch 182): Loss/seq after 00250 batchs: 577.6243896484375
INFO:root:Train (Epoch 182): Loss/seq after 00300 batchs: 591.2755737304688
INFO:root:Train (Epoch 182): Loss/seq after 00350 batchs: 561.3336181640625
INFO:root:Train (Epoch 182): Loss/seq after 00400 batchs: 546.7935180664062
INFO:root:Train (Epoch 182): Loss/seq after 00450 batchs: 554.8524780273438
INFO:root:Train (Epoch 182): Loss/seq after 00500 batchs: 533.6392211914062
INFO:root:Train (Epoch 182): Loss/seq after 00550 batchs: 524.043701171875
INFO:root:Train (Epoch 182): Loss/seq after 00600 batchs: 508.8614807128906
INFO:root:Train (Epoch 182): Loss/seq after 00650 batchs: 487.8779296875
INFO:root:Train (Epoch 182): Loss/seq after 00700 batchs: 466.0671081542969
INFO:root:Train (Epoch 182): Loss/seq after 00750 batchs: 455.8517150878906
INFO:root:Train (Epoch 182): Loss/seq after 00800 batchs: 461.2460632324219
INFO:root:Train (Epoch 182): Loss/seq after 00850 batchs: 446.2767333984375
INFO:root:Train (Epoch 182): Loss/seq after 00900 batchs: 434.9903259277344
INFO:root:Train (Epoch 182): Loss/seq after 00950 batchs: 431.6651916503906
INFO:root:Train (Epoch 182): Loss/seq after 01000 batchs: 422.7892150878906
INFO:root:Train (Epoch 182): Loss/seq after 01050 batchs: 415.2161560058594
INFO:root:Train (Epoch 182): Loss/seq after 01100 batchs: 407.1806945800781
INFO:root:Train (Epoch 182): Loss/seq after 01150 batchs: 395.7927551269531
INFO:root:Train (Epoch 182): Loss/seq after 01200 batchs: 399.80029296875
INFO:root:Train (Epoch 182): Loss/seq after 01250 batchs: 399.65045166015625
INFO:root:Train (Epoch 182): Loss/seq after 01300 batchs: 389.9151916503906
INFO:root:Train (Epoch 182): Loss/seq after 01350 batchs: 380.84478759765625
INFO:root:Train (Epoch 182): Loss/seq after 01400 batchs: 381.27838134765625
INFO:root:Train (Epoch 182): Loss/seq after 01450 batchs: 385.07696533203125
INFO:root:Train (Epoch 182): Loss/seq after 01500 batchs: 393.021240234375
INFO:root:Train (Epoch 182): Loss/seq after 01550 batchs: 394.0606689453125
INFO:root:Train (Epoch 182): Loss/seq after 01600 batchs: 392.0389404296875
INFO:root:Train (Epoch 182): Loss/seq after 01650 batchs: 391.1514892578125
INFO:root:Train (Epoch 182): Loss/seq after 01700 batchs: 396.2543640136719
INFO:root:Train (Epoch 182): Loss/seq after 01750 batchs: 394.76953125
INFO:root:Train (Epoch 182): Loss/seq after 01800 batchs: 393.5139465332031
INFO:root:Train (Epoch 182): Loss/seq after 01850 batchs: 391.8070068359375
INFO:root:Train (Epoch 182): Loss/seq after 01900 batchs: 391.07928466796875
INFO:root:Train (Epoch 182): Loss/seq after 01950 batchs: 390.8735046386719
INFO:root:Train (Epoch 182): Loss/seq after 02000 batchs: 392.22161865234375
INFO:root:Train (Epoch 182): Loss/seq after 02050 batchs: 392.48175048828125
INFO:root:Train (Epoch 182): Loss/seq after 02100 batchs: 391.683837890625
INFO:root:Train (Epoch 182): Loss/seq after 02150 batchs: 391.1556091308594
INFO:root:Train (Epoch 182): Loss/seq after 02200 batchs: 390.5274658203125
INFO:root:Train (Epoch 182): Loss/seq after 02250 batchs: 389.6051940917969
INFO:root:Train (Epoch 182): Loss/seq after 02300 batchs: 386.48321533203125
INFO:root:Train (Epoch 182): Loss/seq after 02350 batchs: 384.2018127441406
INFO:root:Train (Epoch 182): Loss/seq after 02400 batchs: 384.83074951171875
INFO:root:Train (Epoch 182): Loss/seq after 02450 batchs: 382.12982177734375
INFO:root:Train (Epoch 182): Loss/seq after 02500 batchs: 376.00048828125
INFO:root:Train (Epoch 182): Loss/seq after 02550 batchs: 370.2535400390625
INFO:root:Train (Epoch 182): Loss/seq after 02600 batchs: 365.9677734375
INFO:root:Train (Epoch 182): Loss/seq after 02650 batchs: 362.00396728515625
INFO:root:Train (Epoch 182): Loss/seq after 02700 batchs: 359.1884765625
INFO:root:Train (Epoch 182): Loss/seq after 02750 batchs: 354.9242248535156
INFO:root:Train (Epoch 182): Loss/seq after 02800 batchs: 352.5799865722656
INFO:root:Train (Epoch 182): Loss/seq after 02850 batchs: 352.16851806640625
INFO:root:Train (Epoch 182): Loss/seq after 02900 batchs: 352.71795654296875
INFO:root:Train (Epoch 182): Loss/seq after 02950 batchs: 353.45306396484375
INFO:root:Train (Epoch 182): Loss/seq after 03000 batchs: 359.1425476074219
INFO:root:Train (Epoch 182): Loss/seq after 03050 batchs: 360.9471130371094
INFO:root:Train (Epoch 182): Loss/seq after 03100 batchs: 362.2171630859375
INFO:root:Train (Epoch 182): Loss/seq after 03150 batchs: 361.6089172363281
INFO:root:Train (Epoch 182): Loss/seq after 03200 batchs: 361.0618591308594
INFO:root:Train (Epoch 182): Loss/seq after 03250 batchs: 360.1577453613281
INFO:root:Train (Epoch 182): Loss/seq after 03300 batchs: 359.4016418457031
INFO:root:Train (Epoch 182): Loss/seq after 03350 batchs: 357.503173828125
INFO:root:Train (Epoch 182): Loss/seq after 03400 batchs: 354.9951171875
INFO:root:Train (Epoch 182): Loss/seq after 03450 batchs: 353.3385009765625
INFO:root:Train (Epoch 182): Loss/seq after 03500 batchs: 354.3526916503906
INFO:root:Train (Epoch 182): Loss/seq after 03550 batchs: 352.9488220214844
INFO:root:Train (Epoch 182): Loss/seq after 03600 batchs: 358.7237854003906
INFO:root:Train (Epoch 182): Loss/seq after 03650 batchs: 357.8205871582031
INFO:root:Train (Epoch 182): Loss/seq after 03700 batchs: 360.47998046875
INFO:root:Train (Epoch 182): Loss/seq after 03750 batchs: 365.0302734375
INFO:root:Train (Epoch 182): Loss/seq after 03800 batchs: 364.83099365234375
INFO:root:Train (Epoch 182): Loss/seq after 03850 batchs: 364.407958984375
INFO:root:Train (Epoch 182): Loss/seq after 03900 batchs: 365.5013427734375
INFO:root:Train (Epoch 182): Loss/seq after 03950 batchs: 367.4368591308594
INFO:root:Train (Epoch 182): Loss/seq after 04000 batchs: 365.4199523925781
INFO:root:Train (Epoch 182): Loss/seq after 04050 batchs: 363.2066650390625
INFO:root:Train (Epoch 182): Loss/seq after 04100 batchs: 362.8472900390625
INFO:root:Train (Epoch 182): Loss/seq after 04150 batchs: 363.2054138183594
INFO:root:Train (Epoch 182): Loss/seq after 04200 batchs: 362.399658203125
INFO:root:Train (Epoch 182): Loss/seq after 04250 batchs: 361.2337646484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 182): Loss/seq after 00000 batches: 287.9511413574219
INFO:root:# Valid (Epoch 182): Loss/seq after 00050 batches: 634.2313842773438
INFO:root:# Valid (Epoch 182): Loss/seq after 00100 batches: 616.1453247070312
INFO:root:# Valid (Epoch 182): Loss/seq after 00150 batches: 471.2933654785156
INFO:root:# Valid (Epoch 182): Loss/seq after 00200 batches: 442.2099304199219
INFO:root:Artifacts: Make stick videos for epoch 182
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_182_on_20220422_142610.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_182_index_1478_on_20220422_142610.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 183): Loss/seq after 00000 batchs: 531.7957153320312
INFO:root:Train (Epoch 183): Loss/seq after 00050 batchs: 481.14508056640625
INFO:root:Train (Epoch 183): Loss/seq after 00100 batchs: 493.5591125488281
INFO:root:Train (Epoch 183): Loss/seq after 00150 batchs: 469.9744873046875
INFO:root:Train (Epoch 183): Loss/seq after 00200 batchs: 510.4283447265625
INFO:root:Train (Epoch 183): Loss/seq after 00250 batchs: 569.205810546875
INFO:root:Train (Epoch 183): Loss/seq after 00300 batchs: 586.3990478515625
INFO:root:Train (Epoch 183): Loss/seq after 00350 batchs: 557.64794921875
INFO:root:Train (Epoch 183): Loss/seq after 00400 batchs: 545.6648559570312
INFO:root:Train (Epoch 183): Loss/seq after 00450 batchs: 554.1632690429688
INFO:root:Train (Epoch 183): Loss/seq after 00500 batchs: 537.5108642578125
INFO:root:Train (Epoch 183): Loss/seq after 00550 batchs: 530.8818969726562
INFO:root:Train (Epoch 183): Loss/seq after 00600 batchs: 515.7862548828125
INFO:root:Train (Epoch 183): Loss/seq after 00650 batchs: 494.4056396484375
INFO:root:Train (Epoch 183): Loss/seq after 00700 batchs: 471.97271728515625
INFO:root:Train (Epoch 183): Loss/seq after 00750 batchs: 461.27178955078125
INFO:root:Train (Epoch 183): Loss/seq after 00800 batchs: 467.4845275878906
INFO:root:Train (Epoch 183): Loss/seq after 00850 batchs: 452.4175109863281
INFO:root:Train (Epoch 183): Loss/seq after 00900 batchs: 440.8896179199219
INFO:root:Train (Epoch 183): Loss/seq after 00950 batchs: 436.5560607910156
INFO:root:Train (Epoch 183): Loss/seq after 01000 batchs: 427.4259338378906
INFO:root:Train (Epoch 183): Loss/seq after 01050 batchs: 420.2961730957031
INFO:root:Train (Epoch 183): Loss/seq after 01100 batchs: 411.9969177246094
INFO:root:Train (Epoch 183): Loss/seq after 01150 batchs: 400.54534912109375
INFO:root:Train (Epoch 183): Loss/seq after 01200 batchs: 405.37847900390625
INFO:root:Train (Epoch 183): Loss/seq after 01250 batchs: 405.0219421386719
INFO:root:Train (Epoch 183): Loss/seq after 01300 batchs: 394.7099914550781
INFO:root:Train (Epoch 183): Loss/seq after 01350 batchs: 385.373779296875
INFO:root:Train (Epoch 183): Loss/seq after 01400 batchs: 385.3852233886719
INFO:root:Train (Epoch 183): Loss/seq after 01450 batchs: 388.9501037597656
INFO:root:Train (Epoch 183): Loss/seq after 01500 batchs: 395.54632568359375
INFO:root:Train (Epoch 183): Loss/seq after 01550 batchs: 396.5625
INFO:root:Train (Epoch 183): Loss/seq after 01600 batchs: 394.4667053222656
INFO:root:Train (Epoch 183): Loss/seq after 01650 batchs: 393.6678466796875
INFO:root:Train (Epoch 183): Loss/seq after 01700 batchs: 398.6004943847656
INFO:root:Train (Epoch 183): Loss/seq after 01750 batchs: 397.3992614746094
INFO:root:Train (Epoch 183): Loss/seq after 01800 batchs: 396.0655517578125
INFO:root:Train (Epoch 183): Loss/seq after 01850 batchs: 394.3774108886719
INFO:root:Train (Epoch 183): Loss/seq after 01900 batchs: 393.76995849609375
INFO:root:Train (Epoch 183): Loss/seq after 01950 batchs: 393.4747314453125
INFO:root:Train (Epoch 183): Loss/seq after 02000 batchs: 394.6512756347656
INFO:root:Train (Epoch 183): Loss/seq after 02050 batchs: 394.9256591796875
INFO:root:Train (Epoch 183): Loss/seq after 02100 batchs: 394.08251953125
INFO:root:Train (Epoch 183): Loss/seq after 02150 batchs: 393.460693359375
INFO:root:Train (Epoch 183): Loss/seq after 02200 batchs: 392.6888732910156
INFO:root:Train (Epoch 183): Loss/seq after 02250 batchs: 391.44622802734375
INFO:root:Train (Epoch 183): Loss/seq after 02300 batchs: 387.88592529296875
INFO:root:Train (Epoch 183): Loss/seq after 02350 batchs: 385.6968688964844
INFO:root:Train (Epoch 183): Loss/seq after 02400 batchs: 386.5345458984375
INFO:root:Train (Epoch 183): Loss/seq after 02450 batchs: 383.7785339355469
INFO:root:Train (Epoch 183): Loss/seq after 02500 batchs: 377.5893859863281
INFO:root:Train (Epoch 183): Loss/seq after 02550 batchs: 371.86993408203125
INFO:root:Train (Epoch 183): Loss/seq after 02600 batchs: 367.69805908203125
INFO:root:Train (Epoch 183): Loss/seq after 02650 batchs: 363.6716003417969
INFO:root:Train (Epoch 183): Loss/seq after 02700 batchs: 360.8764343261719
INFO:root:Train (Epoch 183): Loss/seq after 02750 batchs: 356.7810363769531
INFO:root:Train (Epoch 183): Loss/seq after 02800 batchs: 354.8624267578125
INFO:root:Train (Epoch 183): Loss/seq after 02850 batchs: 354.37255859375
INFO:root:Train (Epoch 183): Loss/seq after 02900 batchs: 354.8927917480469
INFO:root:Train (Epoch 183): Loss/seq after 02950 batchs: 355.62261962890625
INFO:root:Train (Epoch 183): Loss/seq after 03000 batchs: 361.3412170410156
INFO:root:Train (Epoch 183): Loss/seq after 03050 batchs: 363.2402648925781
INFO:root:Train (Epoch 183): Loss/seq after 03100 batchs: 364.6289367675781
INFO:root:Train (Epoch 183): Loss/seq after 03150 batchs: 363.4864501953125
INFO:root:Train (Epoch 183): Loss/seq after 03200 batchs: 363.051513671875
INFO:root:Train (Epoch 183): Loss/seq after 03250 batchs: 362.52239990234375
INFO:root:Train (Epoch 183): Loss/seq after 03300 batchs: 361.6475830078125
INFO:root:Train (Epoch 183): Loss/seq after 03350 batchs: 359.69073486328125
INFO:root:Train (Epoch 183): Loss/seq after 03400 batchs: 357.0323181152344
INFO:root:Train (Epoch 183): Loss/seq after 03450 batchs: 355.35687255859375
INFO:root:Train (Epoch 183): Loss/seq after 03500 batchs: 356.24908447265625
INFO:root:Train (Epoch 183): Loss/seq after 03550 batchs: 354.8223571777344
INFO:root:Train (Epoch 183): Loss/seq after 03600 batchs: 360.5801696777344
INFO:root:Train (Epoch 183): Loss/seq after 03650 batchs: 359.84283447265625
INFO:root:Train (Epoch 183): Loss/seq after 03700 batchs: 362.1406555175781
INFO:root:Train (Epoch 183): Loss/seq after 03750 batchs: 366.7342224121094
INFO:root:Train (Epoch 183): Loss/seq after 03800 batchs: 366.4549865722656
INFO:root:Train (Epoch 183): Loss/seq after 03850 batchs: 365.95135498046875
INFO:root:Train (Epoch 183): Loss/seq after 03900 batchs: 367.62091064453125
INFO:root:Train (Epoch 183): Loss/seq after 03950 batchs: 369.64080810546875
INFO:root:Train (Epoch 183): Loss/seq after 04000 batchs: 367.65625
INFO:root:Train (Epoch 183): Loss/seq after 04050 batchs: 365.47412109375
INFO:root:Train (Epoch 183): Loss/seq after 04100 batchs: 364.9927062988281
INFO:root:Train (Epoch 183): Loss/seq after 04150 batchs: 365.3806457519531
INFO:root:Train (Epoch 183): Loss/seq after 04200 batchs: 364.5646057128906
INFO:root:Train (Epoch 183): Loss/seq after 04250 batchs: 363.4130859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 183): Loss/seq after 00000 batches: 229.0106964111328
INFO:root:# Valid (Epoch 183): Loss/seq after 00050 batches: 600.1087646484375
INFO:root:# Valid (Epoch 183): Loss/seq after 00100 batches: 558.27001953125
INFO:root:# Valid (Epoch 183): Loss/seq after 00150 batches: 433.65582275390625
INFO:root:# Valid (Epoch 183): Loss/seq after 00200 batches: 408.0202941894531
INFO:root:Artifacts: Make stick videos for epoch 183
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_183_on_20220422_143057.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_183_index_163_on_20220422_143057.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 184): Loss/seq after 00000 batchs: 521.0719604492188
INFO:root:Train (Epoch 184): Loss/seq after 00050 batchs: 496.10009765625
INFO:root:Train (Epoch 184): Loss/seq after 00100 batchs: 482.4222412109375
INFO:root:Train (Epoch 184): Loss/seq after 00150 batchs: 459.9659423828125
INFO:root:Train (Epoch 184): Loss/seq after 00200 batchs: 501.0227966308594
INFO:root:Train (Epoch 184): Loss/seq after 00250 batchs: 538.5700073242188
INFO:root:Train (Epoch 184): Loss/seq after 00300 batchs: 558.630615234375
INFO:root:Train (Epoch 184): Loss/seq after 00350 batchs: 533.6681518554688
INFO:root:Train (Epoch 184): Loss/seq after 00400 batchs: 525.7866821289062
INFO:root:Train (Epoch 184): Loss/seq after 00450 batchs: 535.9435424804688
INFO:root:Train (Epoch 184): Loss/seq after 00500 batchs: 519.0809326171875
INFO:root:Train (Epoch 184): Loss/seq after 00550 batchs: 511.57763671875
INFO:root:Train (Epoch 184): Loss/seq after 00600 batchs: 496.5674743652344
INFO:root:Train (Epoch 184): Loss/seq after 00650 batchs: 474.7790832519531
INFO:root:Train (Epoch 184): Loss/seq after 00700 batchs: 454.6827087402344
INFO:root:Train (Epoch 184): Loss/seq after 00750 batchs: 443.9422302246094
INFO:root:Train (Epoch 184): Loss/seq after 00800 batchs: 449.2645568847656
INFO:root:Train (Epoch 184): Loss/seq after 00850 batchs: 434.7745666503906
INFO:root:Train (Epoch 184): Loss/seq after 00900 batchs: 424.2619934082031
INFO:root:Train (Epoch 184): Loss/seq after 00950 batchs: 420.7025146484375
INFO:root:Train (Epoch 184): Loss/seq after 01000 batchs: 412.5961608886719
INFO:root:Train (Epoch 184): Loss/seq after 01050 batchs: 404.48681640625
INFO:root:Train (Epoch 184): Loss/seq after 01100 batchs: 395.8309326171875
INFO:root:Train (Epoch 184): Loss/seq after 01150 batchs: 384.8506164550781
INFO:root:Train (Epoch 184): Loss/seq after 01200 batchs: 389.1083679199219
INFO:root:Train (Epoch 184): Loss/seq after 01250 batchs: 389.4620666503906
INFO:root:Train (Epoch 184): Loss/seq after 01300 batchs: 379.9638366699219
INFO:root:Train (Epoch 184): Loss/seq after 01350 batchs: 371.25103759765625
INFO:root:Train (Epoch 184): Loss/seq after 01400 batchs: 371.0755920410156
INFO:root:Train (Epoch 184): Loss/seq after 01450 batchs: 375.1092224121094
INFO:root:Train (Epoch 184): Loss/seq after 01500 batchs: 381.78778076171875
INFO:root:Train (Epoch 184): Loss/seq after 01550 batchs: 382.3619384765625
INFO:root:Train (Epoch 184): Loss/seq after 01600 batchs: 379.9763488769531
INFO:root:Train (Epoch 184): Loss/seq after 01650 batchs: 379.2078552246094
INFO:root:Train (Epoch 184): Loss/seq after 01700 batchs: 384.98382568359375
INFO:root:Train (Epoch 184): Loss/seq after 01750 batchs: 384.1417541503906
INFO:root:Train (Epoch 184): Loss/seq after 01800 batchs: 383.1404724121094
INFO:root:Train (Epoch 184): Loss/seq after 01850 batchs: 381.6685791015625
INFO:root:Train (Epoch 184): Loss/seq after 01900 batchs: 381.43731689453125
INFO:root:Train (Epoch 184): Loss/seq after 01950 batchs: 381.69744873046875
INFO:root:Train (Epoch 184): Loss/seq after 02000 batchs: 383.5615234375
INFO:root:Train (Epoch 184): Loss/seq after 02050 batchs: 384.0987243652344
INFO:root:Train (Epoch 184): Loss/seq after 02100 batchs: 383.52093505859375
INFO:root:Train (Epoch 184): Loss/seq after 02150 batchs: 383.3309020996094
INFO:root:Train (Epoch 184): Loss/seq after 02200 batchs: 382.8600769042969
INFO:root:Train (Epoch 184): Loss/seq after 02250 batchs: 381.8521423339844
INFO:root:Train (Epoch 184): Loss/seq after 02300 batchs: 378.4267272949219
INFO:root:Train (Epoch 184): Loss/seq after 02350 batchs: 376.38629150390625
INFO:root:Train (Epoch 184): Loss/seq after 02400 batchs: 377.17901611328125
INFO:root:Train (Epoch 184): Loss/seq after 02450 batchs: 374.7103271484375
INFO:root:Train (Epoch 184): Loss/seq after 02500 batchs: 368.6719055175781
INFO:root:Train (Epoch 184): Loss/seq after 02550 batchs: 363.1189270019531
INFO:root:Train (Epoch 184): Loss/seq after 02600 batchs: 359.1126708984375
INFO:root:Train (Epoch 184): Loss/seq after 02650 batchs: 355.2079162597656
INFO:root:Train (Epoch 184): Loss/seq after 02700 batchs: 352.5012512207031
INFO:root:Train (Epoch 184): Loss/seq after 02750 batchs: 348.53033447265625
INFO:root:Train (Epoch 184): Loss/seq after 02800 batchs: 347.61419677734375
INFO:root:Train (Epoch 184): Loss/seq after 02850 batchs: 347.4425048828125
INFO:root:Train (Epoch 184): Loss/seq after 02900 batchs: 347.9035339355469
INFO:root:Train (Epoch 184): Loss/seq after 02950 batchs: 348.8409729003906
INFO:root:Train (Epoch 184): Loss/seq after 03000 batchs: 354.6788635253906
INFO:root:Train (Epoch 184): Loss/seq after 03050 batchs: 356.63330078125
INFO:root:Train (Epoch 184): Loss/seq after 03100 batchs: 358.0892028808594
INFO:root:Train (Epoch 184): Loss/seq after 03150 batchs: 357.20318603515625
INFO:root:Train (Epoch 184): Loss/seq after 03200 batchs: 356.901611328125
INFO:root:Train (Epoch 184): Loss/seq after 03250 batchs: 356.0109558105469
INFO:root:Train (Epoch 184): Loss/seq after 03300 batchs: 355.2342224121094
INFO:root:Train (Epoch 184): Loss/seq after 03350 batchs: 353.07623291015625
INFO:root:Train (Epoch 184): Loss/seq after 03400 batchs: 350.5393981933594
INFO:root:Train (Epoch 184): Loss/seq after 03450 batchs: 348.914306640625
INFO:root:Train (Epoch 184): Loss/seq after 03500 batchs: 349.8298645019531
INFO:root:Train (Epoch 184): Loss/seq after 03550 batchs: 348.4680480957031
INFO:root:Train (Epoch 184): Loss/seq after 03600 batchs: 354.35821533203125
INFO:root:Train (Epoch 184): Loss/seq after 03650 batchs: 353.43280029296875
INFO:root:Train (Epoch 184): Loss/seq after 03700 batchs: 356.871826171875
INFO:root:Train (Epoch 184): Loss/seq after 03750 batchs: 361.6334228515625
INFO:root:Train (Epoch 184): Loss/seq after 03800 batchs: 361.39898681640625
INFO:root:Train (Epoch 184): Loss/seq after 03850 batchs: 361.01495361328125
INFO:root:Train (Epoch 184): Loss/seq after 03900 batchs: 362.245361328125
INFO:root:Train (Epoch 184): Loss/seq after 03950 batchs: 363.8140869140625
INFO:root:Train (Epoch 184): Loss/seq after 04000 batchs: 361.8726501464844
INFO:root:Train (Epoch 184): Loss/seq after 04050 batchs: 359.72454833984375
INFO:root:Train (Epoch 184): Loss/seq after 04100 batchs: 359.42706298828125
INFO:root:Train (Epoch 184): Loss/seq after 04150 batchs: 359.7498474121094
INFO:root:Train (Epoch 184): Loss/seq after 04200 batchs: 359.0843811035156
INFO:root:Train (Epoch 184): Loss/seq after 04250 batchs: 358.020263671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 184): Loss/seq after 00000 batches: 249.80474853515625
INFO:root:# Valid (Epoch 184): Loss/seq after 00050 batches: 634.9326171875
INFO:root:# Valid (Epoch 184): Loss/seq after 00100 batches: 600.4150390625
INFO:root:# Valid (Epoch 184): Loss/seq after 00150 batches: 461.0672607421875
INFO:root:# Valid (Epoch 184): Loss/seq after 00200 batches: 430.506591796875
INFO:root:Artifacts: Make stick videos for epoch 184
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_184_on_20220422_143547.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_184_index_1579_on_20220422_143547.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 185): Loss/seq after 00000 batchs: 476.17791748046875
INFO:root:Train (Epoch 185): Loss/seq after 00050 batchs: 471.92169189453125
INFO:root:Train (Epoch 185): Loss/seq after 00100 batchs: 483.061279296875
INFO:root:Train (Epoch 185): Loss/seq after 00150 batchs: 460.6513977050781
INFO:root:Train (Epoch 185): Loss/seq after 00200 batchs: 512.8104248046875
INFO:root:Train (Epoch 185): Loss/seq after 00250 batchs: 553.517822265625
INFO:root:Train (Epoch 185): Loss/seq after 00300 batchs: 577.7997436523438
INFO:root:Train (Epoch 185): Loss/seq after 00350 batchs: 548.2069702148438
INFO:root:Train (Epoch 185): Loss/seq after 00400 batchs: 531.7305297851562
INFO:root:Train (Epoch 185): Loss/seq after 00450 batchs: 541.4486694335938
INFO:root:Train (Epoch 185): Loss/seq after 00500 batchs: 523.138916015625
INFO:root:Train (Epoch 185): Loss/seq after 00550 batchs: 515.561279296875
INFO:root:Train (Epoch 185): Loss/seq after 00600 batchs: 499.9726257324219
INFO:root:Train (Epoch 185): Loss/seq after 00650 batchs: 478.8858337402344
INFO:root:Train (Epoch 185): Loss/seq after 00700 batchs: 457.1268310546875
INFO:root:Train (Epoch 185): Loss/seq after 00750 batchs: 446.28704833984375
INFO:root:Train (Epoch 185): Loss/seq after 00800 batchs: 452.6757507324219
INFO:root:Train (Epoch 185): Loss/seq after 00850 batchs: 437.9479064941406
INFO:root:Train (Epoch 185): Loss/seq after 00900 batchs: 426.95330810546875
INFO:root:Train (Epoch 185): Loss/seq after 00950 batchs: 423.0816955566406
INFO:root:Train (Epoch 185): Loss/seq after 01000 batchs: 414.1253662109375
INFO:root:Train (Epoch 185): Loss/seq after 01050 batchs: 406.8877258300781
INFO:root:Train (Epoch 185): Loss/seq after 01100 batchs: 398.0672607421875
INFO:root:Train (Epoch 185): Loss/seq after 01150 batchs: 386.875732421875
INFO:root:Train (Epoch 185): Loss/seq after 01200 batchs: 391.61785888671875
INFO:root:Train (Epoch 185): Loss/seq after 01250 batchs: 391.4264221191406
INFO:root:Train (Epoch 185): Loss/seq after 01300 batchs: 381.5372619628906
INFO:root:Train (Epoch 185): Loss/seq after 01350 batchs: 373.012939453125
INFO:root:Train (Epoch 185): Loss/seq after 01400 batchs: 372.4027099609375
INFO:root:Train (Epoch 185): Loss/seq after 01450 batchs: 376.2074890136719
INFO:root:Train (Epoch 185): Loss/seq after 01500 batchs: 383.655517578125
INFO:root:Train (Epoch 185): Loss/seq after 01550 batchs: 384.4063720703125
INFO:root:Train (Epoch 185): Loss/seq after 01600 batchs: 382.145751953125
INFO:root:Train (Epoch 185): Loss/seq after 01650 batchs: 381.1419677734375
INFO:root:Train (Epoch 185): Loss/seq after 01700 batchs: 386.2619323730469
INFO:root:Train (Epoch 185): Loss/seq after 01750 batchs: 385.09466552734375
INFO:root:Train (Epoch 185): Loss/seq after 01800 batchs: 383.9128723144531
INFO:root:Train (Epoch 185): Loss/seq after 01850 batchs: 382.4147644042969
INFO:root:Train (Epoch 185): Loss/seq after 01900 batchs: 382.0229187011719
INFO:root:Train (Epoch 185): Loss/seq after 01950 batchs: 382.3103332519531
INFO:root:Train (Epoch 185): Loss/seq after 02000 batchs: 383.8210144042969
INFO:root:Train (Epoch 185): Loss/seq after 02050 batchs: 384.2750549316406
INFO:root:Train (Epoch 185): Loss/seq after 02100 batchs: 383.5965576171875
INFO:root:Train (Epoch 185): Loss/seq after 02150 batchs: 383.29144287109375
INFO:root:Train (Epoch 185): Loss/seq after 02200 batchs: 382.70513916015625
INFO:root:Train (Epoch 185): Loss/seq after 02250 batchs: 381.45989990234375
INFO:root:Train (Epoch 185): Loss/seq after 02300 batchs: 377.9610290527344
INFO:root:Train (Epoch 185): Loss/seq after 02350 batchs: 375.9557800292969
INFO:root:Train (Epoch 185): Loss/seq after 02400 batchs: 376.8568115234375
INFO:root:Train (Epoch 185): Loss/seq after 02450 batchs: 374.21331787109375
INFO:root:Train (Epoch 185): Loss/seq after 02500 batchs: 368.2020568847656
INFO:root:Train (Epoch 185): Loss/seq after 02550 batchs: 362.6501159667969
INFO:root:Train (Epoch 185): Loss/seq after 02600 batchs: 358.6294250488281
INFO:root:Train (Epoch 185): Loss/seq after 02650 batchs: 354.69873046875
INFO:root:Train (Epoch 185): Loss/seq after 02700 batchs: 351.97418212890625
INFO:root:Train (Epoch 185): Loss/seq after 02750 batchs: 348.6387634277344
INFO:root:Train (Epoch 185): Loss/seq after 02800 batchs: 346.8146667480469
INFO:root:Train (Epoch 185): Loss/seq after 02850 batchs: 346.619384765625
INFO:root:Train (Epoch 185): Loss/seq after 02900 batchs: 347.15435791015625
INFO:root:Train (Epoch 185): Loss/seq after 02950 batchs: 347.9292297363281
INFO:root:Train (Epoch 185): Loss/seq after 03000 batchs: 353.5983581542969
INFO:root:Train (Epoch 185): Loss/seq after 03050 batchs: 355.5599670410156
INFO:root:Train (Epoch 185): Loss/seq after 03100 batchs: 356.6845397949219
INFO:root:Train (Epoch 185): Loss/seq after 03150 batchs: 356.13751220703125
INFO:root:Train (Epoch 185): Loss/seq after 03200 batchs: 356.0312194824219
INFO:root:Train (Epoch 185): Loss/seq after 03250 batchs: 355.3622741699219
INFO:root:Train (Epoch 185): Loss/seq after 03300 batchs: 355.1517333984375
INFO:root:Train (Epoch 185): Loss/seq after 03350 batchs: 353.24847412109375
INFO:root:Train (Epoch 185): Loss/seq after 03400 batchs: 350.7074279785156
INFO:root:Train (Epoch 185): Loss/seq after 03450 batchs: 349.1243896484375
INFO:root:Train (Epoch 185): Loss/seq after 03500 batchs: 350.3716125488281
INFO:root:Train (Epoch 185): Loss/seq after 03550 batchs: 349.2381286621094
INFO:root:Train (Epoch 185): Loss/seq after 03600 batchs: 354.4474792480469
INFO:root:Train (Epoch 185): Loss/seq after 03650 batchs: 353.3132629394531
INFO:root:Train (Epoch 185): Loss/seq after 03700 batchs: 356.3002014160156
INFO:root:Train (Epoch 185): Loss/seq after 03750 batchs: 360.9856872558594
INFO:root:Train (Epoch 185): Loss/seq after 03800 batchs: 360.72174072265625
INFO:root:Train (Epoch 185): Loss/seq after 03850 batchs: 360.3049011230469
INFO:root:Train (Epoch 185): Loss/seq after 03900 batchs: 361.84326171875
INFO:root:Train (Epoch 185): Loss/seq after 03950 batchs: 363.2309875488281
INFO:root:Train (Epoch 185): Loss/seq after 04000 batchs: 361.2958984375
INFO:root:Train (Epoch 185): Loss/seq after 04050 batchs: 359.1763610839844
INFO:root:Train (Epoch 185): Loss/seq after 04100 batchs: 358.7884521484375
INFO:root:Train (Epoch 185): Loss/seq after 04150 batchs: 359.1908264160156
INFO:root:Train (Epoch 185): Loss/seq after 04200 batchs: 358.5466613769531
INFO:root:Train (Epoch 185): Loss/seq after 04250 batchs: 357.6760559082031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 185): Loss/seq after 00000 batches: 254.17491149902344
INFO:root:# Valid (Epoch 185): Loss/seq after 00050 batches: 605.2557373046875
INFO:root:# Valid (Epoch 185): Loss/seq after 00100 batches: 599.1091918945312
INFO:root:# Valid (Epoch 185): Loss/seq after 00150 batches: 455.5963439941406
INFO:root:# Valid (Epoch 185): Loss/seq after 00200 batches: 428.5079040527344
INFO:root:Artifacts: Make stick videos for epoch 185
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_185_on_20220422_144049.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_185_index_1293_on_20220422_144049.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 186): Loss/seq after 00000 batchs: 507.76971435546875
INFO:root:Train (Epoch 186): Loss/seq after 00050 batchs: 488.0187072753906
INFO:root:Train (Epoch 186): Loss/seq after 00100 batchs: 477.6409912109375
INFO:root:Train (Epoch 186): Loss/seq after 00150 batchs: 459.7579040527344
INFO:root:Train (Epoch 186): Loss/seq after 00200 batchs: 497.2030029296875
INFO:root:Train (Epoch 186): Loss/seq after 00250 batchs: 525.4779052734375
INFO:root:Train (Epoch 186): Loss/seq after 00300 batchs: 547.372802734375
INFO:root:Train (Epoch 186): Loss/seq after 00350 batchs: 522.2767333984375
INFO:root:Train (Epoch 186): Loss/seq after 00400 batchs: 508.6647644042969
INFO:root:Train (Epoch 186): Loss/seq after 00450 batchs: 520.9161987304688
INFO:root:Train (Epoch 186): Loss/seq after 00500 batchs: 502.1461181640625
INFO:root:Train (Epoch 186): Loss/seq after 00550 batchs: 496.06890869140625
INFO:root:Train (Epoch 186): Loss/seq after 00600 batchs: 482.8355712890625
INFO:root:Train (Epoch 186): Loss/seq after 00650 batchs: 462.3197021484375
INFO:root:Train (Epoch 186): Loss/seq after 00700 batchs: 441.1529235839844
INFO:root:Train (Epoch 186): Loss/seq after 00750 batchs: 431.14849853515625
INFO:root:Train (Epoch 186): Loss/seq after 00800 batchs: 437.4154357910156
INFO:root:Train (Epoch 186): Loss/seq after 00850 batchs: 423.1212158203125
INFO:root:Train (Epoch 186): Loss/seq after 00900 batchs: 412.6127624511719
INFO:root:Train (Epoch 186): Loss/seq after 00950 batchs: 409.3186950683594
INFO:root:Train (Epoch 186): Loss/seq after 01000 batchs: 401.3626708984375
INFO:root:Train (Epoch 186): Loss/seq after 01050 batchs: 394.4516296386719
INFO:root:Train (Epoch 186): Loss/seq after 01100 batchs: 386.4482727050781
INFO:root:Train (Epoch 186): Loss/seq after 01150 batchs: 375.9307556152344
INFO:root:Train (Epoch 186): Loss/seq after 01200 batchs: 380.551513671875
INFO:root:Train (Epoch 186): Loss/seq after 01250 batchs: 380.9624938964844
INFO:root:Train (Epoch 186): Loss/seq after 01300 batchs: 371.7059326171875
INFO:root:Train (Epoch 186): Loss/seq after 01350 batchs: 363.2638244628906
INFO:root:Train (Epoch 186): Loss/seq after 01400 batchs: 363.88604736328125
INFO:root:Train (Epoch 186): Loss/seq after 01450 batchs: 367.9394836425781
INFO:root:Train (Epoch 186): Loss/seq after 01500 batchs: 375.2139587402344
INFO:root:Train (Epoch 186): Loss/seq after 01550 batchs: 375.9217224121094
INFO:root:Train (Epoch 186): Loss/seq after 01600 batchs: 373.9894104003906
INFO:root:Train (Epoch 186): Loss/seq after 01650 batchs: 372.9952087402344
INFO:root:Train (Epoch 186): Loss/seq after 01700 batchs: 378.2940673828125
INFO:root:Train (Epoch 186): Loss/seq after 01750 batchs: 377.36004638671875
INFO:root:Train (Epoch 186): Loss/seq after 01800 batchs: 376.24957275390625
INFO:root:Train (Epoch 186): Loss/seq after 01850 batchs: 374.88677978515625
INFO:root:Train (Epoch 186): Loss/seq after 01900 batchs: 374.6600036621094
INFO:root:Train (Epoch 186): Loss/seq after 01950 batchs: 375.1814270019531
INFO:root:Train (Epoch 186): Loss/seq after 02000 batchs: 376.98712158203125
INFO:root:Train (Epoch 186): Loss/seq after 02050 batchs: 377.78875732421875
INFO:root:Train (Epoch 186): Loss/seq after 02100 batchs: 377.53875732421875
INFO:root:Train (Epoch 186): Loss/seq after 02150 batchs: 377.478759765625
INFO:root:Train (Epoch 186): Loss/seq after 02200 batchs: 377.1452941894531
INFO:root:Train (Epoch 186): Loss/seq after 02250 batchs: 376.2134094238281
INFO:root:Train (Epoch 186): Loss/seq after 02300 batchs: 372.97711181640625
INFO:root:Train (Epoch 186): Loss/seq after 02350 batchs: 371.39178466796875
INFO:root:Train (Epoch 186): Loss/seq after 02400 batchs: 372.29583740234375
INFO:root:Train (Epoch 186): Loss/seq after 02450 batchs: 369.760498046875
INFO:root:Train (Epoch 186): Loss/seq after 02500 batchs: 363.84173583984375
INFO:root:Train (Epoch 186): Loss/seq after 02550 batchs: 358.3174133300781
INFO:root:Train (Epoch 186): Loss/seq after 02600 batchs: 354.2335510253906
INFO:root:Train (Epoch 186): Loss/seq after 02650 batchs: 350.4627685546875
INFO:root:Train (Epoch 186): Loss/seq after 02700 batchs: 347.8001403808594
INFO:root:Train (Epoch 186): Loss/seq after 02750 batchs: 343.9173278808594
INFO:root:Train (Epoch 186): Loss/seq after 02800 batchs: 342.0981750488281
INFO:root:Train (Epoch 186): Loss/seq after 02850 batchs: 342.031005859375
INFO:root:Train (Epoch 186): Loss/seq after 02900 batchs: 342.56146240234375
INFO:root:Train (Epoch 186): Loss/seq after 02950 batchs: 343.492431640625
INFO:root:Train (Epoch 186): Loss/seq after 03000 batchs: 349.1960144042969
INFO:root:Train (Epoch 186): Loss/seq after 03050 batchs: 351.110107421875
INFO:root:Train (Epoch 186): Loss/seq after 03100 batchs: 352.5502624511719
INFO:root:Train (Epoch 186): Loss/seq after 03150 batchs: 352.6375732421875
INFO:root:Train (Epoch 186): Loss/seq after 03200 batchs: 352.74774169921875
INFO:root:Train (Epoch 186): Loss/seq after 03250 batchs: 351.9859313964844
INFO:root:Train (Epoch 186): Loss/seq after 03300 batchs: 351.448974609375
INFO:root:Train (Epoch 186): Loss/seq after 03350 batchs: 349.2927551269531
INFO:root:Train (Epoch 186): Loss/seq after 03400 batchs: 346.8575744628906
INFO:root:Train (Epoch 186): Loss/seq after 03450 batchs: 345.2018737792969
INFO:root:Train (Epoch 186): Loss/seq after 03500 batchs: 345.8414611816406
INFO:root:Train (Epoch 186): Loss/seq after 03550 batchs: 344.5099182128906
INFO:root:Train (Epoch 186): Loss/seq after 03600 batchs: 350.0159912109375
INFO:root:Train (Epoch 186): Loss/seq after 03650 batchs: 349.0799255371094
INFO:root:Train (Epoch 186): Loss/seq after 03700 batchs: 351.8392333984375
INFO:root:Train (Epoch 186): Loss/seq after 03750 batchs: 356.3852844238281
INFO:root:Train (Epoch 186): Loss/seq after 03800 batchs: 356.1922607421875
INFO:root:Train (Epoch 186): Loss/seq after 03850 batchs: 355.82550048828125
INFO:root:Train (Epoch 186): Loss/seq after 03900 batchs: 356.6922912597656
INFO:root:Train (Epoch 186): Loss/seq after 03950 batchs: 357.79534912109375
INFO:root:Train (Epoch 186): Loss/seq after 04000 batchs: 355.9883117675781
INFO:root:Train (Epoch 186): Loss/seq after 04050 batchs: 353.8812561035156
INFO:root:Train (Epoch 186): Loss/seq after 04100 batchs: 353.5854187011719
INFO:root:Train (Epoch 186): Loss/seq after 04150 batchs: 353.839111328125
INFO:root:Train (Epoch 186): Loss/seq after 04200 batchs: 353.2563171386719
INFO:root:Train (Epoch 186): Loss/seq after 04250 batchs: 352.2561340332031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 186): Loss/seq after 00000 batches: 218.1346893310547
INFO:root:# Valid (Epoch 186): Loss/seq after 00050 batches: 626.4090576171875
INFO:root:# Valid (Epoch 186): Loss/seq after 00100 batches: 602.4796752929688
INFO:root:# Valid (Epoch 186): Loss/seq after 00150 batches: 457.4325256347656
INFO:root:# Valid (Epoch 186): Loss/seq after 00200 batches: 427.8335876464844
INFO:root:Artifacts: Make stick videos for epoch 186
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_186_on_20220422_144534.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_186_index_456_on_20220422_144534.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 187): Loss/seq after 00000 batchs: 558.2520141601562
INFO:root:Train (Epoch 187): Loss/seq after 00050 batchs: 476.7486877441406
INFO:root:Train (Epoch 187): Loss/seq after 00100 batchs: 475.39166259765625
INFO:root:Train (Epoch 187): Loss/seq after 00150 batchs: 453.551025390625
INFO:root:Train (Epoch 187): Loss/seq after 00200 batchs: 490.3605651855469
INFO:root:Train (Epoch 187): Loss/seq after 00250 batchs: 540.72216796875
INFO:root:Train (Epoch 187): Loss/seq after 00300 batchs: 561.768798828125
INFO:root:Train (Epoch 187): Loss/seq after 00350 batchs: 534.2028198242188
INFO:root:Train (Epoch 187): Loss/seq after 00400 batchs: 521.2504272460938
INFO:root:Train (Epoch 187): Loss/seq after 00450 batchs: 532.3880615234375
INFO:root:Train (Epoch 187): Loss/seq after 00500 batchs: 518.8482666015625
INFO:root:Train (Epoch 187): Loss/seq after 00550 batchs: 512.1278686523438
INFO:root:Train (Epoch 187): Loss/seq after 00600 batchs: 498.7410888671875
INFO:root:Train (Epoch 187): Loss/seq after 00650 batchs: 477.5892333984375
INFO:root:Train (Epoch 187): Loss/seq after 00700 batchs: 455.9136962890625
INFO:root:Train (Epoch 187): Loss/seq after 00750 batchs: 445.5340270996094
INFO:root:Train (Epoch 187): Loss/seq after 00800 batchs: 452.4128723144531
INFO:root:Train (Epoch 187): Loss/seq after 00850 batchs: 438.02301025390625
INFO:root:Train (Epoch 187): Loss/seq after 00900 batchs: 427.9576416015625
INFO:root:Train (Epoch 187): Loss/seq after 00950 batchs: 423.94091796875
INFO:root:Train (Epoch 187): Loss/seq after 01000 batchs: 415.4395751953125
INFO:root:Train (Epoch 187): Loss/seq after 01050 batchs: 409.28204345703125
INFO:root:Train (Epoch 187): Loss/seq after 01100 batchs: 400.6358642578125
INFO:root:Train (Epoch 187): Loss/seq after 01150 batchs: 389.6621398925781
INFO:root:Train (Epoch 187): Loss/seq after 01200 batchs: 393.13330078125
INFO:root:Train (Epoch 187): Loss/seq after 01250 batchs: 393.2434387207031
INFO:root:Train (Epoch 187): Loss/seq after 01300 batchs: 383.6314697265625
INFO:root:Train (Epoch 187): Loss/seq after 01350 batchs: 374.7406005859375
INFO:root:Train (Epoch 187): Loss/seq after 01400 batchs: 374.8038330078125
INFO:root:Train (Epoch 187): Loss/seq after 01450 batchs: 378.48284912109375
INFO:root:Train (Epoch 187): Loss/seq after 01500 batchs: 385.3887634277344
INFO:root:Train (Epoch 187): Loss/seq after 01550 batchs: 385.56072998046875
INFO:root:Train (Epoch 187): Loss/seq after 01600 batchs: 383.7000427246094
INFO:root:Train (Epoch 187): Loss/seq after 01650 batchs: 382.63580322265625
INFO:root:Train (Epoch 187): Loss/seq after 01700 batchs: 387.66217041015625
INFO:root:Train (Epoch 187): Loss/seq after 01750 batchs: 386.56768798828125
INFO:root:Train (Epoch 187): Loss/seq after 01800 batchs: 385.2029113769531
INFO:root:Train (Epoch 187): Loss/seq after 01850 batchs: 383.7701721191406
INFO:root:Train (Epoch 187): Loss/seq after 01900 batchs: 383.6922607421875
INFO:root:Train (Epoch 187): Loss/seq after 01950 batchs: 384.1893615722656
INFO:root:Train (Epoch 187): Loss/seq after 02000 batchs: 385.8468017578125
INFO:root:Train (Epoch 187): Loss/seq after 02050 batchs: 386.5272216796875
INFO:root:Train (Epoch 187): Loss/seq after 02100 batchs: 385.8853759765625
INFO:root:Train (Epoch 187): Loss/seq after 02150 batchs: 385.5870666503906
INFO:root:Train (Epoch 187): Loss/seq after 02200 batchs: 385.0244445800781
INFO:root:Train (Epoch 187): Loss/seq after 02250 batchs: 383.9183349609375
INFO:root:Train (Epoch 187): Loss/seq after 02300 batchs: 380.2396240234375
INFO:root:Train (Epoch 187): Loss/seq after 02350 batchs: 378.1366271972656
INFO:root:Train (Epoch 187): Loss/seq after 02400 batchs: 378.89910888671875
INFO:root:Train (Epoch 187): Loss/seq after 02450 batchs: 376.2145080566406
INFO:root:Train (Epoch 187): Loss/seq after 02500 batchs: 370.1683349609375
INFO:root:Train (Epoch 187): Loss/seq after 02550 batchs: 364.51068115234375
INFO:root:Train (Epoch 187): Loss/seq after 02600 batchs: 360.3302001953125
INFO:root:Train (Epoch 187): Loss/seq after 02650 batchs: 356.4087829589844
INFO:root:Train (Epoch 187): Loss/seq after 02700 batchs: 353.5592041015625
INFO:root:Train (Epoch 187): Loss/seq after 02750 batchs: 349.3572998046875
INFO:root:Train (Epoch 187): Loss/seq after 02800 batchs: 347.0859069824219
INFO:root:Train (Epoch 187): Loss/seq after 02850 batchs: 346.7916259765625
INFO:root:Train (Epoch 187): Loss/seq after 02900 batchs: 347.27484130859375
INFO:root:Train (Epoch 187): Loss/seq after 02950 batchs: 348.10882568359375
INFO:root:Train (Epoch 187): Loss/seq after 03000 batchs: 353.6002197265625
INFO:root:Train (Epoch 187): Loss/seq after 03050 batchs: 355.31536865234375
INFO:root:Train (Epoch 187): Loss/seq after 03100 batchs: 356.7549743652344
INFO:root:Train (Epoch 187): Loss/seq after 03150 batchs: 355.9601745605469
INFO:root:Train (Epoch 187): Loss/seq after 03200 batchs: 354.95965576171875
INFO:root:Train (Epoch 187): Loss/seq after 03250 batchs: 353.6815185546875
INFO:root:Train (Epoch 187): Loss/seq after 03300 batchs: 352.73992919921875
INFO:root:Train (Epoch 187): Loss/seq after 03350 batchs: 350.46484375
INFO:root:Train (Epoch 187): Loss/seq after 03400 batchs: 347.8890380859375
INFO:root:Train (Epoch 187): Loss/seq after 03450 batchs: 346.1942443847656
INFO:root:Train (Epoch 187): Loss/seq after 03500 batchs: 346.9670715332031
INFO:root:Train (Epoch 187): Loss/seq after 03550 batchs: 345.5411682128906
INFO:root:Train (Epoch 187): Loss/seq after 03600 batchs: 350.6908874511719
INFO:root:Train (Epoch 187): Loss/seq after 03650 batchs: 349.4895324707031
INFO:root:Train (Epoch 187): Loss/seq after 03700 batchs: 351.8324890136719
INFO:root:Train (Epoch 187): Loss/seq after 03750 batchs: 356.3872985839844
INFO:root:Train (Epoch 187): Loss/seq after 03800 batchs: 356.2485046386719
INFO:root:Train (Epoch 187): Loss/seq after 03850 batchs: 355.91729736328125
INFO:root:Train (Epoch 187): Loss/seq after 03900 batchs: 356.74322509765625
INFO:root:Train (Epoch 187): Loss/seq after 03950 batchs: 358.3020324707031
INFO:root:Train (Epoch 187): Loss/seq after 04000 batchs: 356.4108581542969
INFO:root:Train (Epoch 187): Loss/seq after 04050 batchs: 354.3146667480469
INFO:root:Train (Epoch 187): Loss/seq after 04100 batchs: 353.8876037597656
INFO:root:Train (Epoch 187): Loss/seq after 04150 batchs: 354.1518859863281
INFO:root:Train (Epoch 187): Loss/seq after 04200 batchs: 353.3296813964844
INFO:root:Train (Epoch 187): Loss/seq after 04250 batchs: 352.3110656738281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 187): Loss/seq after 00000 batches: 255.23756408691406
INFO:root:# Valid (Epoch 187): Loss/seq after 00050 batches: 629.451904296875
INFO:root:# Valid (Epoch 187): Loss/seq after 00100 batches: 600.287109375
INFO:root:# Valid (Epoch 187): Loss/seq after 00150 batches: 456.3060302734375
INFO:root:# Valid (Epoch 187): Loss/seq after 00200 batches: 427.75885009765625
INFO:root:Artifacts: Make stick videos for epoch 187
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_187_on_20220422_145025.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_187_index_609_on_20220422_145025.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 188): Loss/seq after 00000 batchs: 470.6775817871094
INFO:root:Train (Epoch 188): Loss/seq after 00050 batchs: 462.928466796875
INFO:root:Train (Epoch 188): Loss/seq after 00100 batchs: 464.2364807128906
INFO:root:Train (Epoch 188): Loss/seq after 00150 batchs: 444.8969421386719
INFO:root:Train (Epoch 188): Loss/seq after 00200 batchs: 483.6130676269531
INFO:root:Train (Epoch 188): Loss/seq after 00250 batchs: 517.0958862304688
INFO:root:Train (Epoch 188): Loss/seq after 00300 batchs: 540.74462890625
INFO:root:Train (Epoch 188): Loss/seq after 00350 batchs: 516.341064453125
INFO:root:Train (Epoch 188): Loss/seq after 00400 batchs: 501.99041748046875
INFO:root:Train (Epoch 188): Loss/seq after 00450 batchs: 514.6197509765625
INFO:root:Train (Epoch 188): Loss/seq after 00500 batchs: 500.185546875
INFO:root:Train (Epoch 188): Loss/seq after 00550 batchs: 495.5074462890625
INFO:root:Train (Epoch 188): Loss/seq after 00600 batchs: 483.1956481933594
INFO:root:Train (Epoch 188): Loss/seq after 00650 batchs: 463.2442321777344
INFO:root:Train (Epoch 188): Loss/seq after 00700 batchs: 441.3426513671875
INFO:root:Train (Epoch 188): Loss/seq after 00750 batchs: 429.2099609375
INFO:root:Train (Epoch 188): Loss/seq after 00800 batchs: 435.1322326660156
INFO:root:Train (Epoch 188): Loss/seq after 00850 batchs: 421.2681579589844
INFO:root:Train (Epoch 188): Loss/seq after 00900 batchs: 410.91265869140625
INFO:root:Train (Epoch 188): Loss/seq after 00950 batchs: 407.4627380371094
INFO:root:Train (Epoch 188): Loss/seq after 01000 batchs: 399.7645263671875
INFO:root:Train (Epoch 188): Loss/seq after 01050 batchs: 394.0146484375
INFO:root:Train (Epoch 188): Loss/seq after 01100 batchs: 386.029541015625
INFO:root:Train (Epoch 188): Loss/seq after 01150 batchs: 375.564453125
INFO:root:Train (Epoch 188): Loss/seq after 01200 batchs: 380.5430603027344
INFO:root:Train (Epoch 188): Loss/seq after 01250 batchs: 381.19329833984375
INFO:root:Train (Epoch 188): Loss/seq after 01300 batchs: 372.0672912597656
INFO:root:Train (Epoch 188): Loss/seq after 01350 batchs: 363.2708740234375
INFO:root:Train (Epoch 188): Loss/seq after 01400 batchs: 363.58465576171875
INFO:root:Train (Epoch 188): Loss/seq after 01450 batchs: 368.2493896484375
INFO:root:Train (Epoch 188): Loss/seq after 01500 batchs: 375.8513488769531
INFO:root:Train (Epoch 188): Loss/seq after 01550 batchs: 376.57525634765625
INFO:root:Train (Epoch 188): Loss/seq after 01600 batchs: 375.0205383300781
INFO:root:Train (Epoch 188): Loss/seq after 01650 batchs: 374.3666076660156
INFO:root:Train (Epoch 188): Loss/seq after 01700 batchs: 379.7445068359375
INFO:root:Train (Epoch 188): Loss/seq after 01750 batchs: 378.95574951171875
INFO:root:Train (Epoch 188): Loss/seq after 01800 batchs: 377.99822998046875
INFO:root:Train (Epoch 188): Loss/seq after 01850 batchs: 376.5005798339844
INFO:root:Train (Epoch 188): Loss/seq after 01900 batchs: 376.2269592285156
INFO:root:Train (Epoch 188): Loss/seq after 01950 batchs: 376.2999572753906
INFO:root:Train (Epoch 188): Loss/seq after 02000 batchs: 377.7066650390625
INFO:root:Train (Epoch 188): Loss/seq after 02050 batchs: 378.40594482421875
INFO:root:Train (Epoch 188): Loss/seq after 02100 batchs: 378.1755676269531
INFO:root:Train (Epoch 188): Loss/seq after 02150 batchs: 378.07916259765625
INFO:root:Train (Epoch 188): Loss/seq after 02200 batchs: 377.58599853515625
INFO:root:Train (Epoch 188): Loss/seq after 02250 batchs: 376.49798583984375
INFO:root:Train (Epoch 188): Loss/seq after 02300 batchs: 373.0660705566406
INFO:root:Train (Epoch 188): Loss/seq after 02350 batchs: 371.1177978515625
INFO:root:Train (Epoch 188): Loss/seq after 02400 batchs: 371.8738098144531
INFO:root:Train (Epoch 188): Loss/seq after 02450 batchs: 369.3322448730469
INFO:root:Train (Epoch 188): Loss/seq after 02500 batchs: 363.42694091796875
INFO:root:Train (Epoch 188): Loss/seq after 02550 batchs: 358.012451171875
INFO:root:Train (Epoch 188): Loss/seq after 02600 batchs: 353.926513671875
INFO:root:Train (Epoch 188): Loss/seq after 02650 batchs: 350.0428466796875
INFO:root:Train (Epoch 188): Loss/seq after 02700 batchs: 347.1248474121094
INFO:root:Train (Epoch 188): Loss/seq after 02750 batchs: 342.97021484375
INFO:root:Train (Epoch 188): Loss/seq after 02800 batchs: 340.3011474609375
INFO:root:Train (Epoch 188): Loss/seq after 02850 batchs: 340.1111145019531
INFO:root:Train (Epoch 188): Loss/seq after 02900 batchs: 340.60369873046875
INFO:root:Train (Epoch 188): Loss/seq after 02950 batchs: 341.57904052734375
INFO:root:Train (Epoch 188): Loss/seq after 03000 batchs: 347.1997985839844
INFO:root:Train (Epoch 188): Loss/seq after 03050 batchs: 349.2835998535156
INFO:root:Train (Epoch 188): Loss/seq after 03100 batchs: 350.6453857421875
INFO:root:Train (Epoch 188): Loss/seq after 03150 batchs: 349.84796142578125
INFO:root:Train (Epoch 188): Loss/seq after 03200 batchs: 349.33135986328125
INFO:root:Train (Epoch 188): Loss/seq after 03250 batchs: 348.3864440917969
INFO:root:Train (Epoch 188): Loss/seq after 03300 batchs: 348.0345764160156
INFO:root:Train (Epoch 188): Loss/seq after 03350 batchs: 346.0971374511719
INFO:root:Train (Epoch 188): Loss/seq after 03400 batchs: 343.668212890625
INFO:root:Train (Epoch 188): Loss/seq after 03450 batchs: 342.0987548828125
INFO:root:Train (Epoch 188): Loss/seq after 03500 batchs: 343.6307067871094
INFO:root:Train (Epoch 188): Loss/seq after 03550 batchs: 342.5199279785156
INFO:root:Train (Epoch 188): Loss/seq after 03600 batchs: 347.6744079589844
INFO:root:Train (Epoch 188): Loss/seq after 03650 batchs: 346.6760559082031
INFO:root:Train (Epoch 188): Loss/seq after 03700 batchs: 349.3249206542969
INFO:root:Train (Epoch 188): Loss/seq after 03750 batchs: 353.96929931640625
INFO:root:Train (Epoch 188): Loss/seq after 03800 batchs: 353.8408508300781
INFO:root:Train (Epoch 188): Loss/seq after 03850 batchs: 353.5408630371094
INFO:root:Train (Epoch 188): Loss/seq after 03900 batchs: 354.4552307128906
INFO:root:Train (Epoch 188): Loss/seq after 03950 batchs: 355.66241455078125
INFO:root:Train (Epoch 188): Loss/seq after 04000 batchs: 353.8951110839844
INFO:root:Train (Epoch 188): Loss/seq after 04050 batchs: 351.8143005371094
INFO:root:Train (Epoch 188): Loss/seq after 04100 batchs: 351.554443359375
INFO:root:Train (Epoch 188): Loss/seq after 04150 batchs: 351.8797607421875
INFO:root:Train (Epoch 188): Loss/seq after 04200 batchs: 351.1072692871094
INFO:root:Train (Epoch 188): Loss/seq after 04250 batchs: 350.0850830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 188): Loss/seq after 00000 batches: 285.19189453125
INFO:root:# Valid (Epoch 188): Loss/seq after 00050 batches: 616.6480102539062
INFO:root:# Valid (Epoch 188): Loss/seq after 00100 batches: 603.9119873046875
INFO:root:# Valid (Epoch 188): Loss/seq after 00150 batches: 457.30938720703125
INFO:root:# Valid (Epoch 188): Loss/seq after 00200 batches: 427.6340026855469
INFO:root:Artifacts: Make stick videos for epoch 188
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_188_on_20220422_145515.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_188_index_1740_on_20220422_145515.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 189): Loss/seq after 00000 batchs: 519.3043823242188
INFO:root:Train (Epoch 189): Loss/seq after 00050 batchs: 490.0356750488281
INFO:root:Train (Epoch 189): Loss/seq after 00100 batchs: 490.8961486816406
INFO:root:Train (Epoch 189): Loss/seq after 00150 batchs: 467.6529846191406
INFO:root:Train (Epoch 189): Loss/seq after 00200 batchs: 504.4217529296875
INFO:root:Train (Epoch 189): Loss/seq after 00250 batchs: 543.8265380859375
INFO:root:Train (Epoch 189): Loss/seq after 00300 batchs: 563.5715942382812
INFO:root:Train (Epoch 189): Loss/seq after 00350 batchs: 538.6839599609375
INFO:root:Train (Epoch 189): Loss/seq after 00400 batchs: 522.843505859375
INFO:root:Train (Epoch 189): Loss/seq after 00450 batchs: 532.60986328125
INFO:root:Train (Epoch 189): Loss/seq after 00500 batchs: 514.93359375
INFO:root:Train (Epoch 189): Loss/seq after 00550 batchs: 507.8746032714844
INFO:root:Train (Epoch 189): Loss/seq after 00600 batchs: 493.9808044433594
INFO:root:Train (Epoch 189): Loss/seq after 00650 batchs: 472.215087890625
INFO:root:Train (Epoch 189): Loss/seq after 00700 batchs: 450.1573791503906
INFO:root:Train (Epoch 189): Loss/seq after 00750 batchs: 439.53118896484375
INFO:root:Train (Epoch 189): Loss/seq after 00800 batchs: 445.2205810546875
INFO:root:Train (Epoch 189): Loss/seq after 00850 batchs: 431.6536865234375
INFO:root:Train (Epoch 189): Loss/seq after 00900 batchs: 420.8992919921875
INFO:root:Train (Epoch 189): Loss/seq after 00950 batchs: 417.13836669921875
INFO:root:Train (Epoch 189): Loss/seq after 01000 batchs: 408.5444641113281
INFO:root:Train (Epoch 189): Loss/seq after 01050 batchs: 403.896484375
INFO:root:Train (Epoch 189): Loss/seq after 01100 batchs: 396.7855224609375
INFO:root:Train (Epoch 189): Loss/seq after 01150 batchs: 386.4042663574219
INFO:root:Train (Epoch 189): Loss/seq after 01200 batchs: 390.29473876953125
INFO:root:Train (Epoch 189): Loss/seq after 01250 batchs: 390.9979248046875
INFO:root:Train (Epoch 189): Loss/seq after 01300 batchs: 381.43670654296875
INFO:root:Train (Epoch 189): Loss/seq after 01350 batchs: 372.8833923339844
INFO:root:Train (Epoch 189): Loss/seq after 01400 batchs: 374.27606201171875
INFO:root:Train (Epoch 189): Loss/seq after 01450 batchs: 378.4624938964844
INFO:root:Train (Epoch 189): Loss/seq after 01500 batchs: 385.3492431640625
INFO:root:Train (Epoch 189): Loss/seq after 01550 batchs: 387.7092590332031
INFO:root:Train (Epoch 189): Loss/seq after 01600 batchs: 386.2819519042969
INFO:root:Train (Epoch 189): Loss/seq after 01650 batchs: 385.614013671875
INFO:root:Train (Epoch 189): Loss/seq after 01700 batchs: 391.14849853515625
INFO:root:Train (Epoch 189): Loss/seq after 01750 batchs: 389.9064636230469
INFO:root:Train (Epoch 189): Loss/seq after 01800 batchs: 389.00946044921875
INFO:root:Train (Epoch 189): Loss/seq after 01850 batchs: 387.432373046875
INFO:root:Train (Epoch 189): Loss/seq after 01900 batchs: 387.0275573730469
INFO:root:Train (Epoch 189): Loss/seq after 01950 batchs: 387.7816467285156
INFO:root:Train (Epoch 189): Loss/seq after 02000 batchs: 389.2118835449219
INFO:root:Train (Epoch 189): Loss/seq after 02050 batchs: 389.57061767578125
INFO:root:Train (Epoch 189): Loss/seq after 02100 batchs: 389.0395812988281
INFO:root:Train (Epoch 189): Loss/seq after 02150 batchs: 388.6458435058594
INFO:root:Train (Epoch 189): Loss/seq after 02200 batchs: 387.96185302734375
INFO:root:Train (Epoch 189): Loss/seq after 02250 batchs: 387.0548400878906
INFO:root:Train (Epoch 189): Loss/seq after 02300 batchs: 383.7392883300781
INFO:root:Train (Epoch 189): Loss/seq after 02350 batchs: 381.6580810546875
INFO:root:Train (Epoch 189): Loss/seq after 02400 batchs: 382.20751953125
INFO:root:Train (Epoch 189): Loss/seq after 02450 batchs: 379.4104309082031
INFO:root:Train (Epoch 189): Loss/seq after 02500 batchs: 373.2633056640625
INFO:root:Train (Epoch 189): Loss/seq after 02550 batchs: 367.56951904296875
INFO:root:Train (Epoch 189): Loss/seq after 02600 batchs: 363.38702392578125
INFO:root:Train (Epoch 189): Loss/seq after 02650 batchs: 359.3458251953125
INFO:root:Train (Epoch 189): Loss/seq after 02700 batchs: 356.3665771484375
INFO:root:Train (Epoch 189): Loss/seq after 02750 batchs: 352.0984191894531
INFO:root:Train (Epoch 189): Loss/seq after 02800 batchs: 349.5313415527344
INFO:root:Train (Epoch 189): Loss/seq after 02850 batchs: 349.0986328125
INFO:root:Train (Epoch 189): Loss/seq after 02900 batchs: 349.457275390625
INFO:root:Train (Epoch 189): Loss/seq after 02950 batchs: 350.1690368652344
INFO:root:Train (Epoch 189): Loss/seq after 03000 batchs: 355.455810546875
INFO:root:Train (Epoch 189): Loss/seq after 03050 batchs: 357.1661071777344
INFO:root:Train (Epoch 189): Loss/seq after 03100 batchs: 358.4405212402344
INFO:root:Train (Epoch 189): Loss/seq after 03150 batchs: 357.5745849609375
INFO:root:Train (Epoch 189): Loss/seq after 03200 batchs: 356.95831298828125
INFO:root:Train (Epoch 189): Loss/seq after 03250 batchs: 356.1447448730469
INFO:root:Train (Epoch 189): Loss/seq after 03300 batchs: 355.4251708984375
INFO:root:Train (Epoch 189): Loss/seq after 03350 batchs: 353.3960266113281
INFO:root:Train (Epoch 189): Loss/seq after 03400 batchs: 350.83734130859375
INFO:root:Train (Epoch 189): Loss/seq after 03450 batchs: 349.2178039550781
INFO:root:Train (Epoch 189): Loss/seq after 03500 batchs: 350.66717529296875
INFO:root:Train (Epoch 189): Loss/seq after 03550 batchs: 349.9215393066406
INFO:root:Train (Epoch 189): Loss/seq after 03600 batchs: 355.1116027832031
INFO:root:Train (Epoch 189): Loss/seq after 03650 batchs: 353.81341552734375
INFO:root:Train (Epoch 189): Loss/seq after 03700 batchs: 356.4221496582031
INFO:root:Train (Epoch 189): Loss/seq after 03750 batchs: 360.9411315917969
INFO:root:Train (Epoch 189): Loss/seq after 03800 batchs: 360.67816162109375
INFO:root:Train (Epoch 189): Loss/seq after 03850 batchs: 360.3871154785156
INFO:root:Train (Epoch 189): Loss/seq after 03900 batchs: 362.48260498046875
INFO:root:Train (Epoch 189): Loss/seq after 03950 batchs: 364.2259826660156
INFO:root:Train (Epoch 189): Loss/seq after 04000 batchs: 362.3490905761719
INFO:root:Train (Epoch 189): Loss/seq after 04050 batchs: 360.280517578125
INFO:root:Train (Epoch 189): Loss/seq after 04100 batchs: 359.8367919921875
INFO:root:Train (Epoch 189): Loss/seq after 04150 batchs: 360.2469787597656
INFO:root:Train (Epoch 189): Loss/seq after 04200 batchs: 359.4818115234375
INFO:root:Train (Epoch 189): Loss/seq after 04250 batchs: 358.3373718261719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 189): Loss/seq after 00000 batches: 334.9961853027344
INFO:root:# Valid (Epoch 189): Loss/seq after 00050 batches: 611.7259521484375
INFO:root:# Valid (Epoch 189): Loss/seq after 00100 batches: 599.6988525390625
INFO:root:# Valid (Epoch 189): Loss/seq after 00150 batches: 461.8702392578125
INFO:root:# Valid (Epoch 189): Loss/seq after 00200 batches: 434.34466552734375
INFO:root:Artifacts: Make stick videos for epoch 189
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_189_on_20220422_145953.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_189_index_1273_on_20220422_145953.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 190): Loss/seq after 00000 batchs: 545.8873291015625
INFO:root:Train (Epoch 190): Loss/seq after 00050 batchs: 479.5274658203125
INFO:root:Train (Epoch 190): Loss/seq after 00100 batchs: 478.80963134765625
INFO:root:Train (Epoch 190): Loss/seq after 00150 batchs: 452.8832702636719
INFO:root:Train (Epoch 190): Loss/seq after 00200 batchs: 501.5111389160156
INFO:root:Train (Epoch 190): Loss/seq after 00250 batchs: 535.6776123046875
INFO:root:Train (Epoch 190): Loss/seq after 00300 batchs: 559.2482299804688
INFO:root:Train (Epoch 190): Loss/seq after 00350 batchs: 532.7791137695312
INFO:root:Train (Epoch 190): Loss/seq after 00400 batchs: 517.4779663085938
INFO:root:Train (Epoch 190): Loss/seq after 00450 batchs: 528.6244506835938
INFO:root:Train (Epoch 190): Loss/seq after 00500 batchs: 509.7626647949219
INFO:root:Train (Epoch 190): Loss/seq after 00550 batchs: 502.2776794433594
INFO:root:Train (Epoch 190): Loss/seq after 00600 batchs: 487.9470520019531
INFO:root:Train (Epoch 190): Loss/seq after 00650 batchs: 466.4924621582031
INFO:root:Train (Epoch 190): Loss/seq after 00700 batchs: 446.2080993652344
INFO:root:Train (Epoch 190): Loss/seq after 00750 batchs: 434.2602233886719
INFO:root:Train (Epoch 190): Loss/seq after 00800 batchs: 440.87457275390625
INFO:root:Train (Epoch 190): Loss/seq after 00850 batchs: 426.5476989746094
INFO:root:Train (Epoch 190): Loss/seq after 00900 batchs: 415.4553527832031
INFO:root:Train (Epoch 190): Loss/seq after 00950 batchs: 412.1731262207031
INFO:root:Train (Epoch 190): Loss/seq after 01000 batchs: 404.3067626953125
INFO:root:Train (Epoch 190): Loss/seq after 01050 batchs: 400.0819396972656
INFO:root:Train (Epoch 190): Loss/seq after 01100 batchs: 392.04180908203125
INFO:root:Train (Epoch 190): Loss/seq after 01150 batchs: 381.292236328125
INFO:root:Train (Epoch 190): Loss/seq after 01200 batchs: 384.890380859375
INFO:root:Train (Epoch 190): Loss/seq after 01250 batchs: 384.62255859375
INFO:root:Train (Epoch 190): Loss/seq after 01300 batchs: 375.167236328125
INFO:root:Train (Epoch 190): Loss/seq after 01350 batchs: 366.6982116699219
INFO:root:Train (Epoch 190): Loss/seq after 01400 batchs: 367.3511962890625
INFO:root:Train (Epoch 190): Loss/seq after 01450 batchs: 371.4156494140625
INFO:root:Train (Epoch 190): Loss/seq after 01500 batchs: 378.3075866699219
INFO:root:Train (Epoch 190): Loss/seq after 01550 batchs: 379.15118408203125
INFO:root:Train (Epoch 190): Loss/seq after 01600 batchs: 376.82769775390625
INFO:root:Train (Epoch 190): Loss/seq after 01650 batchs: 375.8912658691406
INFO:root:Train (Epoch 190): Loss/seq after 01700 batchs: 381.18426513671875
INFO:root:Train (Epoch 190): Loss/seq after 01750 batchs: 380.02471923828125
INFO:root:Train (Epoch 190): Loss/seq after 01800 batchs: 378.8872985839844
INFO:root:Train (Epoch 190): Loss/seq after 01850 batchs: 377.2867431640625
INFO:root:Train (Epoch 190): Loss/seq after 01900 batchs: 376.8450622558594
INFO:root:Train (Epoch 190): Loss/seq after 01950 batchs: 376.68634033203125
INFO:root:Train (Epoch 190): Loss/seq after 02000 batchs: 378.3855285644531
INFO:root:Train (Epoch 190): Loss/seq after 02050 batchs: 378.95208740234375
INFO:root:Train (Epoch 190): Loss/seq after 02100 batchs: 378.19189453125
INFO:root:Train (Epoch 190): Loss/seq after 02150 batchs: 377.9120788574219
INFO:root:Train (Epoch 190): Loss/seq after 02200 batchs: 377.3456726074219
INFO:root:Train (Epoch 190): Loss/seq after 02250 batchs: 376.3600769042969
INFO:root:Train (Epoch 190): Loss/seq after 02300 batchs: 372.9141540527344
INFO:root:Train (Epoch 190): Loss/seq after 02350 batchs: 371.1869812011719
INFO:root:Train (Epoch 190): Loss/seq after 02400 batchs: 372.0089416503906
INFO:root:Train (Epoch 190): Loss/seq after 02450 batchs: 369.5628356933594
INFO:root:Train (Epoch 190): Loss/seq after 02500 batchs: 363.6474609375
INFO:root:Train (Epoch 190): Loss/seq after 02550 batchs: 358.1173400878906
INFO:root:Train (Epoch 190): Loss/seq after 02600 batchs: 354.0533447265625
INFO:root:Train (Epoch 190): Loss/seq after 02650 batchs: 350.0910949707031
INFO:root:Train (Epoch 190): Loss/seq after 02700 batchs: 347.5433654785156
INFO:root:Train (Epoch 190): Loss/seq after 02750 batchs: 343.4339599609375
INFO:root:Train (Epoch 190): Loss/seq after 02800 batchs: 340.84197998046875
INFO:root:Train (Epoch 190): Loss/seq after 02850 batchs: 340.5235900878906
INFO:root:Train (Epoch 190): Loss/seq after 02900 batchs: 341.0516052246094
INFO:root:Train (Epoch 190): Loss/seq after 02950 batchs: 341.91455078125
INFO:root:Train (Epoch 190): Loss/seq after 03000 batchs: 347.4743347167969
INFO:root:Train (Epoch 190): Loss/seq after 03050 batchs: 349.22589111328125
INFO:root:Train (Epoch 190): Loss/seq after 03100 batchs: 350.44427490234375
INFO:root:Train (Epoch 190): Loss/seq after 03150 batchs: 349.8135070800781
INFO:root:Train (Epoch 190): Loss/seq after 03200 batchs: 349.3669128417969
INFO:root:Train (Epoch 190): Loss/seq after 03250 batchs: 349.1204833984375
INFO:root:Train (Epoch 190): Loss/seq after 03300 batchs: 348.3708190917969
INFO:root:Train (Epoch 190): Loss/seq after 03350 batchs: 346.24005126953125
INFO:root:Train (Epoch 190): Loss/seq after 03400 batchs: 343.69635009765625
INFO:root:Train (Epoch 190): Loss/seq after 03450 batchs: 341.94390869140625
INFO:root:Train (Epoch 190): Loss/seq after 03500 batchs: 342.97979736328125
INFO:root:Train (Epoch 190): Loss/seq after 03550 batchs: 341.67333984375
INFO:root:Train (Epoch 190): Loss/seq after 03600 batchs: 346.3361511230469
INFO:root:Train (Epoch 190): Loss/seq after 03650 batchs: 345.0378112792969
INFO:root:Train (Epoch 190): Loss/seq after 03700 batchs: 347.20758056640625
INFO:root:Train (Epoch 190): Loss/seq after 03750 batchs: 351.7900390625
INFO:root:Train (Epoch 190): Loss/seq after 03800 batchs: 351.65533447265625
INFO:root:Train (Epoch 190): Loss/seq after 03850 batchs: 351.32159423828125
INFO:root:Train (Epoch 190): Loss/seq after 03900 batchs: 352.9315490722656
INFO:root:Train (Epoch 190): Loss/seq after 03950 batchs: 354.55908203125
INFO:root:Train (Epoch 190): Loss/seq after 04000 batchs: 352.7041931152344
INFO:root:Train (Epoch 190): Loss/seq after 04050 batchs: 350.6309814453125
INFO:root:Train (Epoch 190): Loss/seq after 04100 batchs: 350.22210693359375
INFO:root:Train (Epoch 190): Loss/seq after 04150 batchs: 350.41180419921875
INFO:root:Train (Epoch 190): Loss/seq after 04200 batchs: 349.7041015625
INFO:root:Train (Epoch 190): Loss/seq after 04250 batchs: 348.69195556640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 190): Loss/seq after 00000 batches: 295.0643310546875
INFO:root:# Valid (Epoch 190): Loss/seq after 00050 batches: 605.3409423828125
INFO:root:# Valid (Epoch 190): Loss/seq after 00100 batches: 603.2111206054688
INFO:root:# Valid (Epoch 190): Loss/seq after 00150 batches: 458.7915344238281
INFO:root:# Valid (Epoch 190): Loss/seq after 00200 batches: 431.6741638183594
INFO:root:Artifacts: Make stick videos for epoch 190
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_190_on_20220422_150447.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_190_index_1404_on_20220422_150447.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 191): Loss/seq after 00000 batchs: 462.5143127441406
INFO:root:Train (Epoch 191): Loss/seq after 00050 batchs: 474.54547119140625
INFO:root:Train (Epoch 191): Loss/seq after 00100 batchs: 461.7265930175781
INFO:root:Train (Epoch 191): Loss/seq after 00150 batchs: 436.92926025390625
INFO:root:Train (Epoch 191): Loss/seq after 00200 batchs: 477.79705810546875
INFO:root:Train (Epoch 191): Loss/seq after 00250 batchs: 521.7832641601562
INFO:root:Train (Epoch 191): Loss/seq after 00300 batchs: 543.0169677734375
INFO:root:Train (Epoch 191): Loss/seq after 00350 batchs: 516.6155395507812
INFO:root:Train (Epoch 191): Loss/seq after 00400 batchs: 505.3773193359375
INFO:root:Train (Epoch 191): Loss/seq after 00450 batchs: 517.4728393554688
INFO:root:Train (Epoch 191): Loss/seq after 00500 batchs: 501.31976318359375
INFO:root:Train (Epoch 191): Loss/seq after 00550 batchs: 494.35076904296875
INFO:root:Train (Epoch 191): Loss/seq after 00600 batchs: 480.66424560546875
INFO:root:Train (Epoch 191): Loss/seq after 00650 batchs: 458.738037109375
INFO:root:Train (Epoch 191): Loss/seq after 00700 batchs: 438.62274169921875
INFO:root:Train (Epoch 191): Loss/seq after 00750 batchs: 428.1850280761719
INFO:root:Train (Epoch 191): Loss/seq after 00800 batchs: 434.1746826171875
INFO:root:Train (Epoch 191): Loss/seq after 00850 batchs: 420.2173767089844
INFO:root:Train (Epoch 191): Loss/seq after 00900 batchs: 410.1404724121094
INFO:root:Train (Epoch 191): Loss/seq after 00950 batchs: 406.97772216796875
INFO:root:Train (Epoch 191): Loss/seq after 01000 batchs: 399.3294677734375
INFO:root:Train (Epoch 191): Loss/seq after 01050 batchs: 392.56744384765625
INFO:root:Train (Epoch 191): Loss/seq after 01100 batchs: 384.0563659667969
INFO:root:Train (Epoch 191): Loss/seq after 01150 batchs: 373.564453125
INFO:root:Train (Epoch 191): Loss/seq after 01200 batchs: 377.4040832519531
INFO:root:Train (Epoch 191): Loss/seq after 01250 batchs: 377.35662841796875
INFO:root:Train (Epoch 191): Loss/seq after 01300 batchs: 367.98675537109375
INFO:root:Train (Epoch 191): Loss/seq after 01350 batchs: 359.6700134277344
INFO:root:Train (Epoch 191): Loss/seq after 01400 batchs: 360.2017517089844
INFO:root:Train (Epoch 191): Loss/seq after 01450 batchs: 364.2933654785156
INFO:root:Train (Epoch 191): Loss/seq after 01500 batchs: 371.61798095703125
INFO:root:Train (Epoch 191): Loss/seq after 01550 batchs: 372.3503723144531
INFO:root:Train (Epoch 191): Loss/seq after 01600 batchs: 370.4441223144531
INFO:root:Train (Epoch 191): Loss/seq after 01650 batchs: 369.8861999511719
INFO:root:Train (Epoch 191): Loss/seq after 01700 batchs: 375.2610168457031
INFO:root:Train (Epoch 191): Loss/seq after 01750 batchs: 374.3426818847656
INFO:root:Train (Epoch 191): Loss/seq after 01800 batchs: 373.3051452636719
INFO:root:Train (Epoch 191): Loss/seq after 01850 batchs: 371.9263000488281
INFO:root:Train (Epoch 191): Loss/seq after 01900 batchs: 371.8664855957031
INFO:root:Train (Epoch 191): Loss/seq after 01950 batchs: 372.00262451171875
INFO:root:Train (Epoch 191): Loss/seq after 02000 batchs: 373.6055908203125
INFO:root:Train (Epoch 191): Loss/seq after 02050 batchs: 374.15869140625
INFO:root:Train (Epoch 191): Loss/seq after 02100 batchs: 373.7568359375
INFO:root:Train (Epoch 191): Loss/seq after 02150 batchs: 373.7231140136719
INFO:root:Train (Epoch 191): Loss/seq after 02200 batchs: 373.27825927734375
INFO:root:Train (Epoch 191): Loss/seq after 02250 batchs: 372.603759765625
INFO:root:Train (Epoch 191): Loss/seq after 02300 batchs: 369.08868408203125
INFO:root:Train (Epoch 191): Loss/seq after 02350 batchs: 367.5797119140625
INFO:root:Train (Epoch 191): Loss/seq after 02400 batchs: 368.5771179199219
INFO:root:Train (Epoch 191): Loss/seq after 02450 batchs: 366.0677490234375
INFO:root:Train (Epoch 191): Loss/seq after 02500 batchs: 360.1980285644531
INFO:root:Train (Epoch 191): Loss/seq after 02550 batchs: 354.6980895996094
INFO:root:Train (Epoch 191): Loss/seq after 02600 batchs: 350.54669189453125
INFO:root:Train (Epoch 191): Loss/seq after 02650 batchs: 346.6048889160156
INFO:root:Train (Epoch 191): Loss/seq after 02700 batchs: 343.8291931152344
INFO:root:Train (Epoch 191): Loss/seq after 02750 batchs: 339.63653564453125
INFO:root:Train (Epoch 191): Loss/seq after 02800 batchs: 337.4467468261719
INFO:root:Train (Epoch 191): Loss/seq after 02850 batchs: 337.2089538574219
INFO:root:Train (Epoch 191): Loss/seq after 02900 batchs: 337.6958312988281
INFO:root:Train (Epoch 191): Loss/seq after 02950 batchs: 338.5212097167969
INFO:root:Train (Epoch 191): Loss/seq after 03000 batchs: 343.9066467285156
INFO:root:Train (Epoch 191): Loss/seq after 03050 batchs: 345.7967224121094
INFO:root:Train (Epoch 191): Loss/seq after 03100 batchs: 346.7040710449219
INFO:root:Train (Epoch 191): Loss/seq after 03150 batchs: 346.3830261230469
INFO:root:Train (Epoch 191): Loss/seq after 03200 batchs: 345.9317321777344
INFO:root:Train (Epoch 191): Loss/seq after 03250 batchs: 344.822265625
INFO:root:Train (Epoch 191): Loss/seq after 03300 batchs: 343.909423828125
INFO:root:Train (Epoch 191): Loss/seq after 03350 batchs: 341.8299255371094
INFO:root:Train (Epoch 191): Loss/seq after 03400 batchs: 339.523681640625
INFO:root:Train (Epoch 191): Loss/seq after 03450 batchs: 337.94696044921875
INFO:root:Train (Epoch 191): Loss/seq after 03500 batchs: 338.7884826660156
INFO:root:Train (Epoch 191): Loss/seq after 03550 batchs: 337.52105712890625
INFO:root:Train (Epoch 191): Loss/seq after 03600 batchs: 342.70758056640625
INFO:root:Train (Epoch 191): Loss/seq after 03650 batchs: 341.6330871582031
INFO:root:Train (Epoch 191): Loss/seq after 03700 batchs: 344.24505615234375
INFO:root:Train (Epoch 191): Loss/seq after 03750 batchs: 348.6979064941406
INFO:root:Train (Epoch 191): Loss/seq after 03800 batchs: 348.5611267089844
INFO:root:Train (Epoch 191): Loss/seq after 03850 batchs: 348.15008544921875
INFO:root:Train (Epoch 191): Loss/seq after 03900 batchs: 349.9367980957031
INFO:root:Train (Epoch 191): Loss/seq after 03950 batchs: 351.44281005859375
INFO:root:Train (Epoch 191): Loss/seq after 04000 batchs: 349.6039123535156
INFO:root:Train (Epoch 191): Loss/seq after 04050 batchs: 347.59466552734375
INFO:root:Train (Epoch 191): Loss/seq after 04100 batchs: 347.15765380859375
INFO:root:Train (Epoch 191): Loss/seq after 04150 batchs: 347.553955078125
INFO:root:Train (Epoch 191): Loss/seq after 04200 batchs: 346.8497009277344
INFO:root:Train (Epoch 191): Loss/seq after 04250 batchs: 345.8177795410156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 191): Loss/seq after 00000 batches: 253.94003295898438
INFO:root:# Valid (Epoch 191): Loss/seq after 00050 batches: 631.0070190429688
INFO:root:# Valid (Epoch 191): Loss/seq after 00100 batches: 597.93505859375
INFO:root:# Valid (Epoch 191): Loss/seq after 00150 batches: 462.6209716796875
INFO:root:# Valid (Epoch 191): Loss/seq after 00200 batches: 441.3672180175781
INFO:root:Artifacts: Make stick videos for epoch 191
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_191_on_20220422_150947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_191_index_783_on_20220422_150947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 192): Loss/seq after 00000 batchs: 501.7712097167969
INFO:root:Train (Epoch 192): Loss/seq after 00050 batchs: 485.5184020996094
INFO:root:Train (Epoch 192): Loss/seq after 00100 batchs: 488.3614196777344
INFO:root:Train (Epoch 192): Loss/seq after 00150 batchs: 469.3251647949219
INFO:root:Train (Epoch 192): Loss/seq after 00200 batchs: 504.2839660644531
INFO:root:Train (Epoch 192): Loss/seq after 00250 batchs: 550.5653076171875
INFO:root:Train (Epoch 192): Loss/seq after 00300 batchs: 566.1229858398438
INFO:root:Train (Epoch 192): Loss/seq after 00350 batchs: 536.136474609375
INFO:root:Train (Epoch 192): Loss/seq after 00400 batchs: 519.71826171875
INFO:root:Train (Epoch 192): Loss/seq after 00450 batchs: 529.5772705078125
INFO:root:Train (Epoch 192): Loss/seq after 00500 batchs: 509.8956604003906
INFO:root:Train (Epoch 192): Loss/seq after 00550 batchs: 502.10028076171875
INFO:root:Train (Epoch 192): Loss/seq after 00600 batchs: 486.94573974609375
INFO:root:Train (Epoch 192): Loss/seq after 00650 batchs: 465.9203186035156
INFO:root:Train (Epoch 192): Loss/seq after 00700 batchs: 444.1196594238281
INFO:root:Train (Epoch 192): Loss/seq after 00750 batchs: 434.102294921875
INFO:root:Train (Epoch 192): Loss/seq after 00800 batchs: 438.53265380859375
INFO:root:Train (Epoch 192): Loss/seq after 00850 batchs: 424.3425598144531
INFO:root:Train (Epoch 192): Loss/seq after 00900 batchs: 413.1886901855469
INFO:root:Train (Epoch 192): Loss/seq after 00950 batchs: 409.7536926269531
INFO:root:Train (Epoch 192): Loss/seq after 01000 batchs: 401.18792724609375
INFO:root:Train (Epoch 192): Loss/seq after 01050 batchs: 393.6514587402344
INFO:root:Train (Epoch 192): Loss/seq after 01100 batchs: 384.85321044921875
INFO:root:Train (Epoch 192): Loss/seq after 01150 batchs: 374.0509033203125
INFO:root:Train (Epoch 192): Loss/seq after 01200 batchs: 378.1880798339844
INFO:root:Train (Epoch 192): Loss/seq after 01250 batchs: 377.7082214355469
INFO:root:Train (Epoch 192): Loss/seq after 01300 batchs: 368.112548828125
INFO:root:Train (Epoch 192): Loss/seq after 01350 batchs: 359.7610778808594
INFO:root:Train (Epoch 192): Loss/seq after 01400 batchs: 359.65728759765625
INFO:root:Train (Epoch 192): Loss/seq after 01450 batchs: 363.4084167480469
INFO:root:Train (Epoch 192): Loss/seq after 01500 batchs: 370.44195556640625
INFO:root:Train (Epoch 192): Loss/seq after 01550 batchs: 370.690673828125
INFO:root:Train (Epoch 192): Loss/seq after 01600 batchs: 368.5203857421875
INFO:root:Train (Epoch 192): Loss/seq after 01650 batchs: 367.8193054199219
INFO:root:Train (Epoch 192): Loss/seq after 01700 batchs: 373.5090026855469
INFO:root:Train (Epoch 192): Loss/seq after 01750 batchs: 372.46954345703125
INFO:root:Train (Epoch 192): Loss/seq after 01800 batchs: 371.6033020019531
INFO:root:Train (Epoch 192): Loss/seq after 01850 batchs: 370.1630859375
INFO:root:Train (Epoch 192): Loss/seq after 01900 batchs: 369.97747802734375
INFO:root:Train (Epoch 192): Loss/seq after 01950 batchs: 370.0352783203125
INFO:root:Train (Epoch 192): Loss/seq after 02000 batchs: 371.60040283203125
INFO:root:Train (Epoch 192): Loss/seq after 02050 batchs: 372.18182373046875
INFO:root:Train (Epoch 192): Loss/seq after 02100 batchs: 372.36492919921875
INFO:root:Train (Epoch 192): Loss/seq after 02150 batchs: 372.3398132324219
INFO:root:Train (Epoch 192): Loss/seq after 02200 batchs: 371.8668518066406
INFO:root:Train (Epoch 192): Loss/seq after 02250 batchs: 371.0622253417969
INFO:root:Train (Epoch 192): Loss/seq after 02300 batchs: 368.2944030761719
INFO:root:Train (Epoch 192): Loss/seq after 02350 batchs: 366.4925537109375
INFO:root:Train (Epoch 192): Loss/seq after 02400 batchs: 367.4629821777344
INFO:root:Train (Epoch 192): Loss/seq after 02450 batchs: 364.9273376464844
INFO:root:Train (Epoch 192): Loss/seq after 02500 batchs: 359.09332275390625
INFO:root:Train (Epoch 192): Loss/seq after 02550 batchs: 353.7239074707031
INFO:root:Train (Epoch 192): Loss/seq after 02600 batchs: 349.46600341796875
INFO:root:Train (Epoch 192): Loss/seq after 02650 batchs: 345.5958251953125
INFO:root:Train (Epoch 192): Loss/seq after 02700 batchs: 342.7953796386719
INFO:root:Train (Epoch 192): Loss/seq after 02750 batchs: 338.7331848144531
INFO:root:Train (Epoch 192): Loss/seq after 02800 batchs: 336.1769104003906
INFO:root:Train (Epoch 192): Loss/seq after 02850 batchs: 336.0107727050781
INFO:root:Train (Epoch 192): Loss/seq after 02900 batchs: 336.7779846191406
INFO:root:Train (Epoch 192): Loss/seq after 02950 batchs: 337.68060302734375
INFO:root:Train (Epoch 192): Loss/seq after 03000 batchs: 343.1698303222656
INFO:root:Train (Epoch 192): Loss/seq after 03050 batchs: 344.7599182128906
INFO:root:Train (Epoch 192): Loss/seq after 03100 batchs: 346.2663269042969
INFO:root:Train (Epoch 192): Loss/seq after 03150 batchs: 345.5368957519531
INFO:root:Train (Epoch 192): Loss/seq after 03200 batchs: 344.93267822265625
INFO:root:Train (Epoch 192): Loss/seq after 03250 batchs: 344.0755615234375
INFO:root:Train (Epoch 192): Loss/seq after 03300 batchs: 343.26171875
INFO:root:Train (Epoch 192): Loss/seq after 03350 batchs: 341.1097106933594
INFO:root:Train (Epoch 192): Loss/seq after 03400 batchs: 338.6736755371094
INFO:root:Train (Epoch 192): Loss/seq after 03450 batchs: 337.0298156738281
INFO:root:Train (Epoch 192): Loss/seq after 03500 batchs: 337.7935485839844
INFO:root:Train (Epoch 192): Loss/seq after 03550 batchs: 336.45556640625
INFO:root:Train (Epoch 192): Loss/seq after 03600 batchs: 340.849853515625
INFO:root:Train (Epoch 192): Loss/seq after 03650 batchs: 339.7502746582031
INFO:root:Train (Epoch 192): Loss/seq after 03700 batchs: 342.12066650390625
INFO:root:Train (Epoch 192): Loss/seq after 03750 batchs: 346.48382568359375
INFO:root:Train (Epoch 192): Loss/seq after 03800 batchs: 346.42132568359375
INFO:root:Train (Epoch 192): Loss/seq after 03850 batchs: 346.0438232421875
INFO:root:Train (Epoch 192): Loss/seq after 03900 batchs: 346.8836364746094
INFO:root:Train (Epoch 192): Loss/seq after 03950 batchs: 348.0245666503906
INFO:root:Train (Epoch 192): Loss/seq after 04000 batchs: 346.2265319824219
INFO:root:Train (Epoch 192): Loss/seq after 04050 batchs: 344.22735595703125
INFO:root:Train (Epoch 192): Loss/seq after 04100 batchs: 343.9407958984375
INFO:root:Train (Epoch 192): Loss/seq after 04150 batchs: 344.3426208496094
INFO:root:Train (Epoch 192): Loss/seq after 04200 batchs: 343.5834045410156
INFO:root:Train (Epoch 192): Loss/seq after 04250 batchs: 342.5980224609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 192): Loss/seq after 00000 batches: 290.3524475097656
INFO:root:# Valid (Epoch 192): Loss/seq after 00050 batches: 630.735107421875
INFO:root:# Valid (Epoch 192): Loss/seq after 00100 batches: 609.2930908203125
INFO:root:# Valid (Epoch 192): Loss/seq after 00150 batches: 467.9365234375
INFO:root:# Valid (Epoch 192): Loss/seq after 00200 batches: 439.7085266113281
INFO:root:Artifacts: Make stick videos for epoch 192
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_192_on_20220422_151441.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_192_index_1095_on_20220422_151441.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 193): Loss/seq after 00000 batchs: 501.286865234375
INFO:root:Train (Epoch 193): Loss/seq after 00050 batchs: 478.0575866699219
INFO:root:Train (Epoch 193): Loss/seq after 00100 batchs: 480.3922424316406
INFO:root:Train (Epoch 193): Loss/seq after 00150 batchs: 452.3381652832031
INFO:root:Train (Epoch 193): Loss/seq after 00200 batchs: 483.6192321777344
INFO:root:Train (Epoch 193): Loss/seq after 00250 batchs: 514.8216552734375
INFO:root:Train (Epoch 193): Loss/seq after 00300 batchs: 535.1676635742188
INFO:root:Train (Epoch 193): Loss/seq after 00350 batchs: 509.9583740234375
INFO:root:Train (Epoch 193): Loss/seq after 00400 batchs: 495.8797607421875
INFO:root:Train (Epoch 193): Loss/seq after 00450 batchs: 508.3961181640625
INFO:root:Train (Epoch 193): Loss/seq after 00500 batchs: 490.6822509765625
INFO:root:Train (Epoch 193): Loss/seq after 00550 batchs: 484.3968505859375
INFO:root:Train (Epoch 193): Loss/seq after 00600 batchs: 471.6646728515625
INFO:root:Train (Epoch 193): Loss/seq after 00650 batchs: 451.576416015625
INFO:root:Train (Epoch 193): Loss/seq after 00700 batchs: 430.9192199707031
INFO:root:Train (Epoch 193): Loss/seq after 00750 batchs: 420.9033508300781
INFO:root:Train (Epoch 193): Loss/seq after 00800 batchs: 426.7934875488281
INFO:root:Train (Epoch 193): Loss/seq after 00850 batchs: 412.4711608886719
INFO:root:Train (Epoch 193): Loss/seq after 00900 batchs: 401.97576904296875
INFO:root:Train (Epoch 193): Loss/seq after 00950 batchs: 399.35479736328125
INFO:root:Train (Epoch 193): Loss/seq after 01000 batchs: 391.7616271972656
INFO:root:Train (Epoch 193): Loss/seq after 01050 batchs: 385.3646240234375
INFO:root:Train (Epoch 193): Loss/seq after 01100 batchs: 377.68365478515625
INFO:root:Train (Epoch 193): Loss/seq after 01150 batchs: 367.5832214355469
INFO:root:Train (Epoch 193): Loss/seq after 01200 batchs: 371.965576171875
INFO:root:Train (Epoch 193): Loss/seq after 01250 batchs: 371.82672119140625
INFO:root:Train (Epoch 193): Loss/seq after 01300 batchs: 362.7835388183594
INFO:root:Train (Epoch 193): Loss/seq after 01350 batchs: 355.2077331542969
INFO:root:Train (Epoch 193): Loss/seq after 01400 batchs: 356.2569274902344
INFO:root:Train (Epoch 193): Loss/seq after 01450 batchs: 360.0694885253906
INFO:root:Train (Epoch 193): Loss/seq after 01500 batchs: 367.0155334472656
INFO:root:Train (Epoch 193): Loss/seq after 01550 batchs: 367.5582275390625
INFO:root:Train (Epoch 193): Loss/seq after 01600 batchs: 365.6475524902344
INFO:root:Train (Epoch 193): Loss/seq after 01650 batchs: 364.9278259277344
INFO:root:Train (Epoch 193): Loss/seq after 01700 batchs: 370.4655456542969
INFO:root:Train (Epoch 193): Loss/seq after 01750 batchs: 369.3653869628906
INFO:root:Train (Epoch 193): Loss/seq after 01800 batchs: 368.4229431152344
INFO:root:Train (Epoch 193): Loss/seq after 01850 batchs: 367.1336975097656
INFO:root:Train (Epoch 193): Loss/seq after 01900 batchs: 366.96881103515625
INFO:root:Train (Epoch 193): Loss/seq after 01950 batchs: 367.0251770019531
INFO:root:Train (Epoch 193): Loss/seq after 02000 batchs: 368.5843200683594
INFO:root:Train (Epoch 193): Loss/seq after 02050 batchs: 369.0560607910156
INFO:root:Train (Epoch 193): Loss/seq after 02100 batchs: 368.6103515625
INFO:root:Train (Epoch 193): Loss/seq after 02150 batchs: 368.4675598144531
INFO:root:Train (Epoch 193): Loss/seq after 02200 batchs: 368.1925354003906
INFO:root:Train (Epoch 193): Loss/seq after 02250 batchs: 367.16961669921875
INFO:root:Train (Epoch 193): Loss/seq after 02300 batchs: 363.6627197265625
INFO:root:Train (Epoch 193): Loss/seq after 02350 batchs: 361.81085205078125
INFO:root:Train (Epoch 193): Loss/seq after 02400 batchs: 362.6748962402344
INFO:root:Train (Epoch 193): Loss/seq after 02450 batchs: 360.1697082519531
INFO:root:Train (Epoch 193): Loss/seq after 02500 batchs: 354.3919982910156
INFO:root:Train (Epoch 193): Loss/seq after 02550 batchs: 349.00115966796875
INFO:root:Train (Epoch 193): Loss/seq after 02600 batchs: 344.7983093261719
INFO:root:Train (Epoch 193): Loss/seq after 02650 batchs: 340.9482116699219
INFO:root:Train (Epoch 193): Loss/seq after 02700 batchs: 338.23565673828125
INFO:root:Train (Epoch 193): Loss/seq after 02750 batchs: 334.24615478515625
INFO:root:Train (Epoch 193): Loss/seq after 02800 batchs: 331.9128112792969
INFO:root:Train (Epoch 193): Loss/seq after 02850 batchs: 331.95361328125
INFO:root:Train (Epoch 193): Loss/seq after 02900 batchs: 332.6025695800781
INFO:root:Train (Epoch 193): Loss/seq after 02950 batchs: 333.54095458984375
INFO:root:Train (Epoch 193): Loss/seq after 03000 batchs: 338.96051025390625
INFO:root:Train (Epoch 193): Loss/seq after 03050 batchs: 340.89837646484375
INFO:root:Train (Epoch 193): Loss/seq after 03100 batchs: 341.9690856933594
INFO:root:Train (Epoch 193): Loss/seq after 03150 batchs: 341.0743103027344
INFO:root:Train (Epoch 193): Loss/seq after 03200 batchs: 340.3301696777344
INFO:root:Train (Epoch 193): Loss/seq after 03250 batchs: 340.38134765625
INFO:root:Train (Epoch 193): Loss/seq after 03300 batchs: 340.34881591796875
INFO:root:Train (Epoch 193): Loss/seq after 03350 batchs: 338.4282531738281
INFO:root:Train (Epoch 193): Loss/seq after 03400 batchs: 336.0735778808594
INFO:root:Train (Epoch 193): Loss/seq after 03450 batchs: 334.4109191894531
INFO:root:Train (Epoch 193): Loss/seq after 03500 batchs: 335.343017578125
INFO:root:Train (Epoch 193): Loss/seq after 03550 batchs: 334.003173828125
INFO:root:Train (Epoch 193): Loss/seq after 03600 batchs: 338.66668701171875
INFO:root:Train (Epoch 193): Loss/seq after 03650 batchs: 337.70538330078125
INFO:root:Train (Epoch 193): Loss/seq after 03700 batchs: 340.1575927734375
INFO:root:Train (Epoch 193): Loss/seq after 03750 batchs: 344.6592712402344
INFO:root:Train (Epoch 193): Loss/seq after 03800 batchs: 344.6229553222656
INFO:root:Train (Epoch 193): Loss/seq after 03850 batchs: 344.2692565917969
INFO:root:Train (Epoch 193): Loss/seq after 03900 batchs: 345.4682922363281
INFO:root:Train (Epoch 193): Loss/seq after 03950 batchs: 346.94598388671875
INFO:root:Train (Epoch 193): Loss/seq after 04000 batchs: 345.14227294921875
INFO:root:Train (Epoch 193): Loss/seq after 04050 batchs: 343.1324768066406
INFO:root:Train (Epoch 193): Loss/seq after 04100 batchs: 342.77703857421875
INFO:root:Train (Epoch 193): Loss/seq after 04150 batchs: 343.1009521484375
INFO:root:Train (Epoch 193): Loss/seq after 04200 batchs: 342.3996276855469
INFO:root:Train (Epoch 193): Loss/seq after 04250 batchs: 341.35821533203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 193): Loss/seq after 00000 batches: 267.1494445800781
INFO:root:# Valid (Epoch 193): Loss/seq after 00050 batches: 622.8064575195312
INFO:root:# Valid (Epoch 193): Loss/seq after 00100 batches: 608.7725830078125
INFO:root:# Valid (Epoch 193): Loss/seq after 00150 batches: 467.6506652832031
INFO:root:# Valid (Epoch 193): Loss/seq after 00200 batches: 434.79205322265625
INFO:root:Artifacts: Make stick videos for epoch 193
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_193_on_20220422_151925.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_193_index_32_on_20220422_151925.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 194): Loss/seq after 00000 batchs: 548.3917846679688
INFO:root:Train (Epoch 194): Loss/seq after 00050 batchs: 476.7364196777344
INFO:root:Train (Epoch 194): Loss/seq after 00100 batchs: 469.3594055175781
INFO:root:Train (Epoch 194): Loss/seq after 00150 batchs: 447.0787353515625
INFO:root:Train (Epoch 194): Loss/seq after 00200 batchs: 479.7380676269531
INFO:root:Train (Epoch 194): Loss/seq after 00250 batchs: 506.3690185546875
INFO:root:Train (Epoch 194): Loss/seq after 00300 batchs: 529.0730590820312
INFO:root:Train (Epoch 194): Loss/seq after 00350 batchs: 504.8145446777344
INFO:root:Train (Epoch 194): Loss/seq after 00400 batchs: 488.7403259277344
INFO:root:Train (Epoch 194): Loss/seq after 00450 batchs: 501.8473815917969
INFO:root:Train (Epoch 194): Loss/seq after 00500 batchs: 484.56170654296875
INFO:root:Train (Epoch 194): Loss/seq after 00550 batchs: 478.6221008300781
INFO:root:Train (Epoch 194): Loss/seq after 00600 batchs: 465.2886657714844
INFO:root:Train (Epoch 194): Loss/seq after 00650 batchs: 445.03802490234375
INFO:root:Train (Epoch 194): Loss/seq after 00700 batchs: 425.0472717285156
INFO:root:Train (Epoch 194): Loss/seq after 00750 batchs: 415.1939697265625
INFO:root:Train (Epoch 194): Loss/seq after 00800 batchs: 420.305419921875
INFO:root:Train (Epoch 194): Loss/seq after 00850 batchs: 407.11041259765625
INFO:root:Train (Epoch 194): Loss/seq after 00900 batchs: 397.37738037109375
INFO:root:Train (Epoch 194): Loss/seq after 00950 batchs: 394.2437438964844
INFO:root:Train (Epoch 194): Loss/seq after 01000 batchs: 385.969482421875
INFO:root:Train (Epoch 194): Loss/seq after 01050 batchs: 379.16845703125
INFO:root:Train (Epoch 194): Loss/seq after 01100 batchs: 371.5843200683594
INFO:root:Train (Epoch 194): Loss/seq after 01150 batchs: 361.5749816894531
INFO:root:Train (Epoch 194): Loss/seq after 01200 batchs: 365.6905517578125
INFO:root:Train (Epoch 194): Loss/seq after 01250 batchs: 365.767822265625
INFO:root:Train (Epoch 194): Loss/seq after 01300 batchs: 356.8174133300781
INFO:root:Train (Epoch 194): Loss/seq after 01350 batchs: 348.7737121582031
INFO:root:Train (Epoch 194): Loss/seq after 01400 batchs: 349.0118713378906
INFO:root:Train (Epoch 194): Loss/seq after 01450 batchs: 353.2096862792969
INFO:root:Train (Epoch 194): Loss/seq after 01500 batchs: 360.9099426269531
INFO:root:Train (Epoch 194): Loss/seq after 01550 batchs: 363.16412353515625
INFO:root:Train (Epoch 194): Loss/seq after 01600 batchs: 361.9241638183594
INFO:root:Train (Epoch 194): Loss/seq after 01650 batchs: 361.580810546875
INFO:root:Train (Epoch 194): Loss/seq after 01700 batchs: 367.1680603027344
INFO:root:Train (Epoch 194): Loss/seq after 01750 batchs: 366.104736328125
INFO:root:Train (Epoch 194): Loss/seq after 01800 batchs: 365.06390380859375
INFO:root:Train (Epoch 194): Loss/seq after 01850 batchs: 363.8707275390625
INFO:root:Train (Epoch 194): Loss/seq after 01900 batchs: 363.40777587890625
INFO:root:Train (Epoch 194): Loss/seq after 01950 batchs: 363.53289794921875
INFO:root:Train (Epoch 194): Loss/seq after 02000 batchs: 365.1648864746094
INFO:root:Train (Epoch 194): Loss/seq after 02050 batchs: 365.5966796875
INFO:root:Train (Epoch 194): Loss/seq after 02100 batchs: 365.19049072265625
INFO:root:Train (Epoch 194): Loss/seq after 02150 batchs: 365.2214050292969
INFO:root:Train (Epoch 194): Loss/seq after 02200 batchs: 364.9532775878906
INFO:root:Train (Epoch 194): Loss/seq after 02250 batchs: 364.18328857421875
INFO:root:Train (Epoch 194): Loss/seq after 02300 batchs: 360.8148498535156
INFO:root:Train (Epoch 194): Loss/seq after 02350 batchs: 359.0724182128906
INFO:root:Train (Epoch 194): Loss/seq after 02400 batchs: 360.01513671875
INFO:root:Train (Epoch 194): Loss/seq after 02450 batchs: 357.5808410644531
INFO:root:Train (Epoch 194): Loss/seq after 02500 batchs: 351.8359680175781
INFO:root:Train (Epoch 194): Loss/seq after 02550 batchs: 346.5591125488281
INFO:root:Train (Epoch 194): Loss/seq after 02600 batchs: 342.332763671875
INFO:root:Train (Epoch 194): Loss/seq after 02650 batchs: 338.515380859375
INFO:root:Train (Epoch 194): Loss/seq after 02700 batchs: 335.9209289550781
INFO:root:Train (Epoch 194): Loss/seq after 02750 batchs: 332.0709228515625
INFO:root:Train (Epoch 194): Loss/seq after 02800 batchs: 329.9979553222656
INFO:root:Train (Epoch 194): Loss/seq after 02850 batchs: 329.868896484375
INFO:root:Train (Epoch 194): Loss/seq after 02900 batchs: 330.4041748046875
INFO:root:Train (Epoch 194): Loss/seq after 02950 batchs: 331.2933044433594
INFO:root:Train (Epoch 194): Loss/seq after 03000 batchs: 336.7174072265625
INFO:root:Train (Epoch 194): Loss/seq after 03050 batchs: 338.5387268066406
INFO:root:Train (Epoch 194): Loss/seq after 03100 batchs: 339.4672546386719
INFO:root:Train (Epoch 194): Loss/seq after 03150 batchs: 338.7306213378906
INFO:root:Train (Epoch 194): Loss/seq after 03200 batchs: 338.0893249511719
INFO:root:Train (Epoch 194): Loss/seq after 03250 batchs: 336.9525146484375
INFO:root:Train (Epoch 194): Loss/seq after 03300 batchs: 336.4222717285156
INFO:root:Train (Epoch 194): Loss/seq after 03350 batchs: 334.6045227050781
INFO:root:Train (Epoch 194): Loss/seq after 03400 batchs: 332.24554443359375
INFO:root:Train (Epoch 194): Loss/seq after 03450 batchs: 330.7193298339844
INFO:root:Train (Epoch 194): Loss/seq after 03500 batchs: 331.8603820800781
INFO:root:Train (Epoch 194): Loss/seq after 03550 batchs: 331.0080871582031
INFO:root:Train (Epoch 194): Loss/seq after 03600 batchs: 335.8414306640625
INFO:root:Train (Epoch 194): Loss/seq after 03650 batchs: 335.2591552734375
INFO:root:Train (Epoch 194): Loss/seq after 03700 batchs: 338.0909423828125
INFO:root:Train (Epoch 194): Loss/seq after 03750 batchs: 342.7333679199219
INFO:root:Train (Epoch 194): Loss/seq after 03800 batchs: 342.694580078125
INFO:root:Train (Epoch 194): Loss/seq after 03850 batchs: 342.4268798828125
INFO:root:Train (Epoch 194): Loss/seq after 03900 batchs: 343.4106750488281
INFO:root:Train (Epoch 194): Loss/seq after 03950 batchs: 345.5433654785156
INFO:root:Train (Epoch 194): Loss/seq after 04000 batchs: 343.7811279296875
INFO:root:Train (Epoch 194): Loss/seq after 04050 batchs: 341.80499267578125
INFO:root:Train (Epoch 194): Loss/seq after 04100 batchs: 341.36846923828125
INFO:root:Train (Epoch 194): Loss/seq after 04150 batchs: 341.6649475097656
INFO:root:Train (Epoch 194): Loss/seq after 04200 batchs: 340.95184326171875
INFO:root:Train (Epoch 194): Loss/seq after 04250 batchs: 339.9414978027344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 194): Loss/seq after 00000 batches: 215.8586883544922
INFO:root:# Valid (Epoch 194): Loss/seq after 00050 batches: 612.209716796875
INFO:root:# Valid (Epoch 194): Loss/seq after 00100 batches: 581.2351684570312
INFO:root:# Valid (Epoch 194): Loss/seq after 00150 batches: 445.8263244628906
INFO:root:# Valid (Epoch 194): Loss/seq after 00200 batches: 417.59991455078125
INFO:root:Artifacts: Make stick videos for epoch 194
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_194_on_20220422_152415.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_194_index_1015_on_20220422_152415.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 195): Loss/seq after 00000 batchs: 493.62847900390625
INFO:root:Train (Epoch 195): Loss/seq after 00050 batchs: 487.3590393066406
INFO:root:Train (Epoch 195): Loss/seq after 00100 batchs: 497.3493957519531
INFO:root:Train (Epoch 195): Loss/seq after 00150 batchs: 463.752685546875
INFO:root:Train (Epoch 195): Loss/seq after 00200 batchs: 494.63067626953125
INFO:root:Train (Epoch 195): Loss/seq after 00250 batchs: 544.217041015625
INFO:root:Train (Epoch 195): Loss/seq after 00300 batchs: 562.0840454101562
INFO:root:Train (Epoch 195): Loss/seq after 00350 batchs: 534.4322509765625
INFO:root:Train (Epoch 195): Loss/seq after 00400 batchs: 515.3074340820312
INFO:root:Train (Epoch 195): Loss/seq after 00450 batchs: 525.516845703125
INFO:root:Train (Epoch 195): Loss/seq after 00500 batchs: 506.5106506347656
INFO:root:Train (Epoch 195): Loss/seq after 00550 batchs: 499.45672607421875
INFO:root:Train (Epoch 195): Loss/seq after 00600 batchs: 486.06878662109375
INFO:root:Train (Epoch 195): Loss/seq after 00650 batchs: 464.90692138671875
INFO:root:Train (Epoch 195): Loss/seq after 00700 batchs: 442.8604736328125
INFO:root:Train (Epoch 195): Loss/seq after 00750 batchs: 431.8184814453125
INFO:root:Train (Epoch 195): Loss/seq after 00800 batchs: 436.9274597167969
INFO:root:Train (Epoch 195): Loss/seq after 00850 batchs: 422.7659912109375
INFO:root:Train (Epoch 195): Loss/seq after 00900 batchs: 411.7445373535156
INFO:root:Train (Epoch 195): Loss/seq after 00950 batchs: 408.4634704589844
INFO:root:Train (Epoch 195): Loss/seq after 01000 batchs: 400.4275817871094
INFO:root:Train (Epoch 195): Loss/seq after 01050 batchs: 392.6391296386719
INFO:root:Train (Epoch 195): Loss/seq after 01100 batchs: 384.1788330078125
INFO:root:Train (Epoch 195): Loss/seq after 01150 batchs: 373.427734375
INFO:root:Train (Epoch 195): Loss/seq after 01200 batchs: 377.5806884765625
INFO:root:Train (Epoch 195): Loss/seq after 01250 batchs: 377.0617370605469
INFO:root:Train (Epoch 195): Loss/seq after 01300 batchs: 367.74810791015625
INFO:root:Train (Epoch 195): Loss/seq after 01350 batchs: 359.5522766113281
INFO:root:Train (Epoch 195): Loss/seq after 01400 batchs: 359.4665222167969
INFO:root:Train (Epoch 195): Loss/seq after 01450 batchs: 363.2580871582031
INFO:root:Train (Epoch 195): Loss/seq after 01500 batchs: 369.8587646484375
INFO:root:Train (Epoch 195): Loss/seq after 01550 batchs: 369.96044921875
INFO:root:Train (Epoch 195): Loss/seq after 01600 batchs: 367.6361389160156
INFO:root:Train (Epoch 195): Loss/seq after 01650 batchs: 366.8232727050781
INFO:root:Train (Epoch 195): Loss/seq after 01700 batchs: 371.9685974121094
INFO:root:Train (Epoch 195): Loss/seq after 01750 batchs: 371.0517578125
INFO:root:Train (Epoch 195): Loss/seq after 01800 batchs: 369.95172119140625
INFO:root:Train (Epoch 195): Loss/seq after 01850 batchs: 368.58837890625
INFO:root:Train (Epoch 195): Loss/seq after 01900 batchs: 368.05682373046875
INFO:root:Train (Epoch 195): Loss/seq after 01950 batchs: 368.33599853515625
INFO:root:Train (Epoch 195): Loss/seq after 02000 batchs: 370.22515869140625
INFO:root:Train (Epoch 195): Loss/seq after 02050 batchs: 370.8242492675781
INFO:root:Train (Epoch 195): Loss/seq after 02100 batchs: 370.21697998046875
INFO:root:Train (Epoch 195): Loss/seq after 02150 batchs: 370.072265625
INFO:root:Train (Epoch 195): Loss/seq after 02200 batchs: 369.53594970703125
INFO:root:Train (Epoch 195): Loss/seq after 02250 batchs: 368.3244323730469
INFO:root:Train (Epoch 195): Loss/seq after 02300 batchs: 365.55645751953125
INFO:root:Train (Epoch 195): Loss/seq after 02350 batchs: 363.57293701171875
INFO:root:Train (Epoch 195): Loss/seq after 02400 batchs: 364.26513671875
INFO:root:Train (Epoch 195): Loss/seq after 02450 batchs: 361.7627868652344
INFO:root:Train (Epoch 195): Loss/seq after 02500 batchs: 355.92596435546875
INFO:root:Train (Epoch 195): Loss/seq after 02550 batchs: 350.5025634765625
INFO:root:Train (Epoch 195): Loss/seq after 02600 batchs: 346.31292724609375
INFO:root:Train (Epoch 195): Loss/seq after 02650 batchs: 342.59112548828125
INFO:root:Train (Epoch 195): Loss/seq after 02700 batchs: 339.8740539550781
INFO:root:Train (Epoch 195): Loss/seq after 02750 batchs: 336.0127868652344
INFO:root:Train (Epoch 195): Loss/seq after 02800 batchs: 334.3586730957031
INFO:root:Train (Epoch 195): Loss/seq after 02850 batchs: 334.3250732421875
INFO:root:Train (Epoch 195): Loss/seq after 02900 batchs: 335.2209167480469
INFO:root:Train (Epoch 195): Loss/seq after 02950 batchs: 336.1407165527344
INFO:root:Train (Epoch 195): Loss/seq after 03000 batchs: 341.20269775390625
INFO:root:Train (Epoch 195): Loss/seq after 03050 batchs: 343.00927734375
INFO:root:Train (Epoch 195): Loss/seq after 03100 batchs: 344.5476379394531
INFO:root:Train (Epoch 195): Loss/seq after 03150 batchs: 343.9715576171875
INFO:root:Train (Epoch 195): Loss/seq after 03200 batchs: 343.7027893066406
INFO:root:Train (Epoch 195): Loss/seq after 03250 batchs: 343.3648376464844
INFO:root:Train (Epoch 195): Loss/seq after 03300 batchs: 342.9914855957031
INFO:root:Train (Epoch 195): Loss/seq after 03350 batchs: 341.2838134765625
INFO:root:Train (Epoch 195): Loss/seq after 03400 batchs: 338.8502502441406
INFO:root:Train (Epoch 195): Loss/seq after 03450 batchs: 337.4302978515625
INFO:root:Train (Epoch 195): Loss/seq after 03500 batchs: 339.1442565917969
INFO:root:Train (Epoch 195): Loss/seq after 03550 batchs: 338.738525390625
INFO:root:Train (Epoch 195): Loss/seq after 03600 batchs: 343.0864562988281
INFO:root:Train (Epoch 195): Loss/seq after 03650 batchs: 342.27337646484375
INFO:root:Train (Epoch 195): Loss/seq after 03700 batchs: 345.5514831542969
INFO:root:Train (Epoch 195): Loss/seq after 03750 batchs: 350.13421630859375
INFO:root:Train (Epoch 195): Loss/seq after 03800 batchs: 349.98321533203125
INFO:root:Train (Epoch 195): Loss/seq after 03850 batchs: 349.61126708984375
INFO:root:Train (Epoch 195): Loss/seq after 03900 batchs: 350.4925537109375
INFO:root:Train (Epoch 195): Loss/seq after 03950 batchs: 351.8994445800781
INFO:root:Train (Epoch 195): Loss/seq after 04000 batchs: 350.075439453125
INFO:root:Train (Epoch 195): Loss/seq after 04050 batchs: 348.02197265625
INFO:root:Train (Epoch 195): Loss/seq after 04100 batchs: 347.5710144042969
INFO:root:Train (Epoch 195): Loss/seq after 04150 batchs: 347.9631652832031
INFO:root:Train (Epoch 195): Loss/seq after 04200 batchs: 347.3239440917969
INFO:root:Train (Epoch 195): Loss/seq after 04250 batchs: 346.2717590332031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 195): Loss/seq after 00000 batches: 216.53909301757812
INFO:root:# Valid (Epoch 195): Loss/seq after 00050 batches: 659.8328247070312
INFO:root:# Valid (Epoch 195): Loss/seq after 00100 batches: 600.5198974609375
INFO:root:# Valid (Epoch 195): Loss/seq after 00150 batches: 457.15350341796875
INFO:root:# Valid (Epoch 195): Loss/seq after 00200 batches: 427.9683837890625
INFO:root:Artifacts: Make stick videos for epoch 195
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_195_on_20220422_152858.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_195_index_1718_on_20220422_152858.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 196): Loss/seq after 00000 batchs: 553.979736328125
INFO:root:Train (Epoch 196): Loss/seq after 00050 batchs: 471.6441650390625
INFO:root:Train (Epoch 196): Loss/seq after 00100 batchs: 465.3828430175781
INFO:root:Train (Epoch 196): Loss/seq after 00150 batchs: 443.19049072265625
INFO:root:Train (Epoch 196): Loss/seq after 00200 batchs: 492.5955505371094
INFO:root:Train (Epoch 196): Loss/seq after 00250 batchs: 535.1857299804688
INFO:root:Train (Epoch 196): Loss/seq after 00300 batchs: 554.0597534179688
INFO:root:Train (Epoch 196): Loss/seq after 00350 batchs: 525.0148315429688
INFO:root:Train (Epoch 196): Loss/seq after 00400 batchs: 510.763427734375
INFO:root:Train (Epoch 196): Loss/seq after 00450 batchs: 521.9822998046875
INFO:root:Train (Epoch 196): Loss/seq after 00500 batchs: 504.8899230957031
INFO:root:Train (Epoch 196): Loss/seq after 00550 batchs: 498.07464599609375
INFO:root:Train (Epoch 196): Loss/seq after 00600 batchs: 483.8424377441406
INFO:root:Train (Epoch 196): Loss/seq after 00650 batchs: 462.89434814453125
INFO:root:Train (Epoch 196): Loss/seq after 00700 batchs: 440.96173095703125
INFO:root:Train (Epoch 196): Loss/seq after 00750 batchs: 430.6197814941406
INFO:root:Train (Epoch 196): Loss/seq after 00800 batchs: 435.34423828125
INFO:root:Train (Epoch 196): Loss/seq after 00850 batchs: 421.6079406738281
INFO:root:Train (Epoch 196): Loss/seq after 00900 batchs: 410.766845703125
INFO:root:Train (Epoch 196): Loss/seq after 00950 batchs: 407.48992919921875
INFO:root:Train (Epoch 196): Loss/seq after 01000 batchs: 399.5228271484375
INFO:root:Train (Epoch 196): Loss/seq after 01050 batchs: 391.86688232421875
INFO:root:Train (Epoch 196): Loss/seq after 01100 batchs: 383.3670959472656
INFO:root:Train (Epoch 196): Loss/seq after 01150 batchs: 372.86383056640625
INFO:root:Train (Epoch 196): Loss/seq after 01200 batchs: 375.6540222167969
INFO:root:Train (Epoch 196): Loss/seq after 01250 batchs: 374.9527587890625
INFO:root:Train (Epoch 196): Loss/seq after 01300 batchs: 365.7064514160156
INFO:root:Train (Epoch 196): Loss/seq after 01350 batchs: 357.1104736328125
INFO:root:Train (Epoch 196): Loss/seq after 01400 batchs: 356.8898620605469
INFO:root:Train (Epoch 196): Loss/seq after 01450 batchs: 360.2644348144531
INFO:root:Train (Epoch 196): Loss/seq after 01500 batchs: 366.84869384765625
INFO:root:Train (Epoch 196): Loss/seq after 01550 batchs: 367.22119140625
INFO:root:Train (Epoch 196): Loss/seq after 01600 batchs: 364.9798278808594
INFO:root:Train (Epoch 196): Loss/seq after 01650 batchs: 364.0390625
INFO:root:Train (Epoch 196): Loss/seq after 01700 batchs: 369.3684997558594
INFO:root:Train (Epoch 196): Loss/seq after 01750 batchs: 368.2545166015625
INFO:root:Train (Epoch 196): Loss/seq after 01800 batchs: 367.2861022949219
INFO:root:Train (Epoch 196): Loss/seq after 01850 batchs: 365.9259948730469
INFO:root:Train (Epoch 196): Loss/seq after 01900 batchs: 365.36260986328125
INFO:root:Train (Epoch 196): Loss/seq after 01950 batchs: 365.4985656738281
INFO:root:Train (Epoch 196): Loss/seq after 02000 batchs: 367.1461181640625
INFO:root:Train (Epoch 196): Loss/seq after 02050 batchs: 367.5146789550781
INFO:root:Train (Epoch 196): Loss/seq after 02100 batchs: 367.0332946777344
INFO:root:Train (Epoch 196): Loss/seq after 02150 batchs: 366.9568786621094
INFO:root:Train (Epoch 196): Loss/seq after 02200 batchs: 366.5787658691406
INFO:root:Train (Epoch 196): Loss/seq after 02250 batchs: 365.4944152832031
INFO:root:Train (Epoch 196): Loss/seq after 02300 batchs: 362.0653381347656
INFO:root:Train (Epoch 196): Loss/seq after 02350 batchs: 360.32330322265625
INFO:root:Train (Epoch 196): Loss/seq after 02400 batchs: 361.25946044921875
INFO:root:Train (Epoch 196): Loss/seq after 02450 batchs: 358.8739013671875
INFO:root:Train (Epoch 196): Loss/seq after 02500 batchs: 353.1343994140625
INFO:root:Train (Epoch 196): Loss/seq after 02550 batchs: 347.7288513183594
INFO:root:Train (Epoch 196): Loss/seq after 02600 batchs: 343.7370300292969
INFO:root:Train (Epoch 196): Loss/seq after 02650 batchs: 340.0042419433594
INFO:root:Train (Epoch 196): Loss/seq after 02700 batchs: 337.318603515625
INFO:root:Train (Epoch 196): Loss/seq after 02750 batchs: 333.53363037109375
INFO:root:Train (Epoch 196): Loss/seq after 02800 batchs: 331.4529113769531
INFO:root:Train (Epoch 196): Loss/seq after 02850 batchs: 331.4560546875
INFO:root:Train (Epoch 196): Loss/seq after 02900 batchs: 331.97088623046875
INFO:root:Train (Epoch 196): Loss/seq after 02950 batchs: 332.932861328125
INFO:root:Train (Epoch 196): Loss/seq after 03000 batchs: 338.2865905761719
INFO:root:Train (Epoch 196): Loss/seq after 03050 batchs: 340.0691223144531
INFO:root:Train (Epoch 196): Loss/seq after 03100 batchs: 342.15966796875
INFO:root:Train (Epoch 196): Loss/seq after 03150 batchs: 341.7678527832031
INFO:root:Train (Epoch 196): Loss/seq after 03200 batchs: 341.1636657714844
INFO:root:Train (Epoch 196): Loss/seq after 03250 batchs: 340.0924987792969
INFO:root:Train (Epoch 196): Loss/seq after 03300 batchs: 339.6232604980469
INFO:root:Train (Epoch 196): Loss/seq after 03350 batchs: 337.57037353515625
INFO:root:Train (Epoch 196): Loss/seq after 03400 batchs: 335.209228515625
INFO:root:Train (Epoch 196): Loss/seq after 03450 batchs: 333.60845947265625
INFO:root:Train (Epoch 196): Loss/seq after 03500 batchs: 334.659423828125
INFO:root:Train (Epoch 196): Loss/seq after 03550 batchs: 333.5217590332031
INFO:root:Train (Epoch 196): Loss/seq after 03600 batchs: 338.14837646484375
INFO:root:Train (Epoch 196): Loss/seq after 03650 batchs: 337.2959899902344
INFO:root:Train (Epoch 196): Loss/seq after 03700 batchs: 340.87750244140625
INFO:root:Train (Epoch 196): Loss/seq after 03750 batchs: 345.46881103515625
INFO:root:Train (Epoch 196): Loss/seq after 03800 batchs: 345.4323425292969
INFO:root:Train (Epoch 196): Loss/seq after 03850 batchs: 345.09307861328125
INFO:root:Train (Epoch 196): Loss/seq after 03900 batchs: 346.5989074707031
INFO:root:Train (Epoch 196): Loss/seq after 03950 batchs: 347.61639404296875
INFO:root:Train (Epoch 196): Loss/seq after 04000 batchs: 345.85809326171875
INFO:root:Train (Epoch 196): Loss/seq after 04050 batchs: 343.85498046875
INFO:root:Train (Epoch 196): Loss/seq after 04100 batchs: 343.478515625
INFO:root:Train (Epoch 196): Loss/seq after 04150 batchs: 343.7247009277344
INFO:root:Train (Epoch 196): Loss/seq after 04200 batchs: 343.0281982421875
INFO:root:Train (Epoch 196): Loss/seq after 04250 batchs: 341.9981994628906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 196): Loss/seq after 00000 batches: 202.0328369140625
INFO:root:# Valid (Epoch 196): Loss/seq after 00050 batches: 606.1346435546875
INFO:root:# Valid (Epoch 196): Loss/seq after 00100 batches: 583.53466796875
INFO:root:# Valid (Epoch 196): Loss/seq after 00150 batches: 442.2205505371094
INFO:root:# Valid (Epoch 196): Loss/seq after 00200 batches: 414.9977111816406
INFO:root:Artifacts: Make stick videos for epoch 196
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_196_on_20220422_153345.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_196_index_1563_on_20220422_153345.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 197): Loss/seq after 00000 batchs: 744.0137329101562
INFO:root:Train (Epoch 197): Loss/seq after 00050 batchs: 473.86505126953125
INFO:root:Train (Epoch 197): Loss/seq after 00100 batchs: 463.25335693359375
INFO:root:Train (Epoch 197): Loss/seq after 00150 batchs: 444.0252990722656
INFO:root:Train (Epoch 197): Loss/seq after 00200 batchs: 474.6977844238281
INFO:root:Train (Epoch 197): Loss/seq after 00250 batchs: 515.950927734375
INFO:root:Train (Epoch 197): Loss/seq after 00300 batchs: 538.3292846679688
INFO:root:Train (Epoch 197): Loss/seq after 00350 batchs: 514.6702270507812
INFO:root:Train (Epoch 197): Loss/seq after 00400 batchs: 497.8468933105469
INFO:root:Train (Epoch 197): Loss/seq after 00450 batchs: 509.4836120605469
INFO:root:Train (Epoch 197): Loss/seq after 00500 batchs: 492.2157287597656
INFO:root:Train (Epoch 197): Loss/seq after 00550 batchs: 484.93743896484375
INFO:root:Train (Epoch 197): Loss/seq after 00600 batchs: 472.015625
INFO:root:Train (Epoch 197): Loss/seq after 00650 batchs: 452.0835266113281
INFO:root:Train (Epoch 197): Loss/seq after 00700 batchs: 431.14141845703125
INFO:root:Train (Epoch 197): Loss/seq after 00750 batchs: 420.3093566894531
INFO:root:Train (Epoch 197): Loss/seq after 00800 batchs: 426.8866271972656
INFO:root:Train (Epoch 197): Loss/seq after 00850 batchs: 413.0179443359375
INFO:root:Train (Epoch 197): Loss/seq after 00900 batchs: 402.7127685546875
INFO:root:Train (Epoch 197): Loss/seq after 00950 batchs: 398.59979248046875
INFO:root:Train (Epoch 197): Loss/seq after 01000 batchs: 390.45587158203125
INFO:root:Train (Epoch 197): Loss/seq after 01050 batchs: 383.3066101074219
INFO:root:Train (Epoch 197): Loss/seq after 01100 batchs: 374.71783447265625
INFO:root:Train (Epoch 197): Loss/seq after 01150 batchs: 364.0464782714844
INFO:root:Train (Epoch 197): Loss/seq after 01200 batchs: 368.05462646484375
INFO:root:Train (Epoch 197): Loss/seq after 01250 batchs: 368.0826721191406
INFO:root:Train (Epoch 197): Loss/seq after 01300 batchs: 358.83282470703125
INFO:root:Train (Epoch 197): Loss/seq after 01350 batchs: 350.7261047363281
INFO:root:Train (Epoch 197): Loss/seq after 01400 batchs: 351.3065490722656
INFO:root:Train (Epoch 197): Loss/seq after 01450 batchs: 355.4071960449219
INFO:root:Train (Epoch 197): Loss/seq after 01500 batchs: 362.1875
INFO:root:Train (Epoch 197): Loss/seq after 01550 batchs: 362.4632873535156
INFO:root:Train (Epoch 197): Loss/seq after 01600 batchs: 360.3706359863281
INFO:root:Train (Epoch 197): Loss/seq after 01650 batchs: 359.4786071777344
INFO:root:Train (Epoch 197): Loss/seq after 01700 batchs: 364.83697509765625
INFO:root:Train (Epoch 197): Loss/seq after 01750 batchs: 364.0302734375
INFO:root:Train (Epoch 197): Loss/seq after 01800 batchs: 363.1099853515625
INFO:root:Train (Epoch 197): Loss/seq after 01850 batchs: 361.85357666015625
INFO:root:Train (Epoch 197): Loss/seq after 01900 batchs: 361.3773498535156
INFO:root:Train (Epoch 197): Loss/seq after 01950 batchs: 361.30731201171875
INFO:root:Train (Epoch 197): Loss/seq after 02000 batchs: 362.9369201660156
INFO:root:Train (Epoch 197): Loss/seq after 02050 batchs: 363.537841796875
INFO:root:Train (Epoch 197): Loss/seq after 02100 batchs: 363.41680908203125
INFO:root:Train (Epoch 197): Loss/seq after 02150 batchs: 363.2965087890625
INFO:root:Train (Epoch 197): Loss/seq after 02200 batchs: 362.83026123046875
INFO:root:Train (Epoch 197): Loss/seq after 02250 batchs: 361.7201843261719
INFO:root:Train (Epoch 197): Loss/seq after 02300 batchs: 358.5108642578125
INFO:root:Train (Epoch 197): Loss/seq after 02350 batchs: 356.7037658691406
INFO:root:Train (Epoch 197): Loss/seq after 02400 batchs: 357.4630432128906
INFO:root:Train (Epoch 197): Loss/seq after 02450 batchs: 355.0162353515625
INFO:root:Train (Epoch 197): Loss/seq after 02500 batchs: 349.30877685546875
INFO:root:Train (Epoch 197): Loss/seq after 02550 batchs: 343.96319580078125
INFO:root:Train (Epoch 197): Loss/seq after 02600 batchs: 339.84796142578125
INFO:root:Train (Epoch 197): Loss/seq after 02650 batchs: 336.0456848144531
INFO:root:Train (Epoch 197): Loss/seq after 02700 batchs: 333.2558288574219
INFO:root:Train (Epoch 197): Loss/seq after 02750 batchs: 329.3597106933594
INFO:root:Train (Epoch 197): Loss/seq after 02800 batchs: 326.8863220214844
INFO:root:Train (Epoch 197): Loss/seq after 02850 batchs: 326.9413146972656
INFO:root:Train (Epoch 197): Loss/seq after 02900 batchs: 327.559814453125
INFO:root:Train (Epoch 197): Loss/seq after 02950 batchs: 328.5020751953125
INFO:root:Train (Epoch 197): Loss/seq after 03000 batchs: 333.7416687011719
INFO:root:Train (Epoch 197): Loss/seq after 03050 batchs: 335.8486328125
INFO:root:Train (Epoch 197): Loss/seq after 03100 batchs: 337.7620544433594
INFO:root:Train (Epoch 197): Loss/seq after 03150 batchs: 336.9498596191406
INFO:root:Train (Epoch 197): Loss/seq after 03200 batchs: 336.0240478515625
INFO:root:Train (Epoch 197): Loss/seq after 03250 batchs: 334.7293395996094
INFO:root:Train (Epoch 197): Loss/seq after 03300 batchs: 334.1673583984375
INFO:root:Train (Epoch 197): Loss/seq after 03350 batchs: 332.255859375
INFO:root:Train (Epoch 197): Loss/seq after 03400 batchs: 329.9881286621094
INFO:root:Train (Epoch 197): Loss/seq after 03450 batchs: 328.38189697265625
INFO:root:Train (Epoch 197): Loss/seq after 03500 batchs: 329.6458740234375
INFO:root:Train (Epoch 197): Loss/seq after 03550 batchs: 328.7664794921875
INFO:root:Train (Epoch 197): Loss/seq after 03600 batchs: 333.0259094238281
INFO:root:Train (Epoch 197): Loss/seq after 03650 batchs: 331.9315185546875
INFO:root:Train (Epoch 197): Loss/seq after 03700 batchs: 334.515625
INFO:root:Train (Epoch 197): Loss/seq after 03750 batchs: 339.23211669921875
INFO:root:Train (Epoch 197): Loss/seq after 03800 batchs: 339.0938415527344
INFO:root:Train (Epoch 197): Loss/seq after 03850 batchs: 338.8525085449219
INFO:root:Train (Epoch 197): Loss/seq after 03900 batchs: 339.5304260253906
INFO:root:Train (Epoch 197): Loss/seq after 03950 batchs: 340.72314453125
INFO:root:Train (Epoch 197): Loss/seq after 04000 batchs: 339.0021057128906
INFO:root:Train (Epoch 197): Loss/seq after 04050 batchs: 337.0260925292969
INFO:root:Train (Epoch 197): Loss/seq after 04100 batchs: 336.683837890625
INFO:root:Train (Epoch 197): Loss/seq after 04150 batchs: 336.9922790527344
INFO:root:Train (Epoch 197): Loss/seq after 04200 batchs: 336.25543212890625
INFO:root:Train (Epoch 197): Loss/seq after 04250 batchs: 335.3074645996094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 197): Loss/seq after 00000 batches: 236.72891235351562
INFO:root:# Valid (Epoch 197): Loss/seq after 00050 batches: 613.5299682617188
INFO:root:# Valid (Epoch 197): Loss/seq after 00100 batches: 610.4315185546875
INFO:root:# Valid (Epoch 197): Loss/seq after 00150 batches: 467.6575927734375
INFO:root:# Valid (Epoch 197): Loss/seq after 00200 batches: 438.4661865234375
INFO:root:Artifacts: Make stick videos for epoch 197
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_197_on_20220422_153846.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_197_index_1807_on_20220422_153846.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 198): Loss/seq after 00000 batchs: 476.6207580566406
INFO:root:Train (Epoch 198): Loss/seq after 00050 batchs: 444.5599060058594
INFO:root:Train (Epoch 198): Loss/seq after 00100 batchs: 429.0126037597656
INFO:root:Train (Epoch 198): Loss/seq after 00150 batchs: 417.3482666015625
INFO:root:Train (Epoch 198): Loss/seq after 00200 batchs: 453.3016357421875
INFO:root:Train (Epoch 198): Loss/seq after 00250 batchs: 485.15771484375
INFO:root:Train (Epoch 198): Loss/seq after 00300 batchs: 509.5314025878906
INFO:root:Train (Epoch 198): Loss/seq after 00350 batchs: 486.8546142578125
INFO:root:Train (Epoch 198): Loss/seq after 00400 batchs: 473.79119873046875
INFO:root:Train (Epoch 198): Loss/seq after 00450 batchs: 488.1400451660156
INFO:root:Train (Epoch 198): Loss/seq after 00500 batchs: 473.14544677734375
INFO:root:Train (Epoch 198): Loss/seq after 00550 batchs: 469.8165283203125
INFO:root:Train (Epoch 198): Loss/seq after 00600 batchs: 458.1383056640625
INFO:root:Train (Epoch 198): Loss/seq after 00650 batchs: 438.3171691894531
INFO:root:Train (Epoch 198): Loss/seq after 00700 batchs: 417.64208984375
INFO:root:Train (Epoch 198): Loss/seq after 00750 batchs: 407.5298156738281
INFO:root:Train (Epoch 198): Loss/seq after 00800 batchs: 415.8014221191406
INFO:root:Train (Epoch 198): Loss/seq after 00850 batchs: 402.8450927734375
INFO:root:Train (Epoch 198): Loss/seq after 00900 batchs: 394.4530029296875
INFO:root:Train (Epoch 198): Loss/seq after 00950 batchs: 391.6741943359375
INFO:root:Train (Epoch 198): Loss/seq after 01000 batchs: 383.7154846191406
INFO:root:Train (Epoch 198): Loss/seq after 01050 batchs: 379.312744140625
INFO:root:Train (Epoch 198): Loss/seq after 01100 batchs: 372.6846008300781
INFO:root:Train (Epoch 198): Loss/seq after 01150 batchs: 362.757568359375
INFO:root:Train (Epoch 198): Loss/seq after 01200 batchs: 367.1833190917969
INFO:root:Train (Epoch 198): Loss/seq after 01250 batchs: 367.45513916015625
INFO:root:Train (Epoch 198): Loss/seq after 01300 batchs: 358.3321533203125
INFO:root:Train (Epoch 198): Loss/seq after 01350 batchs: 350.2259826660156
INFO:root:Train (Epoch 198): Loss/seq after 01400 batchs: 350.99822998046875
INFO:root:Train (Epoch 198): Loss/seq after 01450 batchs: 355.4272155761719
INFO:root:Train (Epoch 198): Loss/seq after 01500 batchs: 362.2202453613281
INFO:root:Train (Epoch 198): Loss/seq after 01550 batchs: 363.0304870605469
INFO:root:Train (Epoch 198): Loss/seq after 01600 batchs: 361.00726318359375
INFO:root:Train (Epoch 198): Loss/seq after 01650 batchs: 360.1499328613281
INFO:root:Train (Epoch 198): Loss/seq after 01700 batchs: 365.8695373535156
INFO:root:Train (Epoch 198): Loss/seq after 01750 batchs: 365.0241394042969
INFO:root:Train (Epoch 198): Loss/seq after 01800 batchs: 364.0903625488281
INFO:root:Train (Epoch 198): Loss/seq after 01850 batchs: 362.92694091796875
INFO:root:Train (Epoch 198): Loss/seq after 01900 batchs: 362.1683044433594
INFO:root:Train (Epoch 198): Loss/seq after 01950 batchs: 362.26104736328125
INFO:root:Train (Epoch 198): Loss/seq after 02000 batchs: 363.8298645019531
INFO:root:Train (Epoch 198): Loss/seq after 02050 batchs: 364.10540771484375
INFO:root:Train (Epoch 198): Loss/seq after 02100 batchs: 364.0300598144531
INFO:root:Train (Epoch 198): Loss/seq after 02150 batchs: 364.0551452636719
INFO:root:Train (Epoch 198): Loss/seq after 02200 batchs: 363.6872863769531
INFO:root:Train (Epoch 198): Loss/seq after 02250 batchs: 362.53411865234375
INFO:root:Train (Epoch 198): Loss/seq after 02300 batchs: 359.3445129394531
INFO:root:Train (Epoch 198): Loss/seq after 02350 batchs: 357.63153076171875
INFO:root:Train (Epoch 198): Loss/seq after 02400 batchs: 358.57958984375
INFO:root:Train (Epoch 198): Loss/seq after 02450 batchs: 356.2657165527344
INFO:root:Train (Epoch 198): Loss/seq after 02500 batchs: 350.6465148925781
INFO:root:Train (Epoch 198): Loss/seq after 02550 batchs: 345.355712890625
INFO:root:Train (Epoch 198): Loss/seq after 02600 batchs: 341.12628173828125
INFO:root:Train (Epoch 198): Loss/seq after 02650 batchs: 337.3182373046875
INFO:root:Train (Epoch 198): Loss/seq after 02700 batchs: 334.54217529296875
INFO:root:Train (Epoch 198): Loss/seq after 02750 batchs: 330.4947204589844
INFO:root:Train (Epoch 198): Loss/seq after 02800 batchs: 328.32940673828125
INFO:root:Train (Epoch 198): Loss/seq after 02850 batchs: 328.0498046875
INFO:root:Train (Epoch 198): Loss/seq after 02900 batchs: 328.3915100097656
INFO:root:Train (Epoch 198): Loss/seq after 02950 batchs: 329.3302917480469
INFO:root:Train (Epoch 198): Loss/seq after 03000 batchs: 334.6131286621094
INFO:root:Train (Epoch 198): Loss/seq after 03050 batchs: 336.4564514160156
INFO:root:Train (Epoch 198): Loss/seq after 03100 batchs: 337.6325988769531
INFO:root:Train (Epoch 198): Loss/seq after 03150 batchs: 336.5762634277344
INFO:root:Train (Epoch 198): Loss/seq after 03200 batchs: 336.04217529296875
INFO:root:Train (Epoch 198): Loss/seq after 03250 batchs: 334.858642578125
INFO:root:Train (Epoch 198): Loss/seq after 03300 batchs: 334.1029357910156
INFO:root:Train (Epoch 198): Loss/seq after 03350 batchs: 332.6540222167969
INFO:root:Train (Epoch 198): Loss/seq after 03400 batchs: 330.3228759765625
INFO:root:Train (Epoch 198): Loss/seq after 03450 batchs: 328.7045593261719
INFO:root:Train (Epoch 198): Loss/seq after 03500 batchs: 330.4261779785156
INFO:root:Train (Epoch 198): Loss/seq after 03550 batchs: 329.7118225097656
INFO:root:Train (Epoch 198): Loss/seq after 03600 batchs: 334.4526672363281
INFO:root:Train (Epoch 198): Loss/seq after 03650 batchs: 333.9185791015625
INFO:root:Train (Epoch 198): Loss/seq after 03700 batchs: 336.385986328125
INFO:root:Train (Epoch 198): Loss/seq after 03750 batchs: 340.8604431152344
INFO:root:Train (Epoch 198): Loss/seq after 03800 batchs: 340.84088134765625
INFO:root:Train (Epoch 198): Loss/seq after 03850 batchs: 340.5464782714844
INFO:root:Train (Epoch 198): Loss/seq after 03900 batchs: 342.0398864746094
INFO:root:Train (Epoch 198): Loss/seq after 03950 batchs: 343.9208068847656
INFO:root:Train (Epoch 198): Loss/seq after 04000 batchs: 342.14794921875
INFO:root:Train (Epoch 198): Loss/seq after 04050 batchs: 340.2276306152344
INFO:root:Train (Epoch 198): Loss/seq after 04100 batchs: 339.8401794433594
INFO:root:Train (Epoch 198): Loss/seq after 04150 batchs: 340.140380859375
INFO:root:Train (Epoch 198): Loss/seq after 04200 batchs: 339.6133117675781
INFO:root:Train (Epoch 198): Loss/seq after 04250 batchs: 338.54278564453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 198): Loss/seq after 00000 batches: 214.82289123535156
INFO:root:# Valid (Epoch 198): Loss/seq after 00050 batches: 628.7437744140625
INFO:root:# Valid (Epoch 198): Loss/seq after 00100 batches: 612.3079833984375
INFO:root:# Valid (Epoch 198): Loss/seq after 00150 batches: 467.4554443359375
INFO:root:# Valid (Epoch 198): Loss/seq after 00200 batches: 436.6408996582031
INFO:root:Artifacts: Make stick videos for epoch 198
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_198_on_20220422_154330.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_198_index_1431_on_20220422_154330.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 199): Loss/seq after 00000 batchs: 498.2648010253906
INFO:root:Train (Epoch 199): Loss/seq after 00050 batchs: 468.2619323730469
INFO:root:Train (Epoch 199): Loss/seq after 00100 batchs: 464.650634765625
INFO:root:Train (Epoch 199): Loss/seq after 00150 batchs: 452.24249267578125
INFO:root:Train (Epoch 199): Loss/seq after 00200 batchs: 486.3389892578125
INFO:root:Train (Epoch 199): Loss/seq after 00250 batchs: 510.14556884765625
INFO:root:Train (Epoch 199): Loss/seq after 00300 batchs: 530.7611694335938
INFO:root:Train (Epoch 199): Loss/seq after 00350 batchs: 509.1919860839844
INFO:root:Train (Epoch 199): Loss/seq after 00400 batchs: 497.87554931640625
INFO:root:Train (Epoch 199): Loss/seq after 00450 batchs: 510.6191711425781
INFO:root:Train (Epoch 199): Loss/seq after 00500 batchs: 494.64959716796875
INFO:root:Train (Epoch 199): Loss/seq after 00550 batchs: 487.43109130859375
INFO:root:Train (Epoch 199): Loss/seq after 00600 batchs: 474.4678649902344
INFO:root:Train (Epoch 199): Loss/seq after 00650 batchs: 453.9014587402344
INFO:root:Train (Epoch 199): Loss/seq after 00700 batchs: 432.5495910644531
INFO:root:Train (Epoch 199): Loss/seq after 00750 batchs: 422.4486389160156
INFO:root:Train (Epoch 199): Loss/seq after 00800 batchs: 429.42803955078125
INFO:root:Train (Epoch 199): Loss/seq after 00850 batchs: 415.4982604980469
INFO:root:Train (Epoch 199): Loss/seq after 00900 batchs: 405.4283447265625
INFO:root:Train (Epoch 199): Loss/seq after 00950 batchs: 402.5904235839844
INFO:root:Train (Epoch 199): Loss/seq after 01000 batchs: 394.3423156738281
INFO:root:Train (Epoch 199): Loss/seq after 01050 batchs: 390.4228515625
INFO:root:Train (Epoch 199): Loss/seq after 01100 batchs: 382.0821838378906
INFO:root:Train (Epoch 199): Loss/seq after 01150 batchs: 371.60400390625
INFO:root:Train (Epoch 199): Loss/seq after 01200 batchs: 374.14288330078125
INFO:root:Train (Epoch 199): Loss/seq after 01250 batchs: 373.4554748535156
INFO:root:Train (Epoch 199): Loss/seq after 01300 batchs: 364.312744140625
INFO:root:Train (Epoch 199): Loss/seq after 01350 batchs: 356.6037292480469
INFO:root:Train (Epoch 199): Loss/seq after 01400 batchs: 356.6060485839844
INFO:root:Train (Epoch 199): Loss/seq after 01450 batchs: 360.61029052734375
INFO:root:Train (Epoch 199): Loss/seq after 01500 batchs: 367.3849182128906
INFO:root:Train (Epoch 199): Loss/seq after 01550 batchs: 367.965576171875
INFO:root:Train (Epoch 199): Loss/seq after 01600 batchs: 365.6304931640625
INFO:root:Train (Epoch 199): Loss/seq after 01650 batchs: 364.917236328125
INFO:root:Train (Epoch 199): Loss/seq after 01700 batchs: 370.3683776855469
INFO:root:Train (Epoch 199): Loss/seq after 01750 batchs: 369.7108459472656
INFO:root:Train (Epoch 199): Loss/seq after 01800 batchs: 368.72125244140625
INFO:root:Train (Epoch 199): Loss/seq after 01850 batchs: 367.4369812011719
INFO:root:Train (Epoch 199): Loss/seq after 01900 batchs: 366.8719177246094
INFO:root:Train (Epoch 199): Loss/seq after 01950 batchs: 366.8651428222656
INFO:root:Train (Epoch 199): Loss/seq after 02000 batchs: 368.4283752441406
INFO:root:Train (Epoch 199): Loss/seq after 02050 batchs: 368.7381286621094
INFO:root:Train (Epoch 199): Loss/seq after 02100 batchs: 368.14862060546875
INFO:root:Train (Epoch 199): Loss/seq after 02150 batchs: 367.9129638671875
INFO:root:Train (Epoch 199): Loss/seq after 02200 batchs: 367.4841003417969
INFO:root:Train (Epoch 199): Loss/seq after 02250 batchs: 366.3468933105469
INFO:root:Train (Epoch 199): Loss/seq after 02300 batchs: 363.19873046875
INFO:root:Train (Epoch 199): Loss/seq after 02350 batchs: 361.2710266113281
INFO:root:Train (Epoch 199): Loss/seq after 02400 batchs: 362.2230224609375
INFO:root:Train (Epoch 199): Loss/seq after 02450 batchs: 359.77398681640625
INFO:root:Train (Epoch 199): Loss/seq after 02500 batchs: 354.0057678222656
INFO:root:Train (Epoch 199): Loss/seq after 02550 batchs: 348.6324157714844
INFO:root:Train (Epoch 199): Loss/seq after 02600 batchs: 344.8708801269531
INFO:root:Train (Epoch 199): Loss/seq after 02650 batchs: 341.32666015625
INFO:root:Train (Epoch 199): Loss/seq after 02700 batchs: 338.55914306640625
INFO:root:Train (Epoch 199): Loss/seq after 02750 batchs: 334.5541076660156
INFO:root:Train (Epoch 199): Loss/seq after 02800 batchs: 331.7879943847656
INFO:root:Train (Epoch 199): Loss/seq after 02850 batchs: 331.7994384765625
INFO:root:Train (Epoch 199): Loss/seq after 02900 batchs: 332.1866149902344
INFO:root:Train (Epoch 199): Loss/seq after 02950 batchs: 333.0924072265625
INFO:root:Train (Epoch 199): Loss/seq after 03000 batchs: 338.21478271484375
INFO:root:Train (Epoch 199): Loss/seq after 03050 batchs: 340.0124206542969
INFO:root:Train (Epoch 199): Loss/seq after 03100 batchs: 341.4283752441406
INFO:root:Train (Epoch 199): Loss/seq after 03150 batchs: 340.4470520019531
INFO:root:Train (Epoch 199): Loss/seq after 03200 batchs: 339.5797119140625
INFO:root:Train (Epoch 199): Loss/seq after 03250 batchs: 338.9919128417969
INFO:root:Train (Epoch 199): Loss/seq after 03300 batchs: 338.6500244140625
INFO:root:Train (Epoch 199): Loss/seq after 03350 batchs: 336.5662536621094
INFO:root:Train (Epoch 199): Loss/seq after 03400 batchs: 334.21661376953125
INFO:root:Train (Epoch 199): Loss/seq after 03450 batchs: 332.48211669921875
INFO:root:Train (Epoch 199): Loss/seq after 03500 batchs: 333.4745178222656
INFO:root:Train (Epoch 199): Loss/seq after 03550 batchs: 332.310546875
INFO:root:Train (Epoch 199): Loss/seq after 03600 batchs: 336.7846374511719
INFO:root:Train (Epoch 199): Loss/seq after 03650 batchs: 335.9296569824219
INFO:root:Train (Epoch 199): Loss/seq after 03700 batchs: 338.4014892578125
INFO:root:Train (Epoch 199): Loss/seq after 03750 batchs: 342.6939392089844
INFO:root:Train (Epoch 199): Loss/seq after 03800 batchs: 342.6198425292969
INFO:root:Train (Epoch 199): Loss/seq after 03850 batchs: 342.33984375
INFO:root:Train (Epoch 199): Loss/seq after 03900 batchs: 343.5194396972656
INFO:root:Train (Epoch 199): Loss/seq after 03950 batchs: 346.1492919921875
INFO:root:Train (Epoch 199): Loss/seq after 04000 batchs: 344.39630126953125
INFO:root:Train (Epoch 199): Loss/seq after 04050 batchs: 342.3542175292969
INFO:root:Train (Epoch 199): Loss/seq after 04100 batchs: 341.9694519042969
INFO:root:Train (Epoch 199): Loss/seq after 04150 batchs: 342.3370361328125
INFO:root:Train (Epoch 199): Loss/seq after 04200 batchs: 341.8012390136719
INFO:root:Train (Epoch 199): Loss/seq after 04250 batchs: 340.783935546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 199): Loss/seq after 00000 batches: 230.5067596435547
INFO:root:# Valid (Epoch 199): Loss/seq after 00050 batches: 623.4251708984375
INFO:root:# Valid (Epoch 199): Loss/seq after 00100 batches: 593.4992065429688
INFO:root:# Valid (Epoch 199): Loss/seq after 00150 batches: 450.36175537109375
INFO:root:# Valid (Epoch 199): Loss/seq after 00200 batches: 421.23980712890625
INFO:root:Artifacts: Make stick videos for epoch 199
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_199_on_20220422_154826.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_199_index_1761_on_20220422_154826.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Done training.
wandb: Waiting for W&B process to finish... (success).
wandb: - 409.155 MB of 409.155 MB uploaded (0.000 MB deduped)wandb: \ 409.155 MB of 409.155 MB uploaded (0.000 MB deduped)wandb: | 409.155 MB of 409.155 MB uploaded (0.000 MB deduped)wandb: / 409.155 MB of 410.672 MB uploaded (0.000 MB deduped)wandb: - 409.155 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: \ 410.672 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: | 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: / 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: - 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: \ 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: | 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: / 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb: - 410.676 MB of 410.676 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:       loss â–ˆâ–ˆâ–‡â–‡â–‡â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_loss â–ˆâ–†â–…â–†â–†â–‡â–„â–„â–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:      epoch 199
wandb:       loss 340.78394
wandb: valid_loss 421.23981
wandb: 
wandb: Synced misunderstood-serenity-13: https://wandb.ai/bioshape-lab/move/runs/1w23tczv
wandb: Synced 6 W&B file(s), 0 media file(s), 400 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220421_233233-1w23tczv/logs

